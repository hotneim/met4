--- 
title: "MET4 - Empiriske Metoder - V친r 2021"
author: "H친kon Otneim og Geir Drage Berentsen"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    split_by: "section"
    config:
      toc:
        collapse: "section"
        toc_depth: 4
description: "Dette er hjemmesiden til kurset MET4 - Empiriske Metoder, som gis p친 bachelorstudiet ved Norges Handelsh칮yskole."
---

# Innledning {-}


<figure style="float:right; padding:10px; text-align:center">
  <img alt="H친kon" src="bilder/hakon.jpg" width="130" height="130"/>
  <figcaption>H친kon</figcaption>
</figure>

Velkommen til hjemmesiden for kurset [MET4 - Empiriske metoder](https://www.nhh.no/emner/empiriske-metoder/), som er et obligatorisk kurs p친 Bachelorprogrammet i 칒konomi og Administrasjon ved Norges Handelsh칮yskole. Dette er et kurs i anvendt statistikk, spesielt tilpasset 칮konomistudiet, og vi skal fokusere p친 korrekt bruk av statistisk metodikk for 친 l칮se relevante problemstillinger i en verden der innsamlet data utgj칮r en stadig st칮rre del av beslutningsgrunlaget i bedrifts- og samfunnsstyring.

Kursansvarlige er H친kon Otneim og Geir Drage Berentsen, som begge jobber ved Institutt for Foretaks칮konomi ved NHH.

<figure style="float:right; padding:10px; text-align:center">
  <img alt="H친kon" src="bilder/geir.jpg" width="130" height="130"/>
  <figcaption>Geir</figcaption>
</figure>

P친 grunn av coronasituasjonen er store deler av kurset digitalisert. Det vil si at teorigjennomgang plenumsforelesniger i sin helhet er erstattet med videoforelesninger. P친 denne siden vil du finne alle videosnuttene sammen med kommentarer til l칝rebokens fremstilling, samt supplementer og referanser til andre b칮ker der l칝reverket v친rt ikke strekker til (s칝rlig mot slutten av kurset).

Praktisk bruk av statistiske metoder st친r sentralt i MET4, og denne delen dekker vi gjenom kontakttimer, oppgaveseminarer med kursansvarlige, og data칮vinger med studentassistenter. Denne delen vil v칝re digital dersom smittesituasjonen krever det, og fysisk p친 campus dersom smittesituasjonen tillater det. **Det vil v칝re et fullgodt digitalt alternativ til MET4 gjennom hele semsteret**.

### Fremdriftsplan {-}

I et tradisjonelt kursopplegg ville forventet progresjon blitt definert av forelesningstempoet, og forelesningene ville v칝rt den strukturen som mange trenger for 친 jobbe seg jevnt og trutt gjennom pensum.

I et digitalisert opplegg blir ikke pensumgjennomgang lenger gjort i fellesskap, men heller individuelt, der studenten selv kan bestemme tempo og progresjon tilpasset sin egen timeplan og studieteknikk. Prisen for 칮kt fleksibilitet er derimot mindre struktur, og det kan oppleves som en ekstra belastning. Selv om det alltid har v칝rt studentens eget ansvar 친 f칮lge progresjonen i et kurs blir dette ansvaret enda mer tydelig i et heldigitalt kurs. Vi vil derfor minne om det 친penbare: **MET4 er et krevende kurs som krever full innsats fra f칮rste til siste dag.** 

Vi har laget et forslag til progresjon i tabellen under. Kolonnen "jobbe med" refererer til avsnitt p친 denne siden som dere finner igjen i menyen til h칮yre. Der finnes ogs친 alle data칮vingene. Ukene med gr칮nn farge betyr at vi har tid p친 datasal med studentassistenter (s친 sant vi kan m칮tes fysisk, ellers vil disse selvsagt gjennomf칮res digitalt). 

Vi finner ogs친 hva vi skal gj칮re i v친r oppsatte forelesningstider. Som en hovedregel vil vi bruke tirsdagen som en ren kontakttime der kursansvalig(e) er tilgjengelige for sp칮rsm친l og diskusjon, mens torsdagstimen blir mer strukturert, med oppgaveregning i plenum (detaljer blir publisert p친 Canvas etter hvert). Begge disse aktivitetene er digitale i starten av semesteret, og s친 f친r vi se om det blir muligheter for 친 m칮tes fysisk etter hvert.

Legg merke til f칮lgende viktige datoer:

- **1. mars:** Siste frist for oppmelding av grupper til obligatorisk 칮velse og hjemmeeksamen.
- **26. mars:** Frist for innlevering av den obligatoriske innleveringen.
- **23.--24. mars:** Undervisningsfri pga. NHH symposium.
- **26.--28. april:** Gruppebasert hjemmeeksamen.
- **12. mai:** Individuell hjemmeeksamen.

<table class="table table-condensed table-hover" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;"> Uke </th>
   <th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;"> Jobbe med </th>
   <th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;"> Tirsdag 08:15 - 10:00 </th>
   <th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;"> Torsdag 10:15 - 12:00 </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:left;"> Introduksjon til R </td>
   <td style="text-align:left;"> 19.01: Kontakttime, kursansvarlig tilgjengelig p친 [Zoom](https://nhh.zoom.us/j/63633653066?pwd=cTVNV0JvOXl4NnUrMHVKdkw2b0pCZz09). </td>
   <td style="text-align:left;"> 21.01: Introduksjon til R p친 [Zoom](https://nhh.zoom.us/j/63633653066?pwd=cTVNV0JvOXl4NnUrMHVKdkw2b0pCZz09). </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:left;"> Grunnleggende statistikk </td>
   <td style="text-align:left;"> 26.01: Kontakttime, kursansvarlig tilgjengelig p친 [Zoom](https://nhh.zoom.us/j/63633653066?pwd=cTVNV0JvOXl4NnUrMHVKdkw2b0pCZz09). </td>
   <td style="text-align:left;"> 28.01: Oppgaveseminar p친 [Zoom](https://nhh.zoom.us/j/63633653066?pwd=cTVNV0JvOXl4NnUrMHVKdkw2b0pCZz09). </td>
  </tr>
  <tr>
   <td style="text-align:right;background-color: rgba(46, 139, 87, 0.31) !important;"> 5 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;"> Data칮ving 1 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:left;"> Hypotesetesting </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;background-color: rgba(46, 139, 87, 0.31) !important;"> 7 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;"> Hypotesetesting og Data칮ving 2 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 8 </td>
   <td style="text-align:left;"> Regresjon </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 9 </td>
   <td style="text-align:left;"> Regresjon </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;background-color: rgba(46, 139, 87, 0.31) !important;"> 10 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;"> Data칮ving 3/Obligatorisk innlevering </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 11 </td>
   <td style="text-align:left;"> Avansert regresjon og maskinl칝ring </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;background-color: rgba(46, 139, 87, 0.31) !important;"> 12 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;"> Data칮ving 4 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;font-weight: bold;color: white !important;background-color: DarkRed !important;"> 13 </td>
   <td style="text-align:left;font-weight: bold;color: white !important;background-color: DarkRed !important;"> P칀SKE </td>
   <td style="text-align:left;font-weight: bold;color: white !important;background-color: DarkRed !important;">  </td>
   <td style="text-align:left;font-weight: bold;color: white !important;background-color: DarkRed !important;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 14 </td>
   <td style="text-align:left;"> Tidsrekker </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:right;background-color: rgba(46, 139, 87, 0.31) !important;"> 15 </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;"> Tidsrekker (Tid p친 datasal) </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
   <td style="text-align:left;background-color: rgba(46, 139, 87, 0.31) !important;">  </td>
  </tr>
</tbody>
</table>

*Passord til Zoom-m칮tene finnes p친 kursets Canvas-side.*

### L칝rebok og pensum {-}

<figure style="float:right; padding:10px; text-align:center">
  <img alt="H친kon" src="bilder/bok.jpeg" width="130" height="170"/>
  <figcaption>11. utgave</figcaption>
</figure>

Vi bruker l칝reboken *Statistics for Management and Economics* av Gerald Keller, som n친 foreligger i 11. utgave. I utgangspunktet er f칮lgende kapitler pensum: 1--5, 9--13, 15--18 og 20. Mot slutten av kurset g친r vi gjennom noen tema som ikke er dekket i l칝reboken (logistisk regresjon, maskinl칝ring, paneldatamodeller, tidrekkemodeller). Der finner du referanser til andre kilder, samt en del materiale som vi har skrevet selv. I pensumgjennomgangen p친 denne siden finner du ogs친 en del kommentarer til l칝reboken, som for eksempel hva som er viktig, og hva som er mindre viktig for oss. 

Eldre utgaver av l칝reboken g친r bra. Under anbefalte regneoppgaver refererer vi til nummer i 11. og 10. utgave. Oppgavenummer tilbake til 7. utgave finner du i [dette dokumentet](oppgaver/Recommended excercises.doc).

**Merk: Fra og med neste semester kommer det en ny utgave av l칝reboken.**

<!--chapter:end:index.Rmd-->


# Introduksjon til R

Vi skal i dette kurset bruke programmeringsspr친ket **R** til 친 gj칮re beregninger og gjennomf칮re de ulike statistiske analysene som vi skal l칝re etter hvert. Dette vil v칝re nytt for mange. Vi skal f칮rst og fremst skal skrive *kode* og *kommandolinjer* for 친 f친 ut resultater i R, noe som kan oppleves uvant siden vi ellers er vant med 친 klikke oss frem i et menysystem n친r vi jobber med ulike programmer. Tr칮sten kan v칝re at ferdigheter i programmering blir stadig viktigere i mange yrker, spesielt innen 칮konomifaget. 

Vi m친 installere to ting p친 maskinen v친r f칮r vi g친r videre; selve programeringsspr친ket R, samt programmet RStudio som vi skal bruke til 친 skrive og kj칮re koden. Begge deler er gratis, og begge deler fungerer fint p친 b친de Windows og Mac (og Linux!). Det er greiest 친 gj칮re dette i riktig rekkef칮lge:

1. G친 til [r-project.org](https://cran.uib.no/) for 친 laste ned R til ditt operativsystem, og installer p친 vanlig m친te uten 친 forandre p친 foresl친tte innstillinger.

2. G친 til [rstudio.com](https://rstudio.com/), og naviger deg frem til siden for **RStudio**. Du skal der laste ned desktop-versjonen av programmet ("Open source edition") for ditt operativsystem og  installere p친 vanlig m친te. Det er heller ikke her n칮dvendig 친 forandre p친 de foresl친tte innstillingene.

Du kan s친 친pne RStudio, og f칮lge sekvensen av videoforelesniger som f칮lger under. Merk at disse videoene er l친nt fra seminaret [BAN420 - Introduction to R](https://www.nhh.no/en/courses/introduction-to-r/) som gis p친 masterprogrammet ved NHH. De er derfor spilt inn p친 engelsk. Det resterende videomaterialet i kurset gis p친 norsk.

## En gjennomgang av RStudio

<iframe src="https://player.vimeo.com/video/472587681" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

I denne videoen 친pner vi opp Rstudio og rusler gjennom det grafiske grensesnittet.

## Enkle beregninger og variabler

<iframe src="https://player.vimeo.com/video/472587696" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi g친r videre og skriver v친re f칮rste kommandoer i R. Det er kritisk at vi allerede n친 setter i gang med 친 f친 programmeringen inn i fingrene, og det gj칮res best ved 친 skrive inn kodelinjene slik det gj칮res i videoen, og passe p친 at du f친r ut de samme resultatene. N친r du er ferdig med det kan du pr칮ve deg p친 f칮lgende lille oppgave:

**Oppgave:** Velg dine tre favorittall og lagre dem i tre forskjellige variabler. Beregn s친 ditt magiske tall, som er summen av favorittallene dine. Lagre ditt magiske tall i en ny variabel, og gi denne variabelen et informativt navn som identifiserer hva det er.

Fikk du det til? Kikk p친 l칮sningen under for 친 sjekke.

<details><summary>L칮sning</summary>


```r
tall1 <- 1
tall2 <- 87
tall3 <- 101

magisk_tall <- tall1 + tall2 + tall3
```

</details>

## Vektorer

<iframe src="https://player.vimeo.com/video/472587712" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi introduserer begrepet *vektorer* som er sv칝rt viktig i statistikk generel og R spesielt. En vektor er ganske enkelt en samling med tall, og n친r vi senere begynner 친 jobbe med data kommer vi til 친 lagre observasjoner av ulikt slag i vektorer. Vi ser ogs친 at vi kan gj칮re operasjoner p친 vektorer ved 친 bruke *funksjoner*. For eksempel bruker vi `sum()`-funksjonen til 친 regne ut summen av alle tallene som er lagret i en vektor.

**Oppgave:** Beregn maksimum- og minimumsverdien av `vector1`, samt medianen, ved 친 bruke funksjoner i R. (**Hint:** en d친rlig skjult hemmelighet i anvendt programmering er at dersom vi ikke vet navnet p친 funksjonen vi skal bruke, s친 er Google v친r' beste venn!)

<details><summary>L칮sning</summary>

```r
# Relevante Google-s칮k: "minimum value r", "maximum r", "median r"

min(vector1)
max(vector1)
median(vector1)
```
</details>

## Pakker

<iframe src="https://player.vimeo.com/video/472587752" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi l칝rer at n친r vi laster ned R s친 f칮lger det med et grunnleggende sett av funksjoner ("base R"), men at det finnes et stort antall tilleggspakker. Vi kan enkelt laste ned og installere disse pakkene ved 친 skrive kommandoen `install.packages("pakkenavn")`. Det trenger vi bare gj칮re en gang p친 datamaskinen v친r. For 친 bruke pakken m친 vi skrive kommandoen `library(pakkenavn)`, og det m친 vi gj칮re hver gang i restarter R.

**Oppgave:** Installer f칮lgende pakker, som vi kommer til 친 bruke senere i kurset:

- `ggplot2`
- `dplyr`
- `stargazer`

<details><summary>L칮sning</summary>

```r
install.packages("ggplot2")
install.packages("dplyr")
install.packages("stargazer")
```
</details>

## Mappesti

<iframe src="https://player.vimeo.com/video/472587759" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi kommer til 친 forholde oss til *filer* p친 flere m친ter. Vi skal lese inn datafiler, og vi kommer til 친 produsere ulike former for output, slik som figurer og tabeller. Vi m친 da ha kontroll p친 hva R bruker som gjeldende mappesti ("working directory") der filer som skal leses inn ligger, og der ulike output-filer havner. Vi kan bruke funksjonen `getwd()` til 친 sjekke hva som er gjeldende mappesti. For 친 forandre mappestien kan vi bruke menysystemet (Session -> Set Working Directory -> Choose Directory), eventuelt funksjonen `setwd()` med 칮nsket mappesti som argument.

**Oppgave:** Pass p친 at du har gjort f칮lgende f칮r du g친r videre til neste leksjon:

- Du har laget en dedikert mappe p친 datamaskinen din der du skal samle alt materiale som vi bruker i dette kapitlet.
- Du har lastet ned filen [testdata.xls](datasett/testdata.xls) og lagt den i den nye mappen din.
- Du har endret gjeldende mappesti til denne mappen.
- Du har **bekreftet** at gjeldende mappesti n친 er korrekt.

## Innlesing av data

<iframe src="https://player.vimeo.com/video/472587809" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi leser inn tabellen i excelfilen som en tabell ("data frame") i R ved hjelp av funksjonen `read_xls()` i `readxl`-pakken og ser p친 noen enkle kommandoer for 친 jobbe med en slik tabell. 

**Oppgave:** 

1. Hvor mange kolonner har datasettet v친rt?
2. Kan du finne en m친te 친 skrive ut en vektor som inneholder summen av `X1`- og `X2`-kolonnene i datasettet? (Alts친, vi vil vite summen av de to f칮rste elementene i `X1` og `X2`, summen av de to andre elementene, osv.) 
3. Hva er summen av *alle* tallene i `X1`- og `X2`-kolonnene i`testdata`?

<details><summary>L칮sning</summary>

```r
# 1
ncol(testdata)

# 2 
testdata$X1 + testdata$X2

# 3
sum(testdata$X1 + testdata$X2)
```
</details>

## Statistiske analyser

<iframe src="https://player.vimeo.com/video/472587826" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Den f칮rste kommentaren i denne videoen er selvsagt ikke sann for MET4. For oss er det motsatt: Det er ikke R som er poenget med kurset, men de statistiske metodene som vi skal l칝re. R er bare verkt칮yet vi skal bruke. 

Vi ser p친 et eksempel der vi kj칮rer en enkel statistisk analyse (en $t$-test) p친 datasettet v친rt, og hvordan vi kan gj칮re ulike valg ved 친 endre argumenter i funksjonskallet. Vi bruker ogs친 hjelpefilene til 친 lese mer om funksjonen vi bruker.

**Oppgave:** Hva er verdien av *testobservatoren* i testen som vi gjorde i denne videoen? Hint: Bruk hjelpefilene til `t.test()`-funksjonen.

<details><summary>L칮sning</summary>

```r
test_result$statistic
```
</details>

## Plotting

<iframe src="https://player.vimeo.com/video/472587867" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

Vi lager v친r f칮rste figur i R ved 친 bruke den innebygde `plot()`-funksjonen. Vi g친r s친 over til 친 se hvordan vi kan lage det samme plottet ved 친 bruke `ggplot`-pakken, som er det vi kommer til 친 bruke til 친 lage figurer i dette kurset. Vi ser ogs친 hvordan vi kan g친 frem for 친 *lagre* plottet som en pdf-fil i arbeidsmappen v친r.

**Oppgave:** Klarer du, for eksempel ved 친 s칮ke etter relevante ggplot-kommandoer p친 nettet, 친 f친 prikkene i plottet til 친 bli st칮rre, og samtidig gj칮re dem bl친?

<details><summary>L칮sning</summary>

```r
ggplot(testdata, aes(x = X1, y = X2)) + geom_point(colour = "blue", size = 5)
```
</details>

## Script

<iframe src="https://player.vimeo.com/video/472587939" width="640" height="347" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

I stedet for 친 skrive kommandoene rett inn i konsollen, hopper vi n친 over til teksteditoren i RStudio og lager et *script* i stedet. Her kan vi samle alle kommandoene v친re i en fil, som vi kan lagre og kj칮re igjen senere. Vi ser ogs친 hvordan vi enkelt kan kj칮re enkeltlinjer i scriptet v친rt i R-konsollen ved hjelp av Ctrl-Enter (Command-Enter p친 Mac). Vi ser at vi kan skrive kommentarer i scriptene v친re ved 친 bruke `#-tegnet, som kan v칝re nyttig for 친 holde oversikten. Til slutt lagrer vi scripet i arbeidsmappen.

**Oppgave:** Pass p친 at du n친 har lagret scriptet som en .R-fil i mappen som vi laget for denne R-leksjonen. Lukk RStudio. Naviger s친 til denne mappen i filutforskeren og dobbelklikk p친 skriptet. Forh친pentligvis 친pnes RStudio n친 (Hvis ikke, eller hvis filen 친pnes i det som heter R GUI, h칮yreklikker du p친 filen og velger "칀pne i", og deretter RStudio. Du kan ogs친 gjerne sette RStudio som standarsprogram for .R-filer).

Finn ut hva gjeldende arbeidsmappe n친 er i RStudio. Hva skjedde n친? Hvorfor er dette nyttig?

<details><summary>L칮sning</summary>

N친r vi 친pner RStudio ved 친 dobbeltklikke p친 skriptfilen, s친 blir arbeidsstien satt automastisk til mappen der skriptfilen ligger. Dette er veldig nyttig n친r vil kommer tilbake og skal jobbe videre med prosjektet v친rt.

</details>

## Oppsummering og ekstra oppgaver {#r-ekstra}

I denne modulen har vi g친tt gjennom noen helt grunnleggende funksjoner i R. Du har l칝rt at

- R er navner p친 et programmeringsspr친k, 
- RStudio er navnet p친 et program der vi kan skrive og kj칮re R-kode, og
- identifisert fire forskjellige vindu i RStudio: konsollen (der R-koden kj칮res), teksteditoren (der vi skriver script), samt to vinduer der vi kan se en oversikt over hva som er i dataminnet og f친 opp plott og figurer som vi lager.

Videre har du 

- kj칮rt noen enkle kommandoer,
- lagret tall og vektorer ved hjelp av variabelnavn,
- pr칮vd ut noen innebygde R-funksjoner for 친 regne ut f.eks. gjennomsnitt og standardavvik av tallvektorer,
- laget et spredningsplott,
- l칝rt hva et *working directory* (arbeidsmappe) er, og 
- installert R-pakker, f.eks `readxl` som vi brukte den til 친 lese inn et lite datasett i R. 

Til slutt har du

- kj칮rt en $t$-test, og
- skrevet et *script* (et lite program om du vil) der vi har lagret flere av kommandoene over i en tekstfil.

Dersom du har fulgt modulen selv har du n친 kanskje skrevet et lite script i tekstvinduet som ser ut omtrent som koden under. N친r du har gjort alt riktig, skal du n친 kunne kj칮re gjennom disse kodelinjene uten feilmeldinger ved hjelp av `Ctrl-Enter`.

**Dette er helt grunnleggende (Sp칮r om hjelp! Gi hjelp!). Har du problemer her, s칮rg for 친 f친 dem ordnet. Sp칮r f칮rst en medstudent om hjelp, og deretter eventuelt studentassistent eller foreleser. Studenter som har god erfaring med data og/eller programmering, kan l칝re mye av 친 hjelpe medstudenter l칮se feilmeldinger.**


```r
# Introduksjon til R
# -------------------

# Laster inn n칮dvendige pakker
library(readxl)
library(ggplot2)

# Laster inn datasettet
testdata <- read_xls("testdata.xls")

# Gj칮r t-testen til sp칮rsm친l F i den f칮rste data칮vingen
testresultat <- t.test(testdata$X1, 
                       testdata$X2, 
                       var.equal = TRUE, 
                       alternative = "two.sided")

# Skriver ut resultatet av denne t-testen
testresultat

# Lager et plott av variabelen X1 mot X2
p <- ggplot(testdata, aes(x = X1, y = X2)) +
        geom_point()

# Lagrer plottet
ggsave("testplot.pdf", plot = p)
```

1. Lagre scriptet ditt. I RStudio velger du `File -> Save` og trykker `Ok` dersom det kommer opp et vindu om *character encoding* e.l. Finn en fornuftig plassering (gjerne i samme mappe som 칮velsesdatasettet) og gi filen et fornuftig navn. Standard filending for R-script er `.R`, men det er skjult for de fleste Windowsbrukere. Lukk RStudio.

2. Du kan n친 친pne skriptfilen i RStudio igjen. Enten ved 친 dobbeltklikke p친 den, eller ved 친 친pne RStudio, velge `File -> Open file`, og s친 videre (dersom skriptet ikke allerede ligger 친pnet). Du kan ogs친 친pne skriptfilen i en hvilken som helst notatbok (Notebook e.l.) og se at det er en helt standard, *ren tekstfil*. Hva er fordelen med 친 lagre en analyse som *et skript* versus 친 gj칮re ting i et menydrevet grafisk grensesnitt?

<details><summary>L칮sning</summary>

N친r vi lagrer koden v친r i et skript s칮rger vi for at *hele analysen v친r er lagret*, ikke bare resultatene. Med andre ord, dersom du p친 et senere tidspunkt 칮nsker 친 komme tilbake til et analyseprosjekt og gj칮re noen enkle forandringer, s친 er det fort gjort 친 gj칮re det i skriptet, og s친 kj칮re hele analysen p친 nytt. Dersom du i stedet hadde brukt et menydrevet system for 친 gjennomf칮re analysen (pek og klikk) kunne du risikere 친 m친tte gj칮re alt sammen p친 nytt (hvis du da husker hvordan du gjorde det), fordi du ikke like enkelt kan *lagre* hvert eneste museklikk. 

</details>


3. Vi skal n친 pynte p친 plottet og gj칮re det riktig pent. Det gj칮r vi ved 친 legge til nye linjer i ggplot-kommandoen. Erstatt den nest siste linjen i skriptet med kommandoen under, og se at du f친r en figur omtrent som den som f칮lger under det igjen (vi bruker aksetitler i henhold til oppgavene i den f칮rste datalabben, der vi f친r vite at datasettet representerer kvalitet p친 kaffeavlingen f칮r og etter en omlegging i produksjonsmetode):




```r
ggplot(testdata, aes(x = X1, y = X2)) +
        geom_point(size = 2) +
        xlab("Produksjonsmetode 1") +
        ylab("Produksjonsmetode 2") +
        theme_classic()
```

<img src="met4_files/figure-html/unnamed-chunk-10-1.png" width="576" />

4. Merk at vi pruker "+"-tegnet til 친 legge til flere "lag" med grafiske egenskaper til plottet. Hvert "lag" best친r av en funksjon, som ofte kan ta argumenter; f.eks. brukes funksjonen `geom_point()` til 친 lage prikker, og s친 kan vi f.eks. bruke argumentet `size` til 친 styre st칮rrelsen p친 prikkene. Kan du finne ut hva hvert enkelt av disse "lagene" gj칮r? Hint: ta bort en linje av gangen, og se hva som skjer. Pass p친 at det er et pluss mellom hvert lag.

5. Pr칮v 친 endre p친 noen av lagene eller legg til nye. For eksempel kan du lage en tittel ved 친 legge til funksjonen `ggtitle()` som et lag, og du kan endre aksetitlene. Pr칮v ogs친 친 bruke argumentet `shape` i `geom_point()` til 친 bytte ut prikkene med en annen form. Det finnes flere andre "tema" i tillegg til `theme_classic()`, f.eks. `theme_bw()`, `theme_dark()`, etc. 

<details><summary>Forslag</summary>

Pr칮v for eksempel dette:


```r
ggplot(testdata, aes(x = X1, y = X2)) +
        geom_point(size = 2, shape = 4) +
        ggtitle("Produksjonskvalitet") +
        xlab("Ny aksetittel") +
        ylab("Enda en aksetittel") +
        theme_light()
```

<img src="met4_files/figure-html/unnamed-chunk-11-1.png" width="576" />

</details>

6. Det f칮lger med omfattende dokumentasjon med `R`. Du kan lese om alle `R`-funksjoner ved 친 skrive `?` f칮r funksjonsnavnet i konsollen. Pr칮v for eksempel 친 skrive `?mean` i konsollen og trykk enter.


<!--chapter:end:01-intro-til-r.Rmd-->


# Grunnleggende statistikk

I denne modulen introduserer vi en del grunnleggende statistiske begreper. Mye vil oppleves som repetisjon, mens noe vil v칝re nytt. Noe er veldig praktisk ved at vi kan bruke det direkte i eksempler, mens andre ting er mer teoretisk av natur. Felles for det vi skal se p친 her er at vi kommer til 친 bruke mange av begrepene vi l칝rer senere i kurset.

I videoforelesningene g친r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved 친 klikke p친 lenkene under:

[Slides til "Grunnleggende statistikk"](script-slides/grunnleggende-stat/grunnleggende-stat-slides.html)

[R-script til "Grunnleggende statistikk"](script-slides/grunnleggende-stat/grunnleggende-stat-script.R)

## Deskriptiv statistikk

### Videoforelesninger

<div style='padding:74.79% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7748078/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Deskriptiv statistikk handler ikke om analyse eller regning, men om 친 presentere kompleks informasjon p친 en effektiv m친te. Det er alts친 noe ganske annet enn det vi ellers snakker om i kurset, men det er likevel et av de nyttigste l칝ringspunktet vi har. Hvem kan ikke regne med 친 m친tte presentere tall og resultater i l칮pet av sin karriere? Eller selge inn forslag og planer for overordnede i h친p om 친 bli lyttet til? Det kan v칝re direkte avgj칮rende for din egen gjennomslagskraft at du er i stand til 친 produsere overbevisende tabeller og figurer i slike situasjoner, og det er det dette temaet handler om. 

I l칝reboken er det kapitlene **2--4** som behandler deskriptiv statistikk, men det er veldig Excel-fokusert, som ikke er s친 relevant for oss. Det er likevel ikke dumt 친 lese gjennom stoffet for 친 se hva det g친r i, og legg spesielt merke til f칮lgende punkter:

- Ulike datatyper i avsnitt **2-1**.
- **3-4**: The art and science of graphical presentations. Hva er det som gj칮r en grafisk illustrasjon god? Pr칮v 친 ta inn over dere all informasjonen som vi lett kan lese ut av bildet p친 side 75 om Napoleons felttog mot Moskva. Her presenteres informasjon om tid, antall, geografi og temperatur p친 en helt eksepsjonelt effektiv m친te! Videre er det noen grelle eksempler p친 hvordan vi kan bruke grafiske virkemidler til 친 gi skjeve fremstillinger. I videoforelesningen gir vi flere eksempler p친 dette. 
- Kapittel **4** g친r litt mer i dybden om numeriske deskriptive teknikker, som gjennomsnitt, median, standardavvik, korrelasjon, osv. Dette skal v칝re dekket greit i forelesningen, men boken g친r litt lenger.

Det kan v칝re en fin 칮velse 친 kikke p친 eksemplene i l칝reboken og fors칮ke 친 gjenskape noen av Excel-figurene i R. Se p친 eksempel 3.2, der man skal lage to histogrammer over historiske avkastninger for to ulike investeringsstrategier. Vi leser inn datasettet (last ned fra Canvas) som under og kikker p친 det:




```r
library(readxl)
returns <- read_xlsx("Xm03-02.xlsx")
returns
```


```
## # A tibble: 50 x 2
##    `Return A` `Return B`
##         <dbl>      <dbl>
##  1      30         30.3 
##  2      -2.13     -30.4 
##  3       4.3       -5.61
##  4      25         29   
##  5      12.9      -26.0 
##  6     -20.2        0.46
##  7       1.2        2.07
##  8      -2.59      29.4 
##  9      33         11   
## 10      14.3      -25.9 
## # ... with 40 more rows
```

Hver stategi har sin kolonne. Merk at variabelnavnene har mellomrom i seg, noe som er upraktisk n친r vi jobber med et seri칮st programmeringsspr친k. En god vane er 친 rett og slett gi dem nye navn, ved f.eks. 친 kj칮re `colnames(returns) <- c("returnA", "returnB")`, eller s친 m친 vi alltid referere til variabelnavnene ved 친 bruke slike "backticks" som vi ser under.

Vi kan lage to enkle histogrammer slik vi gjorde det i forelesningen:


```r
ggplot(returns, aes(x = `Return A`)) +
        geom_histogram(bins = 10)
ggplot(returns, aes(x = `Return B`)) +
        geom_histogram(bins = 10)
```

<div class="figure">
<img src="met4_files/figure-html/to-histogrammer-1.png" alt="To histogrammer" width="672" /><img src="met4_files/figure-html/to-histogrammer-2.png" alt="To histogrammer" width="672" />
<p class="caption">(\#fig:to-histogrammer)To histogrammer</p>
</div>

Her er noen kontrollsp칮rsm친l som du kan pr칮ve deg p친:

1. Hva er forskjellen p친 deskriptiv statistikk og statistisk inferens?
1. Deskriptiv statistikk kan gj칮res grafisk eller numerisk, eventuelt som tabeller av ulike numeriske m친l. Nevn noen fordeler og ulemper man m친 veie mot hverandre n친r vi skal velge mellom grafisk og numerisk deskriptiv statistikk.

## Utvalg og estimering

> You can, for example, never foretell what any one man will do, but you can say with presicion what an average number will be up to. Individuals vary, but percentages remain constant. So says the statistician.

<footer>--- Sherlock Holmes</footer>

### Videoforelesninger

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7774368/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

I videoforelesningene over g친r vi gjennom noen sentrale begreper i statistikk. Noen av dem skal vi bruke mye i fortsettelsen, mens andre er ment for 친 gi dere et solid teoretisk fundament n친r vi etter hvert skal begi oss ut p친 anvendt statistikk.

Vi startet med 친 sette opp en liten agenda. Som et f칮rste steg kan du kikke p친, og notere ned noen setninger til, disse punktene og se om du har f친tt med deg hva de betyr:

- Samplingfordelinger
- Forventning/varians
- Sentralgrenseteoremet
- Hva er samplingfordelingen til et gjennomsnitt?
- Hva er samplingfordelingen til en andel?
- Forventningsrett
- Konsistens

I Boken er det kapittel **9** (*Sampling distributions*) og **10** (*Introduction to estimation*) som gjelder. Kapittel **6**--**8** omhandler stoff skal skal v칝re greit dekket i MET2 (Sannsynlighet, fordelinger, stokastiske variable, osv.), men det kan v칝re nyttig 친 skumme gjennom likevel hvis disse begrepene ligger langt bak i bevissheten din. 

Kapittel **9** starter med 친 diskutere samplingfordelingen til et gjennomsnitt. Dette er nyttig lesestoff, men de viktigste punktene er som f칮lger:

- Dersom observasjonene $X_1, X_2, \ldots, X_n$ er normalfordelt, er ogs친 gjennomsnittet $\overline X = \frac{1}{n}\sum_{i=1}^n X_i$ normalfordelt.
- Dersom E$(X_i) = \mu$ og Var$(X_i) = \sigma^2$ for alle $i = 1,\ldots,n$, er E$(\overline X)=\mu$ og Var$(\overline X) = \sigma^2/n$. Dette regnet vi ut formelt.
- Dersom $n$ er *stor*, er $\overline X$ tiln칝rmet normalfordelt, uavhengig av fordelingen til den enkelte $X_i$. Dette f칮lger av **sentralgrensesetningen**. 

Dette st친r i en boks p친 slutten av seksjon **9-1a**. Hvor stor m친 $n$ v칝re for at denne tiln칝rmingen er god nok? Det finnes ikke et entydig svar p친, men n친r vi passerer 50-100 observasjoner kan vi i v친re MET4-problemer gjerne si at $n$ er 춺stor nok췉. I **9-1b** og **9-1c** brukes sentralgrenseteoremet til 친 regne p친 normalsannsynligheter i MET2-stil. I **9-1d** er det noen Excel-instruksjoner som du kan hoppe over hvis du vil.

Tekstboksen i **9-2c** oppsummerer det vi fant ut om samplingfordelingen til en observert andel. I seksjon **9-3** snakkes det om samplingfordelingen til *differansen av to gjennomsnitt*. Vi gikk ikke gjennom det eksplisitt i forelesningen, men det er ikke noe substansielt nytt her. Vi skal bruke dette reultatet i neste modul n친r vi skal sammenligne to gjennomsnitt. I seksjon **9-4** f친r vi forklart hva vi skal bruke samplingfordelinger til fremover. B칮r leses.

Kapittel **10** omhandler *estimering*, dvs hvordan vi bruker data til 친 춺gjette췉 p친 verdien til en ukjent parameter. Vi fors칮kte i forelesningen 친 gi litt intuisjon til begrepene

- forventningsrett estimator,
- variansen til en estimator, og
- konsistens.

Vi kan lage et *punktestimat* av en forventningsverdi ved 친 ta gjennomsnittet av observasjoner, og vi kan lage et *konfidensintervall* ved 친 f칮lge oppskriften i boksen p친 s. 316 (i 11. utgave).

I eksempel 10.1 har vi 25 observasjoner fra en normalfordeling. Oppgaven er 친 estimere forventningsverdien med et tilh칮rende 95% konfidensuntervall. Pass p친 at du forst친r den manuelle utregningen. I stedet for 친 bruke Excel (eller taste alle disse tallene inn p친 en kalkulator) kan du skrive et lite R-script som gj칮r det samme:


```r
# Vi skriver inn datasettet i en vektor
demand <- c(235, 374, 309, 499, 253, 
            421, 361, 514, 462, 369,
            394, 439, 348, 344, 330,
            261, 374, 302, 466, 535,
            386, 316, 296, 332, 334)

# Vi trenger 4 verdier for 친 regne ut konfidensintervallet:
gj.snitt <- mean(demand)     # Regner ut gjennomsnittet
z <- 1.96                    # Denne finner vi i tabellen
sigma <- 75                  # Oppgitt i oppgaven
n <- length(demand)          # Antall observasjoner

# V친rt estimat av forventningsverdien er bare gjennomsnittet. 
# Regner ut nedre og 칮vre grense i konfidensintervallet (LCL, UCL):
LCL <- gj.snitt - z*sigma/sqrt(n)
UCL <- gj.snitt + z*sigma/sqrt(n)

# Samler de tre tallene i en vektor og skriver ut:
c(LCL, gj.snitt, UCL)
```

```
## [1] 340.76 370.16 399.56
```
 
 I seksjon **10-2a** fors칮ker boken 친 forklare fortolkningen av et konfidensintervall. Hovedpoengene her er at:
 
 - Et 95%-konfidensintervall skal *ikke* tolkes som 춺sannsynligheten for at den sanne parameterverdien ligger i intervallet er 95%췉.
 - Den korrekte tolkningen er: 춺Dersom vi hadde hatt tilgang til 친 trekke nye utvalg fra populasjonen med like mange observasjoner og bruker dem til 친 regne ut nye konfidensintervaller, vil 95 av 100 intervaller inneholde den sanne parameterverdien췉.
 
Forskjellen p친 disse formuleringene er meget subtil, s친 subtil faktisk at det ikke er 친penbart at det er s칝rlig god pedagogikk 친 peke p친 den. Problemet med den f칮rste formuleringen er at vi der kan f친 inntrykk av at det er den sanne parameterverdien som er stokastisk og avhengig av datasettet vi observerer, mens det strengt tatt er grensene til konfidensintervallet som er tilfeldige, og alts친 avhengige av datasettet. Det kommer klarere frem i den andre formuleringen.
 
Bredden til et konfidensintervall er alts친 et uttrykk for *usikkerhet*, eller motsatt: *presisjon*.  

Seksjon **10-2b** og **10-2c** kan skummes raskt gjennom. Seksjon **10-3** handler om at vi f칮rst bestemmer oss for et presisjonsniv친 (dvs bredde p친 konfiensintervallet) $B$, og s친 regner ut hvor mange observasjoner vi trenger for 친 oppn친 det. Vi kommer frem til en formelen

$$n = \left(\frac{z_{\alpha/2}\sigma}{B}\right)^2,$$
men problemet i praksis er at vi gjerne ikke kjenner $\sigma$, og vi kan heller ikke estimere den fordi vi ikke har samlet inn data enda. L칮sningen er at vi enten p친 bruke fornuften, eller eventuelt et tidligere estimat av $\sigma$ dersom det er tilgjengelig.

N친r du har v칝rt gjennom dette stoffet skal du forh친pentligvis v칝re i stand til 친 diskutere f칮lgende sp칮rsm친l med f.eks. en medstudent:

1. Hva er en samplingfordeling?
2. Hva sier sentralgrenseteoremet?
3. Hva mener en statistiker n친r hen sier at "gjennomsnittet konvergerer som $1/\sqrt{n}$"?
4. Hva er samplingfordelingen til et gjennomsnitt?
5. Hva er samplingfordelingen til en andel?
6. Hva vil det si at et estimator er forventningsrett?
7. Hva vil det si at et estimator er konsistent?

### Ekstra 칮ving i R

Som demonstrert i forelesningen kan vi i R simulere standard normalfordelte observasjoner (dvs normalfordelte observasjoner med $\mu = 0$ og $\sigma^2 = 1$) med kommandoen `rnorm(n)`, der `n` er antallet observasjoner vi 칮nsker. For eksempel kan vi kj칮re f칮lgende kode for 친 generere 10 observasjoner (du vil helt sikkert f친 andre verdier):


```r
n <- 10
rnorm(n)
```

```
##  [1] -0.97767538 -0.85984779 -0.82942978 -0.06430916  0.15950549 -1.20907783
##  [7] -0.56030404  0.64536257  0.46662351  1.43241286
```

Ved 친 skrive `mean(dnorm(n))` i stedet regner vi ut gjennomsnittet av observasjonene direkte. 

La oss gj칮re dette 100 ganger og notere ned gjennomsnittet hver gang. I stedet for 친 gj칮re det manuelt, kan vi skrive et lite program som gj칮r dette for oss ved 친 bruke en for-l칮kke. Det er ikke n칮dvendig (eller pensum) 친 forst친 akkurat hvordan dette fungerer, men dersom du kj칮rer f칮lgende linjer vil du f친 en ny vektor `gj.snitt` som inneholder 100 slike gjennomsnitt:


```r
gj.snitt <- rep(NA, 100)
for(i in 1:100) {
    gj.snitt[i] <- mean(rnorm(n))
}
```

Skriv ut denne vektoren og kontroller at det ser korrekt ut. Vi husker at funksjonen `sd()` regner ut standardavviket til en vektor. Hvilket tall forventer du 친 f친 ut dersom du n친 kj칮rer `sd(gj.snitt)` i konsollen? Stemmer det? 

<details><summary>Hint</summary>

Standardavviket til de enkelte observasjonene er $\sigma = 1$, og standardavviket til et gjennomsnitt best친ende av 10 observasjoner er $\sigma/\sqrt{n} = 1/\sqrt{10} \approx 0.32$. Med andre ord skal det *empiriske* standardavviket `sd(gj.snitt)` v칝re omtrent lik 0.32, pluss/minus en estimeringsfeil.

</details>

Du kan gjerne regne ut 1000 gjennomsnitt i stedet for 100 ved 친 erstatte erstatte `100` med `1000` p친 to steder i koden over. Stemmer det bedre da?

<details><summary>Hint</summary>


```r
gj.snitt <- rep(NA, 1000)            # Lager en tom vektor med 1000 plasser
for(i in 1:1000) {                   # Fyller hver plass med et gjennomsnitt av
    gj.snitt[i] <- mean(rnorm(n))    # 10 standard normalfordelte observasjoner.
}
```

</details>

Pr칮v 친 forklare.

<details><summary>Svar</summary>

Dette er ganske enkelt, men ogs친 litt vanskelig p친 en *inception*-aktig m친te. P친 samme m친te som at gjennomsnittet blir en mer og mer presis estimator for forventningsverdien n친r vi 칮ker antall observasjoner (m친lt ved at standardavviket $\sigma/\sqrt{n}$ blir mindre n친r antall obserasjoner $n$ blir st칮rre), blir det empiriske standardavviket en mer og mer presis estimator av det sanne standardavviket n친r vi 칮ker antall observasjoner. Alts친; det empiriske standardavviket har *ogs친* et standardavvik som g친r mot null som $1/\sqrt{n}$ 游땻 

</details>

## Oppgaver

I tabellen under finner du noen oppgaver som du kan bryne deg p친 for 친 sjekke forst친elsen din og trene p친 metodene som vi har g친tt gjennom i denne modulen. Vi peker ogs친 p친 noen tidligere eksamensoppgaver som er relevante til denne tematikken, du finner oppgavene under seksjon \@ref(skoleeksamen).

Har du en eldre utgave av boken kan du laste ned [dette dokumentet]("oppgaver/Recommended exersices.doc") for en oversikt over oppgavenummer tilbake til 7. utgave.

<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Kapittel i l칝reboken </th>
   <th style="text-align:left;"> 11. Utgave </th>
   <th style="text-align:left;"> 10. Utgave </th>
   <th style="text-align:left;"> Relevante eksamensoppgaver </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1. Hva er statistikk? </td>
   <td style="text-align:left;"> 2, 4, 6 </td>
   <td style="text-align:left;"> 2, 4, 6 </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 5. Datainnsamling og utvalg </td>
   <td style="text-align:left;"> 2, 4, 6, 16, 17, 18 </td>
   <td style="text-align:left;"> 2, 4, 6, 16, 17, 18 </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2. Grafisk databeskrivelse I </td>
   <td style="text-align:left;"> 2, 8, 10, 29, 30, 31, 41, 44 </td>
   <td style="text-align:left;"> 2, 6, 10, 29, 30, 31, 42, 44 </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 3. Grafisk databeskrivelse II </td>
   <td style="text-align:left;"> 2, 6, 34, 58, 84 </td>
   <td style="text-align:left;"> 2, 6, 34, 50, 78 </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 4. Numerisk databeskrivelse </td>
   <td style="text-align:left;"> 8, 13, 30, 33, 34, 35, 37, 42, 58, 71, 83, 84, 92, 136 </td>
   <td style="text-align:left;"> 8, 12, 22, 25-27, 29, 34, 40, 53, 63, 64 , 72, 118 </td>
   <td style="text-align:left;"> H13:1a-b, H12:2a, H14:1g </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 9. Samplingfordelinger </td>
   <td style="text-align:left;"> 9, 10, 11, 13, 14, 22, 42, 64, 32, 50, 70 </td>
   <td style="text-align:left;"> 1-3, 5-6, 14, 22, 30, 38, 48, 54 </td>
   <td style="text-align:left;"> H14:1d,n,o, V14:1e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 10. Estimering </td>
   <td style="text-align:left;"> 1-8, 16, 47, 48, 62 </td>
   <td style="text-align:left;"> 1-8, 12, 41-42, 56 </td>
   <td style="text-align:left;">  </td>
  </tr>
</tbody>
</table>


<!--chapter:end:02-grunnleggende-statistikk.Rmd-->


# Hypotesetesting

Hypotesetesting er et klassisk tema i statistikk. Vi skal f칮rst l칝re generelt om hva det egentlig vil si 친 *teste* en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting *ikke* er. Vi g친r s친 videre til 친 l칝re noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R.

I videoforelesningene g친r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved 친 klikke p친 lenkene under:

[Slides til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-slides.html)

[R-script til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-script.R)

## Generelt om hypotesetesting

### Videoforelesninger 

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780028/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Her snakker vi om kapittel **11** i l칝reboken. Hvis du kan svare p친 f칮lgende sp칮rsm친l har du i all hovedsak f친tt med deg de viktigste begrepene:

- Hva vil det si 친 gjennomf칮re en hypotesetest?
- Hva er Type I-feil og hva er Type II-feil? (Seksjon **11-1** forklarer dette greit)
- Hva er signifikansniv친et ($\alpha$) til en test?
- Styrken (the power) til en test er definert som $1-P(\textrm{Type II-feil})=1-\beta$. Hvordan tolker du denne st칮rrelsen? Se ogs친 **11-3d**.
- Hva er $p$-verdien til en test (Seksjon **11-2c**)? Les ogs친 **11-2d**, **e** og **f** om hvordan vi fortolker og snakker om $p$-verdien p친 en korrekt m친te. Vi kommer tilbake til dette i kapittel \@ref(chap:enpop).

## Inferens om en populasjon {#chap:enpop}

### Videoforelesninger

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780035/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Dette er i hovedsak dekket av kapittel **12** i l칝reboken. Sjekk om du kan svare p친 f칮lgende kontrollsp칮rsm친l:

1. Hva er det vi tester n친r vi gjennomf칮rer en $t$-test for 칠n populasjon? Hva forutsetter vi?
2. Hva er forskjellen p친 en ensidig og en tosidig test? (**11-2j**)

Det kan ogs친 v칝re greit 친 repetere konfidensintervaller i seksjon **11-2k** for de som har glemt det fra MET2.

I Seksjon **11-2g** g친r boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gj칮re det samme i R. P친 kursets nettside finner du alle datasettene som f칮lger med l칝reboken. I dette eksempelet er det snakk om `Xm11-01.xlsx`. Finn tak i denne filen (du kan ogs친 godt 친pne den og se p친 den i Excel!), legg den i en mappe som du kan finne igjen, og 친pne et nytt script i R-studio der du f칮rst s칮rger for 친 sette working directory til denne mappen slik vi gjorde i R-forelesningen.

Etterp친 leser du inn datasettet ved 친 bruke `read_xlsx()`-funksjonen som under:


```r
library(readxl)
data <- read_xlsx("Xm11-01.xlsx")     # Vi bruker read_xslx() fordi det er en .xlsx-fil
```



Konteksten til datasettet er gitt i eksempel 11.1. Det er alts친 balansen p친 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer p친 om forventet balanse er st칮rre enn 170. Vi setter opp f칮lgende test:

\begin{align*}
&H_0: \mu = 170 \\
&H_A: \mu > 170,
\end{align*}
der vi legger merke til at det blir brukt en ensidig test (hvorfor?).

For 친 regne ut testobservatoren for 친 enutvalgs $z$-test trenger vi fire tall: $\overline X$, $\mu_0$, $n$ og $\sigma$. Legger merke til at `data` har en kolonne som heter `Accounts`, og vi bruker dollartegnet til 친 hente den ut som en vektor. Regner ut observatoren:


```r
gj.snitt <- mean(data$Accounts)     # Gjennomsnittet av observasjonene
mu0      <- 170                     # Henter fra teksten
n        <- length(data$Accounts)   # Antall observasjoner
sigma    <- 65                      # Henter fra teksten

Z <- (gj.snitt - mu0)/(sigma/sqrt(n))   # Verdien av testobservatoren
Z                                       # Skriver ut testobservatoren
```

```
## [1] 2.460462
```
Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R:


```r
qnorm(0.95)
```

```
## [1] 1.644854
```

Uansett; vi forkaster $H_0$ siden testobservatoren er st칮rre enn kritisk verdi.

Kapittel **11-3a-d** gir enda mer forst친else for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre.

**Kapittel 12** presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du f칮rst og fremst m친 kunne fra dette kapitlet er 친 gjennomf칮re disse testene, b친de for h친nd med penn og papir, og i R. Under f칮lger kode for 친 gj칮re noen av bokens eksempler i R (les i boken for kontekst):

**Eksempel 12.1:** 

\begin{align*}
&H_0: \mu = 2.0 \\
&H_A: \mu > 2.0,
\end{align*}


```r
data <- read_xlsx("Xm12-01.xlsx")

# Manuell utregning
gj.snitt <- mean(data$Newspaper)
mu0      <- 2.0
n        <- length(data$Newspaper)
s        <- sd(data$Newspaper)

# Testobservator:
(gj.snitt - mu0)/(s/sqrt(n))
```


```
## [1] 2.236869
```

Signifikansniv친et er satt til $\alpha = 1\%$ i eksempelet. Kritisk verdi finner vi i $t$-tabell eller rett fra R:


```r
qt(0.99, df = n-1)
```

```
## [1] 2.351983
```

Alts친 forkaster vi **ikke** nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som st친r i boken. Alternativt bruker vi `t.test()`-funksjonen direkte:


```r
t.test(data$Newspaper, alternative = "greater", mu = 2.0, conf.level = 0.99)
```

```
## 
## 	One Sample t-test
## 
## data:  data$Newspaper
## t = 2.2369, df = 147, p-value = 0.0134
## alternative hypothesis: true mean is greater than 2
## 99 percent confidence interval:
##  1.990716      Inf
## sample estimates:
## mean of x 
##  2.180405
```

Resultatet blir selvsagt det samme. N친r $p$-verdien er st칮rre enn signifikansniv친et p친 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om 친 lage kondidensintervall, noe du ogs친 kan pr칮ve 친 gj칮re ved 친 regne ut de n칮dvendige tallene i R. De som synes dette er greit kan kikke p친 seksjonene **12-1b-e** for 친 utvikle forst친elsen enda litt mer.

**Eksempel 12.3:** 

\begin{align*}
&H_0: \sigma^2 = 1.0 \\
&H_A: \sigma^2 < 1.0.
\end{align*}

Testobservator:

$$\chi^2 = \frac{(n-1)s^2}{\sigma_0^2}.$$


```r
data <- read_xlsx("Xm12-03.xlsx")

# Regner ut testobservatoren direkte denne gangen, uten 친 lagre tallene underveis:
(length(data$Fills) - 1)*var(data$Fills)/1

# Kritisk verdi, 5% niv친, ensidig test, nedre hale:
qchisq(0.05, df = length(data$Fills) - 1)     
```


```
## [1] 15.2
```

```
## [1] 13.84843
```

Vi kan alts친 ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for 친 forst친 bedre hva som skjer. Figur 12.4 viser p친 en fin m친te hva tallene betyr.

**Eksempel 12.5** kan v칝re grei 친 kikke p친 ogs친. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste:

\begin{align*}
&H_0: p = 0.5 \\
&H_A: p > 0.5.
\end{align*}

Vi har en observert andel p친 $\widehat p = 407/765 = 0.532$ etter 친 ha spurt $n = 765$ personer. Testobservatoren er 
$$Z = \frac{\widehat p - p}{\sqrt{p(1-p)/n}}.$$


```r
p.hatt <- 407/765
p0     <- 0.5
n      <- 765

(p.hatt - p0)/sqrt(p0*(1-p0)/n)
```

```
## [1] 1.771599
```

Kritisk verdi for en ensidig z-test p친 5% niv친 er 1.645 (`qnorm(0.95)`), og vi kan forkaste nullhypotesen.

Seksjonene **12-3d-f** b칮r leses p친 egen h친nd, mens vi hopper over **12-3g**.

## Inferens om to populasjoner

### Videoforelesninger

<div style='padding:74.64% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780048/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi har g친tt gjennom kapittel **13**, som i all hovedsak handler om 친 sammenligne to gjennomsnitt (som vi kan gj칮re p친 tre forskjellige m친ter), to varianser og to andeler. Her f칮lger noen kontrollsp칮rsm친l som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper:

- Hva er nullhypotesen n친r vi skal gjennomf칮re en t-test for to populasjoner?
- ... og hvilke antagelser m친 vi gj칮re?
- Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj칮r?
- N친r kan vi bruke matchede par, og hva er hensikten?
- Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen?
- Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj칮r?
- Hvilken test brukes for 친 teste om to andeler er like, og hva m친 du anta?

Videre b칮r du sjekke at du kan utf칮re **3** typer $t$-tester, test for like varianser og test for like andeler b친de for h친nd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber).

Den enkleste m친ten 친 gj칮re $t$-tester i R p친 er 친 bruke funksjonen `t.test()`. Kikk p친 eksempel 13.1 i l칝rebokens 11. utgave, der vi har observert 친rlige avkastninger til to aksjefond som er kj칮pt henholdsvis med og uten megler. 


```r
# Leser inn datasettet
funds <- read_xlsx("Xm13-01.xlsx")

# Ser at det er to kolonner, 춺Direct췉 og 춺Broker췉. Alternativhypotesen p친 s.433 spesifiserer at
# differansen i forventninger er *st칮rre* enn null, signifikansniv친et skal v칝re 5%. Antar f칮rst 
# ulik varians og at vi ikke skal gj칮re en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = FALSE,
       conf.level = 0.95) 
```


```
## 
## 	Welch Two Sample t-test
## 
## data:  funds$Direct and funds$Broker
## t = 2.2872, df = 97.489, p-value = 0.01217
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.79661     Inf
## sample estimates:
## mean of x mean of y 
##    6.6312    3.7232
```

Du kan s친 sjekke at du f친r ut de samme tallene p친 s. 434--435. Videre kan du skrive inn `?t.test` i R-konsollen i RStudio for 친 lese mer om hvilke argumenter vi kan bruke i `t.test()`-funksjonen. Der ser vi at argumentene `paired`, `var.equal` og `conf.level` som utgangspunkt allerede er satt til `FALSE`, `FALSE` og `0.95` henholdsvis, s친 det hadde vi strengt tatt ikke trengt 친 spesifisere i funksjonskallet over.

Vi kan enkelt kj칮re den samme testen under antakelsen om like varianser ved 친 sette `var.equal = TRUE`:


```r
# Ser at det er to kolonner, 춺Direct췉 og 춺Broker췉. Alternativhypotesen p친 s.433 spesifiserer at
# differansen i forventninger er *st칮rre* enn null, signifikansniv친et skal v칝re 5%. Antar f칮rst 
# ulik varians og at vi ikke skal gj칮re en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = TRUE,
       conf.level = 0.95) 
```

```
## 
## 	Two Sample t-test
## 
## data:  funds$Direct and funds$Broker
## t = 2.2872, df = 98, p-value = 0.01217
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.7967156       Inf
## sample estimates:
## mean of x mean of y 
##    6.6312    3.7232
```

Resultatet bli akkurat det samme. Siden testens $p$-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og sl친 fast at forskjellen i gjennomsnitt er statistisk signifikant.

I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner  i de to populasjonene, s친 vi kan tenke oss at m친lingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om *gjennomsittet av differansene* er signifikant forskjellig fra null. Enkelt:


```r
# Ser at det er to kolonner, 춺Direct췉 og 춺Broker췉. Alternativhypotesen p친 s.433 spesifiserer at
# differansen i forventninger er *st칮rre* enn null, signifikansniv친et skal v칝re 5%. Antar f칮rst 
# ulik varians og at vi ikke skal gj칮re en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = TRUE,
       conf.level = 0.95) 
```

```
## 
## 	Paired t-test
## 
## data:  funds$Direct and funds$Broker
## t = 2.5178, df = 49, p-value = 0.007563
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.9716497       Inf
## sample estimates:
## mean of the differences 
##                   2.908
```

Da ser vi at $p$-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du pr칮ve selv. Pass p친 at du kan gj칮re beregningene manuelt ogs친, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forst친r hva som foreg친r. 

Kapittel **13-2** omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig 친 sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen v친r av statistiske resultater. Det er et eksplisitt krav for 친 lykkes i MET4 at du er i stand til 친 sette resultatene inn i en fornuftig kontekst.

I kapittel **13-4** kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R:


```r
bottle <- read_xlsx("Xm13-07.xlsx")
var.test(bottle$`Machine 1`, bottle$`Machine 2`,
         alternative = "greater")
```


```
## 
## 	F test to compare two variances
## 
## data:  bottle$`Machine 1` and bottle$`Machine 2`
## F = 1.3988, num df = 24, denom df = 24, p-value = 0.2085
## alternative hypothesis: true ratio of variances is greater than 1
## 95 percent confidence interval:
##  0.7051295       Inf
## sample estimates:
## ratio of variances 
##           1.398807
```

Ogs친 her kan du sammenligne med tallene som fremg친r av bokens gjennomgang, og s칮rg for at du f친r til dette p친 egen h친nd, *spesielt* det 친 finne frem i tabellen, for det *m친* du kunne p친 eksamen.

Til slutt har vi test for to andeler i kapittel **13-5**. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er *like* ($p_1 - p_2 = 0$), som er det vi har dett p친 i forelesning, men det g친r selvsagt like fint 친 sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall $D$. 

Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved 친 regne ut testobservatoren fra datasettet. Vi ser p친 eksempel 13.9, der vi f친r oppgitt salget av en del forskjellige varenummer, og vi 칮nsker 친 finne ut om andelen 춺9077췉 er st칮rre i Supermarked 1 enn i Supermarked 2:


```r
# Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, s친 jeg 
# velger 친 lese inn de to kolonnene hver for seg:
soap1 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("A"))
soap2 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("B"))

# Hvor stor andel utgj칮r 춺9077췉 i de to kolonnene?
p1 <- mean(soap1 == 9077)
p2 <- mean(soap2 == 9077)

# De to utvalgsst칮rrelsene:
n1 <- nrow(soap1)
n2 <- nrow(soap2)

# Felles estimat for p under nullhypotesen:
p <- (n1*p1 + n2*p2)/(n1 + n2)

# Testobservatoren:
z <- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2))

# Kritisk verdi p친 5% niv친 for en ensidig test:
qnorm(0.95)
```


```
## [1] 1.644854
```

Siden $z = 2.9$ forkaster vi nullhypotesen om at det er lik andel 춺9077췉 i de to populasjonene.

## Kjikvadrattester

### Videoforelesninger

<div style='padding:74.43% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780062/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi m친 kunne *to* anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken:

1. Teste for om en gitt fordeling passer med obervasjoner (*"Goodness-of-fit"*).
2. Teste for uavhengighet.

I den f칮rste anvendelsen f친r vi oppgitt en *diskret* sannsynlighetsfordeling der vi har noen mulige utfall $u_1, \ldots, u_k$, med tilh칮rende sannsynligheter $p_1, \ldots,p_k$. Dersom vi skal observere $n$ utfall fra denne fordelingen, vil vi forvente $e_i = p_i\cdot n$ observasjoner av utfall $u_i$.

N친 har det seg slik at vi *har* observert $n$ utfall fra fordelingen, og utfall $u_i$ har skjedd $f_i$ ganger. **Vi lurer da p친 om de observerte frekvensene ($f_i$) er s친 forskjellige fra de *forventede* frekvensene ($e_i$) at vi ikke lenger tror at $p_1, \ldots,p_k$ er den sanne sannsynlighetsfordelingen.**

Vi kom frem til en fornuftig testobservator:

$$\chi^2 = \sum_{i=1}^k \frac{(f_i - e_i)^2}{e_i},$$
som er $\chi^2$-fordelt med $k-1$ frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan g친 inn i $\chi^2$-tabellen for 친 sjekke om verdien av testobservatoren er for stor (dvs, $f$췂ene er for forskjellige fra $e$`ene) at vi ikke lenger tror at $(p_1, \ldots, p_k)$ er den sanne sannsynlighetsfordelingen.

Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte f칮lgende kommandoer:


```r
p0 <- c(0.45, 0.40, 0.15)  # Fordeling under H0
f  <- c(102, 82, 16)       # Observerte frekvenser

chisq.test(x = f, p = p0)
```

```
## 
## 	Chi-squared test for given probabilities
## 
## data:  f
## X-squared = 8.1833, df = 2, p-value = 0.01671
```

Den andre anvendelsen er 친 teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for 춺$A$ og $B$췉 som et produkt dersom de ar uavhengige: 

$$P(A \cap B) = P(A)\cdot P(B).$$

Vi kan regne ut hvor mange observasjoner vi forventer 친 se for hver kombinasjon av de to kjennetegnene ($e_{ij}$), og bruke kjikvadrattesten over til 친 sjekke om disse er langt fra det vi *faktisk* har observert ($f_{ij}$). Boken har et eksempel p친 dette som de regner ut b친de for h친nd og i Excel. Slik kan vi gj칮re det i R:


```r
# Leser inn data
mba <- read_xlsx("Xm15-02.xlsx")

# Kikker p친 datasettet
mba
```


```
## # A tibble: 152 x 2
##    Degree `MBA Major`
##     <dbl>       <dbl>
##  1      3           1
##  2      1           1
##  3      1           1
##  4      1           1
##  5      2           2
##  6      1           3
##  7      3           1
##  8      1           1
##  9      2           1
## 10      2           2
## # ... with 142 more rows
```

Vi legger merke til at strukturen p친 datasettet er litt annerledes enn krysstabellen som er vist s. 601 i l칝reboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av 춺bachelorgrad췉 og 춺masterprofil췉, har vi f친tt oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R:


```r
table(mba)
```

```
##       MBA Major
## Degree  1  2  3
##      1 31 13 16
##      2  8 16  7
##      3 12 10 17
##      4 10  5  7
```

Det er denne som brukes som argument i `chisq.test()`:


```r
chisq.test(table(mba))
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  table(mba)
## X-squared = 14.702, df = 6, p-value = 0.02271
```

Her er det bare 친 sammenligne tallene med det som l칝reboken finner i Excel.

Noen kontrollsp칮rsm친l:

1. Vi har l칝rt to veldig spesifikke anvendelser av kjikvadrattester. Hvilke?
2. Kan du gi en intuitiv forklaring p친 hvorfor testobservatoren v친r er fornuftig?
3. **Litt mer vanskelig:** Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tiln칝rmet kjikvadratfordelt?

## Oppgaver

I tabellen under finner du noen oppgaver som du kan bryne deg p친 for 친 sjekke forst친elsen din og trene p친 metodene som vi har g친tt gjennom i denne modulen. Vi peker ogs친 p친 noen tidligere eksamensoppgaver som er relevante til denne tematikken, du finner oppgavene under seksjon \@ref(skoleeksamen).

Har du en eldre utgave av boken kan du laste ned [dette dokumentet]("oppgaver/Recommended exersices.doc") for en oversikt over oppgavenummer tilbake til 7. utgave.

<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Kapittel i l칝reboken </th>
   <th style="text-align:left;"> 11. Utgave </th>
   <th style="text-align:left;"> 10. Utgave </th>
   <th style="text-align:left;"> Relevante eksamensoppgaver </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 11. Hypotesetesting </td>
   <td style="text-align:left;"> 1-4, 10, 26-28, 34, 46, 62, 64 </td>
   <td style="text-align:left;"> 1-4, 10, 18-20, 34, 46, 62, 64 </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 12. Inferens: En populasjon </td>
   <td style="text-align:left;"> 6, 10, 26, 32, 68, 74, 82, 84, 96 </td>
   <td style="text-align:left;"> 6, 10, 26, 32, 68, 74, 82, 84, 96 </td>
   <td style="text-align:left;"> V12:1a-f, H10:2, V10:1a </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 13. Inferens: To populasjoner </td>
   <td style="text-align:left;"> 8, 12, 96, 94, 100, 120, 131, 136, 138 </td>
   <td style="text-align:left;"> 8, 12, 96, 94, 100, 120, 131, 136, 138 </td>
   <td style="text-align:left;"> H13:1c-f, V10:1b, V13:1e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 15. Kjikvadrattester </td>
   <td style="text-align:left;"> 1-4, 10, 14, 22-25, 28, 38 </td>
   <td style="text-align:left;"> 1-4, 10, 14, 22-25, 28, 38 </td>
   <td style="text-align:left;"> H08:3 </td>
  </tr>
</tbody>
</table>



<!--chapter:end:03-hypotesetesting.Rmd-->


# Regresjon

I forrige modul fokuserte vi p친 *bin칝re* sp칮rsm친l av typen "Er det en forskjell mellom disse to populasjonene, eller ikke?", "Er disse kjennetegnene uavhengige, eller ikke?", og s친 videre. I denne modulen skal vi pr칮ve 친 g친 et steg lenger og tillate mer interessante sp칮rsm친l. I stedet for bare 친 sp칮rre om en eller annen effekt er til stede (eller ikke), s친 vil vi heller finne ut hvor stor denne effekten er, hvilken retning den g친r, og kanskje om vi kan bruke kunnskapen vi f친r om statistiske sammenhenger til 친 si noe fornuftig om hva som vil skje for noe som vi enda ikke har observert. Da er det regresjon som gjelder, og mer spesifikt for v친r del: *line칝r regresjon*. 

Regresjon er et hovedtema i MET4. Vi innf칮rer en *statistisk modell* som i sin enkleste form sier at en *forklaringsvariabel* $X$ henger sammen med en responsvariabel $Y$ p친 en helt bestemt m친te, nemlig gjennom ligningen

$$Y = \beta_0 + \beta_1 X + \epsilon.$$

Ligningen over sier at det er en *line칝r* sammenheng mellom $X$ og $Y$, men at det i tillegg kommer en uforutsigbar st칮yvariabel $\epsilon$ som gj칮r at vi ikke vil kunne observere den line칝re sammenhengen direkte. Det vi derimot kan gj칮re, er 친 bruke de observerte $X$er og $Y$er til 친 finne ut hvilke verdier av $\beta_0$ og $\beta_1$ som passer *best*. Til det bruker vi minste kvadraters metode, som beskrevet i videoforelesningene i denne modulen.

Vi deler arbeidet med regresjon inn i tre deler. I den f칮rste (og st칮rste) delen g친r vi grundig gjennom ulike sider vi den enkle line칝re regresjonsmodellen over. I den andre delen ser vi p친 *multippel regresjon* som er en utvidelse av enkel regresjon der vi tillater flere forklaringsvariabler p친 h칮yre side av likhetstegnet, og i den tredje delen ser vi p친 ulike praktiske aspekter ved regresjonsmodellering og modellbygging.

I videoforelesningene g친r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved 친 klikke p친 lenkene under:

[Slides til "Regresjon"](script-slides/regresjon/regresjon-slides.html)

[R-script til "Regresjon"](script-slides/regresjon/regresjon-script.R)

## Enkel regresjon

### Videoforelesninger

<div style='padding:75% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7781447/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi har sett p친 en del figurer som illustrerer noen pedagogiske poenger, og l칝rebokens kapittel **16** g친r detaljert til verks n친r de beskriver de ulike l칝ringsmomentene:

I kapittel **16.1** kan vi lese mer om den statistiske modellen som vi kaller enkel regresjon. I kapittel **16.2** introduseres minste kvadraters metode for 친 estimere regresjonskoeffisientene ved hjelp av data. De viser til og med hvordan det kan gj칮res manuelt ved hjelp av bildatasettet, men det er selvsagt kun for 친 illustrere hvodan formlene ser ut. Vi estimerer ved hjelp av R, og vi har sett i videoforelesningen hvordan vi gj칮r det ved hjelp av `lm()`-funksjonen.

Det som gj칮r regresjon til et *statistisk* problem er feilleddet $\epsilon$. Vi tenker oss at for en gitt verdi av $X$, s친 vil 춺naturen췉 regne ut verdien av $Y$ ved 친 regne ut den line칝re sammenhengen $Y = \beta_0 + \beta_1 X$, og s친 legge til st칮yvariabelen $\epsilon$ som *trekkes* fra en sannsynlighetsfordeling. Vi kan ikke observere direkte hvilke $\epsilon$ som 춺naturen췉 har 춺trukket췉 (for da ville vi med en gang kunne regnet oss frem til verdiene av $\beta_0$ og $\beta_1$). For gitte estimater av regresjonskoeffisientene $\widehat \beta_0$ og $\widehat \beta_1$ (som vi kan finne f.eks. ved hjelp av minste kvadraters metode), s친 kan vi regne ut de *observerte residualene* 

$$\widehat\epsilon_i = Y_i - \widehat Y_i = Y_i - (\widehat \beta_0 + \widehat \beta_1 X_i).$$

Ved 친 analysere residualene kan vi si mer om f.eks

1. Er det egentlig en line칝r sammenheng mellom $X$ og $Y$? Hvis det er m칮nstre og sammenhenger i de observerte residualene, tyder det p친 at den enkle line칝re modellen *ikke* fanger opp hele sammenhengen mellom $X$ og $Y$.
2. Vi kan g친 mer spesifikt til verks: n칮yaktig *hvilke* antakelser om residualene er ser ut til 친 v칝re brutt? I senere 칮konometrikurs vil dere kunne l칝re mer om hvordan vi h친ndterer de ulike problemene. 
3. Hvor stor er variansen til $\epsilon$? Det brukes videre til 친 sette opp den viktige signifikanstesten for om stigningstallet i regresjonen er forskjellig fra null.

Alt dette behandles grudig i bokens kapittel **16.3--16.6**. Her b칮r teksten leses godt. Kode til bileksempelet finnes i scriptet som f칮lger med videoforelesningene.

N친r det gjelder enkel regresjon kan du sjekke om du har f친tt med deg det vesentligste ved 친 diskutere f칮lgende sp칮rsm친l:

1. Hva er responsvariabelen og hva er forklaringsvariabelen i enkel regresjon?
1. Hva er fortolkningen av de to regresjonskoeffisientene?
1. Hvilket prinsipp er det vi legger til grunn n친r vi skal bestemme (estimere) verdien av koeffisientene ved hjelp av data?
1. Skriv opp formlene for koeffisientestimatene. Kan du gi en intuitiv fortolkning av disse? Er de rimelige? 
1. Kan du ved hjelp av formelen for $\widehat\beta_1$ utlede sammenhengen mellom *stigningstallet* $\beta_1$ og korrelasjonskoeffisienten* mellom $X$ og $Y$?
1. Hvilken rolle spiller feilleddet ($\epsilon$)?
1. Skriv opp de 4 + 1 forutsetningene. N친r m친 den siste v칝re oppfylt? N친r kan vi klare oss uten?
1. Hva er testobservatoren n친r vi tester H$_0: \beta_1 = 0$?
1. Kan du holde styr p친 de fire standardavvikene vi har jobbet med i denne forelesningen?
1. Hva mener vi med 친 diagnostisere en regresjonsmodell?
1. Hva er $R^2$, og hva m친ler den?
1. Hva sier $R^2$ *ikke* noe om?

Her er noen grunnleggende ferdigheter fra kapittel 16. Klarer du dette? 

1. Bruke \texttt{R} til 친 tilpasse en enkel regresjonsmodell for et datasett?
1. Bruke \texttt{R} til 친 skrive ut oversiktlige regresjonstabeller?
1. Tolke en regresjonsutskrift?
1. Hente ut relevant informasjon etter en slik tilpasning?
1. Bruke informasjon fra regresjonsutskriften til 친 regne ut antall stjerner for h친nd?
1. Lage diagnoseplott i \texttt{R}?
1. Diagnistisere en modell?
1. Identifisere innflytelsesrike observasjoner?

## Multippel regresjon

### Videoforelesninger

<div style='padding:75.14% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7793207/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

I kapittel **17** utvides regresjonsbegrepet til *multippel* regresjon, som i prasis betyr at vi kan ha flere enn en forklaringsvariable:

$$Y = \beta_0 + \beta_1X_1 + \cdots \beta_kX_k + \epsilon,$$
men utover dette er alle detaljene vi har snakket om de samme. For eksempel:

- Tolkningen av regresjonskoeffisienten: En endring p친 en enhet i forklaringsvariabelen $X_j$ henger sammen med $\beta_j$ enhets endring i responsvariabelen $Y$ (merk at jeg ikke brukker begrepet "f칮rer til", vi kan ikke uten videre fortolke sammenhengen som kausal!).
- Analysen av residualene $\widehat \epsilon_i = Y_i - \widehat Y_i$ er den samme og har samme form친l 1--3 som over.
- $R^2$ har samme fortolkning.
- R-kommandoen er den samme, vi bare sette pluss mellom forklaringsvariablene, f.eks `reg <- lm(Y ~ X1 + ... + Xk, data = x)`

I tillegg innf칮rer vi noen nye begreper:

**Justert** $R^2$: Vi viste i forelesningen at vi vil alltid klare 친 칮ke $R^2$ ved 친 legge til forklaringsvariable, selv om de ikke har noe med problemet 친 gj칮re. Derfor innf칮rte vi en *justert* $R^2$ som tar h칮yde for nettopp dette, ved 친 bli st칮rre bare dersom den aktuelle forklaringsvariebelen faktisk forklarer en reell mengde av variasjonen i responsvariabelen. Se avsnitt **17-2f** i l칝reboken.

**Multikolinearitet**: Dersom en forklaringsvariabel er sterkt korrelert med en eller flere andre forklaringsvariabler har vi multikolinearitet. Det blir naturlig nok et problem 친 skille effekter fra hverandre n친r de i realiteten er helt eller nesten like. Ekstremtilfellet er *perfekt multikolinearitet* der en variabel er en eksakt line칝r funksjon av en eller flere andre variable. Det typiske tilfellet er at vi har to kolonner der vi m친ler det samme fenomenet, men med to ulike enheter, f.eks. **cm** og **m**. Selvsagt kan vi ikke klare 친 identifisere en *separat* og *uavhengig* effekt av $X$ p친  $Y$ om vi skifter m친leenhet, og vi vil f친 en feilmelding dersom vi pr칮ver p친 det. Det er ekvivalent med 친 dele p친 null (every time you divide by zero, God kills a kitten!). L칮sning: fjern en av kolonnene fra regresjonsanalysen.

Verre er det om to variable m친ler *nesten* det samme, men ikke helt, som i skoledataeksempelet der vi kunne bruke b친de innbyggertall og antall femteklassinger i kommunen som forklaringsvariabler. De henger tett sammen, men selvsagt ikke eksakt, og det virker rart 친 kunne knytte separate efekter til disse to variablene. I dette tilfellet f친r vi likevel ikke feilmeldinger, men konsekvensen kan fort bli at standardavvikene (usikkerheten!) til koeffisientestimatene eksploderer, og at ingen av variablene blir signifikant forskjellige fra null, selv det det faktisk er en sterk sammenheng mellom kommunest칮rrelse og pr칮veresultat (husk at testobservatoren: $t = \widehat \beta_k/\sigma_{\beta_k}$ blir liten n친r nevneren blir stor).

**F-test for multiple sammenligninger**: Dette henger n칮ye sammen med *variansanalyse (analysis of variance, ANOVA)*, som n친 er tatt ut av pensum i kurset. For 친 forst친 dette kan vi sette opp et eksempel, med to forklaringsvariabler:
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2.$$
Etter 친 ha brukt miste kvadraters metode for 친 estimere de tre koeffisientene er vi kanskje interessert i 친 vurdere den statsistiske signifikansene til de to stigningstallene separat. Da tester vi de to nullhypotesene $\beta_1 = 0$ og $\beta_2 = 0$, som vi i praksis gj칮r ved 친 se p친 hvor mange stjerner de f친r i regresjonsutskriften. Men sett at ingen av koeffisientene er signifikant forskjellige fra null, kan vi da slutte at vi ikke kan forkaste hypotesen $\beta_1 = \beta_2 = 0$, dvs at *begge* koeffisientene er lik null, og at ingen av forklaringsvariablene forklarer variasjon i $Y$? **NEI**, det kan vi ikke. Vi kan for eksempel lett tenke oss at vi p친 grunn av multikolinearitet ikke f친r separate forkastninger av de to nullhypotesene, men at ved 친 fjerne en variabel, s친 blir den andre signifikant.

For 친 virkelig forst친 dette problemet kan du godt lese starten p친 kapittel **14.1** samt kapittel **14.2** om multiple sammenligninger (som strengt tatt ikke er pensum), men essensen er alts친:

$$\textrm{칀 forkaste H}_0: \beta_1 = 0 \textrm{ og H}_0: \beta_2 = 0 \textrm{ er ikke det samme som 친 forkaste H}_0: \beta_1 = \beta_2 = 0!$$

For 친 gjennomf칮re den siste testen m친 vi sette opp en egen testobservator, som viser seg 친 v칝re $F$-fordelt. L칝reboken lister opp noen detaljer i avsnitt **17-2f**, og essensen er at vi setter opp en br칮k p친 formen
$$F = \frac{\textrm{Variasjon i } Y \textrm{ som fanges opp av regresjonsmodellen med } X_1 \textrm{ og }X_2}{\textrm{Variasjon i } Y \textrm{ som fanges opp av regresjonsmodellen uten } X_1 \textrm{ og }X_2}.$$
Dersom denne br칮ken viser seg 친 v칝re stor (som definert av signifikansniv친 og frihetsgrader, se l칝rebok), forkaster vi nullhypotesen om at begge koeffisientene begge kan v칝re lik null. I en generell multippel regresjon med $k$ forklaringsvariable rapporterer R `F-statistic: ` etc, med verdien av $F$-observatoren i testen for
$$H_0: \beta_1 = \cdots = \beta_k = 0,$$
og dersom den oppgitte $p$-verdien er mindre enn f. eks. 5%, kan vi slutte at ikke alle koeffisientene kan v칝re null samtidig (selv om ingen av koeffisientene i seg selv n칮dvendigvis er signifikant forskjellig fra null).

Som en s친kalt *fun fact* kan vi nevne at det er enkelt 친 teste for signifikansen til *grupper* av variable p친 denne m친ten, f.eks hvis det er noen variable som m친ler lignende ting (si $X_2, X_4$ og $X_5$). I R kan du estimere to modeller, en modell som *inkluderer* variablene (f.eks. `reg_stor`) og en modell der du tar bort de aktuelle variablene (f.eks. `reg_liten`). Du kan da kj칮re kommandoen `anova(reg_stor, reg_liten)` for 친 teste
$$H_0: \beta_2 = \beta_4 = \beta_5 = 0.$$


> **Kritikk av l칝reboken:** L칝reboken har en tabell p친 s. 701 som viser sammenhengen mellom ulike statistiske st칮rrelser som vi kan regne ut for en regresjonsmodell. $R^2$ kjenner vi som forklaringsgraden, $s_{\epsilon}$ er standardavviket til residualene, $F$ er testobservatoren for modellgyldighet som vi definerte uformelt over, og som er definert formelt nederst p친 s. 700, mens SSE (Sum of Squares Error) henger n칮ye sammen med standardavviket, som vi ogs친 kan se p친 s. 700. P친 disse sidene ser vi mange ligninger som viser hvordan disse st칮rrelsene formelt henger sammen, og i tabellen p친 s. 701 ser vi blant annet at dersom SSE er liten, er ogs친 $s_{\epsilon}$ liten, $R^2$ er n칝r null, og $F$-observatoren er stor. Det er greit nok, **men** de har en ekstra kolonne som sl친r fast at regresjonsmodellen er *good*. 

 > Her menes det **ikke** at regresjonsmodellen er *god* i den forstand at vi skal reagere med glede eller lettelse (slik noen gjerne gj칮r), men at variasjonen i datamaterialet i stor grad lar seg forklare av modellen v친r. I et tenkt eksempel der den sanne sammenhengen mellom $Y$ og $X$ er gitt ved $Y = \beta_0 + \beta_1X + \epsilon$, men der $\beta_1$ er forholdsvis liten og $s_{\epsilon}$ er relativt stor, vil f.eks. $R^2$ bli *liten*, selv om den enkle line칝re regresjonsmodellen repsesenterer sannheten og av alle tenkende mennesker m친 sies 친 v칝re *god*. 

> Det er desverre mange l칝reb칮ker som blander disse to fortolkningene, ikke gj칮r det!


Her er enda noen grunnleggende begreper. Har du f친tt med deg dette?

1. Hva mener vi med at en observasjon er innflytelsesrik?
1. Hva er grunnen til at vi trenger *justert* $R^2$ med flere forklaringsvariable?
1. Hva er forskjellen p친 *perfekt* og *tiln칝rmet* multikolinearitet i line칝r regresjon? Hva blir konsekvensen i hvert av tilfellene?
1. Kan du gi en praktisk og intuitiv forklaring p친 hvorfor multikolinearitet n칮dvendigvis m친 v칝re et problem?
1. Hva er forskjellen p친 statistisk og 칮konomisk signifikans? Kan du sette opp konkrete eksempler der vi kan estimere statistisk signifikante, men ikke 칮konomisk signifikante effekter i multippel regresjon? Hva med den motsatte situasjonen, 칮konomisk signifikant, men ikke statistisk signifikant? 

Grunnleggende ferdigheter: Klarer du dette?

1. Bruke R til 친 tilpasse en multippel regresjonsmodell for et datasett?
1. Bruke R til 친 finne s칝rlig innflytelsesrike observasjoner?
1. Tolke en multippel regresjonsutskrift?

## Modellbygging

### Videoforelesninger

<div style='padding:75.21% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7793253/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Kapittel **18** dekker de grunnleggende begrepene innen modellbygging. I kap. **18.1** snakkes det om polynomiske modeller, i kap. **18.2** behandles dummyvariabler. Kapittel **18.3** og **18.4** handler om hvordan vi i praksis kan jobbe for 친 velge ut variable i en gitt situasjon. Forelesningene dekker i grunn greit det vi skal f친 med oss her. Som en sjekk om du har f친tt med deg det vesentlige, kan du svare p친 f칮lgende sp칮rsm친l:

1. Vi har l칝rt tre typer log-transformasjoner. Hva blir fortolkningen av koeffisientene for hver av disse?
1. Kan du nevne tre gode grunner til at log-transformasjoner er nyttige?
1. Hvorfor sier vi at f칮lgende modell er line칝r? $Y = \beta_0 + \beta_1X + \beta_1X^2 + \varepsilon$
1. Vil vi ikke f친 problemer med multikolinearitet i modellen over?
1. Nevn en veldig god grunn til at vi m친 v칝re ytterst forsiktig med polynomtransformasjoner.
1. Hva er en dummyvariabel? 
1. Hva er fortolkningen av regresjonskoeffisienten til en dummyvariabel?
1. Hva er fortolkningen av regresjonskoeffisienten til et interaksjonsledd mellom m친levariabelen $X$ og dummyvariabelen $D$?
1. Et utrolig viktig poeng, men bruk tid til 친 tenke over og formulere et svar: Hvorfor er det viktig 친 tenke p친 *multippel testing* i sammenheng med *variabelutvelgelse*?

Grunnleggende ferdigheter: Klarer du dette?

1. Bruke logtransformasjoner i R?
1. Bruke poynomtransformasjner i R?
1. Sette opp en fornuftig regresjonsmodell ved 친 ta utgangspunkt i et datasett og et analyseform친l, og argumentere godt for dine valg? **Denne ferdigheten har blitt testet p친 hver eneste hjemmeeksamen i manns minne!**

## Oppgaver

I tabellen under finner du noen oppgaver som du kan bryne deg p친 for 친 sjekke forst친elsen din og trene p친 metodene som vi har g친tt gjennom i denne modulen. Vi peker ogs친 p친 noen tidligere eksamensoppgaver som er relevante til denne tematikken, du finner oppgavene under seksjon \@ref(skoleeksamen).

Har du en eldre utgave av boken kan du laste ned [dette dokumentet]("oppgaver/Recommended exersices.doc") for en oversikt over oppgavenummer tilbake til 7. utgave.

<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Kapittel i l칝reboken </th>
   <th style="text-align:left;"> 11. Utgave </th>
   <th style="text-align:left;"> 10. Utgave </th>
   <th style="text-align:left;"> Relevante eksamensoppgaver </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 16. Enkel regresjon </td>
   <td style="text-align:left;"> 1, 4, 8, 17, 26, 30, 52, 61, 80 , 84, 93 </td>
   <td style="text-align:left;"> 1, 4, 8, 26, 30, 48, 52, 70, 74, 83 </td>
   <td style="text-align:left;"> H10:1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 17. Multippel regresjon </td>
   <td style="text-align:left;"> 2, 6, 10, 31, 50, 52, 54 </td>
   <td style="text-align:left;"> 2, 6, 10, 29, 46, 48, 50 </td>
   <td style="text-align:left;"> H15:1, V13:2, H08:2, V11:1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 18. Modellbygging </td>
   <td style="text-align:left;"> 2 8, 16, 19, 20, 34 </td>
   <td style="text-align:left;"> 2 8, 16, 19, 20, 34 </td>
   <td style="text-align:left;"> V15:1, V12:2, V10, 2a-f </td>
  </tr>
</tbody>
</table>




<!--chapter:end:04-regresjon.Rmd-->


# Avansert regresjon og maskinl칝ring

I denne modulen tar vi en titt p친 noen litt mer avanserte statistiske metoder. De to f칮rste temaene, logistisk regresjon og "K-nearest-neighbor"-metoden (kNN), har til felles at de kan brukes n친r responsvariabelen er en kategorisk variabel med kun to kategorier. Begge disse metodene faller inn under det som popul칝rt kalles maskinl칝ring og er s친ledes en introduksjon til dette temaet. I det siste temaet, paneldata, skal vi se hvordan vi kan bygge regresjonsmodeller n친r hvert individ er observert flere ganger etter hverandre i tid. 

## Logistisk regresjon

### Videoforelesninger

<div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7802418/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l

* I hvilke situasjoner bruker vi logistisk regresjon?
* Hva er det vi modellerer?
* Hvordan tolker vi 칟n enhets 칮kning i forklaringsvariabelen?
* Hvilken metode brukes til 친 estimere en logistisk regresjonsmodell?
* Hva betyr klassifisering og hvordan gj칮res dette?
* Hvis vi har flere modeller, hvilke(n) metode(r) kan vi bruker til 친 velge den beste?

### Teori

I denne forelesningen ser vi p친 situasjonen der vi 칮nsker 친 forklare utfallet av en *bin칝r* variabel (en dummyvariabel) ved hjelp av et sett med forklaringsvariabler. Vi s친 at vanlig line칝r regresjon ikke er s칝rlig passende her fordi utfallet bare kan ta to verdier (0 eller 1, `FALSE` eller `TRUE` etc.), og fordi vi heller ikke kan tolke et kontinuerlig utfall direkte som en sannsynlighet fordi vi kan f친 ut verdier utenfor intervallet $[0, 1]$.

L칮sningen er 친 heller forklare *log-oddsen til suksessansynligheten*. Sagt p친 en annen m친te: p친 venstresiden i regresjonsligningen plasserer vi en *transformasjon* av suksessansynligheten, som gir oss en kontinuerlig variabel som kun kan variere mellom 0 og 1.

Pensumboken v친r behandler desverre ikke logistisk regresjon. Heldigvis finnes det et meget godt alternativ, *An Introduction to Statistical Learning* (ISLR)  av James m.fl. som kan lastes ned gratis her:

[An introduction to statistical learning](http://faculty.marshall.usc.edu/gareth-james/ISL/)

Denne boken er for 칮vrig pensum i **BAN404**. Logistisk regresjon er omhandlet i kapittel *4.3* (avsnitt 4.3.5 er ikke pensum). Eksempelet v친rt er tatt herfra, og datasettet er, som vist i forelesningsscriptet, inkludert i bokens egen R-pakke `ISLR`.

Bruk litt tid p친 친 lese gjennom disse sidene, konseptet er ganske godt forklart. Bli ogs친 kjent med R-syntaksen, som ligner p친 den vi allerede kan for vanlig line칝r regresjon. Vi bruker f.eks.


```r
reg1 <- glm(default ~ balance, 
            data = Default,
            family = "binomial")
```

N친r du er klar til 친 pr칮ve selv, kan du se p친 oppg *10a*, *b* og f칮rste del av *d* p친 s. 171 i ISLR. Dette datasettet er ogs친 inneholdt i `ISLR`-pakken.

## Introduksjon til maskinl칝ring med kNN

### Videoforelesninger

<div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7802427/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l

* For hvilke typer responsvariabler bruker vi KNN?
* Hvordan fungerer KNN teoretisk sett?
* Hva er den praktiske tolkningen av KNN?
* Hvordan p친virker valget av $k$ m친ten KNN fungerer p친?
* Hvordan velger vi $k$?

### Teori

Kanskje har du allerede h칮rt om maskinl칝ring, "data science", prediktiv modellering, "business analytics", etc., og kanskje har du f친tt med deg at disse tingene virkelig er i vinden for tiden. Som akademisk institusjon skal vi selvsagt v칝re p친 vakt mot 친 la popularitet v칝re en avgj칮rende faktor for hva vi driver med, men, som en kollega s친 treffende uttrykte seg: "Internett er kommet for 친 bli." Det skjer utrolig mye verdiskapning n친r vi f친r tak i den verdifulle informasjonen som ligger gjemt i de store datamengdene, og n칝ringslivet skriker etter kompetanse. NHH har som svar p친 dette opprettet masterprofilen "Business Analytics (BAN)" (som ironisk nok er blitt superpopul칝r!), og det er naturlig 친 gi en liten smakebit p친 hva det g친r ut p친 i MET4. Det herlige er at vi ikke trenger 친 dykke s친 dypt i detaljene for 친 f친 brukbar innsikt i hva som skjer.

Overgangen fra logistisk regresjon er naturlig. Vi bruker det vi kan fra regresjonsanalyse til 친 sette opp en modell der vi *forklarer* utfallet i en dummyvariabel ved hjelp av et sett forklaringsvariable i allerede observerte data. I f칮rste omgang kan vi si at den moderne anvendelsen av logistisk regresjon (kall det gjerne en form for maskinl칝ring) er 친 bruke data til 친 estimere sammenhengen mellom $X$-ene og responsvariabelen $Y$, og s친 bruke denne sammengengen til 친 predikere $Y$ for nye $X$.

Artikkelen [*To explain or to predict* av Galit Shmueli](https://projecteuclid.org/euclid.ss/1294167961) forklarer distinksjonen mellom det 친 forklare og det 친 predikere godt, og skal v칝re noenlunde lesbar for en interessert student.

Eksempelet fra logistisk regresjon er et godt eksempel p친 en anvendelse: Vi predikerer sannsynligheten for at kunder vil misligholde gjelden i fremtiden, basert p친 karakteristika vi kan observere n친. Slike sannsynligheter kan vi mate inn i en strategisk analyse for 친 bestemme oss hvem som skal f친 innvilget nye l친n, men p친 en systematisk m친te der vi s칮rger for at vi oppn친r n칮dvendige profittmarginer og h친ndterer risiko p친 en fornuftig m친te, og kan ta hensyn til f.eks. etiske avveininger. Selv om vi ut fra eget behov for profitt og innenfor en akseptabel risikoprofil kan tilby nye l친n til kunder med 15% sannsynlighet for 친 havne i betalingsproblemer, b칮r vi likevel gj칮re det? *Poenget her er at du ikke kan gj칮re slike vurderinger f칮r du faktisk kan estimere sannsynligheten for mislighold!* Statistikken er bunnplanken, og blir mer og mer relevant etter hvert som vi innser at svarene ligger i 친 analysere data.

Vi g친r videre til et annet eksempel. En teleoperat칮r med abonnementskunder ser at det er en systematikk i hvilke kunder som sier opp avtalene sine. Ved 친 se p친 spredningsplottet under (r칮d prikk = kunde som har sagt opp abonnementet), ser det ut til at *nye* kunder med *dyre* abonnementer har en tendens til 친 forlate oss. Kan vi sette opp en klassifiseringsregel der som vi kan anvende p친 *alle* kundene v친re, som automatisk plukker ut kunder som har f.eks. mer enn 50% sannsynlighet for 친 si opp? Denne listen kan vi s친 sende videre til markedsavdelingen, som kan sette i verk forebyggende tiltak (f.eks. lokke de inn i bindende avtaler...?), og vi kan oppn친 en *umiddelbar* gevinst.

<div class="figure">
<img src="met4_files/figure-html/churn-1.png" alt="R칮de prikker er kunder som har sagt opp abbonnementet sitt, svarte prikker er kunder som ikke har gjort det. Finn den optimale avveiningen mellom systematikk og tilfeldig variasjon." width="672" />
<p class="caption">(\#fig:churn)R칮de prikker er kunder som har sagt opp abbonnementet sitt, svarte prikker er kunder som ikke har gjort det. Finn den optimale avveiningen mellom systematikk og tilfeldig variasjon.</p>
</div>

Vi kan angripe dette datasettet p친 to m친ter:

- Vi estimerer sannsynligheter ved hjelp av logistisk regresjon. Den stramme strukturen gj칮r at klassifiseringsgrensen alltid utgj칮r en rett linje i koordinatsystemet.
- Vi ser ogs친 p친 en annen klassifiseringsregel: kNN (*k* nearest neighbours), som ikke bruker sannsynlighetsmodeller eller regresjonsparametre til 친 klassifisere, men heller er en enkel regel basert p친 f칮lgende prinsipp:

> Hvis et flertall av kundene som er mest lik meg har sagt opp, er det mer enn 50% sannsynlig at ogs친 jeg vil si opp.

Her bruker vi litt tid p친 detaljer, men det handler i grunn bare om 친 lage en presis definisjom om hvem vi definerer som de kundene som ligner mest p친 meg, og svaret er de $k$ kundene som ligger n칝rmest meg i koordinatsystemet. 

P친 samme m친te som for logistisk regresjon kan vi lese mer om kNN i [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/). P친 s. 39--42 st친r det hvordan teknikken fungerer, og i forelesningsnotatene og det medf칮lgende scriptet ser vi hvordan det kan gj칮res i praksis.

N친r vi forst친r hvordan kNN fungerer, er neste steg 친 reflektere litt over hvordan vi har tenkt 친 velge parameteren $k$ i praksis. Vi s친 i forelesningen at:

- Vi kan ikke velge $k$ for liten. Da ser vi for mye p친 st칮y og tilfeldigheter. Vi kan enkelt tenke oss at jeg er en lavrisikokunde, selv om de to kundene som er n칝rmest meg i koordinatsystemet sa opp av en eller annen grunn. Hvis vi velger $k = 3$, vil jeg likevel bli klassifisert som h칮yrisiko og bli bombardert med un칮dvendig reklame (som i seg selv kan gj칮re stor skade!) Hadde vi heller valgt $k = 50$ eller $k=500$ ville disse to raringene ikke bli tatt hensyn til, men blitt dominert av alle andre i omr친det som faktisk ikke har sagt opp. Alts친: **vi kan ikke henge oss for mye opp i detaljene og den tilfeldige variasjonen!**

- Vi kan heller ikke velge $k$ for stor, for det vil til slutt n칝rme seg en situasjon det det bare blir en avstemning mellom alle kundene i datasettet. Det er flest kunder som ikke sier opp avtalen, s친 da blir alle kunder klassifisert som lavrisiko. Alts친: **vi vil heller ikke ignorere variasjonen i datamaterialet!** Hele poenget er jo 친 l칝re noe nyttig fra hvordan prikkene fordeler seg i koordinatsystemet.

I Figur \@ref(fig:churn) kan du pr칮ve f칮lgende: En liten $k$ svarer til 친 se n칮ye p친 figuren (putt hodet ditt helt inntil skjermen!), og virkelig legge merke til hvor hver eneste en av de r칮de prikkene befinner seg. 칀 velge en st칮rre $k$ svarer til 친 trekke lenger bort, og kanskje begynne 친 myse litt, slik at du f친r 칮ye p친 systematikken, nemlig at det r칮de dominerer nede til h칮yre i figuren. Til slutt st친r du i rommet ved siden av med lukkede 칮yne, og da ser du plutselig ingenting! Et eller annet sted i mellom der 칮nsker vi 친 v칝re.

*Kryssvalidering* er en systematisk og generell m친te 친 velge *k* for KNN (og tilsvarende parametre i andre maskinl칝ringsmetoder), som litt lenger enn 친 bare dele datasettet inn i trenings- og testdata [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) behandler temaet p친 s. 181--186, men det er forholdsvis teknisk og skrevet i lys av noen metoder som vi ikke har sett p친 i MET4. 

## Paneldata

### Videoforelesninger

<div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7802431/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l

* Hva er paneldata?
* Hva m친 vi ta hensyn til n친r vi analyserer paneldata?
* Hvordan ser en generell modell for paneldata ut?
* Hva er den konseptuelle forskjellen mellom faste og tilfeldige effekter?
* N친r kan vi bruke faste effekter?
* N친r kan vi bruke tilfeldige effekter?
* Finnes det en m친te 친 formelt teste om man skal bruke faste eller tilfeldige effekter? (obs: se helt nederst p친 denne siden for svaret p친 denne.)

### Teori og R

I denne forelesningen introduserer vi en ny datastruktur. Vi observerer flere individer (tversnittsdimensjonen) *gjentatte ganger* (tidsdimensjonen), og et slikt datasett kaller vi et *panel*, eller *paneldata*. Fordelen ved 친 jobbe med slike data er 친penbar: vi har mer informasjon og kan gjennomf칮re mer presise statistiske analyser. P친 den annen side m친 vi akseptere at en mer kompleks datastruktur gj칮r det n칮dvendig 친 innf칮re mer kompleks metodikk.

I gjennomgangen under bruker vi et liten del av dataene fra eksempelet som er beskrevet i videoene. 칒nsker du 친 f칮lge R-gjennomgangen laster du ned f칮lgende datasett:

- [`panel_liten.xls`](datasett/panel_liten.xls)

#### Struktur p친 Paneldata

Til n친 har vi typisk observert $n$ individer *en* gang. Hvis vi holder oss til eksempelet fra videoforelesningen, kan vi tenke oss at vi har spurt $n$ arbeidstakere om hvor mange timer de jobbet forrige 친r ($X$), og hvor mye de hadde i timel칮nn ($Y$). Da ville datasettet sett omtrent slik ut:

<img src="bilder/panel1.PNG" width="76" />

Her er $y_i$ timel칮nn til arbeidstaker nummer $i$, og $x_i$ er antall timer jobbet for arbeidstaker nummer $i$. Hvis vi s친 칮nsker 친 se om det er en sammenheng mellom disse to variablene, kan vi sette opp en enkel regresjonsmodell som vi har gjort f칮r:

\begin{equation}
y_i = \alpha + \beta x_i + \epsilon_i,
\label{p-ols}
\end{equation}
der vi gj칮r de vanlige antakelsene om homoskedastisitet, uavhengige feilledd, og selvsagt at forklaringsvariabelen er *eksogen*, dvs at de stokastiske variablene $X$ og $\epsilon$ er *uavhengige fra hverandre*. Hvis vi aksepterer det, s친 kan vi estimere $\beta$ ved hjelp av minste kvadreters metode (OLS - orinary least squares), som vi kan tolke som forventet 칮kning i timel칮nn ved 친 jobbe en time ekstra.

For paneldata har vi ikke lenger kun observert $n$ arbeidstakere 1 gang, men  spurt $N$ arbeidstakere $T$ ganger, slik at vi trenger to indekser til 친 identifisere hver enkelt observasjon: $y_{i,t}$ er timel칮nn til arbeidstaker nummer $i$ ved tidspunkt $t$. V친re observerte $X$er og $Y$er kan vi samle i en tabell som f칮r, se illustrasjonen under. Legg merke til at det bare er de to f칮rste kolonnene for $X$ og $Y$ som utgj칮r de faktiske observasjonene, mens de to neste kolonnene sier hvilket individ som er observert, og ved hvilket tidspunkt observasjonen er utf칮rt, og viser bare indeksene til $X$- og $Y$-observasjonene. Kall det gjerne *metadata*, og vi trenger den informasjonen n친r vi skal utf칮re paneldatateknikker.

<img src="bilder/panel2.PNG" width="492" />

Formatet i tabellen over kalles gjerne et *langt* format, og omtrent samtlige R-pakker og funksjoner som brukes til 친 analysere panel data forventer at dataene er organisert p친 denne m친ten.

Vi kan ta en titt p친 hvordan dette ser ut i R for eksempelet v친rt:


```r
df <- read.csv("panel_liten.csv")              # Leser inn datasettet
head(df)                                       # Ser p친 datasettet
```


```
##      X lnhr lnwg kids age disab id year  mlhr  mlwg   dlhr    dwg
## 1 5241 7.71 3.19    0  30     0  1 1979 7.742 3.218 -0.032 -0.028
## 2 5242 7.64 3.14    0  32     0  1 1980 7.742 3.218 -0.102 -0.078
## 3 5243 7.71 3.11    0  33     0  1 1981 7.742 3.218 -0.032 -0.108
## 4 5244 7.72 3.00    0  34     0  1 1982 7.742 3.218 -0.022 -0.218
## 5 5245 7.72 2.94    0  35     0  1 1983 7.742 3.218 -0.022 -0.278
## 6 5246 7.73 3.12    1  35     0  1 1984 7.742 3.218 -0.012 -0.098
```

Her svarer `lnwg`til responsvariabelen (log) l칮nn og `lnhr` til forklaringsvariabelen (log) antall timer jobbet. Legg merke til at det er en egen kolonne med navn `id` som forteller oss hvilket individ observasjonene gjelder for. Dette svarer til $i$-indeksen i notasjonen over. Det er ogs친 en egen kolonne kalt `year` som forteller oss hvilket 친r observasjonen er fra, og dette svarer til $t$-indeksen. F.eks er f칮rste rad observasjoner gjort for individ nr. 1 i 친r 1979.    

#### Hva m친 vi ta hensyn til?

Hovedmotivasjonen for 친 analysere paneldata er enn친 친 unders칮ke sammenhengen mellom respons og forklaringsvariabelen. En slik m친te 친 samle inn data p친 gir f.eks mer innformasjon om sammenhengen mellom timel칮nn og antall arbeidstimer fordi vi har flere observasjoner enn om vi bare betraktet en observasjon per individ. Men siden vi har gjentatte observasjoner over tid kan responsvariablene v칝re avhengige. Vi kan se for oss to grunner til dette:

1. En utvikling i tid som er felles for alle individene; Det er f.eks tenkelig at det er en generell utvikling i l칮nnsniv친et over tid, eller at det f.eks finnes *gode* 친r hvor alle tjener spesielt godt. 
2. De gjentatte observasjonene for ett gitt individ vil typisk v칝re avhengige; Har et individ h칮y inntekt det ene 친ret er det tenkelig at det ogs친 har h칮y inntekt det neste 친ret. Denne effekten kan misforst친s som en effekt av forklaringsvariabelen.  
 
 Alts친 m친 vi b친de ta hensyn til at det kan v칝re en *generell* utvikling i tid og at det kan v칝re  *individuelt*  forskjellige l칮nnsniv친. Disse aspektene kan nemlig p친virke v친rt estimat av effekten av 친 jobbe mer dersom vi bruker den tradisjonelle regresjonsmodellen og OLS.

La oss inspisere de $3$ individene vi har data for i v친rt lille datasett ved 친 lage et figur med l칮nnsutvikling (`lnwg`) langs y-aksen og 친r (`year`) langs x-aksen for 친 se om det finnes et slags felles m칮nster i l칮nnsutviklingen (ref. punkt 1. over):


```r
library(ggplot2)  
ggplot(df) +
  geom_point(aes(x = year, y = lnwg, color = factor(id)))
```

<img src="met4_files/figure-html/unnamed-chunk-51-1.png" width="672" />

her ser vi f.eks at alle individene har et d친rlig 친r i 1983, mens 1985 virker 친 v칝re et godt 친r. Det ogs친 tydelig at l칮nnen holder seg relavivt lik l칮nnen det foreg친ende 친ret. Det er alts친 rimelig 친 tro at det er fellestrekk i l칮nnen til individene for gitte 친r.
 
La oss s친 lage et spredningsplott mellom `lnhr` og `lnwg` hvor vi fargelegger hvilket individ observasjonene kommer fra:
 

```r
library(ggplot2)  
ggplot(df) +
  geom_point(aes(x = lnhr, y = lnwg, color = factor(id)))
```

<img src="met4_files/figure-html/unnamed-chunk-52-1.png" width="672" />

Ser vi p친 disse dataene samlet sett ser du til 친 v칝re en klart positiv korrelasjon mellom l칮nn og antall timer jobbet. Men legg merke til at individ nr. 1  ligger p친 et h칮yere l칮nnsniv친 og jobber mer enn de to andre individene. Det er dette som i stor grad skaper et bilde av en sterk positiv sammenheng mellom variablene. Hvis vi ser p친 de individuelle observasjonene (hver fargesky) hver for seg, virker ikke sammenhengen 친 v칝re like sterk, og det har kanskje ikke like mye 친 si for l칮nnen om du individuelt velger 친 jobber mer. Dette svarer til fenomenet beskrevet i punkt 2. over.   

#### Generelt oppsett av modell

Effektene av de fenomene vi beskrev over kan vi ta hensyn til ved 친 *inkludere* dem i regresjonsmodellen p친 f칮lgende m친te: 
 
 $$y_{it} = \beta_0 + \beta_1 x_{it} + v_t + \alpha_i + \epsilon_{it} $$
hvor vi n친 har lagt til to nye ledd, $v_t$ og $\alpha_i$, i modellen:

1. Her representerer $v_t$ den generelle utviklingen i tid som er felles for alle individene (det er ingen "i"-indeks i denne). Det kan f.eks v칝re en line칝r trend ($v_t = \delta t$) eller helt unike 친rlige effekter $v_t$, som fanger opp *gode* og *d친rlige* 친r. 

2. Leddene $\alpha_i$ representerer s친 de individuelle l칮nnsniv친ene (disse er "i" indeksert). Har individ $1$ h칮yere l칮nn enn individ $2$ s친 vil $\alpha_1$ blir estimert til 친 v칝re st칮rre enn $\alpha_2$. 

Vi justerer alts친 for at individer kan ligge p친 et forskjellig l칮nnsniv친, og at det er en felles 친rlige variasjoner i l칮nn. I praksis betyr dette at vi justerer regresjonslinjen *vertikalt* slik at den tilpasser seg l칮nnsniv친et til hvert individ. Effekten $\beta_1$ av 친 jobbe mer er derimot antatt lik for hvert individ og den estimerte effekten vil da bli et slags gjennomsnitt av hvor mye det individuelt l칮nner seg 친 jobbe mer.

I utgangspunktet kan vi betrakte $v_t$ og $\alpha_i$ som kategoriske variabler som kan estimeres ved hjelp av dummyvariabler slik vi har l칝rt f칮r. Problemet er at i et tradisjonelt paneldatasett s친 er $N$ (antall individer) et stort tall, mens $T$ (antall observasjoner per individ) et relativt lite tall. Dette f칮rer til sv칝rt mange kategoriske variabler $\alpha_i$ 친 estimere, og i praksis m친 vi derfor betrakte andre metoder. Vi noterer oss f칮lgende:

* Egenskapene til $\alpha_i$ bestemmer typen paneldatamodell og vi deler disse modellene grovt sett inn i modeller med *faste effekter* og *tilfeldige effekter*. Selve ligningene vil alts친 se like ut, men tolkning og estimering er forskjellig.

* Leddene $v_t$ vil vi i de fleste tilfeller klare 친 estimere som kategoriske variabler og i fortsettelsen ser vi bort fra dette leddet 

* For enkelthets skyld betrakter vi bare 칟n forklaringsvariabel, men det kan selvsagt v칝re flere forklaringsvariabler i en regresjonsmodell for panel data ogs친.    

#### Forskjellige parameteriseringer

Merk at det b친de i l칝reb칮ker og i forskjellige R-pakker veksles mellom 친 to typer formuleringer av den generelle modellen over. Hvis vi ser bort fra $v_t$ leddet, er modellen vi til n친 har betraktet formulert som:

\begin{align}
y_{it} = \beta_0 + \beta_1 x_{it}  + \alpha_i + \epsilon_{it} 
(\#eq:withb)
\end{align}

hvor $\beta_0$ er inkludert. Her kan $\beta_0$ tolkes som det *gjennomsnittlige* skj칝ringspunktet med y-aksen blant de individuelle regresjonslinjene, mens $\beta_0 + \alpha_i$ vil v칝re skj칝ringspunktet med y-aksen for individ nr. $i$. Men det er ogs친 sv칝rt vanlig (og kanskje litt lettere) 친 formulere modellen uten $\beta_0$: 

\begin{align}
y_{it} = \beta_1 x_{it}  + \alpha_i + \epsilon_{it} 
(\#eq:withoutb)
\end{align}

og da vil $\alpha_i$ v칝re det individuelle skj칝ringspunktet med y-aksen for individ nr. $i$. Forskjellen er rett og slett tolkningsmessig. I videoen for faste effekter g친r vi igjennom estimeringen av begge modellene, men under betrakter vi bare estimering av sistnevnte modell n친r vi bruker faste effekter. Dette gj칮r vi siden modellen i R er definert p친 denne m친ten. N친r vi s친 ser p친 *tilfeldige effekter* vil vi av samme grunn betrakte modell \@ref(eq:withb). 

#### Faste effekter
 
I en modell med *faste effekter* betrakter vi $\alpha_i$ leddene som *faste st칮rrelser* som m친 estimeres. Denne modellen er omtrent alltid gyldig og kan brukes selv om vi tror de individuelle forskjellene $\alpha_i$ er relativt store og at det er avhengighet mellom forklaringsvariabelen(e) og $\alpha_i$.

 I modellen v친r som er formulert som

 $$y_{it} = \beta_1 x_{it}  + \alpha_i + \epsilon_{it} $$

skal vi alts친 estimere $\alpha_1, \alpha_2, ..., \alpha_N$ samt effekten av det 친 jobbe mer $\beta_1$.  Det finnes en rekke estimeringsteknikker og vi vil her (og i videoen) bare beskrive en metode. 

Vi begynner med 친 ta tidsgjennomsnittet av ligningen over for hvert individ: 

$$1/T \sum_{t = 1}^T y_{it} = 1/T \sum_{t = 1}^T \beta_1 x_{it} + 1/T \sum_{t = 1}^T \alpha_i + 1/T \sum_{t = 1}^T \epsilon_{it}$$
Her vil tidsgjennomsnittet av $\alpha_i$ bare v칝re $\alpha_i$ siden dette leddet ikke varierer med tiden. Alts친 kan vi skrive ligningen over som:

\begin{align}
\overline{y}_{i} = \beta_1\overline{x}_i + \alpha_i + \overline{\epsilon}_i
(\#eq:timemean)
\end{align}

Her er henholdsvis $\overline{y}_i$ og $\overline{x}_i$ den gjennomsnittlige l칮nnen og antall timer jobbet for individ nr. i, og dette er st칮rrelser vi kan regne ut. Vi tar s친 v친r originale modell 친 trekker fra denne ligningen:

$$y_{it} - \overline{y}_{i}  = \beta_1(x_{it} - \overline{x}_i) + \alpha_i - \alpha_i +  \epsilon_{it} - \overline{\epsilon}_i$$
N칮kkelen her er at $\alpha_i$-leddene kansellerer hverandre og vi kan formulere en ligning helt uten disse leddene:

$$\tilde{y}_{it} = \beta_1\tilde{x}_{it} + \tilde{\epsilon}_{it},$$
hvor $\tilde{y}_{it} = y_{it} - \overline{y}_{i}$, $\tilde{x}_{it} = x_{it} - \overline{x}_{i}$ og $\tilde{\epsilon}_{it} =  \epsilon_{it} - \overline{\epsilon}_{i}$. 

Siden vi n친 ikke lenger har $\alpha_i$ i ligningen, og siden $\tilde{\epsilon}_{it}$ bare er et nytt feilledd sentrert rundt null, kan vi estimere $\beta_1$ ved vanlig OLS, alts친 velge den verdien $\hat{\beta}_1$ som minimerer:

$$\sum_{i=1}^N\sum_{t=1}^T(\tilde{y}_{it} - \beta_1\tilde{x}_{it})^2$$

Gitt et estimat av $\beta_1$ kan vi f친 estimater av $\alpha_1, \dots, \alpha_N$ ved 친  og ta forventning av den tidsgjennomsnittlige modellen \@ref(eq:timemean) (da forsvinner $\overline{\epsilon}_{it}$ leddet), erstatte $\beta_1$ med estimatet $\hat{\beta}_1$ og l칮se ligningen m.h.p $\alpha_i$.  

\begin{align}
\hat{\alpha}_1 &= \overline{y}_{1} - \hat{\beta}_1\overline{x}_1\\
\hat{\alpha}_2 &= \overline{y}_{2} - \hat{\beta}_1\overline{x}_2\\
&\vdots\\
\hat{\alpha}_N &= \overline{y}_{N} - \hat{\beta}_1\overline{x}_N\\
\end{align}

Sluttproduktet er derfor $N$ individuelle regresjonslinjer:

\begin{align}
y_{1t} &= \hat{\alpha}_1 + \hat{\beta}_1 x_{1t}   \\
y_{2t} &= \hat{\alpha}_2 + \hat{\beta}_1 x_{2t}   \\
&\vdots\\
y_{Nt} &= \hat{\alpha}_N + \hat{\beta}_1 x_{Nt}   \\
\end{align}

som har individuelle skj칝ringspunkt med $y$-aksen ($\hat{\alpha}_i$) for 친 justere for forskjellig l칮nnsniv친, men hvor *alle* observasjonene har blitt brukt til 친 estimere det felles stigningstallet $\hat{\beta}_1$. 

Det er verdt 친 merke seg at denne metoden ikke kan brukes dersom forklaringsvariabelen ikke varierer med tid (eksempelvis kj칮nn). Da vil nemlig $x_{it} - \overline{x}_i = x_{it} - x_{it} = 0$, og vi har derfor ingen mulighet til 친 estimere $\beta_1$ med OLS. 

Det finnes flere pakker som kan estimere slike modeller i R, men en veldig enkel pakke 친 bruke heter `plm`. Det f칮rste vi gj칮r er 친 laste pakken fors친 친 "oversette" dataene v친re til paneldata. P친 denne m친ten forst친r `plm` funksjonen hva som er individ indeksen og hva som er tidsinndeksen:


```r
library(plm)      # Pakke for 친 estimere faste effekter

# Oversetter til panel data frame
p.df <- pdata.frame(df,
                    index = c("id" ,"year"))
```

Syntaksen for 친 bruke `plm` funksjonen er sv칝rt lik den for `lm` og `glm`. For 친 bruke en modell med faste effekter m친 man huske 친 spesifiserer argumentet `model = "within"`:


```r
reg.fe <- plm(lnwg ~ lnhr,
              data = p.df,
              model = "within")
summary(reg.fe)
```

```
## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = lnwg ~ lnhr, data = p.df, model = "within")
## 
## Balanced Panel: n = 3, T = 10, N = 30
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -0.270016 -0.042538 -0.011427  0.051738  0.336355 
## 
## Coefficients:
##      Estimate Std. Error t-value Pr(>|t|)
## lnhr  0.36293    0.26210  1.3847   0.1779
## 
## Total Sum of Squares:    0.37546
## Residual Sum of Squares: 0.34967
## R-Squared:      0.068678
## Adj. R-Squared: -0.038782
## F-statistic: 1.91731 on 1 and 26 DF, p-value: 0.17792
```

Vi ser at den estimerte $\beta_1$ effekten av 친 jobbe mer estimeres til $0.36$. Vi kan ogs친 f친 ut estimatene for de faste effektene $\alpha_1$, $\alpha_2$ og $\alpha_3$: 


```r
fixef(reg.fe)
```

```
##         1         2         3 
##  0.408228 -0.062905 -0.279994
```

Det kan v칝re nyttig 친 ta en visuell innspeksjon p친 hvordan de individuelle regresjonskurvene passer til dataene:


```r
plot(reg.fe)
```

<img src="met4_files/figure-html/unnamed-chunk-56-1.png" width="672" />

Denne figuren viser ogs친 hvordan regresjonskurven ville sett ut dersom vi hadde sett bort fra paneldatastrukturen og brukt en helt vanlig (pooled) regresjonsmodell. Sammenlignet med modellen med faste faste effekter (within) s친 ville vi da estimert effekten av jobbe mer til 친 v칝re st칮rre. Selv om produktet her er $3$ individuelle regresjonsmodeller, presiserer vi at dette ikke er $3$ uavhengige analyser; alle observasjonene er brukt til 친 finne et estimat p친 $\beta_1$.        

Vi husker at det ogs친 kunne v칝re en felles tidskomponent $v_t$ i en slik modell og at denne kunne betraktes som en kategorisk variabel siden det typisk ikke er s친 mange ($T$) av disse. Vi kan derfor bare legge til `year`  som en ekstra (kategorisk) forklaringsvariabel forutsatt at den er koded som en `factor`:


```r
is.factor(p.df$year)
```

```
## [1] TRUE
```

```r
reg.fe <- plm(lnwg ~ lnhr + year,
              data = p.df,
              model = "within")
summary(reg.fe)
```

```
## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = lnwg ~ lnhr + year, data = p.df, model = "within")
## 
## Balanced Panel: n = 3, T = 10, N = 30
## 
## Residuals:
##       Min.    1st Qu.     Median    3rd Qu.       Max. 
## -0.1740253 -0.0689048  0.0054976  0.0668643  0.2081334 
## 
## Coefficients:
##           Estimate Std. Error t-value Pr(>|t|)
## lnhr      0.182181   0.317431  0.5739   0.5735
## year1980  0.030310   0.095869  0.3162   0.7557
## year1981  0.015762   0.095752  0.1646   0.8712
## year1982 -0.050297   0.095805 -0.5250   0.6064
## year1983 -0.063590   0.103765 -0.6128   0.5481
## year1984  0.031862   0.102964  0.3094   0.7607
## year1985  0.162429   0.095752  1.6964   0.1081
## year1986  0.066977   0.095869  0.6986   0.4942
## year1987  0.082429   0.095752  0.8609   0.4013
## year1988  0.087881   0.095682  0.9185   0.3712
## 
## Total Sum of Squares:    0.37546
## Residual Sum of Squares: 0.23334
## R-Squared:      0.37853
## Adj. R-Squared: -0.060163
## F-statistic: 1.03543 on 10 and 17 DF, p-value: 0.45624
```
For dette lekedatasettet kunne vi strengt tatt ogs친 betraktet $\alpha_i$-leddene som kategoriske variabler, men som sagt er som regel $N$ for stor til at dette lar seg gj칮re.


#### Tilfeldige effekter
Hovedmotivasjonen for analysen av paneldataene er 친 finne ut hva effekten av 친 jobbe mer er ($\beta_1$). Vi vet at det eksisterer individuelle effekter $\alpha_i$ som en konsekvens av datastrukturen, men vi er ikke n칮dvendigvis interessert i disse verdiene i seg selv.  

I motsetning til en modell med *faste effekter* hvor vi betraktet $\alpha_i$ som faste st칮rrelser,  vil vi i en modell med *tilfeldige effekter* betrakte disse som *tilfeldige variabler*. I en slik modell estimerer vi derfor heller *fordelingen* til disse effektene. En vanlig antagelse er da at

*$\alpha_i\sim N(0, \sigma_{\alpha}^2)$ dersom vi bruker parameteriseringen \@ref(eq:withb) med $\beta_0$ inkludert.  
* $\alpha_i\sim N(\beta_0, \sigma_{\alpha}^2)$ dersom vi bruker parameteriseringen \@ref(eq:withoutb) uten $\beta_0$.  

Variansen $\sigma_{\alpha}^2$ er da et m친l p친 *uobservert heterogenitet*; i dette tilfellet hvor stor variasjon det i l칮nnsniv친et mellom individene. Det ogs친 vanlig 친 anta at $\epsilon_{it}\sim N(0, \sigma_{\epsilon}^2)$, s친 i en slik modell skal vi alts친 estimere $\beta_1$ (og $\beta_0$), $\sigma_{\alpha}^2$ og $\sigma_{\epsilon}^2$. Vi bruker alts친 bare 칟n ekstra parameter ($\sigma_{\alpha}^2$) for 친 justere for forskjellen i l칮nnsniv친ene. Sammenligner vi dette med modellen med faste effekter der vi trengte $N$ ($\alpha_1, \alpha_2,\dots,\alpha_N$) ekstra parametre er dette en mye enklere modell.

En modell med tilfeldige effekter brukes dersom det er rimelig 친 anta at de individuelle effektene $\alpha_i$ er sm친 og uavhengig av forklaringsvariabelen(e). Dersom dette er oppfylt viser det seg at en kan f친 mer presise estimat av effekten vi egentlig er interessert i , $\beta_1$. Det finnes en rekke estimeringsmetoder og vi skal ikke g친 detaljer p친 noen her, men nevner:

* Varianter av minstekvadraters metode som kan minne om det vi gjorde for faste effekter.
* Sannsynlighetsmaksimeringsestimering.
* Bayesiansk estimering.

De to siste metodene er mye brukt for 친 estimere tilfeldige effekter. 

I R kan vi fortsatt bruke `plm`, men m친 endre `model` argumentet til `"random"`:


```r
# tilfeldig effekt modell
reg.re <- plm(lnwg ~ lnhr,
              data = p.df,
              model = "random")
summary(reg.re)
```

```
## Oneway (individual) effect Random Effect Model 
##    (Swamy-Arora's transformation)
## 
## Call:
## plm(formula = lnwg ~ lnhr, data = p.df, model = "random")
## 
## Balanced Panel: n = 3, T = 10, N = 30
## 
## Effects:
##                   var std.dev share
## idiosyncratic 0.01345 0.11597 0.356
## individual    0.02429 0.15586 0.644
## theta: 0.771
## 
## Residuals:
##      Min.   1st Qu.    Median   3rd Qu.      Max. 
## -0.182643 -0.082132 -0.017109  0.046306  0.421926 
## 
## Coefficients:
##             Estimate Std. Error z-value Pr(>|z|)  
## (Intercept) -1.35059    2.17414 -0.6212  0.53446  
## lnhr         0.54307    0.28506  1.9051  0.05677 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Total Sum of Squares:    0.53409
## Residual Sum of Squares: 0.47281
## R-Squared:      0.11475
## Adj. R-Squared: 0.083133
## Chisq: 3.62944 on 1 DF, p-value: 0.056766
```
I motsetningen til modellen vi estimerte med faste effekter er n친 parameteriseringen gjort med $\beta_0$ leddet inkludert (modell \@ref(eq:withb)) og vi ser at dette blir estimert til 친 v칝re $-1.35$. Videre estimeres effekten av 친 jobbe mer til $\hat{\beta}_1 = 0.54$. Litt lenger oppe i utskriften ser vi at  $\hat{\sigma}^2_{\alpha}= 0.0242$ ("individual"), mens $\hat{\sigma}^2_{\epsilon}= 0.0134$ ("idiosyncratic").   

#### Hausman test

En modell med faste effekter vil v칝re mulig 친 bruke i alle tilfeller, mens en modell med tilfeldige effekter har strengere krav til hvordan disse individuelle effektene oppf칮rer seg. Dersom disse er oppfylt er det en fordel 친 bruke en modell med tilfeldige effekter. 

En strategi for 친 finne riktig modell er 친 estimere begge modellene fors친 친 utf칮re en s친kalt Hausman test. Nullhypotesen er da at den riktige modellen er den med tilfeldige effekter. Forkaster vi bruker vi modellen med faste effekter, forkaster vi ikke bruker vi modellen med tilfeldige effekter.

I R utf칮rer vi testen slik:


```r
# Hausman test
phtest(reg.fe, reg.re)
```

```
## 
## 	Hausman Test
## 
## data:  lnwg ~ lnhr + year
## chisq = 6.6775, df = 1, p-value = 0.009764
## alternative hypothesis: one model is inconsistent
```
Siden vi f친r forkastning vil den beste modellen for dette (leke-) datasettet v칝re modellen med faste effekter.

## Regneoppgaver

### Oppgaver om logistisk regresjon

Kommentar: Oppgave 1 a) og oppgave 2) er sv칝rt like i *hva* du skal gj칮re, bare at den siste er mer realistisk.

**Oppgave 1 **

Du har estimert en logistisk regresjonsmodell med to forklaringsvariabler $x_1$ og $x_2$. Koeffisientene i modellen er estimert til $\hat{\beta}_0 = 0.4$, $\hat{\beta}_1 = -0.1$ og $\hat{\beta}_2 = 0.3$. Du observerer s친 et nytt individ med forklaringsvariablene $x_1 = 1$ og $x_2 = 2$. 

a) Prediker sannsynlighet for at $Y=1$ for dette individet.

<details><summary>L칮sning</summary>

$$z = \beta_0 + \beta_1x_1 + \beta_2x_2 = 0.4 -0.1\times1 + 0.3\times2 = 0.9$$
Den predikerte *sannsynligheten* er gitt ved f칮lgende sammenheng:

$$P(Y=1|Z=z) = \frac{e^z}{1+e^z} = \frac{e^{0.9}}{1 + e^{0.9}} \approx 0.71.$$
</details>



b) Klassifiser det nye individet.

<details><summary>L칮sning</summary>
Siden vi estimerer $P(Y=1)$ til 친 v칝re $0.71$ som er st칮rre enn $0.5$ klassifiserer vi dette individet til $\hat{y}=1$. Avhengig av kontekst, kan det v칝re relevant 친 bruke enn h칮yere eller lavere terskel enn $0.5$, men dette er alts친 standardverdien.
</details>


**Oppgave 2 (Individuell Eksamen V2020 1 i))**

Denne eksamensoppgaven handlet om luftforurensning der myndighetene bruker en m친lestasjon for 친 advare innbyggerne dersom konsentrasjonen av nitrogendioksid (NO$_2$) overstiger 100 $\mu\textrm{g}/\textrm{m}^3$. I en av deloppgavene tilpasses det en logistisk regresjonsmodell der responsvariabelen er en dummyvariabelen `danger_warning`, som indikerer om gjenomsnittskonsentrasjonen av NO$_2$ den aktuelle dagen oversteg 100 $\mu\textrm{g}/\textrm{m}^3$. Dersom det skjer m친 myndighetene utstede et s친kalt gult farevarsel. Den estimerte modellen er gitt i kolonne (2) i tabellen under.

..... I morgen er det l칮rdag 16. mai, og i den aktuelle byen er det meldt en gjennomsnittlig temperatur p친 19 $^\circ$C og en gjennomsnittlig relativ luftfuktighet p친 47%. 

i) Bruk den logistiske regresjonsmodellen til 친 predikere *sannsynligheten* for at gjennomsnittlig NO$\mathbf{_2}$-konsentrasjon overstiger 100 $\mu\textrm{g}/\textrm{m}^3$. Gi en kort vurdering om myndighetene b칮r utstede gult farevarsel. (Husk at luftfuktigheten er gitt p친 skala 0--100, og ikke 0--1).


<img src="bilder/logistisk_output.jpg" width="240" />

<details><summary>L칮sning</summary>

Den predikerte log-oddsen f친r vi ved 친 sette inn for variablene (l칮rdag, temperatur, fuktighet, vinterdummyen er null):

$$z = 5.052 + -2.292 - 0.086*19 - 0.044*47 = -0.942.$$
Den predikerte *sannsynligheten* er gitt ved f칮lgende sammenheng:

$$P(Y=1|Z=z) = \frac{e^z}{1+e^z} = \frac{e^{-0.942}}{1 + e^{-0.942}} \approx 0.28.$$


Den predikerte sannsynligheten er klart under 50%, som passer godt med den tidlighere analysen v친r. Det er snakk om en forholdsvis varm l칮rdag i sommerhalv친ret, og vi vil nok ikke utstede farevarsel.

Det kan ogs친 v칝re gode argumenter for at vi ikke n칮dvendigvis bruker 50% som terskel for farevarsel. Kanskje er det mer alvorlig 친 *ikke* utstede et farevarsel som burde v칝rt sendt ut fordi det kan v칝re farlig for folk, enn 친 utstede et un칮dvendig farevarsel. F칮re var osv., og det kan tilsi at vi f.eks. bruker 40% eller 30% sannsynlighet som grense. Det kommer litt an p친 situasjonen, som vi ikke har full oversikt over her.

</details>

### Oppgaver om KNN

**Oppgave 1  (Individuell hjemmeeksamen H2020, oppgave 3)**

Vi har f칮lgende datasett med seks observasjoner best친ende av en bin칝r responsvariabel $y$ og to forklaringsvariabler $x_1$ og $x_2$:

<table>
<caption>(\#tab:knn)Datasett</caption>
 <thead>
  <tr>
   <th style="text-align:right;"> y </th>
   <th style="text-align:right;"> x1 </th>
   <th style="text-align:right;"> x2 </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 5 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 3 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 6 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 3 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:right;"> 2 </td>
  </tr>
</tbody>
</table>

Du observerer s친 forklaringsvariablene $(x_1, x_2) = (3, 3)$ for et nytt individ.

(a) Regn ut hva klassifiseringen av $y$ blir for det nye individet ved 친 bruke k-nearest neighbor (KNN), med $k=3$.

<details><summary>L칮sning</summary>

Vi begynner med 친 regne ut den euklidske avstanden mellom $(3,3)$ og alle punktene $(x_1, x_2)$ i datasettet v친rt. F.eks er avstanden mellom $(3,3)$ og $(3,4)$ 

\begin{equation*}
d((3,3), (3,4)) = \sqrt{(3 - 3)^2 + (3 - 4)^2} = 1
\end{equation*}

Vi kan s친 legge disse avstandene inn i en egen kolonne i tabellen:

<table>
<caption>(\#tab:knnfasit)Utregnede avstander</caption>
 <thead>
  <tr>
   <th style="text-align:right;"> y </th>
   <th style="text-align:right;"> x1 </th>
   <th style="text-align:right;"> x2 </th>
   <th style="text-align:right;"> avstand </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 1.000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 2.236 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 2.000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:right;"> 3.000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 1.000 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:right;"> 3.162 </td>
  </tr>
</tbody>
</table>

Vi ser da at observasjon $1$,$3$ og $5$ med avstander p친 h.h.v. $1$, $2$ og $1$ er de tre n칝rmeste naboene, og blant dem er det 2 mot 1 i flertall for 친 klassifisere $y$ som en 1'er. Alts친 er $\hat{y}=1$. 
  
Det g친r selvsagt an 친 l칮se oppgaven visuelt ogs친.

</details>


(b) Hvordan fungerer KNN n친r $k = n$, hvor $n$ er antall observajoner i datasettet? Hva vil skje dersom $k = 6$ for dette datasettet?

<details><summary>L칮sning</summary>

Siden vi bare har seks observasjoner vil alle verdier av $k\geq 6$ fullstendig ignorere informasjonen som ligger i forklaringsvariablene. Klassifiseringen vil da bare v칝re basert p친 om det totalt sett er mest 1'ere eller 0'ere. I dette spesifikke datasettet har vi totalt tre 1'ere og tre 0'ere, s친 enhver majortetsavstemning med $k\geq 6$ blir uavgjort. Alts친 vil det her ikke v칝re mulig 친 oppn친 flertall for verken 0'er eller 1'er for store verdier av $k$.

</details>

### Oppgaver om paneldata

**Oppgave 1**

For et paneldata best친ende av en responsvariabel $Y$ og en forklaringsvariabel $X$ har du estimert modellen

$$y_{it} =  \beta_1 x_{it}  + v_t + \alpha_i + \epsilon_{it} $$
der du har betraktet $\alpha_i$ som faste effekter og $v_t$ som kategoriske variabler. Estimatet av $\beta_1$ er $\hat{\beta}_1 = 1.5$. 

a) For individ $4$ i datasettet har du estimert $\alpha_4$ til 친 v칝re $0.2$. Videre er 친rseffekten for 2012, $v_{2012}$, estimert til 친 v칝re $-0.5$. Prediker responsvariabelen til dette individet for 2012 dersom $x_{4,2012} = 2$.

<details><summary>L칮sning</summary>
$$\hat{y}_{4,2012}=\hat{\beta}_1 x_{4,2012}  + \hat{v}_{2012} + \hat{\alpha}_4 = 1.5\times2 -0.5 + 0.2 = 2.7$$
</details>

b) Du tilpasser ogs친 en tilsvarende modell med tilfeldige effekter. En Hausman test gir en p-verdi p친 $0.23$. Hvilken modell skal du da bruke?

<details><summary>L칮sning</summary>

Forenklet sett har denne testen som nullhypotese at modellen med tilfeldige effekter er gyldig. Her er p-verdien veldig stor og vi har lite bevis for at denne nullhypotesen er feil. Vi kan alts친 bruke modellen med tilfeldige effekter. 

Dersom vi hadde f친tt forkastning ville det v칝rt lurt 친 bruke modellen med faste effekter.

</details>

**Oppgave 2**

Pr칮v deg p친 Oppgave 2 i den individuelle hjemmeeksamen H2020 som du finner i kapittel \@ref(skoleeksamen). Det er spesielt oppgave e) og f) som er relatert til paneldata, men vi bemerker at oppgave f) var "n칮tten" i det oppgavesettet.


<!--chapter:end:05-avansert-regresjon-og-maskinlaering.Rmd-->


# Tidsrekker

Vi er n친 klare for den siste modulen i MET4 som handler om tidsrekker. Opplegget er ganske likt det vi har hatt s친 langt i semesteret, men siden l칝reboken behandler dette stoffet s칝rs stemoderlig, har vi valgt 친 lage en litt annen variant.

I motsetning til modulene vi har jobbet med frem til n친, der vi separerte teorivideoene og data칮vingene, er disse to elementene n친 blandet sammen. Vi har delt stoffet opp i en serie overskrifter, der du finner videosnuttene fulgt av en guide til relevante R-funksjoner og noen oppgaver.

Det er alts친 ikke en *egen* data칮vingsoppgave til tidsrekker. Hvis du jobber grundig med stoffet p친 disse sidene, enten alene eller i grupper, vil du f친 et godt grunnlag i et viktig tema innen statistikk for 칮konomifag, som g친r igjen i mange empiriske kurs senere i studiet.

Fagl칝rer og studentassistenter vil v칝re tilgjengelig p친 vanlig m친te for konsultasjon, diskusjon og probleml칮sning.

Lykke til!

## Introduksjon til tidsrekker {#intro}

<div style='padding:75% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7660844/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l

1. Hvilke forskjeller er det mellom en tidsrekke og et sett med samtidige observasjoner?
2. Nevn noen typiske m칮nstre som vi kan se etter i en tidsrekke.
3. Hvorfor er det nyttig 친 identifisere slike m칮nstre?
4. Hvorfor kan det v칝re nyttig 친 glatte en tidsrekke?
5. Beskriv kort hvordan man regner ut et glidende gjennomsnitt.
6. Hvorfor kan vi ikke bruke det glidende gjennomsnittet til 친 predikere neste observasjon i en tidsrekke?
7. Beskriv kort hvordan eksponensiell glatting fungerer, og hvorfor denne teknikken kan brukes til prediksjon.

### Oppgaver fra l칝rebok 

**Keller: Statistics for Management and Economics, 11. utg**

**a)** Regn ut et glidende gjennomsnitt med vindusst칮rrelse 3 for f칮lgende tidsrekke:

![](bilder/oppgave1.jpg){#id .class width=80% height=80%}

**b)** Regn ut et glidende gjennomsnitt med vindusst칮rrelse 5 for tidsrekken over.

**c)** Tegn inn tidsrekken over med de to glattingene inn i samme figur.


**d)** Regn ut eksponensiell glatting for tidsrekken under med glattefaktor $w = 0.1$:

![](bilder/oppgave1b.jpg){#id .class width=80% height=80%}

**e)** Gjenta oppgaven over med glattefaktor $w = 0.8$.

**f)** Tegn tidsrekken over inn i samme figur som de to glattede versjonene. Ser det ut til 친 v칝re en trend i denne tidsrekken?

**bonussp칮rsm친l)** Hva blir prediksjonen av $Y_{11}$ n친r du bruker modellen i henholdsvis oppgave d) og e)? 

### R-칮ving

Vi har lastet [ned den daglige prisen p친 Eqinoraksjen](./equinor.xlsx) over en 5-친rs periode fra Oslo B칮rs' hjemmeside. Vi laster inn datasettet som f칮r ved hjelp av `readxl`-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker `rev()`-funksjonen til 친 reversere rekkef칮lgen til observasjonene slik at den f칮rste verdien komme f칮rst:


```r
library(readxl)
equinor <- read_excel("equinor.xlsx")
pris <- rev(equinor$Siste)                
```



Du kan s친 lage et raskt plott av tidsrekken:


```r
plot(pris, type = "l")
```

B친de glidende gjennomsnitt og eksponensiell glatting har flere ulike implementeringer i R. For glidende gjennomsnitt skal vi bruke funksjonen `rollmean()` i pakken `zoo`. Du m친 f칮rst installere pakken og laste den inn;


```r
install.packages("zoo")
library(zoo)
```


Hvis du leser litt p친 dokumentasjonen til `rollmean()` ved 친 kj칮re `?rollmean` vil du se at du kan regne ut f.eks et glidende gjennomsnitt for Equinoraksjen med vindusst칮rrelse 5 ved 친 kj칮re


```r
pris_glatt5 <- rollmean(pris, k = 5, fill = NA)
```

Da f친r vi ut en ny vektor med lik lengde som den vi hadde, og som inneholder den glattede versjonen. Den fyller opp verdiene i starten og slutten som vi ikke kan regne ut med et glidende gjennomsnitt med NA, slik at vi kan tegne inn den glattede versjonen i samme plott som vi viste selve tidsrekken:


```r
lines(pris_glatt5, col = "red")
```

Dersom du er interessert kan du lese mer [her](https://tradingsim.com/blog/simple-moving-average/) om hvordan det glidende gjennomsnittet blir brukt som en investeringsstrategi.

Tanken er at det glidende gjennomsnittet representerer den langsiktige trenden. Dersom tidrekken ligger under det glidende gjennomsnittet tolkes det som at aksjen er p친 vei nedover, og motsatt: dersom prisen ligger over det glidende gjennomsnittet, s친 er det et tegn p친 at aksjen er p친 vei oppover. N친r de to seriene krysser hverandre g친r "alarmen", og man tar stilling til om man skal kj칮pe eller selge. 

Vindusst칮rrelsen velger man ut fra hvor hyppig man handler. For profesjonelle investorer som driver med handel i h칮y hastighet kan kanskje 5-dagersviduet som vi regnet ut over v칝re nok. Andre med mellomlang og lang sikt vil gjerne bruke et vindu p친 50 eller 200 dager.

**Oppgave:** Regn ut et glidende gjennomsnitt med vindusst칮rrelse 200 for Equinoraksjen, og tegn det inn i figuren du har laget. Hjelper denne figuren deg til 친 lage en investeringsstrategi?

Et problem med analysen over  er at vi trenger *fremtidige observasjoner* til 친 regne ut den glattede tidsrekken. Det betyr at vi kjenner den glattede versjonen av tidsrekken ved tid $t$ f칮rst ved tid $t+200$. Vi kan enkelt lage en annen variant der vi glatter tidsrekken ved tid $t$ ved 친 ta gjennomsnittet av $Y_{t-200}, Y_{t-199}, \ldots, Y_{t-1}$ i stedet for $Y_{t-100}, \ldots, Y_{t}, \ldots, Y_{t+100}$, alts친 at vi bare bruker fortiden. Det gj칮r du i R ved 친 legge til det ekstra argumentet `align = "right"` i funksjonen `rollmean`. Fordelen n친 er at vi ved hvert tidspunkt kjenner b친de prisen p친 aksjen og den glattede varianten.

**Oppgave:** Regn ut et glidende gjennomsnitt med vindusst칮rrelse 200 for Equinoraksjen som hele tiden bruker tidligere observasjoner i glattingen. Tegn glattingen inn i figuren. Hvordan ser investeringsstrategien din ut n친?

**Eksponensiell glatting** har ogs친 et annet navn: Holt Winters Metode. En funksjon for 친 gjennomf칮re den finnes innebygget i R, og heter `HoltWinters()`. I denne funksjonen er vektparameteren $w$ representert ved argumentet `alpha`. Funksjonen har noen flere argumenter som ikke vi skal bruke, s친 dersom vi 칮nsker 친 regne ut den eksponensielle glattingen for Equinoraksjen med $w = 0.5$, kj칮rer vi:


```r
pris_exp1 <- HoltWinters(pris, alpha = .5, beta = FALSE, gamma = FALSE)
```

For 친 hente ut den glattede versjonen skriver vi


```r
pris_exp1$fitted[,"xhat"]
```

**Oppgave:** Lag en ny figur der du tegner inn aksjeprisen, samt den eksponensielle glattingen med hhv. $w = 0.5$, $w = 0.01$ og $w = 0.99$.

## Trend og sesong {#trend-og-sesong}

<iframe src="https://player.vimeo.com/video/467126794" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

### Kontrollsp칮rsm친l

1. Hvilke tre komponenter kan en tidsrekke typisk best친 av?

### R-칮ving

**1. Data.** I pakken `fpp` finnes en tidsrekke som heter `ausbeer`, som er den kvartalsvise produksjonen av 칮l i Australia fra 1956 til 2008. Du kan f친 tak i det og se p친 tidsrekken ved 친 kj칮re f칮lgende  kommandoer:


```r
install.packages("fpp")
library(fpp)
plot(ausbeer)
```

<img src="met4_files/figure-html/unnamed-chunk-71-1.png" width="672" />

Vi ser at det er en klar trendkomponent, selv om den ikke er line칝r, samt en 친rlig sesongvariasjon.


**2. Dekomponering.** Funksjonen `stl`  *dekomponerer* tidsrekken i de tre komponentene: trend, sesong, og tilfeldig variasjon. For 친 f친 tilgang p친 denne funskjonen trenger vi pakken `forecast`:



```r
install.packages("forecast")
library(forecast)
```

Vi s친 kan kj칮re funksjonen slik:


```r
dekomponert <- stl(ausbeer, s.window = "periodic")
```

Vi kan hente ut de ulike komponentene ved 친 bruke dollartegnet: `dekomponert$time.series`. Pakken `forecast` har en egen plottefunksjon, `autoplot` som er spesialdesignet for tidsrekkeobjekter. Pr칮v 친 plotte de tre komponentene hver for seg ved 친 kj칮re:


```r
autoplot(dekomponert)
```

<img src="met4_files/figure-html/unnamed-chunk-74-1.png" width="672" />

**3. Predikere.** For predikering bruker vi funksjonen `forecast()`, som tar en estimert modell som input, og som bruker modellen til 친 skrive frem tidsrekken ved 친 estimere fremtidige verdier. Dekomponeringen over utgj칮r ogs친 en modell som vi kan bruke til 친 predikere fremtidige observasjoner med.  

Kodesnutten under viser hvordan man predikerer $10$ tidssteg frem i tid ved 친 sette `h = 10` i funksjonen. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi `level = 0.95` for $95\%$ prediksjonsintervall. Resultatet lagrer vi i objektet `prediksjon`. Dette objektet kan vi plotte ved bruk av `autoplot`-funksjonen:


```r
prediksjon <- forecast(dekomponert, h = 10, level = 0.95)
autoplot(prediksjon)
```

<img src="met4_files/figure-html/unnamed-chunk-75-1.png" width="672" />

## AR(p) {#ar}

<div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7661169/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l

1. Hva er definisjonen p친 en Hvit-st칮y-prosess?
2. Hva er definisjonen p친 en AR(1)-prosess?
3. Hvilken effekt har parameteren $\phi$ p친 egenskapene til en AR(1)-prosess?
4. Hva er forskjellen p친 en AR(1)-prosess og en generell AR($p$)-prosess?
5. Hvorfor kan vi si at AR($p$) er en *utvidelse*/*generalisering* av hvit st칮y?

### R-칮ving

**1. Simulere.** La oss f칮rst se hvordan vi kan simulere noen realiseringer fra disse tidsrekkene. Hvit st칮y best친r av ukorrelerte trekninger som alle har samme forventningsverdi og varians, noe vi kan simulere i R ved 친 bare trekke $n$ uavhengige observasjoner fra hvilken som helst fordeling og kalle det en tidsrekke. For eksempel har vi tidligere trukket standard normalfordelte observasjoner ved hjelp av `rnorm()`-funsksjonen. La oss gj칮re det igjen, og plotte det som en tidsrekke. Merk at din trekning ikke vil v칝re identisk som den under:


```r
n <- 50
hvit_st칮y <- rnorm(n)
plot(hvit_st칮y, type = "b")
```

<img src="met4_files/figure-html/unnamed-chunk-76-1.png" width="672" />

Vi kan bruke funksjonen `arima.sim()` til 친 simulere tidsrekker fra AR-modellen (og den mer generelle ARIMA-modellen, mer om det senere). Du kan for eksempel simulere $n$ observasjoner fra en AR(1)-prosess med $\phi = 0.95$ ved hjelp av f칮lgende kommandoer:


```r
ar1 <- arima.sim(model = list(ar = 0.95), n)
plot(ar1, type = "b")
```

<img src="met4_files/figure-html/unnamed-chunk-77-1.png" width="672" />

I det siste eksempelet trekker `arima.sim()`-funskjonen hvit-st칮y-prosessen $u_t$ fra `rnorm()`-funksjonen, men det kan vi endre p친 hvis vi vil, se hjelpesiden `?arima.sim`. Videre kan vi bruke denne funksjonen til 친 simulere fra hvit st칮y ved 친 sette `model`-argumentet til en tom liste (`model = list()`), eller vi kan simulere fra en AR(2)-prosess med $\phi_1 = 0.2$ og $\phi_2 = 0.1$ ved 친 sette `model = list(ar = c(0.2, 0.1))`.

**2. Estimere.** 

La oss i f칮rste omgang si at vi har observert tidsrekken `ar1` som vi simulerte over, at vi mistenker at den f칮lger en AR(1)-prosess $Y_t = \phi Y_{t-1} + u_t$, og at vi 칮nsker 친 estimere den ukjente parameteren $\phi$ ved hjelp av observasjonene. Som vi antydet i **AR**-videoen kan vi i dette tilfellet betrakte det som et regresjonsproblem med $Y_t$ som responsvariabel og $Y_{t-1}$ som forklaringsvariabel. La oss lage en `data.frame` med disse to kolonnene, og se hva vi f친r n친r vi bruker `lm()`-funksjonen. .


```r
df <- data.frame(Y = ar1[2:n],
                 lagged_Y = ar1[1:(n-1)])
summary(lm(Y ~ lagged_Y, data = df))
```

```
## 
## Call:
## lm(formula = Y ~ lagged_Y, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5400 -0.6819 -0.1418  0.6725  1.9269 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  0.04664    0.13890   0.336    0.739    
## lagged_Y     0.87116    0.06494  13.415   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9106 on 47 degrees of freedom
## Multiple R-squared:  0.7929,	Adjusted R-squared:  0.7885 
## F-statistic:   180 on 1 and 47 DF,  p-value: < 2.2e-16
```

Vi ser at v친rt estimat av $\phi$, som i regresjonutskriften er koeffisienten til `lagged_Y`, er i n칝rheten av den sanne verdien 0.95, men med s친 f친 observasjoner kan det godt hende at ditt estimat er noe forskjellig. Poenget er: vi kan bruke line칝r regresjon til 친 estimere koeffisientene i en AR-modell basert p친 observasjoner. 


Som i forrige oppgave er pakken `forecast` sv칝rt nyttig for estimering og predikering:


```r
library(forecast)
```



Denne pakken inneholder en funskjon `Arima` for 친 estimere koeffisientene i en AR-modell (egentlig den mer generelle klasssen av ARIMA-modeller som vi kommer tilbake til senere). Denne funksjonen kan vi andvende direkte p친 tidsrekken ved 친 skrive


```r
Arima(ar1, order = c(1, 0, 0))
```

```
## Series: ar1 
## ARIMA(1,0,0) with non-zero mean 
## 
## Coefficients:
##          ar1    mean
##       0.8916  1.1769
## s.e.  0.0601  1.0403
## 
## sigma^2 estimated as 0.8496:  log likelihood=-66.64
## AIC=139.29   AICc=139.81   BIC=145.03
```
I f칮rste omgang kan vi legge merke til at vi har spesifisert *hvilken* modell vi 칮nsker 친 estimere gjennom argumentet `order = c(1, 0, 0)`, der ett-tallet angir AR-modellens orden $p$, som i dette tilfellet er 1. Dersom du mistenker at AR(2)-modellen gir en bedre beskrivelse av tidsrekken din, kan du endre til `order = c(2, 0, 0)`. Vi kommer tilbake til sp칮rsm친let om hvordan du kan velge den beste modellen for et gitt praktisk problem.

Legg merke til at de to estimatene ikke er identiske selv om vi bruker det samme tidsrekken. Det er fordi `arima()`-funksjonen ikke bruker minste kvadraters metode til 친 regne ut estimatene (slik `lm()` gj칮r), men heller bruker en annen estimeringsteknikk som heter *maximum likelihood*.

**3. Predikere.** For predikering bruker vi funksjonen `forecast()`, som tar en estimert modell som input, og som bruker modellen til 친 skrive frem tidsrekken ved 친 estimere fremtidige verdier.

I kodesnutten under bruker vi den simulerte tidsrekken, og estimerer en AR(1)-modell som over som vi lagrer i objektet `ar1_estimat`. S친 bruker vi det som argument i `forecast()`, der vi ogs친 spesifiserer hvor mange tidssteg fremover vi 칮nsker 친 predikere, her velger vi `h = 10`. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi `level = 0.95` for $95\%$ prediksjonsintervall.  Resultatet lagrer vi i objektet `prediksjon`.


```r
ar1_estimat <- Arima(ar1, order = c(1, 0, 0))
prediksjon  <- forecast(ar1_estimat, h = 10, level = 0.95) 
```

Vi kan plotte resultatet i en pen liten figur ved 친 bruke funksjonen `autoplot` som under:


```r
# Plotter den opprinnerlige tidsrekken, sammen med prediksjon og
# prediksjonsintervall
autoplot(prediksjon)
```

<img src="met4_files/figure-html/unnamed-chunk-83-1.png" width="672" />

## Stasjonaritet {#stasjonaritet}

<iframe src="https://player.vimeo.com/video/467126666" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

### Kontrollsp칮rsm친l

1. Hva er definisjonen p친 en stasjon칝r tidsrekke?
2. Hva er poenget med 친 innf칮re stasjonaritet som et konsept i tidsrekkeanalyse?
3. Er AR(1) prosessen $X_t = 1.5 X_{t - 1} + u_t$ stasjon칝r? 

### Merk

En AR-prosess kan vi definere ogs친 med et konstantledd $c$, f.eks: $Y_t = c + \phi Y_{t-1} + u_t$. Vi kan ikke forvente at alle tidsrekkene vi observerer i praksis vil ligge 친 variere rundt null (dvs at E$(Y_t) = 0$). Vi kan flytte den opp og ned ved 친 legge til den samme konstanten $c$ i hver tidssteg. I forrige oppgavesett, der vi estimerte parameteren $\phi$ i en AR(1)-modell, kom det (p친 samme m친te som n친r vi gj칮r regresjon) ut et estimat av et `intercept`, som alts친 er denne $c$'en. I den simulerte tidsrekken vi jobbet med der, var det ikke noe konstantledd (alts친, $c = 0$), som vi ser igjen i estimatene ved at de ikke er signifikant forskjellige fra null. Vi kunne tvunget estimeringsfunksjonene til 친 sette $c = 0$, f.eks ved 친 inkludere argumentet `include.mean = FALSE` i `arima()`-funksjonen.

## Autokorrelasjon {#autokorrelasjon}

<iframe src="https://player.vimeo.com/video/467120768" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

### Kontrollsp칮rsm친l/Diskusjonssp칮rsm친l

1. Formuler med egne ord: Hva er autokorrelasjon?
2. Hva kan vi l칝re ved 친 se p친 autokorrelasjonsplottet til en tidsrekke?
3. Kan du komme p친 noe vi *ikke* kan finne ut av ved 친 se p친 korrelasjoneplottet til en tidsrekke?

### R-칮ving

**1. Utregning av ACF** I R bruker vi funsksjonen `acf()` til 친 lage autokorrelasjonsplott. La oss i f칮rste omgang gjenskape noen av figurene fra videoen ved hjelp av simuleringer. For eksempel kan vi laget til to tidsrekker som p친 forrige oppgavesett, en hvit st칮y og en AR(1):


```r
n <- 50
hvit_st칮y <- rnorm(n)
ar1 <- arima.sim(model = list(ar = 0.95), n)
```

Autokorrelasjonsplottene til disse to tidsrekkene kan vi f친 frem ved 친 anvende `acf()`-funksjonen p친 dem:

<!-- ```{r fig.subcap=c('Autokorrelasjonsplott til en simulert hvit st칮y prosess', 'Autokorrelasjonsplott til en simulert AR(1)-prosess'), out.width='.49\\linewidth', fig.asp=1, fig.ncol = 2} -->
<!-- acf(hvit_st칮y) -->
<!-- acf(ar1) -->
<!-- ``` -->


```r
acf(hvit_st칮y)
```

<img src="met4_files/figure-html/unnamed-chunk-85-1.png" width="672" />

```r
acf(ar1)
```

<img src="met4_files/figure-html/unnamed-chunk-85-2.png" width="672" />

Vi ser igjen m칮nsteret fra videoen: Hvit st칮y best친r av ukorrelerte observasjoner, mens AR(1)-modellen best친r av observasjoner som bygger p친 forrige observasjon, slik at det er en viss korrelasjon, og dermed avhengighet fra dag til dag. Det ser vi igjen i autokorrelasjonsplottet som gir tydelig utslag, og der korrelasjonen g친r gradvis mot null med 칮kende avstand mellom observasjonene.

**2. ACF som sjekk av modell** En sjekk vi gjerne gj칮r for 친 se om en estimert tidsrekkemodell passer dataene v친re, er 친 se autokorrelasjonen til residualene i modellen er liten. Det betyr nemlig at modellen plukker opp den (line칝re) avhengigheten i tidsrekken. For en AR(1) modell er residualene f.eks gitt ved $\hat{u}_t = Y_t - \hat{\phi}Y_{t-1}$, men disse er tilgjengelig direkte fra modell estimeringen i R:


```r
library(forecast)
ar1_estimat <- Arima(ar1, order = c(1, 0, 0))
acf(ar1_estimat$residuals)
```

<img src="met4_files/figure-html/unnamed-chunk-86-1.png" width="672" />


**3. Oppgave:** Pr칮v n친 lage et plott av f칮lgende tre tidsrekker, plott autokorrelasjonsfunksjonen, og knytt en kort kommentar til hver av dem om hva du l칝rer om tidsrekken ved 친 se p친 autokorrelasjonsplottet til:

1. Prisen p친 Equinor-aksjen, som vi jobbet med i det f칮rste oppgavesettet.
2. Equinoraksjens *prosentvise avkastning* (som er tiln칝rmet lik `diff(log(pris))`) fra dag til dag.
3. Tidsrekken som er igjen etter at du fjernet trend og sesong fra 칮lproduksjonstidsrekken i det andre oppgavesettet.

Til slutt: husk at ogs친 autokorrelasjonsplottene m친 pyntes og ordnes p친 hvis vi skal vise dem til andre i rapporter, innleveringer etc. Du kan stort sett bruke de samme argumetene som i vanlige plott: `xlab = `, `ylab = `, `main = ` osv.



## MA(q) {#ma}

<iframe src="https://player.vimeo.com/video/467126617" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

### Kontrollsp칮rsm친l/Diskusjonssp칮rsm친l

1. Hva er definisjonen p친 en MA(1)- og en MA($q$)-modell?
2. Hvordan skiller definisjonen av en MA-prosess seg fra definisjonen av en AR-prosess?
3. P친 hvilken m친te er autokorrelasjonsfunksjonene til AR- og MA-prosesser forskjellige?
4. Kan du, med egne ord, beskrive en type reelle fenomener som kan modelleres som en MA-prosess?

### R-칮ving

**1. Estimering og predikering.** P친 samme m친te som for AR-prosessen kan vi n친 **simulere** og **estimere** en MA(1)-prosess med $\theta = 0.95$:


```r
library(forecast)                                # Trengs for estimering
n    <- 100                                      # Antall observasjoner
ma1  <- arima.sim(model = list(ma = 0.95), n)    # Simuler tidsrekken
plot(ma1, type = "b")                            # Lag et plott 
Arima(ma1, order = c(0,0,1))                     # Estimer theta
```


Stemmer estimatet overens med den sanne $\theta$? Sjekk ut dokumentasjonen `?Arima` og se hva du m친 gj칮re for 친 spesifisere at modellen ikke har noe konstantledd $c$. Pr칮v ogs친 친 modifisere koden fra AR-oppgavene slik at du predikerer den simulerte MA(1)-tidsrekken 10 steg frem. 




**2. Analyse av global temperatur.** La oss n친r ta for oss eksempelet fra videoen der vi ser p친 den globale m친nendlige gjennomsnittstemperaturen fra 1880 til 2016. Last ned [temp.csv](datasett/temp.csv), som er en CSV-fil med datasettet. Se p친 de f칮rste par radene:


```r
temp <- read.csv("temp.csv")
head(temp)
```


```
##         Date    Mean
## 1 1880-01-06  0.0009
## 2 1880-02-06 -0.1229
## 3 1880-03-06 -0.1357
## 4 1880-04-06 -0.0499
## 5 1880-05-06 -0.0738
## 6 1880-06-06 -0.1692
```

F칮rste kolonne inneholder informasjon om tidspunkt, og temperaturen er inneholdt i andre kolonne. La oss plotte b친de temperaturrekken og den *differensierte* temperaturrekken (dvs. forskjellen fra dag til dag). Hvis vi avsl칮rer at den differensierte tidsrekken kan regnes ut ved 친 kj칮re `difftemp <- diff(temp$Mean)`, skulle det n친 v칝re grei skuring 친 produsere f칮lgende to enkle plott:


```r
difftemp <- diff(temp$Mean)
plot(temp$Mean, type = "l")
```

<img src="met4_files/figure-html/unnamed-chunk-93-1.png" width="672" />

```r
plot(difftemp, type = "l")
```

<img src="met4_files/figure-html/unnamed-chunk-93-2.png" width="672" />

Lag videre autokorrelasjonsplottet som vist i videoen for den differensierte tidsrekken:

<img src="met4_files/figure-html/unnamed-chunk-94-1.png" width="672" />

I autokorrelasjonsplottet ser vi nettopp et slikt MA-m칮nster som vi s친 i videoen; nemlig at autokorrelasjonen plutselig blir null (eller omtrent null) for et gitt lag. I dette tilfellet har vi at f칮rste ordens autokorrelasjon er klart forskjellig fra null, men at den fra og med $k = 2$ nesten ikke har utslag. 

Hvis de differensierte temperaturm친lingene faktisk er MA(1), kan den skrives slik:

$$Y_t = c + \theta u_{t-1} + u_t,$$
der $\theta$ er en ukjent parameter. Vi kan bruke datasettet v친rt til 친 estimere $\theta$ ved 친 bruke `Arima()`-funksjenen p친 samme m친te som da vi estimerte en AR(1)-modell. Den eneste forandringen vi m친 gj칮re er 친 endre `order`-argumentet fra `c(1, 0, 0)` til `c(0, 0, 1)`:


```r
Arima(difftemp, order = c(0, 0, 1))
```

```
## Series: difftemp 
## ARIMA(0,0,1) with non-zero mean 
## 
## Coefficients:
##           ma1    mean
##       -0.4988  0.0005
## s.e.   0.0251  0.0012
## 
## sigma^2 estimated as 0.009078:  log likelihood=1532.11
## AIC=-3058.23   AICc=-3058.21   BIC=-3042.01
```

Hvis du har tid til slutt og vil ha litt ekstra trening kan du pr칮ve deg p친 f칮lgende oppgave: 

- Prediker den differensierte temperaturrekken tre m친neder frem i tid.
- Lag en figur der du plotter de 12 siste m친nedene i den observerte tidsrekken sammen med prediksjonene dine med prediksjonsintervaller.
- **Bonuspoeng:** Husk at vi n친 har predikert *forandringen* i den globale gjennomsnittstemperaturen fra m친ned til m친ned. Kan du heller lage en figur med selve temperaturserien og bruke prediksjonene dine til 친 heller plotte inn de tilh칮rende predikerte temperaturene?
- Pynt s친 figuren slik at du kan sende den fra deg.

## ARMA og ARIMA {#arma-arima}

<div style='padding:56.25% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7661207/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kontrollsp칮rsm친l/Diskusjonssp칮rsm친l

1. Hva er sammenhengen mellom AR-, MA-, og ARMA-modellene?
2. Hva er en ARIMA-modell?
3. Hvilken modell er dette: $$y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \theta u_{t-1} + u_t$$

### R-칮ving

**1. Data**
Vi tar en ny titt p친 [den daglige prisen p친 Eqinoraksjen](datasett/equinor.xlsx) over en 5-친rs periode som vi s친 p친 i introduksjonen til tidsrekker. Vi laster inn datasettet som f칮r ved hjelp av `readxl`-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker `rev()`-funksjonen til 친 reversere rekkef칮lgen til observasjonene slik at den f칮rste verdien komme f칮rst:


```r
library(readxl)
equinor <- read_excel("equinor.xlsx")
pris <- rev(equinor$Siste)
plot(pris, type = "l")
```

<img src="met4_files/figure-html/unnamed-chunk-97-1.png" width="672" />

Vi kan lage en figur av den differensierte tidsrekken p친 f칮lgende m친te:


```r
# Sjekk av differanse 
diff_pris <- diff(pris)
plot(diff_pris, type = "l")
```

<img src="met4_files/figure-html/unnamed-chunk-98-1.png" width="672" />

**Oppgave:** Vurder om en ARIMA modell er bedre egnet enn en ARMA modell ut fra de to figurene over.


**2. Estimering av ARIMA modeller**
Vi bruker den samme funksjonen `Arima` fra `forecast` pakken til 친 estimere b친de ARMA og ARIMA modeller og spesifisering av modellen gj칮r vi via argumentet `order`. Skal du estimerer en ARMA(1,1) modell setter du f.eks dette argumentet til `c(1, 0, 1)`. Elementet i midten av denne vektoren spesifiserer hvor mange ganger tidsrekken skal differensieres i ARIMA modellen. Estimering av en ARIMA modell med en enkelt differensiering og ett MA og AR ledd kan gj칮res slik:

```r
library(forecast)
arima111 <- Arima(pris, order = c(1, 1 , 1))
```

**3. Hvordan skal vi velge p, d og q i en ARIMA(p,d,q) modell?**
Etter 친 ha tilpasset en ARIMA modell kan vi bruke modellen til 친 predikere de samme observasjonene vi har brukt til 친 tilpasse modellen. Vi kan s친 sammenligne hvor n칝r prediksjoner fra forskjellige modeller er de sanne dataene. Dette heter p친 godt norsk 친 gj칮re en "in-sample" vurdering av modellen. 

N친r du har tilpasset en modell, kan du ved 친 bruke `summary` funksjonen f친 opp flere m친l p친 hvor god modellen er in-sample under fanen "Training set error measure":


```r
summary(arima111)
```

```
## Series: pris 
## ARIMA(1,1,1) 
## 
## Coefficients:
##          ar1      ma1
##       0.5121  -0.5780
## s.e.  0.1680   0.1584
## 
## sigma^2 estimated as 6.614:  log likelihood=-2958.16
## AIC=5922.32   AICc=5922.34   BIC=5937.72
## 
## Training set error measures:
##                      ME     RMSE      MAE         MPE     MAPE      MASE
## Training set 0.03973471 2.568719 1.949446 0.009091475 1.251353 0.9955157
##                    ACF1
## Training set 0.02035596
```

Her er f.eks $RMSE = \sqrt{1/T\sum_{t = 1}^T (\hat{y}_t - y_t)^2}$ et slags gjennomsnittlig avvik mellom prediksjonene og observasjonene. Litt lenger oppe i `summary` utskriften er det ogs친 en st칮rrelse som heter AIC som m친ler hvor sannsynlig hver observasjon er gitt modelvalget ditt. Sammenligner du flere modeller er du  p친 jakt etter den modellen som har minst RMSE og/eller AIC.

Det krever en del arbeid skal du sammenligne mange ARIMA(p,d,q) modeller ettersom det er s친 mange m친ter 친 kombinere p,d og q p친 selv om du bestemmer en maksverdi for hver av dem. Det finnes heldigvis en veldig smart R funksjon kalt `auto.arima` som f칮lger med pakken `forecast` som estimerer mange modeller og gir deg ut den modellen med minst AIC:


```r
arima_best_AIC <- auto.arima(pris)
summary(arima_best_AIC)
```

```
## Series: pris 
## ARIMA(0,1,2) 
## 
## Coefficients:
##           ma1      ma2
##       -0.0421  -0.0947
## s.e.   0.0282   0.0281
## 
## sigma^2 estimated as 6.581:  log likelihood=-2955.04
## AIC=5916.09   AICc=5916.1   BIC=5931.48
## 
## Training set error measures:
##                     ME    RMSE      MAE         MPE     MAPE      MASE
## Training set 0.0398931 2.56232 1.948444 0.009249629 1.249956 0.9950042
##                      ACF1
## Training set -0.001297121
```
Hva slags modell har `auto.arima` valgt her?


**4. Prediksjon**
Prediksjon gj칮res som tidligere med `forecast` funksjonen, s친 hvis en vil predikere 10 tidssteg frem i tid gj칮r man f칮lgende:

```r
pred_arima111 <- forecast(arima111, h =  10)
autoplot(pred_arima111, include = 100)
```

<img src="met4_files/figure-html/unnamed-chunk-102-1.png" width="672" />

merk at i `autoplot` har vi valgt 친 bare vise 100 observasjoner av tidsrekken sammen med prediksjonene

## Modellbygging 

Vi har allerede sett p친 hvordan vi kan sammenligne modeller "in-sample". For 친 sammenligne tidsrekkemodeller bruker en ofte ogs친 친 sammenligne hvor godt modellene predikerer observasjoner som ikke har v칝rt inkludert n친r man tilpasser modellen. Dette heter p친 godt norsk 친 vurdere "out-of-sample" egenskapene ved modellen. 

Det finnes mange varianter for 친 unders칮ke dette, og under skal vi ta en titt p친 en enkel variant.

**Oppgave** Vi viser hvordan dette gj칮res for en modell med eksponensiell glatting. Du skal gjenta prosedyren, men for en ARIMA-modell (velg den med best AIC, hint: `auto.arima`). Sammenlign s친 out-of-sample egenskapene til til disse to modellene.


### R-칮ving


**1. Data** 
Vi skal i denne 칮vingen pr칮ve 친 finne en god modell for dax-indeksen:

```r
library(forecast)
dax <- EuStockMarkets[ ,1]
plot(dax)
```

<img src="met4_files/figure-html/unnamed-chunk-103-1.png" width="672" />

**2. Trening og test data**
Vi 칮nsker f.eks 친 teste hvor god modellen er til 친 predikere de 10 siste observasjonene i datasettet. Vi deler derfor dataene inn i et treningssett best친ende av alle observasjoner utenom disse 10 siste observasjonene, og et testsett best친ende av de 10 siste observasjonene:


```r
trening <- head(dax, length(dax) - 10)
test <- tail(dax, 10)
```


**3. Estimering og prediksjon**
Vi tilpasser s친 en modell til treningssettet ved bruk av eksponensiell glatting og predikerer 10 tidssteg frem for 친 f친 prediksjoner av testsettet:


```r
fit_exp <- HoltWinters(trening)
pred_exp <- forecast(fit_exp, h = 10)
```

Merk at n친r vi ikke spesifiserer noen argumenter i `HoltWinters` vil en mer avansert modell bli tilpasset, samtidig som glattingsparameteren faktisk vil bli estimert ved 친 minimerer MSE. 

**3. Out-of-sample vurdering**

Vi kan s친 sammenligne disse prediksjonene `pred_exp` med de faktiske observasjonene `test` ved 친 "m친le" hvor langt disse er fra hverandre. Funksjonen `accuracy` som kommer med `forecast` pakken regner ut flere forskjellig m친l p친 avstand:


```r
accuracy(pred_exp, test)
```

```
##                       ME      RMSE       MAE         MPE      MAPE       MASE
## Training set    1.251117  35.82454  23.42652  0.03438446 0.8276219 0.04295353
## Test set     -317.477645 350.63504 317.47765 -5.82900543 5.8290054 0.58210884
##                    ACF1 Theil's U
## Training set 0.07394258        NA
## Test set     0.62441059  3.510695
```
Hver kolonne i utskriften over representerer et slikt m친l, og det er rad nummer to med navn "Test set" som vi er interessert i siden det er utregningen av disse m친lene mellom prediksjonene og testsettet (Den f칮rste raden representerer in-sample egenskapene). Jo mindre disse verdiene er jo mindre er avstanden mellom prediksjonene og de sanne verdiene i v친rt testsett.





<!--chapter:end:06-tidsrekker.Rmd-->


# Data칮vinger

Her finner du data칮vingene som skal gjennomf칮res i MET4. Se tidsplanen til kurset for en oversikt over n친r de ulike 칮vingene skal gj칮res og hvilke uker studentassistentene gjennomf칮rer 칮vingene p친 datasal.

## Data칮ving 1

### Innledning

Velkommen til den f칮rste data칮velsen i MET4. I denne 칮velsen skal vi bli litt kjent med verkt칮yene R og Rstudio som brukes i datalabbene. Disse verkt칮yene er ogs친 essensielle for gjennomf칮ringen av den obligatoriske innleveringen og p친 hjemmeksamen. Den f칮rste delen av 칮vingen inneholder praktisk informasjon om bruk av R og Rstudio etterf칮lgt av oppgaver.

### Om R og Rstudio

R er et program/programmeringsspr친k som er spesialdesignet til 친 utf칮re statistiske analyser. R er basert p친 at du m친 skrive forskjellige kommandoer for 친 utf칮re utregninger og analyser. Gjennomsnittet av 3, 2 og 5 finner man for eksempel ved 친 skrive:  


```r
mean(c(3,2,5))
```
Dette kan for mange v칝re litt uvant i starten, men datalabbene vil gi deg god trening p친 denne type tankegang.

Rstudio er et program som gj칮r det enklere 친 bruke R. P친 samme m친te som Word kan hjelpe deg til 친 lage fine og oversiktlige tekster, kan Rstudio hjelpe deg til 친 utf칮re fine og oversiktlige statistiske analyser. Rstudio er et redigeringsprogram som vi i dette kurset skal bruke til 친 redigere og utf칮re R-kommandoer.

#### Installere R og Rstudio

Bruker du din egen datamaskin kan du enkelt laste ned og installere R og Rstudio. Begge programvarene er gratis og kan installeres med 친 f칮lge instruksene under. F친r du problemer kan du f친 en av studentassistentene til 친 hjelpe deg.

1. Start med 친 installere R:
    - G친 til [r-project.org](https://cran.uib.no/)
    - Last ned versjonen som passer ditt operativsystem (Windows/Mac/Linux) 
    - Kj칮r installasjonsfilen og f칮lg instruksene. Standard innstillingene skal v칝re greie 친 bruke, s친 du kan trykke neste/ok til installasjonen er ferdig. 
2. Installer s친 RStudio:
    - [rstudio.com](https://rstudio.com/), og naviger deg frem til siden for **RStudio**. Du skal der laste ned desktop-versjonen av programmet ("Open source edition") for ditt operativsystem og  installere p친 vanlig m친te.
    - Kj칮r installasjonsfilen som lastes ned og f칮lg instruksene 

#### Vinduene i Rstudio og det 친 jobbe med R
F칮rste gang du 친pner Rstudio vil du se tre vinduer. Et fjerde vindu 친pner du med 친 klikke p친 **File** i menyen, s친 **New File**, og s친 **R Script**. Figur \@ref(fig:rstudio1) viser en oversikt over de fire vinduene. Det er viktig at du forst친r forskjellen p친 de to vinduene til venstre. 

<div class="figure">
<img src="bilder/Rstudio1.PNG" alt="Oversikt over vinduene i RStudio." width="590" />
<p class="caption">(\#fig:rstudio1)Oversikt over vinduene i RStudio.</p>
</div>


Nederste vindu til venstre (b) viser R-konsollen og det er her alle utregninger blir gjennomf칮rt. I dette vinduet kan du for eksempel skrive

```r
(3*5 - 3/4)*(2 + 2)
```

```
## [1] 57
```

Her er $(3*5 - 3/4)*(2 + 2)$ en s친kalt kommando og det er programmet R som finner ut hva du mener med kommandoen og gir deg svaret $57$ i retur. Du kan se at R tillater standard matteoperasjoner som gange, deling, pluss og minus (`*, /, +, -`). 

R er det vi kaller 'objektbasert', som betyr at du kan definere 'objekter'. Utregningen over kan for eksempel ogs친 regnes ut ved 친 skrive: 


```r
a <- 3*5 - 3/4
b <- 2 + 2
a*b
```

```
## [1] 57
```



Her er `a` og `b` objekter som vi definerer ved bruk av 'tildelingspilen'  `<-` (du kan ogs친 bruke `=`). Det g친r an 친 lagre objekter i egne filer, men vi skal se at det stort sett er smartere 친 lagre 'oppskriften' (selve koden) p친 hvordan de lages i en egen .R fil. 

Det 칮verste vinduet til venstre (a) viser en .R fil (et skript). En .R fil fungerer som et manuskript med R-kommandoer (kode) og kan lagres slik at du kan senere kan se hvilke kommandoer du har brukt i analysen og eventuelt fortsette der du slapp. I Del 2 av denne data칮vingen skal du selv lage en .R fil som inneholder alle kommandoer som brukes i en enkel analyse.  N친r du vil at R skal utf칮re noen av kommandoene du har skrevet i .R filen markerer du bare disse (eller lar pekeren st친 i linjen du vil kj칮re) og trykker **ctrl + Enter** (**Cmd + Enter** p친 Mac):

<div class="figure">
<img src="bilder/Rstudiorun.PNG" alt="Utf칮relse av kommandoer du har skrevet i R filen. Marker eller la pekeren st친 i linjen du vil kj칮re og trykk **ctrl + Enter** (**Cmd + Enter p친 Mac**)" width="238" />
<p class="caption">(\#fig:rstudiorun)Utf칮relse av kommandoer du har skrevet i R filen. Marker eller la pekeren st친 i linjen du vil kj칮re og trykk **ctrl + Enter** (**Cmd + Enter p친 Mac**)</p>
</div>

Vinduet nederst til h칮yre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet 칮verst til h칮yre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en n칝rmere titt p친 et datasett du har lest inn. 

Vinduet nederst til h칮yre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet 칮verst til h칮yre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en n칝rmere titt p친 et datasett du har lest inn. 

Det er viktig at du forst친r forskjellen p친 de to vinduene til venstre, alts친 .R filen og konsollen. R kode du 칮nsker 친 ta vare p친 og som er en essensiell del av analysen skriver og lagrer du i .R filen, mens sm친 eksperimenter og unders칮kelser kan du gjerne gj칮re direkte i konsollen. 

For de av dere som er glad i hurtigtaster finnes det en oversikt i Rstudio som kommer opp dersom du trykker **Alt + Shift + K** (**Option + Shift + K** p친 Mac). Ofte vil man f.eks m친tte skifte musepeker fra R-filen til konsoll og motsatt, og hurtigtaster for 친 veksle mellom disse er **Ctrl + 1** (R-fil) og **Ctrl + 2** (konsoll). Hurtigtasten du kommer til 친 bruke desidert mest er **ctrl + Enter** for 친 kj칮re kode fra R-skriptet ditt i konsollen (P친 Mac erstatter du **ctrl** med **command** over alt).

#### Funksjoner, dokumentasjon og R-pakker

I R kan man lage egne funksjoner som utf칮rer det en m친tte 칮nske, f.eks en funksjon som regner ut t-observatoren gitt en vektor med observasjoner `x` og en gitt $\mu_0$:


```r
t.observator <- function(x, mu0){
  t <- (mean(x) - mu0)/(sd(x)/sqrt(length(x)))
  return(t)
}
```

R kommer med en rekke "innebygde" funksjoner som kan utf칮re ulike statistiske analyser. For eksempel kan en t-test utf칮res med 친 bruke en funksjon som heter nettopp `t.test`. Alle slike funksjoner kommer med en dokumentasjon som viser hva funksjonen gj칮r og hvordan den skal brukes. For 친 tilgang til denne dokumentasjonen skriver man `?` foran funksjonen i konsollen. Skriver du f.eks `?t.test` ser du at det dukker opp en side i vinduet nede til h칮yre:

<div class="figure">
<img src="bilder/Dokumentasjon.JPG" alt="Dokumentasjon av funksjoner dukker opp i et vindu nede til h칮yre. Dette vinduet kan 친pnes til et st칮rre vindu som vist over" width="312" />
<p class="caption">(\#fig:dokumentasjon)Dokumentasjon av funksjoner dukker opp i et vindu nede til h칮yre. Dette vinduet kan 친pnes til et st칮rre vindu som vist over</p>
</div>

Dokumentasjonen vil som hovedregel inneholder en kort beskrivelse av hva funksjonen gj칮r, hvilke argumenter funksjonen tar og hva den gir ut. Helt i slutten av dokumentasjonen er det ofte et eksempel p친 hvordan funksjonen kan brukes og er ofte sv칝rt nyttig 친 se p친. 

Selv om det finnes mange funksjoner som allerede er innebygget i R, m친 man noen ganger installere ekstra 'pakker' for 친 f친 tilgang til spesielle funksjoner. I oppgave 2.2 i denne 칮velsen vil vi g친 gjennom hvordan dette gj칮res for en bestemt pakke. 

#### Skriv pen R-kode!

Det er viktig at R-koden du skriver er veldokumentert og skrevet p친 en oversiktlig og pen m친te. Hvis vi 칮nsker 친 skrive kommentarer til koder som st친r i .R filen bruker vi tegnet `#` foran kommentaren. Dette gj칮r at R ikke pr칮ver 친 evaluere kommentaren som en R-kode. Det finnes en rekke konvensjoner n친r det kommer til mellomrom, linjeskift, navngivning av objekter og lignende. Vi anbefaler tipsene som er oppsummert p친 (http://adv-r.had.co.nz/Style.html)[http://adv-r.had.co.nz/Style.html], men det er selvsagt lov 친 ha sine egne preferanser. 

Under ser du et eksempel p친 d친rlig praksis ved R-koding. Her er det manglende dokumentasjon, d친rlig navngivning og ingen 'luft' i form av mellomrom og linjeskift. Dette gj칮r at du eller andre vil m친tte bruke un칮dvendig tid p친 친 finne ut hva koden faktisk gj칮r p친 et senere tidspunkt.


```r
# D친rlig praksis:

library(readxl)
library(tidyverse)
d<-readxl(file="financedata.xlsx",sheetIndex = 1) %>%
  na.omit()
칒95<-mean(d$value)-qt(0.975,df=length(d$value)-1)*sd(d$value)  
N95<-mean(d$value)+qt(0.975,df=length(d$value)-1)*sd(d$value)
```

F칮lgende R kode gir det samme resultatet men er mye mer oversiktlig siden den er mer luftig, er brutt ned i biter, er godt dokumentert og har fornuftige objektnavn:


```r
# God praksis:

# ---------- Analyse av data

# N칮dvendige pakker i analysen
library(readxl)
library(tidyverse)

# Les data, fjern NA-verdier og hent ut gjeld
my_data <- readxl(file = "financedata.xlsx", sheetIndex = 1) %>%
  na.omit()
debt <- my_data$debt

# Konfidensintervall
n_obs <- length(debt)     # antall observasjoner
alpha <- 0.05             # signifikansniv친  
average <- mean(debt)     # gjennomsnitt
st_dev <- sd(debt)        # standardavvik
lower <- average - qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n)  # nedre grense
upper <- average + qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n)  # 칮vre grense
```

Vi oppfordrer deg til 친 pr칮ve 친 skrive R-kode som er pen og oversiktlig i datalabbene fremover. D친rlige vaner kan v칝re vonde 친 vende!

### Oppgave 1: Interaktiv 칮velse 

Her skal du bruke et l칝ringsverkt칮y kalt `swirl` som vil ta deg gjennom en interaktive 칮velse hvor du m친 utf칮re forskjellige oppgaver i konsollen. I flere av data칮vingene vil det v칝re en slik interaktiv del. Her er tanken at du skal leke deg litt med R.

F칮r du kan begynne m친 du installere swirl. Kopier derfor f칮lgende tre linjer og lim dem inn i R-konsollen: 

```r
install.packages("swirl")
library(swirl)
install_course("R Programming")
```

For 친 starte swirl skriver du s친 f칮lgende i konsollen:


```r
swirl()
```

Du vil i starten bli bedt om 친 skrive inn ditt navn og s친 f칮lger litt info om hvordan swirl fungerer. Du blir s친 bedt om 친 velge kurs. Her skal du velge alternativet 'R Programming' (**1** og s친 **enter**). Du f친r s친 se alle modulene dette kurset inneholder:


<img src="bilder/swirl1.PNG" width="466" />

I denne 칮vingen skal du pr칮ve deg p친 modul 1 **'Basic Building Blocks'**, modul 4  **'Vectors'** (kun f칮rste halvdel), og modul 12 **'Looking at Data'**.  I modul 1 vil du l칝re litt om de mest grunnleggende operasjonene som kan gj칮res i R. Modul 4 ser n칝rmere p친 vektorer og her er f칮rste halvdel av modulen mest relevant. Modul 12 tar for seg det 친 utforske strukturen p친 et datasett. Start med modul 1 (**1** og s친 **enter**). Du vil bli bedt om 친 gj칮re enkle operasjoner i R og av og til m친 du svare p친 multiple choice sp칮rsm친l:

<img src="bilder/swirl2.PNG" width="461" />

Merk at det helt til h칮yre vil st친r hvor langt du har kommet i prosent. St친r du helt fast med et punkt kan du skrive `skip()` for 친 hoppe over dette punktet. N친r du har fullf칮rt en modul blir du spurt om du vil motta 'credit' for 친 ha fullf칮rt modulen. Her kan du svare nei. 칒nsker du 친 avbryte underveis skriver du `bye()`. Skriver du inn det samme navnet n친r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk 친 avslutt swirl (**esc**) f칮r du begynner p친 del to av 칮vingen. Lykke til!

### Oppgave 2: Innlesning av data og deskriptiv statistikk i R

I denne oppgaven skal vi lese inn noen data og produsere enkel deskriptiv statistikk av disse dataene. Dataene kommer fra [et amerikansk fors칮k](https://journals.sagepub.com/doi/10.1177/0956797619829688) hvor man ville unders칮ke p친standen om at voldelige dataspill f칮rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det "voldelige" dataspillet var oppdraget 친 *skyte* og *drepe* et romvesen,  mens i den ikke-voldelige varianten skulle man *finne* og *redde* romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille칮kt ble deltakernes aggresjonsniv친 m친lt p친 en skala fra 1 til 9 ved hjelp av en standard psykologisk test. Dette datasettet ble brukt i eksamensoppgaven v친rsemesteret 2019.

**Oppgave 2.1.** [Last ned filen violence.xslx](datasett/violence.xlsx). Denne filen lagrer du fortrinnsvis i en egen mappe der du 칮nsker at filer fra denne 칮vingen skal ligge. 칀pne s친 **RStudio**, velg  `File -> New File -> R Script` for 친 친pne et nytt Rscript.  Lagre s친 scriptet ditt i samme mappen som du har lagt datasettet, slik at du n친 har en mappe som ser ut som figuren under:

<img src="bilder/mappe.JPG" width="518" />

N친r vi skal lese inn data, lagre figurer og andre ting har R en standard 'mappesti' (working directory) den leter/lagrer i. Du kan se hva denne stien peker p친 ved 친 skrive \textbf{getwd()} i konsollen. Du skal n친 spesifisere denne mappestien til mappen du har opprettet. Dette gj칮r du raskest ved 친 velge `Session -> Set Working Directory -> To Source File Location`. Neste gang du skal jobbe med dette prosjektet kan du 친pne **RStudio** ved 친 dobbeltklikke p친 `data칮ving1.R`, og mappestien skal da settes automatisk til riktig mappe.

Lag gjerne en liten overskrift ved hjelp av kommentartegnet `#` slik at .R filen din ser omtrent slik ut:

<img src="bilder/rstudio3.JPG" width="356" />

**Oppgave 2.2.** Du skal n친 lese inn excel filen du lagret i over i R. Selv om det finnes mange funksjoner som allerede er innebygget i R, m친 man noen ganger installere ekstra 'pakker' for 친 f친 tilgang til spesielle funksjoner. For 친 lese inn en excel fil trenger du nettopp en slik ikke standard funksjon. Denne finnes i pakken `readxl`. Selve installeringen kan du gj칮re direkte i konsollen med 친 skrive (hvis du ikke har gjort det allerede):


```r
install.packages("readxl")
```

Pakken legger seg da i en bibliotekmappe der R er installert. For 친 gi R beskjed om 친 laste inn funksjonene til pakken du nettopp installerte bruker du funksjonen `library`. Du har n친 tilgang til en funksjon kalt `read_excel()` som du kan bruke til 친 lese inn excel filen:


```r
# MET4 - Data칮ving 1
# ------------------

# les inn data
library(readxl)
violence <- read_excel("violence.xlsx")
```




Marker linjene du nettopp skrev i R-skriptet ditt og trykk **ctrl + enter** (**cmd + enter**), for 친 opprette objektet `violence` som inneholder datasettet.  Funksjonen `ls` lister opp alle objekter som har blitt definert. Du kan pr칮ve selv 친 skrive f칮lgende i konsollen:


```r
ls()
```

```
## [1] "violence"
```

Du ser at det har kommet et nytt objekt som heter `violence`. En tilsvarende oversikt finner du i vinduet 칮verst til   h칮yre i Rstudio (se Figur \@ref(fig:rstudio1)) hvor du ogs친 kan klikke p친 objektet for 친 se n칝rmere p친 det.

**Oppgave 2.3.** Ta en titt p친 strukturen til datasettet du nettopp leste inn. Husker du kanskje noe fra den interaktive 칮velsen 'Looking at Data'? N친r du gj칮r slike sm친 utforskninger kan du gjerne jobbe direkte i konsollen, og det du gj칮r i dette punktet trenger n칮dvendigvis ikke v칝re med i .R-filen din. G친 til konsollen og bruk funksjoner som `class`, `dim`, `names`, `head` og `str` for 친 utforske strukturen p친 dataene. Vi ser at det er 5 variabler:

- `id` er bare et tall som identifiserer fors칮kspersonen.
- `aggression_level` er aggresjonsniv친et som ble m친lt rett etter at fors칮kspersonen hadde spilt en viss tid.
- `violent_treatment` er varianten av dataspillet som fors칮kspersonen ble utsatt for; enten `Violent` eller `Less Violent`.
- `difficulty_treatment` er vanskelighetsgraden av spillet, som enten var `Easy` eller `Hard`. En mulig forklaring p친 aggressiv adferd er at vanskelige spill f칮rer til h칮yere stressniv친, som igjen kan f칮re til aggressivitet.
- `experienced_violence` er svaret til fors칮kspersonen p친 sp칮rsm친let om vedkommende *oppfattet* spillet som `Violent` eller `Less Violent`.  Fors칮kspersonene visste ikke selv hva forss칮ket gikk ut p친, eller at det var flere varianter av det samme spillet.

**Oppgave 2.4**

Vi skal se n칝rmere p친 om aggresjonsniv친et er forskjellig i de to gruppene. Da m친 vi trekke ut de aktuelle tallene fra datasettet. Vi 칮nsker 친 velge ut *to vektorer* for 친 gj칮re denne sammenligningen: en vektor som inneholder aggresjonsniv친et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv친et til gruppen som har spilt det ikke-voldelige dataspillet. 

La disse to vektorene f친 navn `voldelig` og `ikke_voldelig`, og lag dem ved 친 skrive f칮lgende kodelinjer:


```r
# Vektorer med aggresjonsniv친 til gruppen som har spilt voldelig/ikke-voldelig spill 
voldelig      <- violence$aggression_level[violence$violent_treatment == "Violent"]      
ikke_voldelig <- violence$aggression_level[violence$violent_treatment == "Less Violent"]
```

Sjekk n친 at dette har fungert ved 친 skrive `voldelig` og `ikke_voldelig` inn i konsollen for 친 se at det faktisk er vektorer som inneholder tallene 1 -- 9. Bruk ogs친 noen minutter til 친 pr칮ve 친 forst친 hva kodelinjene over faktisk gj칮r. Her er noen punkter som kan hjelpe til med 친 obdusere den f칮rste linjen:

1. `violence$aggression_level` henter ut kolonnen `aggression_level` fra datasettet `violence`.
2. Vi kan bruke firkantparantes `[ ]` til 친 hente ut spesifikke elementer fra en vektor. Her skal vi hente ut bestemte elementer fra vektoren `violence$aggression_level`, og vi kan for eksempel skrive  `violence$aggression_level[1]`, `violence$aggression_level[1:10]` eller `violence$aggression_level[c(1, 5)]` for 친 hente ut henholdsvis det f칮rste, de ti f칮rste, eller det f칮rste og det femte tallet i vektoren. (Pr칮v!)
3. Vi skal hente ut noen helt bestemte tall fra `violence$aggression`, nemlig de m친lingene som tilh칮rer testpersonene som har `violent_treatment` lik `"Violent"`. Alle disse kan vi finne ved 친 skrive inn `violence$violent_treatment == "Violent"`. Pr칮v det. Du vil da f친 ut en vektor fylt med enten `TRUE` eller `FALSE`, alt etter om den tilh칮rende fors칮kspersonen har `violent_treatment` lik `Violent` eller ikke.
4. Denne vektoren kan vi bruke til 친 hente ut tall som svarer til `TRUE` fra `violence$aggression_level` ved 친 putte den i firkantparanteser. Det er det som st친r til h칮yre for tilordningen `<-`.
5. Til slutt lagrer vi resultatet i vektoren `voldelig`.

(**NB!** Pass p친 at du skriver `Violent` og `Less Violent` helt riktig med store og sm친 bokstaver, ellers vil det ikke fungere!)

**Oppgave 2.5.** I eksamensoppgaven fra 2019 f친r vi oppgitt deskriptiv statistikk over aggresjonsniv친et for de to gruppene i f칮lgende tabell:

<img src="bilder/descriptive.png" width="624" />

Bruk funksjoner som `min()`, `max()`, `median()`, `mean()`, `length()` og `summary()` til 친 finne ut om tallene stemmer. Hvordan kan det ha seg at tallene ikke er identiske?

**Oppgave 2.6.** Vi skal n친 lage et histogram av hver av gruppene du lagret som vektorer i tidligere, og vi skal gj칮re det p친 to m친ter:

- F칮rst skal vi bruke plottefunksjonene som f칮lger med R ("Base R").
- S친 skal vi gj칮re det samme ved hjelp av `ggplot`-pakken.

Vi skal f칮rst bruke funksjonen `hist()` som alts친 f칮lger med R-installasjonen din. De fleste R-funksjoner har flere argumenter slik de kan utf칮re forskjellige operasjoner. Om vi for eksempel 칮nsker at histogrammet skal vise andel og ikke frekvens, m친 vi angi dette i ett av argumentene. For 친 ta en titt p친 hvilke argument `hist()` har 친 tilby skriver `?hist`  i konsollen. Det vil da poppe opp en dokumentasjonside i vinduet nede til h칮yre. Skroll ned 친 les om argumentet 'freq'. Hva skal du erstatte sp칮rsm친lstegnene under med for at histogrammene skal vise andel? 


```r
# Skalert Histogram, vi velger breaks = 9 fordi det er 9 mulige utfall: 1 -- 9.
hist(voldelig, freq = ?, breaks = 9, main = "Voldelig")
hist(ikke_voldelig, freq = ?, breaks = 9, main = "Ikke-voldelig")
```

De fullf칮rte linjene over skal v칝re med i .R-filen din. For 친 se histogrammene kan du kj칮re kommandoene en etter en i konsoll med 친 trykke **ctrl + enter**. Figurene dukker da opp i vinduet nede til h칮yre. Du kan ogs친 pr칮ve 친 eksperimentere med argumentet `breaks`.

La oss s친 fors칮ke 친 gjenta denne operasjonen ved 친 bruke `ggplot`-pakken. Vi kan f칮rst kikke p친 Figur \@ref(fig:to-histogrammer) og koden som lagde disse figurene for 친 f친 en id칠 om hva vi m친 gj칮re. Et sv칝rt viktig punkt er f칮gende:

**`ggplot`-funksjonen skal alltid ha hele datasettet (en data frame) som argument!!**

Det betyr at vi *ikke* skal bruke de to vektorene `voldelig` og `ikke_voldelig`, slik som i `hist()`-funksjonen, men bruke hele datasettet `violence`. Vi ser av oversikten over at variabelen som inneholder aggresjonsniv친et er `aggression_level`, s친 det er den vi skal bruke som $x$-argument. Ved 친 ta utganspunkt i koden som lagde Figur \@ref(fig:to-histogrammer), kan vi gj칮re et f칮rste fors칮k (der vi husker 친 laste inn `ggplot2`-pakken f칮rst):


```r
library(ggplot2)
ggplot(violence, aes(x = aggression_level)) +
        geom_histogram(bins = 9)
```

<img src="met4_files/figure-html/unnamed-chunk-127-1.png" width="672" />

Nesten! Det eneste problemet er at vi har ett histogram for alle observasjonene, mens det vi egebntlig 칮nsket var 친 lage et histogram for hver av gruppene. Dette er s친re enkelt i `ggplot2`. Det eneste vi trenger 친 gj칮re er 친 identifisere den variabelen i datasettet som angir gruppetilh칮righet (sjekk variabeloversikten over, svaret er `experienced_violence`), og s친 plusse p친 en funksjon som heter `facet_wrap()` som vist under.


```r
ggplot(violence, aes(x = aggression_level)) +
  geom_histogram(bins = 9) +
  facet_wrap(~ experienced_violence)
```

<img src="met4_files/figure-html/unnamed-chunk-128-1.png" width="672" />

Dersom vi i stedet 칮nsker et skalert histogram kan vi spesifisere `y`-argumentet p친 f칮lgende vis:


```r
ggplot(violence, aes(x = aggression_level, y = ..density.. )) +
  geom_histogram(bins = 9) +
  facet_wrap(~ experienced_violence)
```

**Oppgave 2.7.** N친r man skal sammenligne sentrum og spredning i to grupper er et boxplott et ypperlig alternativ og vi kan da bruke funksjonen `boxplot()` i "base R", eller funksjonen `geom_boxplot()` hvis vi heller 칮nsker 친 benytte `ggplot2`. Vi holder oss til det siste alternativet her, og ser at kodelinjene ligner p친 det vi laget over.

Dersom vi 칮nsker 친 lage et enkelt boxplot av en variabel for 친 sammenligne spredingen i to eller flere grupper kan vi skrive


```r
ggplot(a, aes(x = b, y = c)) +
  geom_boxplot()
```

Her m친 du selv erstatte bokstavene a, b og c i henhold til f칮lgende regel:

- `a` er navnet p친 datasettet.
- `b` er variabelen som inneholder gruppeinndelingen.
- `c` er variabelen som inneholder m친lingene.

De ferdige kodelinjene skal v칝re med i .R-skriptet ditt. For 친 se boxplottet kan du som vanlig kj칮re kommandoene med 친 trykke **ctrl + enter**. Ser det ut til 친 v칝re noe forskjell p친 sentrum og spredning i de to gruppene?

**Bonusoppgave.** Bytt ut `geom_boxplot()` over med `geom_jitter()` og `geom_violin()`. Hva viser disse plottene?

## Data칮ving 2

### Interaktiv 칮velse 
F칮r vi tar fatt p친 dataanalysen begynner vi med litt R-trening i swirl.  Har du allerede installert pakken `swirl` (skriv `install.packages("swirl")` i konsoll hvis ikke) starter du opp swirl med 친 skrive f칮lgende i konsollen:


```r
library(swirl)
swirl()
```

Du vil i starten bli bedt om 친 skrive inn ditt navn. Hvis du bruker samme navn som tidligere f친r du kanskje tilbud om 친 starte opp igjen der du slapp, men da kan du bare velge det nederste valget 'No. Let me start something new'. Du velger s친 alternativet 'R Programming' hvor du f친r se alle modulene dette kurset inneholder. I denne 칮vingen skal du pr칮ve deg p친 modul 6 **'Subsetting Vectors'** og modul 8 **'Logic'**. 

Husk at det helt til h칮yre vil st친r hvor langt du har kommet i prosent. St친r du helt fast med et punkt kan du skrive `skip()` for 친 hoppe over dette punktet. N친r du har fullf칮rt en modul blir du spurt om du vil motta 'credit' for 친 ha fullf칮rt modulen. Her kan du svare nei. 칒nsker du 친 avbryte underveis skriver du `bye()`. Skriver du inn det samme navnet n친r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk 친 avslutt swirl (\textbf{esc}) f칮r du begynner p친 neste del av datalabben. Lykke til!


### Data til data칮velsen

I denne data칮velsen skal vi ved hjelp av R gjennomf칮re en del av testene som vi har l칝rt i praksis. Vi skal gj칮re b친de ett- og to-utvalgs tester, og vi skal bruke $\chi^2$-testen

Vi skal jobbe med tre ulike datasett i denne 칮vingen, og alle sammen kan lastes ned ved 친 klikke p친 lenkene under:

- [`testdata.xls`](datasett/testdata.xls)
- [`violence.xlsx`](datasett/violence.xlsx)
- [`roubik_2002_coffee_yield.xlsx`](datasett/roubik_2002_coffe_yield.xlsx)

Last ned disse filene og legg dem i en mappe p친 datamaskinen din. 칀pne s친 **RStudio**, velg  `File -> New File -> R Script` for 친 친pne et nytt Rscript, og lag gjerne en liten overskrift ved hjelp av kommentartegnet `#`. Lagre s친 scriptet ditt i samme mappen som du har lagt datasettene, slik at du n친 har en mappe som ser ut som figuren under:

<img src="bilder/mappe2.png" width="381" />

Det neste du m친 gj칮re er 친 s칮rge for at du har satt opp riktig mappesti (working directory) i **RStudio**, og det gj칮r du raskest ved 친 velge `Session -> Set Working Directory -> To Source File Location`. Neste gang du skal jobbe med dette prosjektet kan du 친pne **RStudio** ved 친 dobbeltklikke p친 `data칮ving2.R`, og mappestien skal da settes automatisk til riktig mappe. I alle tilfeller skal vinduet ditt se omtrent slik ut:

<img src="bilder/rstudio2.png" width="210" />

### Oppgaver til 칮vingen:

#### Oppgave 1

Costa Rica er en stor kaffeprodusent med moderne produksjon. Kaffeprodusentene har over lengre tid benyttet en standardisert miks av spr칮ytemidler som skal ta knekken p친 ugress og skadelige insekter, men uten 친 skade avlingen eller milj칮et ellers. 

En liten kaffeplantasje i Costa Rica har begynt 친 eksperimentere med en ny kombinasjon av spr칮ytemidler som skal v칝re like effektiv mot ugress, men samtidig enda mer sk친nsom mot kaffeplantene, slik at avlingen blir st칮rre. Innehaveren av plantasjen 칮nsker 친 sette opp et eksperiment for 친 unders칮ke denne p친standen. Han velger ut 25 tilfeldige jordlapper fordelt p친 hele eiendommen der han bruker de nye spr칮ytemidlene gjennom en hel sesong.

Lang erfaring har vist at avlingen ved bruk av gammel metode er normalfordelt med forventning $\mu = 100$ og varians $\sigma^2 = 10$, der vi har brukt en standardisert enhet for mengde avling per arealenhet. Hjelp bonden, ved 친 l칮se f칮lgende oppgaver:

**Oppgave 1.1:** Les inn datasettet `testdatasdata.xsl` i **RStudio** og se p친 de f칮rste par radene. Det kan du gj칮re ved 친 kj칮re f칮lgende kodelinjer:


```r
library(readxl)                                 # Pakke for 친 lese excel-filer
data <- read_excel("testdata.xls")              # Leser inn datasettet
data                                            # Ser p친 datasettet
```


```
## # A tibble: 25 x 4
##       X1    X2    A1    A2
##    <dbl> <dbl> <dbl> <dbl>
##  1 122.  121.      1     1
##  2 101.  105       1     1
##  3 114.  108       1     1
##  4 103    99.1     1     0
##  5  97.6  96.2     0     0
##  6  85.9  95.4     0     0
##  7  93.5 101.      0     1
##  8  92    97       0     0
##  9  98.8 106.      0     1
## 10  99.9 100.      0     1
## # ... with 15 more rows
```

Det er kolonnen `X2` som inneholder de observerte avlingene p친 de 25 fors칮ksseksjonene. 

**Oppgave 1.2:** Er forventet avling ved bruk av den nye metoden *st칮rre* enn forventet avling ved bruk av den gamle metoden? *Hint: Forelesningsnotatene/scriptet inneholder koden du trenger for 친 l칮se denne og neste oppgave.*

**Oppgave 1.3:** Det er viktig for kaffebonden at avlingen ikke varierer for mye mellom de ulike delene av farmen. En viktig m친leparameter for denne type produksjon er derfor variansen. Kan vi sl친 fast at variansen til avlingen har forandret seg etter omlegging til ny metode? 

**Oppgave 1.4:** Kaffebonden er skeptisk til p친standen om at forventet avling med den gamle metoden er $\mu = 100$, og mener at det vil variere med for eksempel jordsmonn. For 친 ta h칮yde for dette gjennomf칮rte han 친ret i forveien tilsvarende m친linger p친 de samme jordlappene, med med gammel spr칮ytemetode. Disse m친lingene finner du i kolonne `X1` i datasettet. Test om avlingene er forskjellige, b친de med og uten paring av observasjonene. Kommenter resultatet. 

#### Oppgave 2

Vi skal i denne oppgaven se p친 oppgave **1a** og **1b** som ble gitt p친 skoleeksamen i MET4 v친rsemesteret 2019. Dette er det samme datasettet som vi s친 p친 i forrige data칮ving. I [et amerikansk fors칮k](https://journals.sagepub.com/doi/10.1177/0956797619829688) ville man unders칮ke p친standen om at voldelige dataspill f칮rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det "voldelige" dataspillet var oppdraget 친 *skyte* og *drepe* et romvesen,  mens i den ikke-voldelige varianten skulle man *finne* og *redde* romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille칮kt ble deltakernes aggresjonsniv친 m친lt p친 en skala fra 1 til 9 ved hjelp av en standard psykologisk test.

I denne oppgaven skal vi i hovedsak finne ut om gruppen som spilte de voldelige dataspillet hadde signifikant h칮yere aggresjonsniv친 enn kontrollgruppen.

**Oppgave 2.1:** Les inn datasettet `violence.xslx` p친 samme m친te som over. Hvis du allerede har kj칮rt `library(readxl)` trenger du ikke gj칮re det igjen med mindre du har startet **RStudio** p친 nytt. Gi datasettet et passende navn, f.eks


```r
violence <- read_excel("violence.xlsx")
```



Vi skal alts친 teste om aggresjonsniv친et er forskjellig i de to gruppene. Da m친 vi trekke ut de aktuelle tallene fra datasettet. Som vi husker fra forelesningsnotatene trenger vi *to vektorer* for 친 gj칮re en to-utvags $t$-test: en vektor som inneholder aggresjonsniv친et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv친et til gruppen som har spilt det ikke-voldelige dataspillet. 

La disse to vektorene f친 navn `voldelig` og `ikke_voldelig`, og lag dem ved 친 skrive f칮lgende kodelinjer:


```r
voldelig      <- violence$aggression_level[violence$violent_treatment == "Violent"]
ikke_voldelig <- violence$aggression_level[violence$violent_treatment == "Less Violent"]
```

For en forklaring p친 disse kodelinjene, se Data칮ving 1.

**Oppgave 2.2:** Vi er n친 klare til 친 gj칮re en to-utvalgs $t$-test for om aggresjonsniv친et er det samme i de to gruppene. Pr칮v 친 gj칮re det n친, men v칝r bevisst p친 hvilke valg du gj칮r underveis, og som du mater inn i `t.test()`-funksjonen, f.eks:

- Antar du lik varians i de to gruppene? Hvorfor/Hvorfor ikke?
- Bruker du ensidig eller tosidig test? Hvorfor?

**Oppgave 2.3:** En avgj칮rende detalj i studien som vi ser p친 i denne oppgaven er at forskerne ogs친 spurte fors칮kspersonene hvorvidt de selv syntes spillet de spilte var voldelig. For 친 kunne trekke noen som helst l칝rdom fra et slikt fors칮k er det viktig at den voldelige spillvarianten faktisk blir oppfattet som voldelig og vice versa. Vi 칮nsker dermed 친 unders칮ke nullhypotesen om at variablene `violence_tratment` og `experienced_violence` er uavhengige av hverandre. Den hypotesen er vi n칮dt til 친 forkaste for at fors칮ket skal v칝re gyldig: hvis det ikke er noen sammenheng mellom opplevd og faktisk voldelighet er fors칮ket helt klart ugyldig.

F칮rste steg er 친 lage et nytt datasett der vi bare ta med oss de to kolonnene vi er interessert i. Kall det hva du vil, f.eks. `violence_redusert`:


```r
violence_redusert <- violence[c("violent_treatment", "experienced_violence")]
```

Vi fortsetter som i videoforelesningen og lager en krysstabell for disse variablene


```r
krysstabell <- table(violence_redusert) 
krysstabell
```

```
##                  experienced_violence
## violent_treatment Less Violent Violent
##      Less Violent          114       9
##      Violent                33      93
```

**Oppgave 2.4:** Heldigvis ser det ut til at det er en klar sammenheng mellom faktisk og opplevd voldelighet ved at de fleste fors칮kspersonene havner p친 diagonalen i krysstabellen. Bruk funksjonen `chisq.test()` p친 samme m친te som i forelesningen til 친 teste nullhypotesen om uavhengighet formelt.

#### Oppgave 3

Vi skal i denne oppgaven returnere til kaffeproduksjon. Vi skal gj칮re statistiske tester i R som i de tidligere oppgavene i denne 칮vingen, men vanskelighetsgraden g친r opp fordi vi ogs친 m친 tenke n칮ye over hvordan vi anvender metodene korrekt i en gitt kontekst.

I 2002 publiserte det prestisjetunge tidsskriftet *Nature* en kort artikkel skrevet av David W. Roubik^[David W. Roubik: *The value of bees to the coffee harvest*. Nature (2002)], som handler om den kjente kaffeb칮nnen *Arabica*. Arabicab칮nnen kommer opprinnelig fra Afrika, og er en selvpollinerende plante. Det vil si at den ikke er avhengig av insekter for 친 formere seg, og man trodde lenge at den heller ikke hadde noen fordeler av insektspollinering. 

For 친 unders칮ke denne p친standen samlet Roubik inn historiske data over arabicaavlinger fra hele verden. Han delte verdens kaffeproduserende land inn i to kategorier: *Old world* som omfatter afrikanske  og asiatiske land, og *New world* som omfatter land i Latin-Amerika. Han registrerte videre *gjennomsnittlig 친rlig avling* (m친lt i kg/hektar) i to perioder: 1961--80 og 1981--2001.

N칮kkelen til analysen er at den afrikanske honningbien var en viktig pollinator i Afrika og Asia b친de i den f칮rste og andre perioden, men knapt eksisterte i Amerika f칮r 1980. Etter 1980, derimot, 칮kte utbredelsen av denne bien i Amerika, og ble fort naturalisert. Kan vi sette denne utviklingen i sammenheng med 칮kt kaffeavling i Latin-Amerika etter 1980, og dermed skrote teorien om at kaffeplanter ikke drar nytte av insektspollinering?

**Oppgave 3.1:** For 친 unders칮ke dette kan vi bruke datasettet som Roubik brukte, som finnes i filen `roubik_2002_coffe_yield.xlsx`. Last datasettet inn i R p친 vanlig m친te, og se p친 det:


```r
yield <- read_excel("roubik_2002_coffe_yield.xlsx")
yield
```


```
## # A tibble: 28 x 4
##    world country     yield_61_to_80 yield_81_to_01
##    <chr> <chr>                <dbl>          <dbl>
##  1 new   Costa_Rica            9139          14620
##  2 new   Bolivia               7686           8767
##  3 new   El_Salvador           9996           8729
##  4 new   Guatemala             5488           8231
##  5 new   Colombia              5920           7740
##  6 new   Honduras              4096           7264
##  7 new   Nicaragua             4566           6408
##  8 new   Brazil                4965           6283
##  9 new   Peru                  5487           5740
## 10 new   Mexico                5227           5116
## # ... with 18 more rows
```

Vi ser at det er fire kolonner i datasettet:

- `world` angir om det er snakk om *New world* (`new`) eller *Old world* (`old`).
- `country` angir navnet p친 landet.
- `yield_61_to_80` angir avlingen i perioden 1961--80.
- `yield_81_to_01` angir avlingen i perioden 1981--2001.

**Oppgave 3.2:** Kall den f칮rste tidsperioden `p1` og den andre tidsperioden `p2`. Lag s친 *fire* vektorer, en for hver kombinasjon av `world` og tidsperiode ved 친 bruke samme teknikk som i oppgave **2.2** over. N친r du er ferdig, skal du ha laget f칮lgende vektorer:

- `new_p1`: inneholder avling for alle land med `world == new` i f칮rste periode.
- `new_p2`: inneholder avling for alle land med `world == new` i andre periode.
- `old_p1`: inneholder avling for alle land med `world == old` i f칮rste periode.
- `old_p2`: inneholder avling for alle land med `world == old` i andre periode.



Dersom du har gjort det riktig, ser vektorene slik ut n친r du er ferdig:


```r
new_p1
```

```
##  [1] 9139 7686 9996 5488 5920 4096 4566 4965 5487 5227 2347 3089 1938
```

```r
new_p2
```

```
##  [1] 14620  8767  8729  8231  7740  7264  6408  6283  5740  5116  4124  3240
## [13]  2789
```

```r
old_p1
```

```
##  [1]  4251 10522  3509 10028  5667 17064  5904  4001  6604  4738  5716  3824
## [13]  3525  3393  3213
```

```r
old_p2
```

```
##  [1] 13380 11561  9652  9593  8797  7869  7354  7288  6055  5432  5394  3576
## [13]  3141  2391  2136
```

**Oppgave 3.3:** Bruk en paret $t$-test til 친 finne ut om kaffeavlingen i den gamle verden er signifikant forskjellig i de to tidsperiodene.

**Oppgave 3.4:** Bruk en paret $t$-test til 친 finne ut om kaffeavlingen i den nye verden er signifikant forskjellig i de to tidsperiodene.

**Oppgave 3.5 (Diskusjonsopgave):** Dersom du har gjort de to foreg친ende oppgavene riktig vil du se at den gjennomsnittlige kaffeavlingen ikke har endret seg signifikant i den gamle verden, mens 칮kningen i den nye verden er klart statistisk signifikant. Vi har brukt parrede $t$-tester, slik at vi "kontrollerer for" eventuelle landeffekter (denne terminologien blir skal vi bruke mer n친r vi skal jobbe med regresjon).

Roubik omtaler funnet som f칮lger:

> *A substantial increase in Latin American coffee yield partly coincided with the establishment of African honeybees in those countries, although there was no such change in the Old World, where honeybees originated [...]. This comparison underlines a possible cause-and-effect relationship between the presence of social bees and cofee yield.* 

Dette er intet mindre enn en **kortslutning**, p친 minst to forskjellige m친ter. Hvorfor? Diskuter med dine medstudenter. Kan det gjennomf칮res en enkel test som gir et bedre bilde av situasjonen?

### BONUS: En alternativ teknikk for datamanipulering (Gj칮r bare om du har overskudd til det!)
 
Se p친 denne kodelinjen:


```r
voldelig <- violence$aggression_level[violence$violent_treatment == "Violent"]
```

Vi skrev denne linjen for 친 hente ut noen bestemte verdier fra et bestemt datasett. Det er kanskje ikke s친 lett 친 se hva kodelinjen gj칮r ved 친 bare kaste et raskt blikk p친 den, og det er spesielt to grunner til det:

- den er lang, og
- du m친 lese den delvis "innenfra og ut" (alst친, begynne innerst i parantesene) og delvis fra h칮yre mot venstre.

Spesielt det siste punktet er kontraintuitivt, siden det er motsatt av slik vi vanligvis leser. Mye arbeid i R g친r ut p친 친 manipulere datasett p친 ulike vis (hente ut kolonner og rader, lage nye kolonner), og derfor er det utviklet noen alternative verkt칮y for 친 gj칮re slike jobber mye mer effektivt. Vi vil i dette avsnittet gi en kort og meget grunleggende innf칮ring i slike teknikker. Merk at dette ikke er *pensum* i klassisk forstand. Det viktigste er at jobben blir gjort korrekt. Hvordan du gj칮r det er i s친 m친te underordnet.

For 친 gjennomf칮re 칮velsen under m친 du installere og laste inn en ny pakke: `dplyr`:


```r
install.packages("dplyr")
library(dplyr)
```



#### KONSEPT 1: Pipe-operatoren `%>%` {-}

Tenk deg at vi skal regne ut logaritmen til kvadratroten av 2. Vi m친 da anvende to funksjoner i riktig rekkef칮lge. Vi kan alltids bruke en mellomregning:


```r
kvadratroten_til_2 <- sqrt(2)
log(kvadratroten_til_2)
```

```
## [1] 0.3465736
```

Eventuelt kj칮rer vi alt sammen i en linje:


```r
log(sqrt(2))
```

```
## [1] 0.3465736
```

N친 er ikke den siste linjen spesielt lang, men den er som sagt ikke helt intuitiv. Grunnen er at hvis vi skal lese h칮yt hva den gj칮r, s친 m친 vi begynne innerst i parantesene: "Vi starter med tallet 2, s친 tar vi kvadratroten, s친 tar vi logaritmen..."

I `dplyr`-pakken finnes en s친kalt pipe-operator som gj칮r at vi kan skrive dette som kode i den rekkef칮lgen ting skal skje. Eksempelet over skrives slik:


```r
2 %>% sqrt %>% log
```

```
## [1] 0.3465736
```

Det som skjer er at R leser linjen fra venstre, og ved hver "pipe/`%>%`" sendes det som st친r p친 venstre side inn som argument i funksjonen p친 h칮yre side. N친r du leser kode, kan denne operatoren uttales som **s친** (**then** p친 engelsk): **F칮rst** har vi tallet 2, **s친** tar vi kvadratroten, **s친** tar vi logaritmen.

Tenk n친r vi har en sekvens av 10 eller 20 eller 50 steg (ikke uvanlig i den virkelige verden), hvor mye enklere det blir 친 kode p친 denne m친ten fremfor 친 ha 10, 20 eller 50 niv친 med paranteser!

**Tips:** Hurtigtasten for `%>%` i RStudio er `Ctrl - Shift - M` (Bytt ut **Ctrl** med **Cmd** p친 Mac).

#### KONSEPT 2: Datamanipuleringsfunksjoner i `dplyr` {-}

I `dplyr` finnes det noen meget praktiske funksjoner som vi kan bruke til 친 manipulere datasatt i R. La oss ta utgangspunkt i datasettet `violence` og pr칮ve 친 skrive om den aktuell kodelinjen over ved hjelp av pipe-operatoren. I klartekst skal vi gj칮re f칮lgende operasjoner:

1. Starte med datasettet `violence`
2. Plukke ut alle radene som har verdi `"Violent"` i kolonnen `violent_treatment`.
3. Plukke ut kolonnen `aggression_level`

For 친 velge ut bestemte rader kan vi bruke funksjonen `filter()`. Ved hjelp av pipe-operatoren kan vi skrive steg 1 og 2 som


```r
violence %>% filter(violent_treatment == "Violent")
```

```
## # A tibble: 126 x 5
##       id aggression_level violent_treatment difficulty_treatm~ experienced_viol~
##    <dbl>            <dbl> <chr>             <chr>              <chr>            
##  1     1                4 Violent           Easy               Less Violent     
##  2     2                5 Violent           Hard               Violent          
##  3     5                2 Violent           Easy               Violent          
##  4     6                9 Violent           Hard               Less Violent     
##  5    10                4 Violent           Hard               Violent          
##  6    18                4 Violent           Hard               Violent          
##  7    21                4 Violent           Easy               Violent          
##  8    22                9 Violent           Hard               Less Violent     
##  9    25                7 Violent           Easy               Violent          
## 10    26                1 Violent           Hard               Less Violent     
## # ... with 116 more rows
```

N친 ser vi at vi bare har 126 rader igjen, og det er nettopp de radene som i kolonnen `violent_treatment` har verdi `"Violent"`. Det neste steget er 친 velge ut kolonnen `aggression_level`. Det gj칮r vi ved 친 bruke funksjonen `select()`, og hele sekvensen ser da slik ut (linjeskift gj칮r det enda mer lesbart):


```r
violence %>% 
  filter(violent_treatment == "Violent") %>% 
  select(aggression_level)
```

```
## # A tibble: 126 x 1
##    aggression_level
##               <dbl>
##  1                4
##  2                5
##  3                2
##  4                9
##  5                4
##  6                4
##  7                4
##  8                9
##  9                7
## 10                1
## # ... with 116 more rows
```

Man kan velge flere kolonner ved 친 sette komma mellom kolonnenavn, og man kan i stedet velge *bort* kolonner ved 친 sette minustegn foran kolonnenavnet, f.eks:


```r
violence %>% select(id, aggression_level)
violence %>% select(-id)
```

N친 har det seg slik at vi gjerne 칮nsker 친 hente ut den aktuelle kolonnen som en *vektor*. Det gj칮r vi enkelt ved 친 slenge p친 en `pull` p친 slutten av en pipe-sekvens. Til slutt m친 vi passe p친 친 lagre vektoren med riktig navn, slik at vi f친r:


```r
voldelig <- violence %>% 
  filter(violent_treatment == "Violent") %>% 
  select(aggression_level) %>% 
  pull
```

Denne koden er ekvivalent med den som startet dette avsnittet i 칮vingen. Den er derimot mye enklere 친 lese, og *veldig* mye enklere 친 utvide til 친 inkludere flere operasjoner.

La oss se p친 enda en funksjon som vil v칝re sv칝rt nyttig for oss senere. Vi kan bruke `mutate()` til 친 *lage nye kolonner*. La oss for eksempel si at vi vil lagre kvadratet av `aggression_level` eller summen av `aggression_level` og `id` som egne kolonner (som selvsagt er helt meningsl칮st i dette tilfellet, kun et eksempel). Det kan vi gj칮re slik:


```r
violence %>% 
  mutate(ny1 = aggression_level^2) 
```

eller


```r
violence %>% 
  mutate(ny2 = id + aggression_level)
```

Her er `ny1` og `ny2` navn p친 de nye kolonnene, som vi kan velge selv.

**Oppgave:** Gjenta **Oppgave 3.2**, men ved 친 bruke teknikkene i dette avsnittet.

#### Interaktiv 칮ving i `dplyr` {-}

Hvis du 칮nsker 친 trene mer p친 dette s친 finnes det en interaktiv modul i `swirl` som omhandler datamanipulasjon ved hjelp av `dplyr`. Hvis du ikke har gjort det alledede, skriv `install.packages("swirl")` i konsoll. Start du opp `swirl` med 친 skrive f칮lgende:


```r
library(swirl)
install_course("Getting_and_Cleaning_Data ") # legger til nytt kursmateriale
swirl()
```

Du vil i starten bli bedt om 친 skrive inn ditt navn og s친 f칮lger litt info om hvordan swirl fungerer. Du blir s친 bedt om 친 velge kurs. Her skal du f칮rst velge alternativet 'Getting and Cleaning Data'. Du f친r s친 se alle modulene dette kurset inneholder. I denne 칮vingen skal du pr칮ve deg p친 modul 1 **'Manipulating Data with dplyr'**. 

## Data칮ving 3

### Oppgave 1: Interaktiv 칮velse

F칮r vi tar fatt p친 dataanalysen begynner vi som vanlig med litt R-trening i swirl.  Har du allerede installert pakken swirl (skriv `install.packages("swirl")` i konsoll hvis ikke) starter du opp swirl med 친 skrive f칮lgende i konsollen:


```r
library(swirl)
install_course("Regression_Models") # legger til nytt kursmateriale om regresjon
swirl()
```

Du vil i starten bli bedt om 친 skrive inn ditt navn. Hvis du bruker samme navn som tidligere f친r du kanskje tilbud om 친 starte opp igjen der du slapp, men da kan du bare velge det nederste valget 'No. Let me start something new'. Du velger s친 alternativet 'Regression Models' hvor du f친r se alle modulene dette kurset inneholder. I denne 칮vingen skal du pr칮ve deg p친 modul modul 1 **'Introduction'**. Her vil du l칝re litt om hvordan du kan bruke R til 친 gj칮re en regresjonsanalyse ved hjelp av et treningsdatasett. Noen av kommandoene som gjennomg친s i denne modulen vil komme til nytte senere i datalabben. 

Husk at det helt til h칮yre vil st친r hvor langt du har kommet i prosent. St친r du helt fast med et punkt kan du skrive `skip()` for 친 hoppe over dette punktet. N친r du har fullf칮rt en modul blir du spurt om du vil motta 'credit' for 친 ha fullf칮rt modulen. Her kan du svare nei. 칒nsker du 친 avbryte underveis skriver du `bye()`. Skriver du inn det samme navnet n친r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk 친 avslutt swirl (`esc`) f칮r du begynner p친 del to av 칮vingen. Lykke til!

### Oppgave 2: Regresjonsanalyse 

Et rock-and-roll museum 친pnet i Atlanta i 1990. Museet l친 i en sentral del av byen i n칝rheten av mange ulike butikker. Mot slutten av juli m친ned i 1992 startet en stor brann i en av disse butikkene som 칮dela hele kvartalet, inkludert museet. Heldigvis var museet forsikret, b친de mot selve brannskadene, og mot tapte billettinntekter i gjennoppbyggingsperioden. 

Vanligvis vil et forsikringsselskap beregne erstatningsbel칮pet under antakelsen om at bes칮kstallene i gjenoppbyggingsperioden ville v칝rt p친 samme niv친 som bes칮kstallene i tiden f칮r brannen. I dette tilfellet mente derimot eierne av museet at bes칮kstallene var *칮kende*, slik at de reelt sett hadde krav p친 et st칮rre erstatningsbel칮p. Argumentet var basert p친 bes칮kstallene til en forn칮yelsespark like ved. Forn칮yelsesparken 친pnet i desember 1991, slik at museet og parken opererte sammen i de siste fire ukene av 1991, og de f칮rste 28 ukene i 1992 f칮r brannen 칮dela museet. 

Museet 친pnet igjen i april 1995, men var da betydelig st칮rre enn det var opprinnelig. Data for bes칮kstall for museet og forn칮yelsesparken finner vi i regnearket [`C16-01.xlsx`](datasett/C16-01.xlsx). Som i de to foreg친ende data칮vingene legger du denne filen i en mappe p친 maskinen din, og oppretter et tomt R-script der du lagrer koden for denne oppgaven. 

**Oppgave 2.1:** Kikk raskt p친 datasettet i Excel eller tilsvarende. Du ser at det er tre kolonner, en som angir ukenummer (`Week`, teller fra 1 til 205), en som angir ukentlig bes칮kstall p친 museet (`Museum`) og en som angir ukentlig bes칮kstall i forn칮yelsesparken (`A-Park`). Legg merke til at bes칮kstallet i museet er null fra og med uke 33, til og med uke 179, som er perioden fra brannen til ny친pning.

**Oppgave 2.2:** Last s친 datasettet inn i R som f칮r ved hjelp av `read_excel()`-funksjonen. Gi det et passelig navn (f.eks `visits`), og sjekk raskt at det har g친tt bra ved 친 taste inn datanavnet i konsollen. Da skal det se omtrent slik ut:




```r
visits
```

```
## # A tibble: 205 x 3
##     Week Museum `A-Park`
##    <dbl>  <dbl>    <dbl>
##  1     1    787     1379
##  2     2   1179     1396
##  3     3   4225     5332
##  4     4   1336     1477
##  5     5   2122     3717
##  6     6   1136     1663
##  7     7   2413     3573
##  8     8   1399     2086
##  9     9   1528     2503
## 10    10   1788     2553
## # ... with 195 more rows
```
Legg merke til f칮lgende:

- Observasjonene ser ut til 친 v칝re de samme som vi s친 da vi kikket p친 selve regnearket. Det er alltid en god vane 친 forsikre seg om at R har lest inn datasettet p친 riktig m친te.
- Et av variabelnavnene har f친tt noen rare t칮dler rundt seg. Grunnen til det er at `A-park` inneholder en bindestrek, s친 for at R ikke skal tolke det tegnet som et minustegn (og dermed gi oss et mareritt med feilmeldinger), m친 vi alltid bruke disse t칮dlene n친r vi refererer til denne variabelen. (P친 tastaturet som forfatteren av disse ord skriver p친, er det `Shift +`  tasten til venstre for `Backspace`. 

**Oppgave 2.3:** F칮r vi g친r videre, m친 vi f친 et bedre begrep om problemet ved 친 kikke grafisk p친 observasjonene. La oss plotte observasjonene i et linjeplott for 친 se hvordan de utvikler seg over tid, ved 친 ha ukenummer p친 $x$-aksen og bes칮kstall p친 $y$-aksen. Vi kan lage et enkelt plott for bes칮kstall for museet ved 친 skrive


```r
# Laster f칮rst ggplot-pakken (det trenger vi bare gj칮re en gang i skriptet)
library(ggplot2)        

# Lager et enkelt linjeplott:
ggplot(visits, aes(x = Week, y = Museum)) +
  geom_line()
```

<img src="met4_files/figure-html/unnamed-chunk-161-1.png" width="672" />

Du kan legge til bes칮kstall for forn칮yelsesparken ved 친 plusse p친 en ny linje med `geom_line()`, men da m친 du spesifisere `y`-variabelen p친 nytt. Hele plottekommandoen blir da:


```r
ggplot(visits, aes(x = Week, y = Museum)) +
  geom_line() +
  geom_line(aes(y = `A-Park`))
```

<img src="met4_files/figure-html/unnamed-chunk-162-1.png" width="672" />

Vi ser at det er en sterk sammenheng mellom bes칮kstallene til museet og parken, spesielt etter gjen친pningen i 1995, og det skal vi utnytte n친r vi senere skal beregne erstatningssummen.

**Oppgave 2.4:** Juster p친 argumentene i `geom_line()`-funskjonene, og legg til flere "lag" p친 samme m친te som vi gjorde for 친 pynte p친 figuren i oppgave 3 i kapittel \@ref(r-ekstra) (det er 100% lov 친 Google). Dette ser bedre ut:

<img src="met4_files/figure-html/unnamed-chunk-163-1.png" width="672" />

**Oppgave 2.5:** La oss n친 ta utgangspunkt i forsikringsselskapets p친stand: bes칮kstallet i perioden der museet er stengt skal beregnes ved hjelp av observasjonene *f칮r brannen*. Vi estimerer parametrene i en enkel regresjonsmodell

$$y_i = \beta_0 + \beta_1x_i + \epsilon,$$
der responsvariabelen $y_i$ er bes칮kstallet p친 museet p친 dag nr. *i*, og $x_i$ er bes칮kstallet i forn칮yelsesparken samme dag. Datasettet vi skal bruke er alts친 *de 28 f칮rste radene* i datasettet `visits`. Da kan vi enten lage en ny tabell som best친r av de 28 f칮rste radene, eller s친 kan vi bruket argumentet `subset` i `lm()`-funkesjonen til 친 spesifisere hvilke observasjoner som skal brukes.

Estimer regresjonsmodellen ved 친 kj칮re f칮lgende kall til `lm()`:


```r
reg1 <- lm(Museum ~ `A-Park`, data = visits, subset = 1:28)
```

**Oppgave 2.6:** Pakken `stargazer` inneholder funksjoner for 친 lage pene regesjonstabeller automatisk fra regresjonsobjekter i R. Pakken m친 installeres og lastes p친 vanlig m친te:


```r
install.packages("stargazer")
library(stargazer)
```

Inne i `stargazer`-pakken er det en funksjon som ogs친 heter `stargazer()`. Hvis du ikke har sett den brukt f칮r (f.eks i forelesning), kan du lese mer om den ved hjelp av hjelpefunksjonen: `?stargazer`. Bruk s친 `stargazer()` til 친 lage f칮lgende regresjonsutskrift (hint: bruk argumentet `type = text`):


```

===============================================
                        Dependent variable:    
                    ---------------------------
                              Museum           
-----------------------------------------------
`A-Park`                     0.712***          
                              (0.035)          
                                               
Constant                      -63.489          
                             (160.948)         
                                               
-----------------------------------------------
Observations                    28             
R2                             0.941           
Adjusted R2                    0.938           
Residual Std. Error      355.223 (df = 26)     
F Statistic           411.512*** (df = 1; 26)  
===============================================
Note:               *p<0.1; **p<0.05; ***p<0.01
```

**Oppgave 2.7:** Lag tre diagnoseplott etter mal som er gitt i forelesningsnotatene: Et som viser residualene i regresjonsmodellen i et spredningsdiagram, et QQ-plott, og et histogram. Kan du gj칮re en grov vurdering om hvorvidt forutsetningene for line칝r regresjon er oppfylt?

**Oppgave 2.8:** Bruk denne regresjonsmodellen til 친 beregne hva bes칮kstallet *hadde v칝rt* dersom museet hadde v칝rt 친pent som vanlig. Dette kan vi gj칮re ved 친 bruke `predict()`-funksjonen. F칮lg oppskriften under n친, s친 skal du pr칮ve 친 gj칮re det selv etterp친.


```r
# La oss bruke R til 친 finne ut hvilke uker museet var stengt. Kommandoen under
# lager en vektor som viser hvilke uker museet var stengt:
uker_stengt <- visits$Museum == 0

# S친 lager vi en ny data frame som inneholder verdiene av ukenummer og `A-Park`
# de ukene museet var stengt. Vi velger rader f칮r kommaet i firkantparantesene,
# og vi velger kolonner etter kommaet:
visits_pred <- visits[uker_stengt, c("Week", "A-Park")]

# Bruker predict()-funksjonen til 친 predikere tilh칮rende y'er:
predicted_visits1 <- predict(reg1, newdata = visits_pred)

# Til slutt legger vi til de predikerte verdiene som en ny kolonne i visits_pred:
visits_pred$predikert1 <- predicted_visits1
```

De predikerte bes칮kstallene er n친 lagret som kolonne `predicted1` i datasettet `visits_pred`.

**Oppgave 2.9** For 친 f친 bedre greie p친 hvordan prediksjonene egentlig ser ut kan vi legge dem til figuren v친r fra over. La oss lage en bl친 stiplet linje, og det kan vi gj칮re med 친 legge til enda et kall til `geom_lines()`. Denne gangen m친 vi bruke flere argumenter:

- Vi m친 bruke argumentet `data` til 친 si at tallene vi skal plotte for den nye linjen n친 ligger i datasettet `visits_pred`, og ikke `visits`.
- Vi m친 bruke argumentet `colour` til 친 fortelle hvilken farge vi skal ha p친 linjen.
- Vi m친 bruke argumentet `linetype` til 친 fortelle at vi vil ha en stiplet linje.

Ta for deg figuren du lagde i oppgave 2.4, og legg til f칮lgende linjer (husk 친 f친 med en `+` mellom hvert lag):


```r
geom_line(aes(x = Week, y = predikert1), 
          data = visits_pred, 
          colour = "blue", 
          linetype = "dashed")
```

Da blir figuren min seende slik ut:

<img src="met4_files/figure-html/unnamed-chunk-169-1.png" width="672" />

**Oppgave 2.10:** Kommenter kort regresjonsutskriften fra oppgave 2.6 og figuren fra oppgave 2.9. Ser det fornuftig ut?

**Oppgave 2.11:** Se p친 saken heller fra museets side. De mener at det er bes칮kstallene fra *etter* 친pningen i 2005 som skal brukes til 친 estimere regresjonsmodellen. Det er lett 친 forst친 hvorfor de 칮nsker det, for da ser det ut som at det er omtrent like mange bes칮kende p친 museet som i forn칮yelsesparken.



Repeter oppgave 2.5, men n친 bruker du alts친 bes칮kstallene fra etter 친pningen til 친 estimere regresjonskoeffisientene. **Hint 1:** Det eneste du m친 endre er hva som skal inn i `subset`-argumentet. **Hint 2:** Stigningstallet i den nye modellen skal v칝re 0.97.

**Oppgave 2.12:** Beregn hvilke bes칮kstall museet hadde hatt i perioden det var stengt ved 친 legge til grunn den nye regresjonsmodellen etter m칮nster fra oppgave 2.8, og legg dem inn i figuren etter m칮nster fra oppgave 2.9. Figuren blir skal da se omtrent slik ut hvis vi bruker en finn gr칮nnfarge (`forestgreen`) til den siste linjen:

<img src="met4_files/figure-html/unnamed-chunk-171-1.png" width="672" />

**Oppgave 2.13:** N친r vi ser hvor tett de to bes칮kstallene beveger seg etter ny친pningen er det ikke rart at de beregnede bes칮kstallene basert p친 den nye modellen (markert i gr칮nt over) f칮lger observasjoenen fra forn칮yelsesparken.  

Anta at hver billett til museet koster $6.99. Hvor stor er differansen mellom erstatningskravet til museet og tilbudet til forsikringsselskapet?



**Oppgave 2.14 (Diskusjon):** Det er ganske stor forskjell mellom tilbud og krav, men hvis vi tenker oss om skj칮nner vi fort at begger parter befinner seg i en klassisk *catch-22*. Hvis den ene partens argument f칮rer til en utbetaling som er for stor eller for liten fordi de tar utgangspunkt i slutten eller starten p친 en stigende utvikling, m친 n칮dvendigvis det motsatte standpunkt ogs친 v칝re galt av n칮yaktig samme grunn. Kan du foresl친 et kompromiss?

### Oppgave 3: Rapporter basert p친 R-analyser

Ofte er det 칮nskelig 친 bruke resultater fra R inn i rapporter, artikler og foredrag. I MET4 skal du blant annet levere b친de en obligatorisk innlevering og en hjemmeksamen. Det er fullt mulig 친 친pne et hvilken som helst tekstdokument (f.eks Word) for s친 친 belage seg p친 en 'klipp og lim'-tiln칝rming. I R-studio kan man lagre figurer ved 친 trykke p친 'Export' fanen i vinduet nede til h칮yre og s친 'Save as', eventuelt bruke `ggsave()`-funksjonen til 친 lagre plott laget med `ggplot2`. Disse kan s친 친pnes i det samme dokumentet. 

En klipp og lim-tiln칝rming kan v칝re tidkrevende og det finnes verkt칮y som gj칮r det lett 친 lage ganske s친 elegante rapporter av R-analyser. I de f칮lgende oppgavene gir vi to alternativer til 친 lage rapporter. Den f칮rste metoden er noe enklere enn den andre. 
**Oppgave 3.1:**  Rstudio kan lage en enkel rapport ut av .R filen din ved at du trykker **ctrl + shift + k** (**cmd + shift + K** p친 mac).  Pr칮v det med .R filen du laget i Oppgave 2. F칮rste gang du gj칮r dette blir du bedt om 친 installere noen pakker og det aksepterer du. Du f친r s친 opp et vindu som ber deg velge format p친 rapporten:

<img src="bilder/compile.PNG" width="184" />

Har du tilgang til 'Word' kan du velge 'MS word', hvis ikke velger du formatet HTML. For PDF format er du avhengig av 친 installere 'latex'. Rapporten vil da legge seg i mappen hvor du har lagret datasettet og .R filen. Fordelen med 친 velge 'MS word' formatet er at du kan bruke den samme word filen til 친 redigere og kommentere resultatene.     

**Oppgave 3.2 (litt mer krevende):** Man kan ogs친 lage rapporter ved 친 bruke et tekstformat kalt R Markdown. Dette er nok litt mer utfordrende enn tiln칝rmingen i oppgaven over, men vil gi sv칝rt pene raporter/dokumenter. 칒nsker du 친 utforske denne muligheten s친 ta en titt p친 [denne videoguiden](https://www.youtube.com/watch?v=tKUufzpoHDE).

## Data칮ving 4

### Oppgave 1: Interaktiv 칮velse
F칮r vi tar fatt p친 dataanalysens begynner vi som vanlig med litt R-trening i swirl.  Har du allerede installert pakken swirl (skriv `install.packages("swirl")` i konsoll hvis ikke) starter du opp swirl med 친 skrive f칮lgende i konsollen:


```r
library(swirl)
swirl()
```

Du vil i starten bli bedt om 친 skrive inn ditt navn og s친 f칮lger litt info om hvordan swirl fungerer. Du blir s친 bedt om 친 velge kurs. Her skal du f칮rst velge alternativet 'R Programming'. Merk at du kanskje m친 trykke alternativet **'No. Let me start something new'** for 친 komme tilbake til hovedmenyen etter 친 ha brukt swirl tidligere. Du f친r s친 se alle modulene dette kurset inneholder. I denne 칮vingen skal du pr칮ve deg p친 modul 9 **'Functions'**. I denne modulen vil du l칝re litt om funksjoner i R.

Merk at det helt til h칮yre vil st친r hvor langt du har kommet i prosent. St친r du helt fast med et punkt kan du skrive `skip()` for 친 hoppe over dette punktet. N친r du har fullf칮rt en modul blir du spurt om du vil motta 'credit' for 친 ha fullf칮rt modulen. Her kan du svare nei. 칒nsker du 친 avbryte underveis skriver du `bye()`. Skriver du inn det samme navnet n친r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk 친 avslutt swirl (`esc`) f칮r du begynner p친 del to av 칮vingen. Lykke til!

### Oppgave 2 - Maskinl칝ring: Logistisk regresjon og k n칝rmeste naboer

I denne oppgaven skal vi se p친 de samme dataene som ble brukt i forelesningen om logistisk regresjon. Vi har data p친 10000 kredittkortkunder og vi 칮nsker 친 kunne bygge og trene en best mulig modell til 친 predikere hvilke kunder som vil misligholde sin gjeld. 

**Oppgave 2.1:** Vi starter med 친 f친 tak i dataene. Disse er integrert i pakken `ISLR`. Last inn pakken og ta en titt p친 dataene ved bruk av f칮lgende linjer (hvordan du kommenterer er opp til deg):


```r
library(ISLR)       # Pakke som inneholder dataene     
head(Default)       # Viser starten p친 dataframen
str(Default)        # Viser hvilke typer variabler dataframen inneholder
```
 
* Responsvariabelen er
    + \texttt{default}: Dette er en kategorisk variabel. Misligholdt kunden gjelden?
* Forklaringsvariabler:
    + \texttt{student}: Kategorisk
    + \texttt{balance}: Kontinuerlig, st칮rrelsen p친 gjelden ($)
    + \texttt{income}: Kontinuerlig, kundens 친rlige inntekt ($)

**Oppgave 2.2:** Det neste vi gj칮r er 친 visuelt unders칮ke avhengigheten mellom det 친 misligholde (`default`) og hvor stor gjeld (`balance`) kunden har . Vanligvis n친r vi visuelt skal inspisere sammenhengen mellom to variabler lager vi et spredningsplott. Men n친r den ene variabelen er kategorisk er det mer informativt 친 sammenligne to boksplott av den kontinuerlige variabelen for hver av gruppene den kategoriske variabelen representer. Dette kan gj칮res p친 f칮lgende m친te:


```r
boxplot(balance ~ default, data = Default,
        ylab = "balance", xlab = "default")
```
Her er det formelen `balance ~ default` som gj칮r at `boxplot()` funksjonen lager to boksplott av `balance`; et for gruppen som misligholdt ("Yes") og et for gruppen som ikke misligholdt ("No"). Reflekter over figuren og gj칮r deg opp en mening om sammenhengen mellom `default` og `balance`.

**Oppgave 2.3:** Det er lurt 친 dele inn dataene i et treningssett og et testsett n친r vi driver med maskinl칝ring. Treningsettet bruker vi til 친 tilpasse (trene/l칝re) modellen, mens testsettet bruker vi til 친 se hvor godt forskjellige modeller presterer. Dette kan gj칮res p친 flere m친ter, men vi velger her 친 bruke pakken `dplyr` som ble beskrevet i siste del av datalabb 2. 

F칮rst legger vi til en unik id til hver kunde. Vi lar id-nummeret v칝re lik radnummeret til kunden og til dette bruker vi funksjonen `mutate`: 


```r
library(dplyr)
my_data <- Default %>%
  mutate(id = row_number()) 
```
Siden vi n친 skal trekke et utvalg av dataene v친re kan det v칝re lurt 친 sikre at resultatet er reprodusibelt ved 친 sette 

```r
set.seed(123) 
```
foran koden som f칮lger. Du kan gjerne velge et annet tall enn 123, men n친r en gj칮r dette i forkant av en tilfeldig trekning i R er trekningen bestemt.

S친 trekker vi et treningssett best친ende av 70 % av dataene ved bruk av funksjonen `sample_frac`:

```r
train <- my_data %>%  
  sample_frac(.70)
```
De resterende kundene bruker vi som testsett ved bruk av funksjonen `anti_join`: 

```r
test <- my_data %>%         # Treningssettet er da de resterende 30 % av dataene
  anti_join(train, by = 'id')
```
Koden over trekker ut alle kunder som ikke har lik `id` som i treningssettet som derfor svarer til de resterende 30 % av dataene.

**Oppgave 2.4:** Vi forklarer i denne oppgaven hvordan en logistisk regresjonsmodell kan estimeres, tolkes og brukes. Du vil m친tte lage nye modeller med tilsvarende koder i oppgavene som f칮lger.

Vi lager en modell hvor vi bruker variabelen `balance` (gjeld) som forklaringsvariabel.  Vi bruker da funksjonen `glm`:

```r
model1 <- glm(default ~ balance, data = train,
              family = "binomial")
```
Syntaksen til `glm`-funksjonen er veldig lik den vi bruker i regresjon (`lm`-funksjonen) bortsett fra at vi p친 spesifisere argumentet `family = "binomial"` for at 친 fortelle `R` at vi 칮nsker 친 gj칮re en logistisk regresjon. Merk at vi bruker treningssettet til 친 estimere (trene) modellen ved 친 spesifisere argumentet `data = train`. 

Det kan v칝re lurt 친 se om forklaringsvariabelen `balance` har en signifikant effekt p친 `default` ved 친 bruke `summary` funksjonen:

```r
summary(model1)
```

For 친 tolke hvilken effekt `balance` (gjeld) har p친 `default` (mislighold) er det lurt 친 regne ut hva effekt en 칮kning p친 1 $ i  `balance` har p친 oddsen for `default` (Se forelesning): 

```r
exp(coef(model1))
```

```
##  (Intercept)      balance 
## 2.205746e-05 1.005567e+00
```
Vi ser at oddsen for `default` 칮ker med en faktor 1.0056 (en 0.56 % 칮kning) dersom `balance` 칮ker med 1 $.

Si at du 칮nsker 친 predikere sannsynligheten for hvorvidt to kunder med henholdsvis 1000 \$ og 2000 \$ i `balance`  vil misligholde sitt l친n. Da kan vi bruke `predict`^[Funksjonen `predict`  er satt opp med litt forskjellige argumenter alt ettersom hvilken type modell vi bruker. Du kan lese dokumentasjonen `?predict.glm` for 친 se hvordan den er satt opp for `glm` objekter] p친 f칮lgende m친te:


```r
to_personer <- data.frame(balance = c(1000, 2000))
pred <- predict(model1, newdata = to_personer, type = "response")
pred
```

```
##           1           2 
## 0.005648303 0.593966756
```
Det f칮rste argumentet i funksjonen `predict` er hvilken modell vi skal bruke i prediksjonen (`model1`). Det andre argumentet `newdata` er hvilke kunder vi 칮nsker 친 predikere misligholdsannsynligheter for. Vi setter dette argumentet til `data.frame`'n vi har kalt `to_personer` hvor hver rad svarer til en kunde med et sett forklaringsvariabler (i dette tilfellet to kunder og derfor to rader). Det er viktig at den inneholder en (eller flere) kolonne(r) med kolonnenavn som svarer til navnet til forklaringsvariabelen(e) vi har brukt i modellen.  Argumentet `type = "response"` gj칮r at vi f친r returnert sannsynligheten for mislighold og ikke bare verdien av det line칝re leddet i modellen. 

Hvis vi ut fra disse sannsynlighetene 칮nsker en klassifiseringsregel som klassifiserer om kunden vil misliholde eller ikke ("Yes/No") er det naturlig 친 tildele kunden "Yes" hvis misligholdsannsynligheten overstiger en hvis grense og "No" hvis ikke. Det kan det tenkes at kredittgiver vil v칝re enten konservativ (sette grensen lavt, si 0.3) eller liberal (sette grensen h칮yt, si 0.7), men i eksempelet under bruker vi en "n칮ytral" grense p친 0.5:


```r
ifelse(pred > 0.5, "Yes", "No")
```

```
##     1     2 
##  "No" "Yes"
```
Som navnet tilsier, vurderer `ifelse` funksjonen en logisk test i f칮rste argumentet (`pred > 0.5` hvor `pred` er misligholdsannsynlighetene vi predikerte) og hvis testen har verdi `TRUE` gir den ut det du skriver i det andre argumentet (`"Yes"`), og det tredje argumentet (`"No"`) ellers. Vi ser at individet med 1000 \$ i gjeld blir klassifisert som "No", mens individet med 2000 \$ i gjeld blir klassifisert som "Yes".    

**Oppgave 2.4:** Lag en ny modell ved navn `model2` hvor du bruker den kategoriske variabelen `student` som forklaringsvariabel.

* Hvilken effekt har det 친 v칝re student p친 for oddsen for mislighold? 
* Prediker sannsynligheten for at en student og en ikke-student misligholder gjelden sin.

**Oppgave 2.5:** Lag en tredje model ved navn `model3` hvor du bruker alle forklaringsvariablene. 

* Hvilken effekt har det 친 v칝re student p친 for oddsen for mislighold n친? Sammenlign med forrige oppgave.
* Unders칮k visuelt om det er en sammenheng mellom `student` og `balance` med 친 lage et boxplot over `balance` for studenter og et for ikke-studenter (hint: se Oppgave 2.2). 
* Prediker sannsynligheten for mislighold for en ikke-student og en student med lik `balance` og `income` p친 henholdsvis 1500 $ og 10000 $. Sammenlign med prediksjonen du gjorde i Oppgav 2.4. Basert p친 `model2` og `model3`, hvordan skal kredittgiver forholde seg til en student versus en ikke-student dersom a) Ingen informasjon om `balance` eller `income` er oppgitt og b) dersom en vet `balance` og `income`?  

**Oppgave 2.6:** I denne oppgaven skal vi trene opp en knn (k-n칝rmeste-naboer) modell til 친 gj칮re en tilsvarende klassifisering som den logistiske regresjonsmodellen gjorde over. Funksjonen `train` som vi trenger er inneholdt i pakken `caret` (som m친 installeres ved hjelp av `install.packages("caret")`). Vi velger 친 tilpasse en modell hvor antall naboer "k" velges automatisk med kryssvalidering vi argumentet "`trControl":  



```r
library(caret)

# R-kode dersom vi vil velge k automatisk
set.seed(200)
trControl <- trainControl(method  = "cv", # 5-fold kryssvalidering
                          number  = 5)

# Tilpasser modellen
model4 <- train(default ~ balance + income + student,
                 data = train,
                 method = "knn",
                 trControl  = trControl,
                 metric     = "Accuracy")
```

Vi kan sjekke hvilken k som ble valgt p친 f칮lgende m친te (siden kryssvalidering bruker tilfeldige trekninger kan resultatet bli noe foreskjellig fra gang til gang, selv om datasettet er det samme):


```r
# Hvilken k valgte kryssvalideringen?
k <- model4$finalModel$k
k
```

```
## [1] 5
```
Som for de andre modellene bruker vi funksjonen `predict` n친r vi skal predikere og syntaksen er helt lik:

```r
to_kunder <- data.frame(balance = c(1000, 2000), income = 10000, student = c("Yes", "Yes"))
predict(model4, newdata = to_kunder)
```

```
## [1] No  Yes
## Levels: No Yes
```
Merk at i motsetning til de logistiske regresjonsmodellene som predikerte sannsynligheter klassifiserer knn modellen kundene direkte som "Yes"/"No". 

**Oppgave 2.7:** Vi 칮nsker 친 vurdere hvilken av `model3` (logistisk regresjon) og `model4` (knn) som er best. Vi kan da sjekke hvor godt de klarer 친 klassifisere testsettet v친rt hvor vi vet hvem som har misligholdt l친nene sine. Vi starter med 친 hente ut de sanne verdiene av `default` i treningssettet: 


```r
sann <- test$default  # Den sanne verdien av default i testdataene
```
Disse skal vi s친 sammenligne med hvordan modellene klassifiserer de samme kundene basert p친 de andre variablene. Vi gj칮r f칮rst klassifiseringen med den logistiske regresjonsmodellen:




```r
pred_logreg <- predict(model3, newdata = test, type = "response") # Predikert sannsynlighet
klass_logreg <- ifelse(pred_logreg > 0.5, "Yes", "No")            # Klassifisering av kundene
```
En oversikt over hvor mange riktige/feil klassifiseringer modellen gj칮r kan lett oppsummeres med en kontigenstabell. For 친 lage en kontigenstabell i R bruker vi funksjonen `table`:


```r
logreg_tab <- table(sann, klass_logreg) # Kontigenstabell
logreg_tab
```

```
##      klass_logreg
## sann    No  Yes
##   No  2889   11
##   Yes   70   30
```
Her kan vi f.eks se at 2889 kunder blir riktig klassifisert som "No", dvs at de ikke misligholdt l친net og modellen sp친r at de ikke vil misligholde l친net. Merk at diagonalen (2889 og 30) representerer korrekte klassifiseringer, mens av-diagonal (11 og 70) representer feil klassifiseringer. 

Det kan v칝re en fordel 친 dele kontigenstabellen over med totalt antall kunder for 친 f친 andelel i stedet. Funksjonen `prop.table` gj칮r nettopp dette:


```r
logreg_tab_norm <- logreg_tab %>% 
  prop.table %>%  # normaliser
  round(3)        # rund av til 3 desimaler
logreg_tab_norm
```

```
##      klass_logreg
## sann     No   Yes
##   No  0.963 0.004
##   Yes 0.023 0.010
```

Summen av diagonalen p친 denne tabellen (0.963 og 0.01) gir da totalt andel korrekt klassifiseringer:


```r
logreg_tot <- sum(diag(logreg_tab_norm))               # Total andel korrekt klassfisering
logreg_tot
```

```
## [1] 0.973
```

**Oppgave 2.8:** Gj칮r en tilsvarende klassifisering av kundene i testsettet med knn modellen `model4` og sammenlign med resultatet over. Hvilken modell foretrekker du? Hvilke egenskaper ved klassifisering tror du kredittgiver vektlegger?

<!--chapter:end:07-data칮vinger.Rmd-->


# Diverse ekstrastoff

Her vil du finne diverse ekstrastoff somm kan v칝re nyttig etter hvert som semesteret skrider frem. Per n친 er det snakk om tidligere eksamensoppgaver, samt diverse (og lett redigert) korrespondanse mellom studenter og studentassistenter som kan v칝re nyttig for senere 친rganger av studenter.

## Tidligere eksamensoppgaver (skoleeksamen) {#skoleeksamen}

I tabellen under finner du en lang rekke eksamenssett som er gitt tidligere i MET4 (og dets forl칮per INT010). Vi har lagt til en kolonne med oppgaver som 친penbart ligger utenfor pensum i dag. Utover det er selvsagt oppgavene relevante i st칮rre eller mindre grad for kurset i dag, uten at vi har mulighet til 친 g친 n칝rmere inn p친 en slik detaljert rangering.

Lenger nede p친 siden finner du noen kommentarer og rettelser til oppgavesett og l칮sningsforslag som har dukket opp i ettertid.

<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Semester </th>
   <th style="text-align:left;"> Oppgaver </th>
   <th style="text-align:left;"> L칮sningsforslag </th>
   <th style="text-align:left;"> Ikke lenger pensum per 2021 </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2008 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-08-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-08-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1c-1e, 3a-3c, 4a-4c </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2009 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-09-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-09-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1, 2c-2e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2009 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-09-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-09-h-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2010 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-10-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-10-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1c, 3a-3e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2010 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-10-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-10-h-fasit.pdf) </td>
   <td style="text-align:left;"> 3a-3c </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2011 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-11-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-11-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1d-1e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2011 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-11-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-11-h-fasit.pdf) </td>
   <td style="text-align:left;"> 1a-1f, 3c-3e </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2012 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-12-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-12-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2012 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-12-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-12-h-fasit.pdf) </td>
   <td style="text-align:left;"> 1a (ANOVA-delen) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2013 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-13-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-13-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2013 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-13-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-13-h-fasit.pdf) </td>
   <td style="text-align:left;"> 1g-1h </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2014 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-14-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-14-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1f-1i </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2014 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-14-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-14-h-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2015 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-15-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-15-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2015 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-15-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-15-h-fasit.pdf) </td>
   <td style="text-align:left;"> 3a-3c </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2016 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-16-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-16-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2016 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-16-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-16-h-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-17-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-17-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1c </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-17-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-17-h-fasit.pdf) </td>
   <td style="text-align:left;"> 1f-1g </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-18-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-18-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-18-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-18-h-fasit.pdf) </td>
   <td style="text-align:left;"> 1d, 1g </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2019 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-19-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-19-v-fasit.pdf) </td>
   <td style="text-align:left;"> 1c </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2019 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-19-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-19-h-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2020 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-20-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-20-v-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2020 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/skole-20-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/skole-20-h-fasit.pdf) </td>
   <td style="text-align:left;">  </td>
  </tr>
</tbody>
</table>

### Rettelser og kommentarer til oppgaver og l칮sningsforslag {-}

Her vil du finne en del kommentarer og rettelser som er spesifikke for de enkelte oppgavesettene. Dette er basert p친 et dokument som [Jarle M칮en](https://www.nhh.no/en/employees/faculty/jarle-moen/) startet p친 i sin tid, og som senere er oppdatert av [Benjamin Narum](https://www.nhh.no/en/employees/faculty/benjamin-narum/). Vi vil oppdatere denne oversikten med de nyeste 친rgangene etter hvert som det kommer inn sp칮rsm친l til eksamensoppgavene.

<details><summary>V친r 2008</summary>

**Sp칮rsm친l 1d:** *Vi skal regne ut forventet nytte. Hvorfor f친r vi $EX^2 =  20( var + \mu^2 )$?* 

Det er tatt utgangspunkt i den f칮rste regneregelen for varians i forelesningsnotatene. $Var(X)=E(X^2)-(E(X))^2$. Derav $E(X^2)=Var(X) +(E(X))^2$

**Sp칮rsm친l 2a:** *Jeg lurer jeg p친 hvordan man kommer frem til $S^2$*?

Du regner ut variansen til de to observasjonsseriene som er gitt i oppgaven (evt. standardavviket slik det er oppgitt i l칮sningsforslaget). Det kan du gj칮re p친 en lommeregner, eller du kan bruke den informasjonen som er oppgitt. For den f칮rste serien er $S^2=1,835/7$ hvor 7 er $n-1$ med $n=8$ observasjoner.

**Sp칮rsm친l 2b:** *Jeg lurer p친 hvorfor en skal bruke ensidig test der. Har du tid til 친 forklare meg det, for jeg ser ikke helt hvorfor det skal v칝re ensidig. Kan det ikke v칝re tosidig ogs친?*

Jeg ser ingen dypere mening i dette. Oppgavegiver ber om ensidig test i b/c og tosidig i d - og i l칮sningsforslaget kommenterer vedkommende at man burde brukt ensidig test ogs친 i d for 친 sammenligne resultatet av testene. Pussig. Dersom jeg skal resonnerer utenfor oppgaven antar jeg at argumentet for ensidig test er at dersom s칮lvinnholdet endrer seg, knytter det seg til at de som lager penger har et incentiv til 친 begynne jukse med s칮lvinnholdet, mens det er vanskelig 친 se for seg hvorfor noen skulle 칮ke s칮lvinnholdet i samme mynttype over tid. Dermed er man a priori villig til 친 se bort fra at sant s칮lvinnhold 칮ker.

**Sp칮rsm친l 3b:** *I oppgaven f친r vi oppgitt at det er 39 observasjoner. I oppgave b skal vi finne konfidensintervall. Hvorfor bruker vi 36 som frihetsgrader n친r det st친r at det er n-2? Og hvilken formel brukes for 친 komme fram til 0,083?*

*(n-2)* har du nok fra plansjene om enkel regresjon dvs konstantledd pluss 칠n variabel. Her blir det *n-3* (konstantledd pluss to forklaringsvariabler, *n-k-1*). *0,083* er oppgitt i regresjonsutskriften som standardavviket til koeffisienten.

**Oppgave 3c:** *Skal man ikke her p친 $F$-testen bruke $(F, \alpha, k-1,n-k)$? Er ikke $k$ her 2? (arbeidskraft og kapital) og $n$ fortsatt 36? Fasiten sier frihetsgradene er 2 og 36.*

$F$-testen er $(F, \alpha, k,n-k-1)$ dersom $k$ er antall forklaringsvariabler i tillegg til konstantleddet (slik det er i bokas og min notasjon). $n$ er 39.

**Oppgave 3i** *Det sp칮rres om hvordan man kan teste en hypotese om konstant skalautbytte! Jeg finner ikke ut av hvordan man gj칮r det! Kan du hjelpe meg med det?*

Jeg tror ikke dette er et sp칮rsm친l jeg ville gitt i denne formen. V친ren 2008 l친 kurset i siste semester. Da kunne vi forutsette at studentene skulle vite at konstant skalautbytte med denne funksjonsformen inneb칝rer at summen av koeffisientene er 칠n (Det ligger ogs친 inne som et punkt i plansjene mine om multikolinearitet, tror jeg). Da vi gjennomgikk $F$-testen for regresjon (test for om alle koeffisientene er null samtidig) nevnte jeg muntlig at $F$-testen ogs친 kan brukes p친 mindre grupper av koeffisienter. Man kan alts친 teste uttrykk av typen $\alpha+\beta=1$. Det som kommer i klammeparentes i l칮sningsforslaget har dere ingen forutsetning for 친 forst친 siden heller ikke boken har med noe om dette. Kanskje ble det sagt noe om det p친 forelesningene det semesteret, eller kanskje oppgavegiveren har tatt det med i l칮sningsforslaget for spesielt interesserte...
 
</details>

<details><summary>H칮st 2008</summary>

**Oppgave 1d:** *Med 0.05,3,144 (5 %, 3 og 144 frihetsgrader) burde grensen v칝rt p친 2.67, men i fasiten st친r det 2.60.*

Enig. Det m친 v칝re trykkfeil i l칮sningsforslaget.

**Oppgave 2d:** *N친r man skal lage et konfidensintervall for koeffisienten til en av de uavhengige variablene i en multippel regresjon, hva er da riktig antall frihetsgrader for t-verdien? I H09 oppgave 2g benyttes $(n-k-1)$ mens i H08 oppgave 2d benyttes $(n-2)$.*

Det er $n-k-1$ som er riktig frihetsgradstall, s친 l칮sningsforslaget h칮st 2008 m친 v칝re feil.

**Oppgave 3c:** *I Tabellen for kjikvadrattesten er $(f_i-e_i)^2 /e_i$ oppgitt 친 v칝re 0,04 og 0,05 i hhv. 1. og 2. rekke. Deler man 1/228 og 1/212 f친r man hhv. ca 0,004 og 0,005. Dette sl친r dog ikke ut p친 konklusjon til testen.*

Du har rett.

</details>

<details><summary>V친r 2009</summary>

**Oppgave 2c:** *Jeg lurer p친 hvorfor fasiten sier at frihetsgradene til $F$-testen er $F_{\alpha, k-1,n-1}$? Jeg trodde frihetsgradene ved denne testen var $F_{\alpha, k, n-k-1}?*

Det ser for meg ut som om l칮sningsforslaget er riktig, og at du blander sammen denne F-testen med formelen for den n칝rt beslektede F-testen knyttet til multippel regresjon.

</details>

<details><summary>H칮st 2009</summary>

**Oppgave 1a:** *렗opulation brukes veldig fritt i boken, og kan, som jeg har forst친tt oversettes til b친de gruppe og populasjon. Eksempelvis i denne oppgaven med 렱ormalfordelte populasjoner. Dette sjekkes jo vha dataene (fra utvalget?). Er det da snakk om hele populasjonen eller utvalget?*

Populasjonene i den virkelige verden kan vi aldri observere, men det er de som har en fordeling. S친 observerer vi utvalget som er trukket fra populasjonen til 친 teste hypoteser om populasjonen, for eksempel en hypotese om at populasjonen er normalfordelt. Du har sikkert rett i at vi noen ganger snakker om grupper for det som er en populasjon.

**Oppgave 2c:** *Vi skal dr칮fte et residualplott. I fasiten her st친r det at histogram og normalscore antyder at residualene ikke er normalfordelt? Vi har da godkjent mye d친rligere figurer tidligere, med ca. likt antall observasjoner? I samme eksamenssett oppgave1 b) skal vi teste for lik varians. her er n1=14 og n2=9. videre skal v1=n1-1=14-1=13 og v2=n2-2=9-2=7 (jf. formel s. 442 i pensumboken) fasiten her sier derimot at v2=8?*

For 친 ta det siste f칮rst. Det er trykkfeil i boken p친 side 442. N친r det gjelder residualplottet er jeg enig med deg. Man kunne like gjerne skrevet at det ikke er tydelig avvik fra normalitet.

**Oppgave 2g:** *I kompendiet st친r det at man bruker $k$ fra $t$-tabell med $n-2$ frihetsgrader, i fasiten her ser det ut til at de har brukt $n-k-1$?*

Ogs친 i forelesningsnotatene st친r det *n-k-1* under multippel regresjon (plansje 269).
</details>

<details><summary>V친r 2010</summary>

**Oppgave 3d:** *Hvorfor blir det 12  F(12) - 10F(11)-(12-10) n친r $q=15$ og $\mu=10$?*

Dette ser merkelig ut for meg ogs친 (Han som har laget oppgaven har sluttet.) Antar det skulle v칝rt 15 og 14.

</details>

<details><summary>H칮st 2010</summary>

**Oppgave 1a:** *I h칮steksamen i 2010 oppgave 1a) har de brukt antall frihetsgrader lik 31. Jeg lurte p친 hvorfor det ikke blir 34, alts친 n-2? Hvordan vet vi n친r frihetsgrader er $n - k - 1$, og n친r det er $n - 2$?*

For line칝r regresjon er antall frihetsgrader lik $n$ minus antall parametre du har estimert i analysen din. I enkel regresjon antar vi formen p친 uttrykket $Y = \beta_1 X + \beta_0$ og m친 estimere $\beta_1$ og $\beta_0$, alts친 2 parametre. Derfor blir regelen $n - 2$. I Multippel regresjon antar vi f.eks. en form p친 uttrykket $Y = \beta_2 X_2 + \beta_1 X_1 + \beta_0$ og m친 estimere $\beta_2$, $\beta_1$ og $\beta_0$, alts친 3 stk. I regelen $n - k - 1$ er $k$ antall variable vi estimerer en koeffisient for ($k = 2$) og den siste "1" er for $\beta_0$. I eksempelet mitt blir det da $n - 3$. I eksamensoppgaven blir det $n - 5$.

**Oppgave 1b:** *Har du mulighet til 친 sende meg utdypende forklaring p친 Eksamen H10 oppgave 1 b?*

Her er det det er feil i l칮sningsforslaget. Jeg tror oppgavegiver endret modellen etter at f칮rsteutkastet til l칮sningsforslaget var klar, og s친 har l칮sningsforslaget ikke blitt oppdatert tilsvarende. Rett svar skal v칝re $-0,160 \pm 2,042*0,034$.

**Oppgave 1d:** *Hvordan er fremgangsm친ten for 친 forst친 at dette er en loglog-modell, og ikke en log-lin eller lin-log? Fasiten sl친r fast at det er en loglog, men forst친r ikke helt hvordan man g친r frem.*

Modellen er loglog mellom pris (PG) og inntekt (I) fordi regresjonen er gjort med hensyn p친 logaritmen av disse to. I fasit tenker de nok at de isolerer de to variablene for 친 tolke dem for seg f칮rst. Vi har jo egentlig 친r line칝rt og kvadrert i modellen ogs친. Kanskje man skal kalle hele modellen en log-log-lin-sq modell (ikke gj칮r det). Poenget er at loglog-forhold har tolkningen om at prosentvis 칮kning i den ene svarer til prosentvis 칮kning av den andre, som gj칮r seg fint i en diskusjon der man skal tolke en modell.

</details>

<details><summary>H칮st 2012</summary>

**Oppgave 1a:** *I l칮sningsforslaget er Analyse 2 omtalt som 춺enveis faktoranalyse췉. Er dette riktig?*

Nei, det er en trykkfeil. Det skulle st친tt 춺enveis variansanalyse췉. Faktoranalyse er en helt annen metode som ligger utenfor pensum, men som noen ganger foreleses i forbindelse med hjemmeeksamen.

**Oppgave 1d:** *Hvor en skal regne ut en kritisk grense for $F$ p친 5% sign.niv친 for v1= 175 og v2= 569. Hvorfor er det brukt en ensidig test her? (gir verdi 1,18) Er det ikke mer naturlig 친 bruke en tosidig her? En annen ting, er det nok 친 se p친 p-verdi eller m친 man regne ut en kritisk grense?*

Enig med deg. Det er ikke noe holdepunkt for 친 bruke ensidig test her. Jeg har ment 친 bruke tosidig test, men brukt feil tabell  0.05 i stedet for 0.025. Korrekt kritisk grense skulle dermed v칝re 1,22. Det er ingen grunn til 친 regne ut kritisk grense hvis det er gitt en programutskrift med p-verdi

</details>

<details><summary>H칮st 2015</summary>

**Oppgave 1b:** *I H15-eksamen b) bruker vi en ensidig t-test for 친 se om koeffisienten er 0 eller negativ. Jeg lurer p친 hvordan fasiten kom fram til antall frihetsgrader. Antall observasjoner er 898. Er det s친nn at antall frihetsgrader er 893 fordi vi har et konstantledd og 4 frihetsgrader? Dersom det hadde v칝rt en tosidig test, hadde vi f친tt samme antall frihetsgrader?*

Det stemmer at man trekker fra antall estimerte parametre. Tosidig vs ensidig p친virker ikke antall frihetsgrader, men p친virker signifikansniv친et du bruker.

**Oppgave 1b:** *Vi gjennomf칮re en t-test for koeffisienten i en regresjonsmodell. Hvorfor finner vi her testobservatoren ved 친 ta koeffisienten delt p친 standardavvik? Er dette en formel, eller kan du forklare n칝rmere intuisjonen bak dette?*

Se kapittel 16-4d og 17-2h i boken for formelene. Alts친, $t = \frac{\widehat \beta - \beta}{s_{b}}$ hvor $s_{b} = \frac{s_{\epsilon}}{\sqrt{(n-1) s_x^2}}$ er standardavviket til regresjonskoeffisienten.

Dette minner om 친 sammenligne avvik i forventningen p친 en normalfordeling, ved 친 dele p친 standardavviket til estimatoren $\widehat \mu = \overline X$, som er $s/\sqrt{n}$.

**Oppgave 1b og 1c:** *I b) bruker man t-test for to utvalg, mens i c) bruker man t-test for matchede par. Kommer det av at i b) har man to utvalg, mens i c) tester man forventet poengsum i samme utvalg, men med ulike sensorer? Jeg vet ikke om jeg helt har skj칮nt n친r man skal bruke t-test for matchede par.*

Matchede par vil jo gi st칮rre presisjon til 친 vurdere om de to sensorene retter forskjellig. Vi kan bruke matchede par fordi de to sensorene har rettet n칮yaktig de samme eksamensoppgavene. Alts친 har vi fjernet kilden til variasjon som ellers kommer av at ulike studenter scorer ulikt p친 pr칮ven.

I b) skal vi jo teste om den samme sensoren retter likt, men vi vet jo ikke om de to gruppene av studenter (som alts친 ikke er de samme, hver student har bare tatt eksamen en gang) egentlig burde gj칮re det like godt p친 eksamen. Dermed er det to utvalg. Du kan se video om matchede par om dette.

Man bruker T-test fordi standardavviket ogs친 m친 estimeres i analysen, det har ikke s친 mye med matchede par i seg selv 친 gj칮re.

**Oppgave 1e:** *I oppgave e) blir vi bedt om 친 bruke modell 2 hvor vi har 3 koeffisienter og 1 konstantledd. hvorfor er antall frihetsgrader fortsatt 893 og ikke 894 (da vi har en mindre koeffisient i modell 2 sammenlignet med modell 5)? Men i oppgave e) bruker man tosidig test, men er usikker p친 om det har noe 친 si for antall frihetsgrader.*

Det har nok g친tt litt fort i fasit p친 oppgave e), det skal v칝re 894 frihetsgrader, men fordi antallet er veldig stort (over 200) har det heller ikke noe 친 si. 

</details>

<details><summary>H칮st 2016</summary>

**Oppgave 1h:** *I oppgave 1 h, eksamen h칮st 2016 bes det om 친 regne ut "... variansen til andelen klager (av kandidatene som m칮tte) v친ren 2014 og v친ren 2015." I l칮sningsforslaget bruker man imidlertid  data oppgitt for v친r 2013 og 2014 til 친 regne variansen til andelen klager for henholdsvis v친ren 2014 og 2015. Hvorfor skal man her bruke fjor친ret til 친 regne ut variansen til andel klager for gjeldende 친r?*

De har bommet med 친ret.

</details>

<details><summary>V친r 2017</summary>

**Oppgave 2c:** *Eksamen V17, oppgave 2c): Man blir bedt om 친 regne ut om koeffisienten er signifikant, hvorfor er frihetsgraden 282 ($v = n - k - 1$) og ikke 286 ($n-2$)?*

Den generelle regelen for line칝r regresjon er at man trekker fra antall frihetsgrader som svarer til antall parametre man har estimert f칮rst, som s친 brukes i beregningen av standardavviket. I oppgave 2c p친 analyse (1) er det brukt 6 estimerte parametre (5 koeffisienter og ett konstantledd) dermed blir det $n - 5 - 1$. I sliden du viser er det en koeffisient og ett konstantledd, dermed $n - 2$.

</details>

<details><summary>H칮st 2017</summary>

**Oppgave 1b:** *"Viser resultatet av testen at studentene i gruppe A kanskje har plagiert?". F-testen vil jo kun teste om variansene er den samme for gruppe A og gruppe B, eller ulik? Hvordan kan vi svare p친 dette sp칮rsm친let ved hjelp av en F-test? I fasiten st친r det at studentene i gruppe A har kanskje plagiert. Er dette fordi variansen i gruppe A er minst, dermed har de mer like respons, noe som kan indikere plagiat?*

Ja, oppgave a og b henger tett sammen. Det stemmer at F-testen bare kan si om de er ulik. Man m친 tolke hva ulike standardavvik m친 bety utfra konteksten av "eksperimentet" for 친 komme frem til at det er juks p친 gang. Det stemmer som du sier at lavt standardavvik betyr plagiat. Poenget her er at gruppe B skal v칝re representativt for studenter generelt, s친 ettersom standardavviket er signifikant forskjellig fra det det skulle v칝rt (statistisk lik gruppe B) er det noe som foreg친r.

</details>

<details><summary>V친r 2018</summary>

**Oppgave 1b:** *I fasiten st친r det at man ogs친 kan bruke T-test for 친 sammenligne forventningsverdiene i de to datasettene, er det fordi n er stor og dermed vil normal og t-fordeling v칝re omtrent det lik?*

Vi kan gj칮re to forskjellige argumenter n친r $n$ er stor i dette tilfellet:

- N친r $n$ er stor er det ikke s친 farlig med normalitetsantakelsen for observasjonene, siden sentralgrenseteoremet s칮rger for at testobservatoren er tiln칝rmet normalfordelt uansett, og da kan vi bruke Z-test eller t-test avhengig av om vi kjenner det/de sanne standardavviket/standardavvikene eller ikke.
- I tillegg ser vi at n친r $n$ blir stor s친 er de kritiske verdiene for hypotesetesten nesten like. Det f칮lger av at vi da kan estimere standardavviket mer presist, s친 de empiriske standandardavvikene $s$ (eventuelt ($s_1$ og $s_2$) er n칝rme de sanne verdiene $\sigma$ (eventuelt $\sigma_1$ og $\sigma_2$).
</details>

<details><summary>H칮st 2018</summary>

**Oppgave 1c:** *I oppgaven skal man se hvorvidt "... the trimmed mean of the offers is smaller in 2008 than in 2006." De setter opp H0 = Mean(Libor2006) = Mean(Libor2008), men s친 setter de opp H1 : Mean(Libor2006) < Mean(Libor2008). Burde det ikke v칝re omvendt her ettersom vi skal se om gjennomsnittet er lavere i 2008 enn i 2006? alts친 at H1: Mean(Libor2006) > Mean(Libor2008). Videre konkluderer man med at "The test indicates that the Libor in 2006 is lower than the Libor in 2008". Men i summary tabellen f친r man oppgitt at gjennomsnittlig libor i 2006 = 3.09 og 2.00 i 2008. Hvordan kan det ha seg da at man konkluderer med at libor er lavere i 2006 enn i 2008?*

De har snudd ulikheten. Det er feil i fasiten og det skal egentlig v칝re Mean(Libor2006) > Mean(Libor2008). I konklusjonen skal det f칮lgelig konkluderes med at Libor i 2006 er st칮rre enn i 2018.

</details>

<details><summary>H칮st 2019</summary>

**Oppgave 1a:** *Oppgaven sp칮r om hvilke tester man kan utf칮re for 친 finne ut hvilket land som har den signifikant st칮rste andelen kjempelykkelige land. Er det ikke z-test man da bruker? Videre blir vi bedt om 친 gi et datatransformasjon for Norge, hva mener de med dette? Hvorfor har fasiten kun brukt det som st친r under br칮kstreken i testobservatoren?*

Det stemmer at de bruker en z-test i fasit, men det er ogs친 mulig 친 bruke en chi-squared goodness-of-fit test. Poenget her er at man skal finne ut hvem som er mest lykkelig i forhold til hverandre og dermed m친 man teste to og to land mot hverandre ved bruk av flere z-tester. Tanken med "transformasjonen" er at man tar tallene fra tabellen og beregner noe man enkelt kan sammenligne to og to land basert p친, det blir da estimatet av "sannsynlighet for kjempelykkelig" med et empiriske standardavvik. Det empiriske standardavviket er da det som st친r i telleren for testobservatoren (se kap 12-3c i boken). Siden testen i teorien m친 gjennomf칮res 3 ganger er det bedre 친 regne p og empirisk standardavvik for s친 친 sette disse tallene inn i uttrykket for testobservatoren etterp친.


**Oppgave 1b:** *Etter at $z = 5.33$ er regnet ut dukker det opp en $z = 0.11$ under. Hvor kommer denne fra og hva forklarer den? Den blir ikke kommentert videre.*

I oppgave B har de f칮rst regnet ut z dersom man antar pooled standardavvik, deretter har de beregnet z med hvert sitt standardavvik og testet om disse to z-verdiene er ulike. Det er en litt knotete m친te 친 gj칮re det p친. De kunne bare brukt den sistnevnte z og testet den ulik null heller enn lik f칮rstnevnte z. Konklusjonen blir den samme. Se side 482, Case 2. I eksemplene i boken beregner de ikke D f칮rst slik de har gjort i fasit, men sier at den er kjent.

**Oppgave 1j:** *Vi blir bedt om 친 skissere regresjonslinjen for r친alders samlede p친virkning p친 lykkeniv친et. Jeg forstod fasiten, men dersom oppgaven hadde bedt om 친 skissere regresjonslijen for rettferdighet samlede p친virkning p친 rettferdighet, hadde linjen bare v칝rt line칝r med en stigningstall p친 0.03? M친tte vi gj칮re alle de beregningene igjen siden variabelen var logaritmen til alder?*

Det stemmer. Rettferdighet-til-lykke-forholdet er lin칝rt, s친 det hadde bare blitt en linje. Her sp칮rres det om en skisse nettopp fordi forholdet skal v칝re ikke-line칝rt, s친 du ville nok ikke f친tt samme sp칮rsm친l for "rettferdighet" med mindre begge skulle inn i figuren samtidig som sammenligning. Beregningene var for 친 st칮tte at plottet ble riktig. I det line칝re tilfellet kunne du jo bare ha funnet to punkter og dratt en linje imellom, det g친r jo ikke i det ikke-line칝re tilfellet.

</details>

<details><summary>V친r 2020</summary>
**Oppgave 3c:** *Jeg er litt usikker ifm oppgave c) hvor vi blir spurt om redisualserien er stasjon칝r. Jeg forst친r resonnementet i fasiten, men er litt usikker n친r det kommer til denne figuren. Her ser det jo ut til at variansen 칮ker med tiden? Et av forutsetningene for stasjon칝r tidsrekke er jo at variansen skal v칝re konstant og uavhengig av t? Hvordan ser vi forresten om forventningen er konstant eller ikke?*

Visuell inspeksjon kan gi deg en del innsikt, men noen ganger kan det v칝re vanskelig 친 konkludere eksakt kun fra figuren. Om det er tvil m친 man st칮tte seg videre p친 beregninger.

For residualserien er den litt kort til 친 konkludere bare fra plottet om variansen 칮ker eller ikke. De laveste residualverdiene (p친 bunnen av plottet) ser ikke ut til 친 endre seg slik som det kanskje kan se ut for de h칮yeste (p친 toppen av plottet). Om du hadde plottet denne over lenger tid ville du kanskje ikke lenger tenkt at variansen endrer seg.

Forventningen er konstant, og lik 0, om det er ca like mange punkter over som under 0-linjen over tid. Det ser ut til 친 v칝re tilfelle her.
</details>

## Tidligere eksamensoppgaver (hjemmeeksamen)

Her finner du oppgavene som er gitt ved hjemmeeksamen etter at eksamensformen ble lagt om i 2017. Merk at besvarelsen skal leveres som en sammenhengende rapport, og at l칮sningsforslagene under ikke oppfyller det kravet, men heller er en skisse av kodesnutter som *kan* brukes til 친 besvare sp칮rsm친lene. For v친r 2018 har vi et sett med eksempelbesvarelser p친 ulike karakterniv친er, med sensors kommentarer.

<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Semester </th>
   <th style="text-align:left;"> Oppgaver </th>
   <th style="text-align:left;"> L칮sningsforslag </th>
   <th style="text-align:left;"> Data, relevante artikler, etc. </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2017 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-17-v.pdf) </td>
   <td style="text-align:left;"> Ikke tilgjengelig </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-17-v-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-17-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-17-h-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-17-h-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-18-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-18-v-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-18-v-ekstra.zip), [Eksempelbesvarelser](tidligere-eksamensoppgaver/hjemme-18-v-eksempler.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-18-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-18-h-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-18-h-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2019 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-19-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-19-v-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-19-v-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2019 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-19-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-19-h-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-19-h-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2020 - V친r </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-20-v.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-20-v-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-20-v-ekstra.zip) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2020 - H칮st </td>
   <td style="text-align:left;"> [Oppgaveformulering](tidligere-eksamensoppgaver/hjemme-20-h.pdf) </td>
   <td style="text-align:left;"> [L칮sningsforslag](tidligere-eksamensoppgaver/hjemme-20-h-solprop.pdf) </td>
   <td style="text-align:left;"> [Materiale](tidligere-eksamensoppgaver/hjemme-20-h-ekstra.zip) </td>
  </tr>
</tbody>
</table>

## Sp칮rsm친l og svar

P친 denne siden vil vi samle  svar p친 sp칮rsm친l som er kommet inn til studentassistenter p친 e-post og gjennom snapmentor, og som kan v칝re nyttige for senere 친rganger av studenter. Tusen takk til [Benjamin Narum](https://www.nhh.no/en/employees/faculty/benjamin-narum/) for at han har samlet inn materiale til denne siden.

### Hypotesetesting og frihetsgrader

<details><summary>Hvor mange frihetsgrader skal det v칝re i andre, eller mer kompliserte modeller, enn dem vi g친r gjennom i faget?</summary>

Det finnes en rekke forskjellige typer statistiske tester som har ulike form친l. En tommelfingerregel som ofte fungerer i statistisk inferens (som for eksempel i en test for om en estimert parameter er signifikant forskjellig fra null) er:

Antall frihetsgrader = Antall observasjoner - Antall parametre som er estimert i modellen. 

I multippel regresjon estimerer vi $k+1$ regresjonskoeffisienter, ergo blir antall frihetsgrader i testene $n-(k+1) = n - k - 1$. Begrepet "frihetsgrader" har lange historiske r칮tter og spiller p친 denne type intuisjon (observasjonene gir oss frihet til 친 finne ut av ting med en viss presisjon, og denne friheten "bruker vi opp" n친r vi estimerer ukjente parametre), men det er ikke et idiotsikkert system. Det at testobservatoren i en ett-utvalgs $t$-test med ukjent varians er $t$-fordelt med $n-1$ frihetsgrader ($n$ observasjoner minus en estimert parameter $s^2 \approx \sigma^2$) er et presist matematisk resultat som bevises p친 vanlig m친te ved hjelp av antakelsene i testen (dvs nullhypotesen om at observasjonene er trukket fra den samme normalfordelingen).
</details>

<details><summary>I en F-test, hvor g친r grensen for n친r man skal runde frihetsgradene opp til uendelig eller ned til 200?
</summary>

Om du kommer i en situasjon der det er tvil ville jeg brukt en funksjon i R til 친 f친 den eksakt. Ellers kan du vurdere det utfra differansen for verdien av testobservatoren for lavere frihetsgrader. For eksempel: Om du har 250 frihetsgrader vil forskjellen i testobservatoren mellom 150 og 200 frihetsgrader v칝re h칮yere enn den mellom 200 og 250 frihetsgrader. S친 lenge du ser at konklusjonen for oppgaven blir den samme spiller det ingen rolle.
</details>

<details><summary>Er det ikke slik at man skal bruke Z-tester for sammenligning av to forventningsverdier? Hvorfor bruker man da t-tester i noen eksamensoppgaver, som f.eks v17 1b)?</summary>

Z-test brukes n친r man vet det eksakte standardavviket. I dette eksempelet setter vi det empiriske standardavviket i nevneren av testobservatoren, og da kan man bevise matematisk at den ikke lenger er standard normalfordelt, men heller t-fordelt med n-1 frihetsgrader.

Dersom antall observasjoner er stort er v친rt estimat av populasjonens standardavvik s친 presist at det ikke utgj칮r noen forskjell, noe vi ser fra t-tabellen for stor n, som gir tiln칝rmet samme kritiske verdi som den tilsvarende verdien i Z-tabellen.

Sagt med andre ord: N친r n blir stor er t-fordelingen med n frihetsgrader tiln칝rmet lik normalfordelingen. Dette er en eksakt grenseverdi n친r $n \to \infty$.
</details>

<details><summary>N친r man skal finne kritisk verdi av z-test, bruker man da t-fordeling med uendelig frihetsgrader?</summary>

Det blir det samme, ja. Det er ogs친 gitt i Tabell 3 i boken, men da er verdien av z-observatoren gitt langs aksene (f칮rste desimal langs radene og andre desimal langs kolonnene) med sannsynligheten gitt i midten.
</details>

<details><summary>Data칮ving 2, oppgave 1.3: Testobservatoren blir beregnet til ca 2.5, mens oppgaven sier at den ligger i mellom de kritiske verdiene p친 0.025 og 0.975. Hvilken tabell skal jeg bruke for 친 f친 dette til 친 stemme? Hvilke linjer skal jeg se p친 i den tabellen for 친 se at det er riktig?</summary>

Tabell 5 "Critical values of the chi^2 distribution" gir deg riktige verdier. Du kan ogs친 bruke R-funksjonen qchisq(0.025, df = n - 1) til 친 f친 samme tall. Det er 25 observasjoner og du har benyttet et estimat av forventningsverdien til 친 beregne det empiriske standardavviket. Da er det 25 - 1 = 24 frihetsgrader, s친 da m친 du se p친 linjen hvor "Degrees of Freedom" er 24. Kolonnene er $\chi_{0.025}$ og $\chi_{0.975}$, s친 skal du finne 12.4 og 39.4.

</details>

### Regresjon

<details><summary> Hvordan finner man kritisk grense for $F$-test i multippel regresjon? $F$-observatoren er jo oppgitt i regresjonstabellen, men dersom det ikke er oppgitt signifikansniv친 der, skal man finne forkatsningsgrense i normaltabell eller i $F$-fordeling, og skal antall frihetsgrader v칝re $n-k-1$?  </summary>

F-observatoren har to tall for frihetsgrader. For multippel regresjon tester den nullhypotesen om at alle koeffisientene er null **samtidig**. Den f칮rste frihetsgraden kommer av modellen og er lik antall koeffisienter, den andre kommer av frihetsgradene i datasettet som er $n - k - 1$. Tabell 6 i boken viser kritisk grense for ulike signifikansniv친 og kombinasjoner av de to frihetsgradene. Stargazer oppgir `df=x;y`, der `x` er f칮rste frihetsgrad og `y` er andre frihetsgrad.

</details>

<details><summary> Hva er en indikatorvariabel? Og hvordan kan man lage dette, eventuelt finne mer informasjon. Sikter til eksamen v친ren 2020 oppgave 2. </summary>

Indikatorvariabler er et annet ord for dummyvariabler, og tar verdien 0 eller 1. Det kan gjerne brukes til 친 gj칮re statistisk analyse n친r noe enten er sant eller ikke-sant. I oppgaven p친 eksamen bruker de jo det til 친 si om NO2 oversteg faregrensen. Da bruker man gjerne en indikator fordi du har informasjon om hva som er farlig og ikke, alts친 bryr vi oss ikke s친 mye om akkurat hva niv친et er, bare vi det om det er farlig eller ikke (i akkurat denne analysen i hvert fall). Indikatorvariabler er ogs친 interessante som verkt칮y for 친 danne "kategorier" i dataene.

Du kan se her eller google litt om du er interessert: https://en.wikipedia.org/wiki/Dummy_variable_(statistics) 
</details>

<details><summary> Om det ikke er multikolinearitet, er det slik at man da kan tolke koeffisienten som kausalt?  </summary>

Nei, ikke n칮dvendigvis.

</details>

<details><summary> Hvordan tolker man et konfidensintervall for en koeffisient i en regresjonsmodell? Si for eksempel at et 95% konfidensintervall for koeffisienten er (-50,-30).
 </summary>

P친 samme m친te som andre konfidensintervaller for ukjente, men estimerte paramtetre: Dersom modellen er riktig (det vil si at det eksisterer en *sann* regresjonskoeffisient $\beta$), og dersom vi hadde hatt mulighet til 친 trekke flere datasett av samme st칮rrelse som det vi har, s친 ville 95% av konfidensintervallene inneholdt den sanne regresjonskoeffisienten. 
</details>

### Tidsrekker

<details><summary> Jeg forst친r ikke helt hvordan man kan se om det er autokorrelasjon i residualene eller ikke. F.eks i eksamen v20 oppgave 2g). </summary>

P친 oppgave 2g er det nok vanskelig 친 se at det er autokorrelasjon rett fra residualene, men du kan set det p친 ACF plottet. Der er det signifikante (barer over den bl친 linjen) autokorrelasjoner for flere "lag" st칮rre enn 0. Se video om autokorrelasjon for en forklaring. 
</details>

### R etc.

<details><summary>  Jeg skal gj칮re noe i R, og f친r opp en feilkode. Hva kan jeg gj칮re for 친 f친 den til 친 fungere? F.eks. kommer det opp 춺Error in plot.new()췉.  </summary>

Koding kan ofte f칮re til mange forskjellige type feil og det kan v칝re vanskelig 친 vite alltid hva som er galt. For denne type feil er Google din venn. S칮k p친 feilkoden, i dette tilfellet "plot.new() figure margins too large", s친 kommer det som regel opp en tr친d men noen som opplever noe lignende og en l칮sning.

Et annet tips er 친 kommentere ut deler av koden og se om du f친r deler av den til 친 fungere. Da kan du isolere hva som for친rsaker problemet og pr칮ve 친 Google kun for det, da kommer det oftere opp gode svar. 
</details>

<details><summary>  Jeg skriver inn i `stargazer()`-funksjonen, men output-en ser underlig ut. </summary>
Du m친 bruke tillegsargumentet: `type = "text"`.
</details>

<details><summary>  Hvordan lager jeg regresjonsanalyse i Excel slik det er gjort i oppgave 17.2 h? 
 </summary>
Selve regresjonsanalysen gj칮res i Excel under: Data > Data Analysis > Regression. Velg ut rutene for X (begge kolonner) og Y og trykk ok. Om "Data Analysis" ikke ligger der m친 du aktivere "Analysis ToolPak in Excel", google det s친 finner du ut av det.
</details>






<!--chapter:end:08-ekstra.Rmd-->

