
# Hypotesetesting

Hypotesetesting er et klassisk tema i statistikk. Vi skal først lære generelt om hva det egentlig vil si å *teste* en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting *ikke* er. Vi går så videre til å lære noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R.

I videoforelesningene går vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved å klikke på lenkene under:

[Slides til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-slides.html)

[R-script til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-script.R)

**TIPS:** Hvis du ønsker å laste ned lysbildene som PDF trykker du på linken over, velger "Skriv ut", og så skriver du ut som PDF. Før du gjør det bør du scrolle gjennom alle sidene slik at ligningene vises korrekt.

## Generelt om hypotesetesting

### Videoforelesninger 

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780028/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Her snakker vi om kapittel **11** i læreboken. Hvis du kan svare på følgende spørsmål har du i all hovedsak fått med deg de viktigste begrepene:

- Hva vil det si å gjennomføre en hypotesetest?
- Hva er Type I-feil og hva er Type II-feil? (Seksjon **11-1** forklarer dette greit)
- Hva er signifikansnivået ($\alpha$) til en test?
- Styrken (the power) til en test er definert som $1-P(\textrm{Type II-feil})=1-\beta$. Hvordan tolker du denne størrelsen? Se også **11-3d**.
- Hva er $p$-verdien til en test (Seksjon **11-2c**)? Les også **11-2d**, **e** og **f** om hvordan vi fortolker og snakker om $p$-verdien på en korrekt måte. Vi kommer tilbake til dette i kapittel \@ref(enpop).

## Inferens om en populasjon {#enpop}

### Videoforelesninger

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780035/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Dette er i hovedsak dekket av kapittel **12** i læreboken. Sjekk om du kan svare på følgende kontrollspørsmål:

1. Hva er det vi tester når vi gjennomfører en $t$-test for én populasjon? Hva forutsetter vi?
2. Hva er forskjellen på en ensidig og en tosidig test? (**11-2j**)

Det kan også være greit å repetere konfidensintervaller i seksjon **11-2k** for de som har glemt det fra MET2.

I Seksjon **11-2g** går boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gjøre det samme i R. På kursets nettside finner du alle datasettene som følger med læreboken. I dette eksempelet er det snakk om `Xm11-01.xlsx`. Finn tak i denne filen (du kan også godt åpne den og se på den i Excel!), legg den i en mappe som du kan finne igjen, og åpne et nytt script i R-studio der du først sørger for å sette working directory til denne mappen slik vi gjorde i R-forelesningen.

Etterpå leser du inn datasettet ved å bruke `read_xlsx()`-funksjonen som under:

```{r, eval = F}
library(readxl)
data <- read_xlsx("Xm11-01.xlsx")     # Vi bruker read_xslx() fordi det er en .xlsx-fil
```

```{r, echo = F}
library(readxl)
data <- read_xlsx("datasett/Xm11-01.xlsx")     # Vi bruker read_xslx() fordi det er en .xlsx-fil
```

Konteksten til datasettet er gitt i eksempel 11.1. Det er altså balansen på 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer på om forventet balanse er større enn 170. Vi setter opp følgende test:

\begin{align*}
&H_0: \mu = 170 \\
&H_A: \mu > 170,
\end{align*}
der vi legger merke til at det blir brukt en ensidig test (hvorfor?).

For å regne ut testobservatoren for å enutvalgs $z$-test trenger vi fire tall: $\overline X$, $\mu_0$, $n$ og $\sigma$. Legger merke til at `data` har en kolonne som heter `Accounts`, og vi bruker dollartegnet til å hente den ut som en vektor. Regner ut observatoren:

```{r}
gj.snitt <- mean(data$Accounts)     # Gjennomsnittet av observasjonene
mu0      <- 170                     # Henter fra teksten
n        <- length(data$Accounts)   # Antall observasjoner
sigma    <- 65                      # Henter fra teksten

Z <- (gj.snitt - mu0)/(sigma/sqrt(n))   # Verdien av testobservatoren
Z                                       # Skriver ut testobservatoren
```
Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R:

```{r}
qnorm(0.95)
```

Uansett; vi forkaster $H_0$ siden testobservatoren er større enn kritisk verdi.

Kapittel **11-3a-d** gir enda mer forståelse for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre.

**Kapittel 12** presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du først og fremst må kunne fra dette kapitlet er å gjennomføre disse testene, både for hånd med penn og papir, og i R. Under følger kode for å gjøre noen av bokens eksempler i R (les i boken for kontekst):

**Eksempel 12.1:** 

\begin{align*}
&H_0: \mu = 2.0 \\
&H_A: \mu > 2.0,
\end{align*}

```{r, eval = F}
data <- read_xlsx("Xm12-01.xlsx")

# Manuell utregning
gj.snitt <- mean(data$Newspaper)
mu0      <- 2.0
n        <- length(data$Newspaper)
s        <- sd(data$Newspaper)

# Testobservator:
(gj.snitt - mu0)/(s/sqrt(n))
```

```{r, echo = F}
data <- read_xlsx("datasett/Xm12-01.xlsx")

# Manuell utregning
gj.snitt <- mean(data$Newspaper)
mu0      <- 2.0
n        <- length(data$Newspaper)
s        <- sd(data$Newspaper)

# Testobservator:
(gj.snitt - mu0)/(s/sqrt(n))
```

Signifikansnivået er satt til $\alpha = 1\%$ i eksempelet. Kritisk verdi finner vi i $t$-tabell eller rett fra R:

```{r}
qt(0.99, df = n-1)
```

Altså forkaster vi **ikke** nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som står i boken. Alternativt bruker vi `t.test()`-funksjonen direkte:

```{r}
t.test(data$Newspaper, alternative = "greater", mu = 2.0, conf.level = 0.99)
```

Resultatet blir selvsagt det samme. Når $p$-verdien er større enn signifikansnivået på 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om å lage kondidensintervall, noe du også kan prøve å gjøre ved å regne ut de nødvendige tallene i R. De som synes dette er greit kan kikke på seksjonene **12-1b-e** for å utvikle forståelsen enda litt mer.

**Eksempel 12.3:** 

\begin{align*}
&H_0: \sigma^2 = 1.0 \\
&H_A: \sigma^2 < 1.0.
\end{align*}

Testobservator:

$$\chi^2 = \frac{(n-1)s^2}{\sigma_0^2}.$$

```{r, eval = F}
data <- read_xlsx("Xm12-03.xlsx")

# Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis:
(length(data$Fills) - 1)*var(data$Fills)/1

# Kritisk verdi, 5% nivå, ensidig test, nedre hale:
qchisq(0.05, df = length(data$Fills) - 1)     
```

```{r, echo = F}
data <- read_xlsx("datasett/Xm12-03.xlsx")

# Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis:
(length(data$Fills) - 1)*var(data$Fills)/1

# Kritisk verdi, 5% nivå, ensidig test, nedre hale:
qchisq(0.05, df = length(data$Fills) - 1)     
```

Vi kan altså ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for å forstå bedre hva som skjer. Figur 12.4 viser på en fin måte hva tallene betyr.

**Eksempel 12.5** kan være grei å kikke på også. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste:

\begin{align*}
&H_0: p = 0.5 \\
&H_A: p > 0.5.
\end{align*}

Vi har en observert andel på $\widehat p = 407/765 = 0.532$ etter å ha spurt $n = 765$ personer. Testobservatoren er 
$$Z = \frac{\widehat p - p}{\sqrt{p(1-p)/n}}.$$

```{r}
p.hatt <- 407/765
p0     <- 0.5
n      <- 765

(p.hatt - p0)/sqrt(p0*(1-p0)/n)
```

Kritisk verdi for en ensidig z-test på 5% nivå er 1.645 (`qnorm(0.95)`), og vi kan forkaste nullhypotesen.

Seksjonene **12-3d-f** bør leses på egen hånd, mens vi hopper over **12-3g**.

## Inferens om to populasjoner

### Videoforelesninger

<div style='padding:74.64% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780048/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi har gått gjennom kapittel **13**, som i all hovedsak handler om å sammenligne to gjennomsnitt (som vi kan gjøre på tre forskjellige måter), to varianser og to andeler. Her følger noen kontrollspørsmål som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper:

- Hva er nullhypotesen når vi skal gjennomføre en t-test for to populasjoner?
- ... og hvilke antagelser må vi gjøre?
- Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør?
- Når kan vi bruke matchede par, og hva er hensikten?
- Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen?
- Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør?
- Hvilken test brukes for å teste om to andeler er like, og hva må du anta?

Videre bør du sjekke at du kan utføre **3** typer $t$-tester, test for like varianser og test for like andeler både for hånd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber).

Den enkleste måten å gjøre $t$-tester i R på er å bruke funksjonen `t.test()`. Kikk på eksempel 13.1 i lærebokens 11. utgave, der vi har observert årlige avkastninger til to aksjefond som er kjøpt henholdsvis med og uten megler. 

```{r, eval = F}
# Leser inn datasettet
funds <- read_xlsx("Xm13-01.xlsx")

# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = FALSE,
       conf.level = 0.95) 
```

```{r, echo = F}
# Leser inn datasettet
funds <- read_xlsx("datasett/Xm13-01.xlsx")

# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = FALSE,
       conf.level = 0.95) 
```

Du kan så sjekke at du får ut de samme tallene på s. 434--435. Videre kan du skrive inn `?t.test` i R-konsollen i RStudio for å lese mer om hvilke argumenter vi kan bruke i `t.test()`-funksjonen. Der ser vi at argumentene `paired`, `var.equal` og `conf.level` som utgangspunkt allerede er satt til `FALSE`, `FALSE` og `0.95` henholdsvis, så det hadde vi strengt tatt ikke trengt å spesifisere i funksjonskallet over.

Vi kan enkelt kjøre den samme testen under antakelsen om like varianser ved å sette `var.equal = TRUE`:

```{r}
# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = TRUE,
       conf.level = 0.95) 
```

Resultatet bli akkurat det samme. Siden testens $p$-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og slå fast at forskjellen i gjennomsnitt er statistisk signifikant.

I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner  i de to populasjonene, så vi kan tenke oss at målingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om *gjennomsittet av differansene* er signifikant forskjellig fra null. Enkelt:

```{r}
# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = TRUE,
       conf.level = 0.95) 
```

Da ser vi at $p$-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du prøve selv. Pass på at du kan gjøre beregningene manuelt også, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forstår hva som foregår. 

Kapittel **13-2** omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig å sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen vår av statistiske resultater. Det er et eksplisitt krav for å lykkes i MET4 at du er i stand til å sette resultatene inn i en fornuftig kontekst.

I kapittel **13-4** kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R:

```{r, eval = F}
bottle <- read_xlsx("Xm13-07.xlsx")
var.test(bottle$`Machine 1`, bottle$`Machine 2`,
         alternative = "greater")
```

```{r, echo = F}
bottle <- read_xlsx("datasett/Xm13-07.xlsx")
var.test(bottle$`Machine 1`, bottle$`Machine 2`,
         alternative = "greater")
```

Også her kan du sammenligne med tallene som fremgår av bokens gjennomgang, og sørg for at du får til dette på egen hånd, *spesielt* det å finne frem i tabellen, for det *må* du kunne på eksamen.

Til slutt har vi test for to andeler i kapittel **13-5**. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er *like* ($p_1 - p_2 = 0$), som er det vi har dett på i forelesning, men det går selvsagt like fint å sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall $D$. 

Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved å regne ut testobservatoren fra datasettet. Vi ser på eksempel 13.9, der vi får oppgitt salget av en del forskjellige varenummer, og vi ønsker å finne ut om andelen «9077» er større i Supermarked 1 enn i Supermarked 2:

```{r, eval = F}
# Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg 
# velger å lese inn de to kolonnene hver for seg:
soap1 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("A"))
soap2 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("B"))

# Hvor stor andel utgjør «9077» i de to kolonnene?
p1 <- mean(soap1 == 9077)
p2 <- mean(soap2 == 9077)

# De to utvalgsstørrelsene:
n1 <- nrow(soap1)
n2 <- nrow(soap2)

# Felles estimat for p under nullhypotesen:
p <- (n1*p1 + n2*p2)/(n1 + n2)

# Testobservatoren:
z <- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2))

# Kritisk verdi på 5% nivå for en ensidig test:
qnorm(0.95)
```

```{r, echo = F}
# Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg 
# velger å lese inn de to kolonnene hver for seg:
soap1 <- read_xlsx("datasett/Xm13-09.xlsx", range = cell_cols("A"))
soap2 <- read_xlsx("datasett/Xm13-09.xlsx", range = cell_cols("B"))

# Hvor stor andel utgjør «9077» i de to kolonnene?
p1 <- mean(soap1 == 9077)
p2 <- mean(soap2 == 9077)

# De to utvalgsstørrelsene:
n1 <- nrow(soap1)
n2 <- nrow(soap2)

# Felles estimat for p under nullhypotesen:
p <- (n1*p1 + n2*p2)/(n1 + n2)

# Testobservatoren:
z <- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2))

# Kritisk verdi på 5% nivå for en ensidig test:
qnorm(0.95)
```

Siden $z = `r format(z, digits = 3)`$ forkaster vi nullhypotesen om at det er lik andel «9077» i de to populasjonene.

## Kjikvadrattester

### Videoforelesninger

<div style='padding:74.43% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780062/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi må kunne *to* anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken:

1. Teste for om en gitt fordeling passer med obervasjoner (*"Goodness-of-fit"*).
2. Teste for uavhengighet.

I den første anvendelsen får vi oppgitt en *diskret* sannsynlighetsfordeling der vi har noen mulige utfall $u_1, \ldots, u_k$, med tilhørende sannsynligheter $p_1, \ldots,p_k$. Dersom vi skal observere $n$ utfall fra denne fordelingen, vil vi forvente $e_i = p_i\cdot n$ observasjoner av utfall $u_i$.

Nå har det seg slik at vi *har* observert $n$ utfall fra fordelingen, og utfall $u_i$ har skjedd $f_i$ ganger. **Vi lurer da på om de observerte frekvensene ($f_i$) er så forskjellige fra de *forventede* frekvensene ($e_i$) at vi ikke lenger tror at $p_1, \ldots,p_k$ er den sanne sannsynlighetsfordelingen.**

Vi kom frem til en fornuftig testobservator:

$$\chi^2 = \sum_{i=1}^k \frac{(f_i - e_i)^2}{e_i},$$
som er $\chi^2$-fordelt med $k-1$ frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan gå inn i $\chi^2$-tabellen for å sjekke om verdien av testobservatoren er for stor (dvs, $f$´ene er for forskjellige fra $e$`ene) at vi ikke lenger tror at $(p_1, \ldots, p_k)$ er den sanne sannsynlighetsfordelingen.

Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte følgende kommandoer:

```{r}
p0 <- c(0.45, 0.40, 0.15)  # Fordeling under H0
f  <- c(102, 82, 16)       # Observerte frekvenser

chisq.test(x = f, p = p0)
```

Den andre anvendelsen er å teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for «$A$ og $B$» som et produkt dersom de ar uavhengige: 

$$P(A \cap B) = P(A)\cdot P(B).$$

Vi kan regne ut hvor mange observasjoner vi forventer å se for hver kombinasjon av de to kjennetegnene ($e_{ij}$), og bruke kjikvadrattesten over til å sjekke om disse er langt fra det vi *faktisk* har observert ($f_{ij}$). Boken har et eksempel på dette som de regner ut både for hånd og i Excel. Slik kan vi gjøre det i R:

```{r, eval = F}
# Leser inn data
mba <- read_xlsx("Xm15-02.xlsx")

# Kikker på datasettet
mba
```

```{r, echo = F}
# Leser inn data
mba <- read_xlsx("datasett/Xm15-02.xlsx")

# Kikker på datasettet
mba
```

Vi legger merke til at strukturen på datasettet er litt annerledes enn krysstabellen som er vist s. 601 i læreboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av «bachelorgrad» og «masterprofil», har vi fått oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R:

```{r}
table(mba)
```

Det er denne som brukes som argument i `chisq.test()`:

```{r}
chisq.test(table(mba))
```

Her er det bare å sammenligne tallene med det som læreboken finner i Excel.

Noen kontrollspørsmål:

1. Vi har lært to veldig spesifikke anvendelser av kjikvadrattester. Hvilke?
2. Kan du gi en intuitiv forklaring på hvorfor testobservatoren vår er fornuftig?
3. **Litt mer vanskelig:** Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tilnærmet kjikvadratfordelt?

## Oppgaver

### Standard oppgaver

Introduksjon til hypotesetesting

1. For hvert av scenarioene i a og b, gjør følgende:
   -	Sett opp relevant nullhypotese og alternativhypotese (hint: nullhypotese avhenger av hvor ‘bevisbyrden’ bør ligge)
   -	Definer type I-og type II-feil. 
   -	Diskuter konsekvensene av type I-feil og type II-feil i det aktuelle scenarioet. 

   a. En ny type medisin skal vurderes for kommersialisering. Du sitter i et vurderingspanel som skal vurdere om medisinen kan     bli godkjent eller ikke. 

   b. Du blir presentert to ulike investeringer å velge mellom. En av dem er veldig risikabel, men med stor potensiell             profitt. Den andre er mindre risikabel, men med lavere potensiell profitt. 

<details><summary>Løsning</summary>

> a. $H_0$: Den nye medisinen er ikke trygg og effektiv. $H_1$: Den nye medisinen er trygg og effektiv. Type I-feil: Forkaste $H_0$ når $H_0$     er sann. Konsekvens: Risikerer at vi begynner å produsere en medisin som ikke er trygg og effektiv. Type II-feil: Forkaster *ikke* $H_0$     når $H_1$ er sann. Konsekvens: Vi lar være å produsere en medisin som faktisk er trygg og effektiv.
>
>Kommentar: Signifikansnivået ved produksjon av medisiner settes ofte lavt fordi konsekvensene av en type I-feil kan være svært alvorlige.


> b. $H_0$: Den mest risikable investeringen er mest lønnsom. $H_1$: Den mest risikable investeringen er ikke mest lønnsom. Type I-feil:          Forkaste $H_0$ når $H_0$ er sann. Konsekvens:Vi investerer i den minst risikable investeringen, som ikke er mest lønnsom. Type II-feil:      Forkaster *ikke* $H_0$ når $H_1$ er sann. Konsekvens: Vi investerer i den mest risikable investeringen, som ikke er mest lønnsom.


</details>

2. Vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 150$ mot $H_1: \mu \neq 150$. $\sigma = 10$, $n =100$, $\overline{x} = 150$.

   Bestem verdi av testobservator, forkastelsesområde dersom signifikansnivået er $\alpha = 0.05$, og p-verdi. Konkluder.

<details><summary>Løsning</summary>

>Her er $\sigma$ kjent så vi kan bruke en z-observator. Forkastelsesområde $Z < -z_{0.025}=-1.96$ eller $Z> z_{0.025}=1.96$.
>
>$$Z = \frac{\overline{x} - \mu}{\sigma/\sqrt{n}} = \frac{150 - 150}{10/\sqrt{100}}=0$$
>
> p-verdi$=2P(Z > 0) = 2\times0.5=1$. Vi kan ikke forkaste nullhypotesen $H_0: \mu = 0$. Faktisk er det ekstremt sannsynlig (p-verdi = 1) å observere det vi har observert dersom nullhypotesen er sann. 

</details>

3. Vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 55$ mot $H_1: \mu > 55$.
  $\sigma = 20$, $n = 25$, $\overline{x} = 67$.

    a.	Regn ut testobservatoren $Z$.

    b.	Regn ut p-verdi.

    c. 	Regn ut p-verdi, denne gangen med $\overline{x}$ = 63.

    d. 	Regn ut p-verdi, denne gangen med $\overline{x}$ = 59.

    e. 	Fastslå hva som skjer med verdien av testobservatoren (Z) og p-verdien når $\overline{x}$ nærmer seg $55$ (verdien av $\mu$ under $H_0$). 

<details><summary>Løsning</summary>

> a. $$Z = \frac{\overline{x} - \mu}{\sigma/\sqrt{n}} = \frac{67 - 55}{20/\sqrt{25}}=3$$
>
> b. $\text{p-verdi} = P(Z > 3.00) = 1 – P(Z<3) = 1 – 0.9987 = 0.0013$. Kommentar: Her kan du bruke `pnorm(3)` i R til å regne ut $P(Z<3)$.
>
> c. Ny verdi av testobservator blir da $Z = 2$. 
> $\text{p-verdi} = P(Z > 2.00) = 1 – 0.9772 = 0.0228$.
>
> d. Ny verdi av testobservator blir da $Z = 1$. 
> $\text{p-verdi} = P(Z > 1.00) = 1 – 0.8413 = 0.1587$.
>
> e. Vi ser at testobservatoren minker og p-verdien øker når $\overline{x}$ nærmer seg $55$. 
>
>Forklaring: La $\mu_0 = 55$ være verdien av $\mu$ under $H_0$. Z-observatoren måler avviket mellom antagelsen under $H_0$ og dataene vi observerer og avtar derfor når vår observasjon av $\overline{x}$ nærmer seg $\mu_0$. P-verdien sier hvor sannsynlig det er å observere de dataene vi har dersom $H_0$ er sann og øker følgelig når $\overline{x}$ nærmer seg $\mu_0$.  

</details>


4. Annta at vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 50$ mot $H_1: \mu > 50$. $\sigma = 10$, $n = 40$, $\alpha = 0.05$.

   Bestem $\beta$, altså sannsynligheten for en type-II feil, under antagelsen at $\mu = 55$. 

<details><summary>Løsning</summary>

> Forkastningsområdet blir da
>
>$$Z = \frac{\overline{X} - 50}{10/\sqrt{40}} > Z_{0.05} = 1.645 $$
>dvs at vi forkaster $H_0$ når
> $$\overline{X} > 50 + 1.645\times\frac{10}{\sqrt{40}}=52.6$$
>En type-II feil svarer til å *ikke* forkaste $H_0$ når $H_1$ er sann. For å regne på sannsynligheten for type-II feil må vi ikke bare anta at $H_1$ er sann, men være spesifike på hva verdien til $\mu$ er (i dette tilfellet 55). Vi lurer altså på hva sannsynligheten for at vi *ikke* er i forkastnings området ($\overline{X} < 52.6$) gitt at $\mu = 55$: 
> \begin{equation*}
\begin{split}
\beta &= P(\overline{X} < 52.6\quad\text{gitt at $\mu = 55$})\\
&= P(\frac{\overline{X} - 55}{10/\sqrt{40}} < \frac{52.6 - 55}{10/\sqrt{40}})\\
&=P(Z < -1.52) = 0.064
\end{split}
\end{equation*}
> Merk: Et begrep som ofte blir brukt om tester er *styrken* til testen $1-\beta$ som da er sannsynligheten for å forkaste $H_0$ når $H_1$ er sann. En god test har god (stor) styrke. Hadde vi gjentatt denne testen mange ganger ville vi ha forkastet $H_0$  i $(100 - 6.4)\% = 93.6\%$ av gangene dersom det faktisk er slik at sann $\mu$ er 55. 

</details>

5.  En leder frykter at den gjennomsnittlige tiden ansatte daglig bruker på sosiale medier overstiger 45 minutter. For å teste denne mistanken, plukker han ut et tilfeldig utvalg på 15 personer, og spør om tid brukt på sosiale medier etter en tilfeldig arbeidsdag. Resultatene er oppsummert nedenfor. 

          70, 96, 58, 88, 34, 42, 34, 56, 68, 46, 26, 18, 22, 60, 84

    a. Hvis samlingen av tider er normalfordelt med standardavvik på 20 minutter, kan lederen hevde at mistanken hans stemmer på et 1 % signifikans-nivå?

    b. Tror du observasjonene over er et representativt utvalg? Hva kunne lederen gjort annerledes?

<details><summary>Løsning</summary>

>   a. Lederen ønsker altså å teste $H_0: \mu = 45$ mot alternativ hypotesen $H_1: \mu > 45$. Testobservatoren er da gitt ved 
>
>$$Z = \frac{\overline{X} - \mu_0}{\sigma/\sqrt{n}} = \frac{53.46 - 45}{20/\sqrt{15}} = 1.64$$ 
>
>Sannsynligheten for å observerer noe minst like ekstremt og til fordel for $H_1$ (p-verdien) er da
>
>$$P-verdi = P(Z > 1.645) \approx 0.05 > 0.01$$.
>
> Lederen kan altså ikke trekke denne konklusjonen på 1 % signifikansnivå. For å forkaste null hypotesen på et 1 % signifikansnivå, måtte vi hatt p-verdi lavere enn 1 %. 
>
>   b. Dersom lederen spør ansatte fjes til fjes er det nærliggende å tro at de ansatte vil underdrive sin bruk av sosiale medier. En anonym spørreundersøkelse ville nok gitt et mer representativt utvalg.

</details>

6. Gjennomsnitt og standardavvik i et utvalg på $n=100$ er $\overline{x} = 20$ og $s = 2$.

    a. Finn 95 % konfidensintervall av gjennomsnitt ($\mu$) i populasjonen.

    b. Gjenta a. med $s = 5$.

    c. Gjenta a. med $s = 10$.

    d. Fastslå hvordan det estimerte konfidensintervallet endrer seg når vi øker $s$.

    e. Anta at $s=5$ og regn et 95 % konfidensintervall dersom størrelsen på utvalget er henholdsvis $n = 50$ og $n=10$. 

    f. Fastlå hvordan det estimerte konfidensintervallet endrer seg når vi øker $n$.

<details><summary>Løsning</summary>

>   a. $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 1.984\times 2/\sqrt{100} = [19.60 ,20.40]$$
>
>   b. $$ 20 \pm 1.984\times 5/\sqrt{100} = [19.01 ,20.99]$$
> 
>   c. $$ 20 \pm 1.984\times 10/\sqrt{100} = [18.02 ,21.98]$$
>
>   d. Konfidensintervallet blir større når $s$ øker.
> 
>   e. $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 2.09\times 5/\sqrt{50} = [18.58 ,21.42]$$
>    $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 2.26\times 5/\sqrt{10} = [16.42 ,23.58]$$
>   
>   f. Vi ser at jo større $n$ er jo mindre blir konfidensintervallet. Flere observasjoner gjør at vi med større sikkerhet (smalere intervall) kan si hvor $\mu$ ligger.  

</details>

7. Med sterkt fall i flyreiser og passasjerer på grunn av koronakrisen var det i samme periode sannsynlig med færre forsinkelser i flytrafikken. Før krisen hevdet et flyselskap at de landet presist 92 % av flyreisene. I et tilfeldig utvalg flyreiser hos det samme selskapet under krisen ble 156 av 165 vurdert til å være presise. Kan vi konkludere på 5 % signifikansnivå at det er færre forsinkelser under koronakrisen? 


<details><summary>Løsning</summary>
>La $p$ være den sanne andelen av flyreiser som kommer presist under krisen. Vi skal da teste $H_0: p = 0.92$ mot $H_1: p > 0.92$. Vårt estimat på $p$ er $\hat{p}=156/165 \approx 0.945$ og testobservatoren er gitt ved

>$$z = \frac{\hat{p} - p_0}{\sqrt{p_0(1 - p_0)/n}} = \frac{0.945 - 0.92}{\sqrt{0.92(1 - 0.92)/165}} \approx 1.18$$
>Dersom vi bruker kritisk verdi ville forkastningsområdet vært $z > 1.645$ og siden $z < 1.645$ kan vi altså ikke forkaste $H_0$. Alternativt kan vi regne ut p-verdien som er "sannsynligheten for det vi har observert eller noe enda mer til fordel for $H_1$. En enda mer positiv verdi enn 1.18 ville vært til fordel for $H_1$, derfor er 

>$$p-verdi = P(Z >  1.18) = = 1 - P(Z < 1.18) \approx 0.12$$
>og vi kan derfor *ikke* forkaste $H_0$ siden p-verdien *ikke* er mindre enn 0.05. TIPS: $P(Z<1.18) =$ `pnorm(1.18)` i R.

</details>

8. Vi har følgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: $\overline{x}_1 = 400$, $s_1 = 130$, $n_1 = 130$, $\overline{x}_2 = 390$, $s_2 = 50$, $n_2 = 130$. 

 a.	Kan vi hevde på et 5 % signifikansnivå at $\mu_1$ er større enn $\mu_2$? Det oppgis at
    
  $$\nu =  \frac{\left(\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}\right)^2}{\left(\frac{s^2_{1}}{n_1}\right)^2/(n_1 - 1) + \left(\frac{s^2_{2}}{n_2}\right)^2/(n_2 - 1)}\approx 166$$

 b.  Gjenta a., denne gangen med $s_1 = 30$ og $s_2 = 15$. Som over, oppgis det at $\nu \approx 190$.  
	 
 c.  Fastslå hva som skjer hvis utvalgenes standardavvik blir mindre.
	  
 d.  Gjenta a., denne gangen med utvalg på $n_1 = n_2 = 20$ observasjoner. Som over, oppgis det at $\nu \approx 28$. 
	  
 e.  Fastslå effekten av å redusere utvalgsstørrelser. 
	  
<details><summary>Løsning</summary>

a. Vi skal altså teste $H_0: \mu_1 - \mu_2 = 0$ mot $H_1: \mu_1 - \mu_2 > 0$. Siden variansene i utvalget er såpass ulike antar vi at vi må bruke varianten av testen med ulik varians. Testobservatoren er da gitt ved

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{130^2}{130} + \frac{50^2}{130}}} = 0.82$$
Antall frihetsgrader oppgis til å være $v \approx 166$. Vi forkaster $H_0$ dersom $T > t_{0.05, 166} = 1.654$, og siden dette *ikke* er tilfelle her kan vi *ikke* forkaste $H_0$ ved 5 % signifikansnivå. 

b. Testobservatoren blir i dette tilfellet

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{30^2}{130} + \frac{15^2}{130}}} = 3.40$$
Antall frihetsgrader oppgis til å være $v \approx 190$. Siden $T = 3.40 > t_{0.05, 190} = 1.653$ forkaster vi $H_0$ på 5 % signifikansnivå.   

c. Når standardavvikene i utvalgene blir mindre øker verdien av testobservatoren. Mindre standardavvik betyr at vi er mer sikre på at $\overline{x}_1 - \overline{x}_2$ ligger nær $\mu_1 - \mu_2$, og at en evt. differanse kan tyde på avvik fra $H_0$. Dette blir reflektert av en større testobservator. 

d. Testobservatoren blir da

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{130^2}{20} + \frac{50^2}{20}}} = 0.32$$
Antall frihetsgrader oppgis til å være $v \approx 28$. Vi forkaster $H_0$ dersom $T > t_{0.05, 28} = 1.701$, og siden dette *ikke* er tilfelle her kan vi *ikke* forkaste $H_0$ ved 5 % signifikansnivå. 

e.  Få observasjoner representerer større usikkerhet om differansen $\overline{x}_1 - \overline{x}_2$ bare skyldes tilfeldighet, og dette reflekteres av testobservatoren som vil synke når utvalgsstørrelsen reduseres.

<!-- m1 <- 400 -->
<!-- m2 <- 390 -->
<!-- s1 <- 130 -->
<!-- s2 <- 50 -->
<!-- n1  <- n2 <- 20 -->

<!-- t <- (m1 - m2)/sqrt(s1^2/n1 + s2^2/n2) -->
<!-- v <- (s1^2/n1 + s2^2/n2)^2/((s1^2/n1)^2/(n1 - 1) + (s2^2/n2)^2/(n2 - 1)) -->
<!-- qt(0.95, v) -->

</details>

9. Et nystartet firma har utviklet to løsninger for automatisk registrering av av antall lus på oppdrettslaks. Metode A er litt dyrere enn metode B, men firmaet mener Metode A en den raskeste metoden. For å teste ut denne hypotesen blir begge metodene brukt til å registrere lus på 11 basseng av ulik størrelse og med forskjellig antall fisk. Antall minutter hver metode tar blir registrert for hvert basseng. 

    a. Under er det gitt en R-utskrift fra en to-utvalgs t-test. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå.

```{r,echo=F}
set.seed(2)
mu1 <- 80
mu2 <- 75
sigma1 <- 15
n <- 11
t_kritisk <- 2.228
mu0 <- 90
metodeB <- rnorm(n, mean = mu1, sd = sigma1)
barmetodeB <- round(mean(metodeB), 2)
sdmetodeB <- round(sd(metodeB), 2)
lower <- round(barmetodeB - t_kritisk*sdmetodeB/sqrt(n), 2)
upper <- round(barmetodeB + t_kritisk*sdmetodeB/sqrt(n), 2)
t <- round((barmetodeB - 90)/(sdmetodeB/sqrt(n)), 2)
metodeA <- metodeB - rnorm(n, mean = 10, sd = 5)
d <- metodeB - metodeA
bard <- round(mean(d), 2)
sdd <- round(sd(d), 2)
t2 <- round((bard - 0)/(sdd/sqrt(n)),2)
t_kritisk2 <- 1.812

t.test(metodeB, metodeA, alternative = "greater")
```
  b. Under er det gitt en R-utskrift fra en paret t-test for de samme dataene. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Formuler testobservatoren og bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå.
    
```{r, echo=F}
t.test(metodeB, metodeA, paired = TRUE, alternative = "greater" )
```

c. Hvilke av de to foregående testene bør en bruke i dette tilfellet? 

<details><summary>Løsning</summary>

>a. La $\mu_1$ og $\mu_2$ være forventet tid til registrering av lus i et basseng for hhv metode B og metode A. Da er R-utskriften en test av $H_0: \mu_1 - \mu_2 = 0$ mot det enside alternativet $H_1: \mu_1-\mu_2 > 0$. Fra utskriften ser vi at $p-value= 0.06164 > 0.05$, altså kan vi ikke forkaste $H_0$ ved $5\%$ signifikansnivå.
>
Praktisk tolkning: Vi kan ikke konkludere med at det er noe forskjell i tiden de to metodene bruker.
>
>b.I en paret t-test baserer vil testen på de parvise differansene $d_i = x_i - y_i$, der $x_i$ og $y_i$ er tiden hhv metode B og A bruker på å registrere lus i basseng nr. i. Utskriften viser en test av $H_0: \mu_d = 0$ mot det ensidige alternativet $H_1: \mu_d > 0$. Testobservatoren er da gitt ved
>
> $$T=\frac{\overline{d}-0}{s_d/\sqrt{n}}$$ 
>
> Fra utskriften ser vi at $p-value= 0.0001409 < 0.05$, altså kan vi forkaste $H_0$ ved $5\%$ signifikansnivå.
>
>Praktisk tolkning: Det ser ut til at metode A er raskere enn metode B.

>c. En paret t-test er generelt det riktige valget dersom observasjonene som blir "paret" er avhengige. I dette tilfellet er det naturlig å tro at tiden metode A og B bruker på et basseng er avhengige størrelser (f.eks vil et basseng med mye fisk ta lang tid å registrere for begge metodene). I en to-utvalgs t-test antar vi derimot at tiden det tar for metode A og B å registrere lus for et basseng er uavhengige. 


</details>

10. Vi har følgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: $s_{1}^2 = 1400$,	$n_1 = 60$,		$s_{2}^2 = 700$,	$n_2 = 60$.

    a.	Kan vi hevde at de to utvalgene har ulik varians? Bruk 5 % signifikansnivå.

    b. 	Gjenta a., denne gangen med $n_1 = 30$ og $n_2 = 30$.

	  c. Fastslå hva som er effekten på verdi av testobservator og konklusjon av testen når vi reduserer           utvalgsstørrelse.

<details><summary>Løsning</summary>
>a. Her ønsker vi å test $H_0: \sigma_{1}^2/\sigma_{2}^2 = 1$ mot $H_1: \sigma_{1}^2/\sigma_{2}^2 \neq 1$. Husk at for en tosidig test er det smart å formulere null- og alternativ hypotesen slik at den største utvalgsvariansen kommer i telleren til testobservatoren:
>
>$$F = s_{1}^2/s_{2}^2 = 1400/700 = 2$$
>
>Da trenger vi nemlig kun å sammenligne testobservatoren med den øvre kvantilen i F-fordelingen. Forkastningsområdet blir i dette tilfellet $F > F_{0.025, 59, 59} = 1.67$. Siden $F = 2$ er større enn $1.67$ kan vi altså forkaste $H_0$ til fordel for $H_1$ på et 5 % signifikansnivå. 


>b. Forkastningsområdet er da $F > F_{0.025, 29, 29} = 2.1$ og siden $F < 2.1$ kan vi ikke forkaste $H_0$ på et 5 % signifikansnivå.

>c. Testobservatoren forblir uendret, men vi ser at den kritiske verdien som må overstiges for å få forkastning øker når antall observasjoner avtar. Konklusjonen blir derfor motsatt i oppgave b. Skulle vi fått forkastning også i b. måtte det reduserte utvalget blitt kompensert av et større avvik mellom $s_1$ og $s_2$.     


<!-- qf(0.975, 59, 59) -->
<!-- qf(0.975, 29, 29) -->

</details>

11. En bedrift som har en dyr leieavtale av en parkeringsplass vurderer innkjøp av elektroniske sparkesykler. Tanken er at de som bor nær bedriften da kan benytte seg av disse istedenfor å kjøre bil. I et prøveprosjekt får bedriften leid en rekke sparkesykler i 20 arbeidsdager og antall biler på parkeringsplassen blir registrert daglig. Den samme registreringen blir gjort de 20 påfølgende arbeidsdagene når sparkesyklene ikke er tilgjengelig. En ansatt som er ansvarlig for prøveprosjektet bruker R til å utføre to tester basert på data fra disse to  registreringene. 

  a. Formuler null- og alternativhypotesen til den første testen. Hvorfor utfører den ansatte denne testen?
    
  b. Formuler null- og alternativhypotesen samt testobservatoren til den andre testen. Trekk en praktisk konklusjon om innføringen av sparkesykler ut fra utskriften.

```{r, echo = F}
set.seed(1)
med_sparkesykkel <- rnorm(20, 30, 10)
uten_sparkesykkel <- rnorm(20, 40, 13)
var.test(uten_sparkesykkel, med_sparkesykkel)



```
```{r, echo = F}
t.test(uten_sparkesykkel, med_sparkesykkel, var.equal = TRUE, alternative = "greater")
```
<details><summary>Løsning</summary>

> a. La $\sigma^2_{1}$ og $\sigma^2_{2}$ være populasjonsvariansene til antall biler som kommer for å parkere på henholdsvis dager der sparkesykler *ikke* er tilgjengelig og dager der sparkesykler er tilgjengelig. Utskriften viser da en test av $H_0: \sigma^2_{1}/\sigma^2_{2} = 1$ mot $H_1: \sigma^2_{1}/\sigma^2_{2} \neq 1$.
>
> Den ansatte utfører denne testen for å se om han kan bruke varianten av to-utvalgs t-test som antar lik varians når vedkommende tester om innføringen av sparkesykler har noen effekt (se b.). Ut fra p-verdien på 0.3559 (altså ingen forkastning av $H_0$) vil det være greit å bruke en slik test i dette tilfellet.
>
> Tips: variabel navnet som står først i testen ("uten_sparkesykkel") indikerer hvilke av de to variansen som står i telleren av $\sigma^2_{1}/\sigma^2_{2}$ (i $H_0$) og $s^2_{1}/s^2_{2}$ (i testobservatoren) i testen R utfører.

> b. La $\mu_1$ og $\mu_2$ være forventet antall biler på henholdsvis dager der sparkesykler *ikke* er tilgjengelig og dager der sparkesykler er tilgjengelig. Utskriften viser en en-sidig, to-utvalgs t-test av hypotesen $H_0: \mu_1 - \mu_2 = 0$ mot $H_1: \mu_1 - \mu_2 > 0$. $H_1$ er altså om det forventes ferre biler på dager med sparkesykler enn på dager uten sparkesykler. 
>
>"Two sample t-test" betyr at vi har antatt lik varians (ellers ville det stått "Welch two sample t-test"), og testobservatoren er derfor gitt ved:
>
>   $$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{s^2_{P}(1/n_1 + 1/n_2)}}$$
>
> der $$s^2_{P} = \frac{(n_1 - 1)s^2_{1} + (n_2 - 1)s^2_{2}}{n_1 + n_2 -2}$$ 
>
>Ut fra p-verdien på 0.009232 forkaster vi $H_0$ på 1 % (!) signifikansnivå. Vi har med andre ord god grunn til å tro at en innføring av sparkesykler vil redusere antall biler på parkeringsplassen. 
>
> Tips: Variabelnavnet som står først ("uten_sparkesykkel") indikerer hva som er første verdi i differansene $\mu_1 - \mu_2$ (i hypotesene) og $\overline{x}_1 - \overline{x}_2$ (i testobservatoren) i testen R utfører.
</details>

12. Vi har følgende informasjon om fra to tilfeldige utvalg fra to populasjoner: I utvalg 1 har $x_1 = 100$ av $n_1 = 200$ individer et spesielt kjennetegn, mens i utvalg 2 er det det tilsvarende tallet $x_2 = 90$ av $n_2 = 200$. 

a. Utfør en test for å undersøke om de to populasjonene har ulik andel av kjennetegnet. Bruk 5 % signifikansnivå.

b. Regn ut p-verdien for testen over.

c. Gjenta a., denne gangen med $x_1 = 190$ og $x_2 = 180$. Fastslå effekten på p-verdien av å øke andelene (dersom differansen er uendret).

<details><summary>Løsning</summary>

>a. Vi skal her teste hypotsen $H_0: p_1 - p_2 = 0$ mot $H_1: p_1 - p_2 \neq 0$. Med $\hat{p_1} = 100/200 = 0.5$, $\hat{p}_2 = 90/200 = 0.45$ og $\hat{p} = (100 + 90)/(200 + 200) = 0.475$ er testobservatoren er gitt ved 

>$$Z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})(1/n_1 + 1/n_2)}} = \frac{0.5 - 0.45}{\sqrt{0.475(1-0.475)(1/200 + 1/200)}}=1.00$$
>
> Siden dette er en tosidig test er forkastningsområdet til testen $|Z| > z_{\alpha/2} = z_{0.025}=1.96$. Siden 1 < 1.96 kan vi altså *ikke* forkaste $H_0$ ved 5 % signifikansnivå.

> b. P-verdier for tosidige tester kan være litt tricky å forstå. Vi er altså ute etter sannsynligheten for at noe "minst like ekstremt og til fordel for $H_1$ intreffer". For en tosidig test ville vi også reagert på store negative verdier av $Z$, og "minst like ekstremt" i negativ retning ville vært $Z < - 1.00$. Altså blir p-verdien
>
>$$\text{P-value} = P(Z < -1.00\quad \text{og/eller}\quad Z > 1.00)\\ = P(Z < -1.00) + P(Z > 1.00) = 2P(Z > 1.00) = 2*(1 - 0.841) = 0.317$$
>
> c. Regner på nytt ut $\hat{p}_1 = 0.95, \hat{p}_2 = 0.90, \hat{p} = 0.925$. Testobservatoren er da gitt ved
>
>$$Z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})(1/n_1 + 1/n_2)}} = \frac{0.95 - 0.90}{\sqrt{0.925(1-0.925)(1/200 + 1/200)}}=1.89$$
>
> P-verdien er som før gitt ved
>
> $$ \text{P-value} = 2P(Z > 1.89) = 2*(1 - 0.97) = 0.06 $$
>
> Vi ser at p-verdien avtar når andelene blir større. Vi er her ganske nære på å forkaste $H_0$ selv om differansen mellom $\hat{p}_1$ og $\hat{p}_2$ er den samme som i oppgave a. I nevneren til testobservatoren ser vi at variansen til differansen $\hat{p}_1 - \hat{p}_2$ er proposjonal med $\hat{p}(1-\hat{p})$. Denne vil bli mindre når $\hat{p}$ nærmer seg 1 (eller 0), og er størst når $\hat{p} = 0.5$. Vi er derfor sikrere på at differansen $\hat{p}_1 - \hat{p}_2$ i oppgave b. ligger nær den sanne differansen i populasjon sammenlignet med oppgave a. Bevismateriale mot $H_1$ øker (p-verdien går ned), men i dette tilfellet holder det ikke til å forkaste $H_0$. 

<!-- z = (0.5 - 0.45)/sqrt(0.475*(1 - 0.475)*(1/200 + 1/200)) -->
<!-- pval = 2*(1 - pnorm(z)) -->
<!-- z = (0.95 - 0.90)/sqrt(0.925*(1 - 0.925)*(1/200 + 1/200)) -->
<!-- pval = 2*(1 - pnorm(z)) -->
</details>

13. En kredittutsteder gir kundene en rating basert på blant annet gjeld, formue og tidligere betalingsanmerkninger. Tanken er at en lav rating medfører høyere sannsynlighet mislighold av lånet sitt. For å sjekke om ratingen gir en reell indikasjon på mislighold, blir det registrert antall mislighold i et utvalg med rating under 800, og i et utvalg med rating 800 eller høyere.  

|   | Rating < 800 | Rating  > 800 |
|---|:---:|:---:|
| Utvalgsstørrelse  |  612 | 854   |
|  Mislighold | 14  | 9  | 

Kan vi konkludere med at personer med rating lavere enn 800 har høyere sannsynlighet for mislighold av lånet sitt sammenlignet med de med rating over 800? Bruk 5 % signifikansnivå.

<details><summary>Løsning</summary>

>La $p_1$ være sannsynlighet for mislighold for de med rating under 800 og la $p_2$ være den samme sannsynligheten for de med rating over 800. Vi skal da teste $H_0: p_1 - p_2 = 0$ mot det ensidige alternativet $H_1: p_1 - p_2 > 0$. Med $\hat{p_1} = 14/612 = 0.0229$, $\hat{p}_2 = 0.0105$, og $\hat{p}=(14 + 9)/(612 + 854)=0.0157$ er testobservatoren gitt ved
>
>    $$Z =  \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})(1/n_1 + 1/n_2)}} = \frac{0.0229 - 0.0105}{\sqrt{0.0157(1-0.0157)(1/612 + 1/854)}}=1.874$$
>
> Forkastningsområdet er gitt ved $Z > z_\alpha = 1.645$, og siden 1.874 > 1.645 forkaster vi $H_0$. Det er grunn til å tro at personer med rating lavere enn 800 har større sannsynlighet for mislighold.

<!-- x1 = 14 -->
<!-- x2 = 9 -->
<!-- n1 = 612 -->
<!-- n2 = 854 -->
<!-- p1 = x1/n1 -->
<!-- p2 = x2/n2 -->
<!-- p = (x1 + x2)/(n1 + n2) -->
<!-- z = (p1 - p2)/sqrt(p*(1-p)*(1/n1 + 1/n2)) -->

</details>

14. To konkurrerende selskaper, A og B, dominerer et marked for et bestemt produkt og har historisk sett hatt markedsandeler på hhv. 40 % og 50 % (altså 10 % til andre markeder). Selskap A gjennomfører så en markedsføringskampanje. For å avgjøre kampanjens effekt trekker et markedsanalyseselskap et tilfeldig utvalg av 300 kunder som spørres om deres produkt preferanse:  

|Foretrukket selskap |  A | B  |andre|
|:---:|:---:|:---:|:---:|
|  Frekvens | 140  | 142  | 18 |

Har markedsandelene endret seg?

<details><summary>Løsning</summary>

>Vi skal her test $H_0: p_1 = 0.4, p_2 = 0.5, p_3 = 0.1$ mot $H_1:$ minst to sannsynligheter er forskjellige. Utregning av testobservator blir da som følger:

|Foretrukket selskap |  $f_i$ | $e_i$  | $(f_i - e_i)^2/e_i$|
|:---:|:---:|:---:|:---:|
|  A | 140  | $300\times 0.4 = 120$   | 3.3333 |
|  B | 142  | $300\times 0.5 = 150$   | 0.4266 |
|  andre | 18  | $300\times 0.1 = 30$   | 4.8000 |
|  \bf{totalt} | 300  | 300   | $\chi^2 = 8.564$ |

>Forkastelsesområdet er $\chi^2 > \chi^2_{\alpha, k - 1} = \chi^2_{0.05, 2} = 5.99$. Siden $\chi^2 = 8.564 > 5.99$ forkaster vi $H_0$ på 5 % signifikansnivå.


<!-- n=300 -->
<!-- p1=0.4 -->
<!-- p2 = 0.5 -->
<!-- p3 = 0.1 -->
<!-- f1 = 140 -->
<!-- f2 = 142 -->
<!-- f3 = 18 -->
<!-- f = c(f1,f2,f3) -->
<!-- p = c(p1, p2, p3)     -->
<!-- e = n*p -->
<!-- s = (f - e)^2/e -->
<!-- chi = sum(s) -->
<!-- q = qchisq(0.95, 2) -->

</details>

15. Et produksjonsselskap har mulighet til å bruke tre forskjellige kjemikalier for å fremstille det samme produktet. Lederen ved produksjonsselskapet ønsker å undersøke hvorvidt det er forskjell på hvor mange mangelfulle produkter som blir produsert når en varierer bruken av type kjemikalier. Hun gjør et tilfeldig utvalg på 700 produkter og klassifiserer dem som enten tilfredsstillende eller mangelfull. Funnene er oppsummert i tabellen nedenfor:

|Klassifisering/kjemikalie |  Kjemikalie 1 | Kjemikalie 2  | Kjemikalie 3 | sum |
|:---:|:---:|:---:|:---:|:---:|
|  Tilfredstillende | 268  |  216  | 164  | 648 |
|  Mangelfull  |  15  | 17  | 20 | 52 |
|  sum  |  283  | 233  | 184 | 700 |

Utfør en test for å avgjøre om det er en sammenheng mellom mangelfulle produkter og kjemikalie brukt under produksjon. 



<details><summary>Løsning</summary>

>Vi skal altså teste $H_0:$ *De to variablene klassfisering og kjemikalie er uavhengige* mot $H_1:$ *Variablene klassifisering og kjemikalie er avhengige*. Vi begynner med å regne ut de forventede frekvensene ved bruk av formelen $e_{ij} = f_{i.}f_{.j}/n$: 

|klas./kjem. |  Kjem 1 | Kjem 2  | Kjem 3 |
|:---:|:---:|:---:|:---:|:---:|
|  Tilfreds. | $e_{11} = 648\times 283/700 = 262.0$  |  $e_{12} = 648\times 233/700 = 215.7$  | $e_{13} = 648\times 184/700 = 170.3$  |
|  Mangel.  |  $e_{21} = 52\times 283/700 = 21.0$  | $e_{22} = 52\times 233/700 = 17.3$  | $e_{23} = 52\times 184/700 = 13.7$ |

>Så regner vi ut hvert element $(f_{ij} - e_{ij})^2/e_{ij}$ som skal inn i summen til test observatoren:

|klas./kjem. |  Kjem 1 | Kjem 2  | Kjem 3 |
|:---:|:---:|:---:|:---:|:---:|
|  Tilfreds. | $(268 - 262.0)^2/262 = 0.1384$  | 0.0004    |  0.2353 |
|  Mangel.  | 1.7255   |  0.0055 | 2.9327 |


>Testobservatoren er da gitt ved

$$\chi^2 = \sum_{i = 1}^2\sum_{j = 1}^3(f_{ij} - e_{ij})^2/e_{ij} = 0.1385 + 0.0004 + 0.2352 + 1.7255 + 0.0055 + 2.9327 = 5.0378$$

>Forkastelsesområdet er $\chi^2 > \chi^2_{\alpha, (r - 1)(s - 1)} = \chi^2_{0.05, 2} = 5.99$. Siden $\chi^2 = 5.0378 < 5.99$ forkaster vi *ikke* $H_0$ på 5 % signifikansnivå. 
>
> I R ville vi gjort følgende:
>
```{r, }
f = matrix(c(268, 216, 164, 15, 17, 20), nrow = 2, ncol = 3, byrow = T)
chisq.test(f)
```

<!-- n = 700 -->
<!-- f = matrix(c(268, 216, 164, 15, 17, 20), nrow = 2, ncol = 3, byrow = T) -->
<!-- for(i in 1:2){ -->
<!-- for(j in 1:3){ -->
<!-- e[i,j] = rowSums(f)[i]*colSums(f)[j]/n -->
<!-- } -->
<!-- } -->

<!-- chi = matrix(NA, nrow = 2, ncol = 3) -->
<!-- for(i in 1:2){ -->
<!-- for(j in 1:3){ -->
<!-- chi[i,j] = (f[i,j] - e[i,j])^2/e[i,j] -->
<!-- sum(chi) -->
<!-- chisq.test(f) #OK -->

</details>

16. [Individuell eksamen V21, oppgave 1 a - c:](tidligere-eksamensoppgaver/skole-21-v.pdf)
<details><summary>Løsning</summary>
[Løsningsforslag](tidligere-eksamensoppgaver/skole-21-v-fasit.pdf)
</details>


<!-- **På Canvas finner du en .zip-fil som inneholder alle datasettene, samt løsningsforslag til oppgavene i læreboken.** -->

<!-- ```{r, echo = FALSE, message = FALSE} -->

<!-- library(dplyr) -->
<!-- options(knitr.kable.NA = '') -->

<!-- "oppgaver/oppgaver-hypotesetesting.xlsx" %>%  -->
<!--     readxl::read_excel() %>%  -->
<!--     kableExtra::kbl() %>%  -->
<!--     kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed")) -->

<!-- ``` -->

## Relevante R-kommandoer {#relevante-r-testing}

Under følger en liste over hvilke oppgaver du skal klare i R fra denne modulen. Vår policy fra og med **vårsemesteret 2022** er at R-kommandoene under er *tilstrekkelige* for å løse oppgavene i datalabber og hjemmeeksamen i MET4. Det er med andre ord ikke nødvendig å lære seg teknikker utover det som er listet opp eksplisitt i listen under. Eventuelle nye teknikker som trengs for å løse en bestemt oppgave vil bli oppgitt og forklart dersom det er nødvendig. Det antas i tillegg at du kan den grunnleggende R-syntaksen som er dekket under [Introduksjon til R].

### Antakelser om datasett {-}

Di kan gjøre de samme antakelsene om datasettet som i [den tilsvarende oversikten i forrige modul](#relevant-r-grunnleggende): Datasettene er inneholdt i Excel-filer (`.xls` eller `xslx`) eller `.csv`-filer, som kolonner av variabler, med variabelnavn i første rad.

### $t$-tester {-}

Du må kunne gjøre de ulike $t$-testene ved hjelp av `t.test()`-funksjonen. vi bruker eksempeldatasettet [testdata.xls](datasett/testdata.xls) som illustrasjon, som inneholder de to kolonnene `X1` og `X2`. I bunn og grunn handler det om å hente ut de relevante kolonnene i datasettet som vektorer, og så å sette argumentene i `t.test()`-funksjonen riktig.

```{r, echo = FALSE}
testdata <- readxl::read_excel("datasett/testdata.xls")
```

```{r, eval = FALSE}
# Tosidig, ett-utvalgs $t$-test for om forventningen til `X1` er lik 100:
t.test(testdata$X1, mu = 100)

# Samme testen, men ensidig med alternativhypotese om at $\mu > 100$
t.test(testdata$X1, mu = 100, alternative = "greater")

# For å gjøre ensidig test den andre veien bytter du ut `"greater"` med `"less"`.

# Vanlig to-utvalgs $t$-test for om forventningen til `X1` og `X2` er like:
t.test(testdata$X1, testdata$X2)

# Vanlig to-utvalgs t-test der vi antar at variansen i de to populasjonene er like:
t.test(testdata$X1, testdata$X2, var.equal = TRUE)

# Parret to-utvalgs $t$-test, som bare gir mening dersom de to vektorene med
# observasjoner er like lange, og dersom observasjonene er matchet opp slik at
# første element i den første vektoren skal matches mot første elemenet i den
# andre vektoret etc.:
t.test(testdata$X1, testdata$X2, paired = TRUE)
```

Vi kan bytte ut alternativhypotesen til ensidige tester over alt ved å sette `alternative = ` til ønskelig verdi.

Videre kan vi tenke oss tilfeller der observasjonsvektorene ikke er like lange, og for eksempel kommer i en excel-fil slik som [denne](datasett/ulik-lengde.xlsx) der den ene kolonnen inneholder flere tall enn den andre. Det gjør ingenting. Vi kan lese inn datasettet på vanlig måte, og legger merke til at de "tomme" plassene i tabellen blir fylt med `NA`. Vi kan kjøre $t$-testene på vanlig måte.

```{r, eval = FALSE}
testdata2 <- readxl::read_excel("ulik-lengde.xlsx")
testdata2
t.test(testdata2$X1, testdata2$X2)
```

```{r, echo = FALSE}
testdata2 <- readxl::read_excel("datasett/ulik-lengde.xlsx")
testdata2
t.test(testdata2$X1, testdata2$X2)
```

### Varianstester {-}

Varianstest for ett uvalg er ikke bygget inn i R som en egen funksjon. Da må vi gjøre den "semi-automatisk" og regne ut testobservatoren ved å bruke formelen direkte. Her tester vi om variansen til `X2`-kolonnen i testdatasettet er lik 10:

```{r}
# Varianstest
s <- sd(testdata$X2)
sigma_0 <- 10
n <- length(testdata$X2)

# Testobservatoren
T <- (n-1)*s^2/sigma_0^2

# Kritiske verdier
L <- qchisq(0.025, df = n - 1)
U <- qchisq(0.975, df = n - 1)
```

Vi må så sammenligne verdien av testobservatoren `T` med de kritiske verdiene `L` og `U`. Legg merke til at vi har brukt en funksjon i R (`qchisq()`) for å finne de aktuelle kvantilene i kjikvadratfordelingen. Alternativt kan vi slå opp i tabell.

For to-utvalgs varianstest kan vi bruke funksjonen `var.test()`:

```{r, eval = FALSE}
var.test(testdata$X1, testdata$X2)
```
Vi kan også her gjøre ensidige tester ved å sette `alternative =`-argumentet til enten `"less"` eller `"greater"`.

### Tester for andeler {-}

Både for ett-utvalgs og to-utvalgs test for andeler kan vi fylle inn tall direkte i testobservatoren på denne måten (sett inn for de nødvendige verdiene):

```{r}
# Ett-utvalgs test for andeler
p_hatt <- mean(testdata$A1)
p_null <- 0.5
n      <- length(testdata$A1) 

Z <- (p_hatt - p_null)/sqrt(p_null*(1-p_null)/n)   

# To-utvalgs test for andeler
p1_hatt <- mean(testdata$A1)
p2_hatt <- mean(testdata$A2)

n1 <- length(testdata$X1)
n2 <- length(testdata$X2)

p_hatt <- mean(c(testdata$A1, testdata$A2))        # <- Regner ut felles p_hatt

Z <- (p1_hatt - p2_hatt)/sqrt((1/n1 + 1/n2)*p_hatt*(1-p_hatt))
```

Testobservatorene må da sammenlingnes med relevant kvantil i normalfordelingen, som du enten finner i tabell i læreboken eller ved å bruke funksjonen `qnorm()` med ønsket kvantil som argument.

### Kjikvadrattester for goodness-of-fit {-}

Hvis vi skal teste for goodness-of-fit for en fordeling kan vi raskt regne ut testobservatoren direkte. Vi bruker eksempelet fra forelesningsvideoen:

```{r, eval = FALSE}
p0 <- c(0.45, 0.40, 0.15)  # Fordeling under H0
f  <- c(102, 82, 16)       # Observerte frekvenser
e  <- p0*sum(f)            # Forv. frekv. under H0

T  <- sum((f - e)^2/e)     # Testobservator

c  <- qchisq(.95, df = 2)  # Kritisk verdi

# Forkast H0?
T > c
```

Alternativt så kan vi bruke `chisq.test()`-funksjonen direkte. Pass på å bruke riktige argumentnavn (`x = ` og `p = `) når du skal gjøre goodness-of-fit:

```{r, eval = FALSE}
# Eventuelt direkte
chisq.test(x = f, p = p0)
```

Dersom du skal teste for uavhengighet så kan du anta at datasettet kommer som en ferdig kontingenstabell, med den ene gruppeinndelingen langs kolonnene, og den andre gruppeinndelingen langs radene. En slik tabell kan du sende rett inn i `chisq.test()`-funksjonen for å gjøre en test for uavhengighet:

```{r, eval = FALSE}
# Test for uavhengighet
immigration <-
  read_xls("immigration-wide.xls",
           range = "B2:E12",
           col_names = c("many", "some", "few", "none"))
chisq.test(immigration)
```

### Kjikvadrattester for uavhengighet {-}

```{r, echo = F, message=F}
library(dplyr)
library(readxl)
violence <- read_excel("datasett/violence.xlsx")
```

Som eksempel kan vi ta oppgaven fra Dataøving 2. Vi starter med å lese inn dataene:

```{r, eval = F, warning=F}
# les inn data
library(readxl)
violence <- read_excel("violence.xlsx")
```
Vi bruker `select()` til å velge de to variablene vi er interessert i og funksjonen `table()` til å lage en krysstabell:

```{r voldelig}
violence_redusert <-
  violence %>%
  select(violent_treatment, experienced_violence)
krysstabell <- table(violence_redusert)

```
Det ser ut til at det er en klar sammenheng mellom faktisk og opplevd voldelighet ved at de fleste forsøkspersonene havner på diagonalen i krysstabellen over.

Nå skal vi utføre en test av nullhypotesen $H_0$: faktisk og opplevd voldelighet er uavhengige kjennetegn, mot den alternative hypotesen $H_1:$ at de er avhengige kjennetegn. Dette er en chikvadrattest som kan utføres i R på følgende måte:

```{r chisq}
chisq.test(krysstabell)
```
og vi ser at vi får en soleklar forkastning. Dette er også logisk gitt hva vi faktisk tester her.

### Kritiske verdier i R {-}

Som vi har sett over baserer tester i R seg stort sett på en eller annen datainput. Som output får du både testobservator og p-verdi. Hvis du allikevel av en eller annen grunn (f.eks. på en hjemmeeksamen) trenger å finne en kritisk verdi i en fordeling, så kan det være nyttig å vite hvordan man gjør dette i R i stedet for å slå opp i en eller annen tabell i en bok.

De kritiske verdiene finner vi ved å bruke kvantilfunksjonene til den respektive fordelingen. Disse funksjonene har alltid et argument `p` og har som output det tallet som har sannsynlighetsmasse `p` til venstre for seg. Du må derfor velge `p` ut fra signifikansnivå og om det er en ensidig/tosidig test.

#### Kritiske verdier i T-fordelingen {-}

Dersom du f.eks skal utføre en t-test for $H_0: \mu = \mu_0$ mot $H_1: \mu < \mu_0$, med signifikansnivå $\alpha = 0.05$ og har $40$ observasjoner er kritisk verdi:

```{r, eval = TRUE}
qt(0.05, df = 40 - 1)
```
og du forkaster da dersom din testobservator $T$ er mindre enn dette tallet.

Hadde alternativ hypotesen vært $H_1: \mu > \mu_0$ ville kritisk verdi vært


```{r, eval = TRUE}
qt(1 - 0.05, df = 40 - 1)
```
og du forkaster dersom din testobservator $T$ er større enn dette tallet.

For en to-sidig test ($H_1: \mu\neq \mu_0$) forkaster du dersom $T$ faller uten for intervallet:
```{r, eval = TRUE}
L <- qt(0.05/2, df = 40 - 1)
U <- qt(1 - 0.05/2, df = 40 - 1)
c(U,L)
```

#### Kritiske verdier i standardnormalfordelingen {-}
Helt likt som for t-fordelingen bare at det ikke er noen frihetsgrader involvert:

```{r, eval = TRUE}

# Ensidig mu < mu0, alpha = 0.05
qnorm(0.05)

# Ensidig mu > mu0, alpha = 0.05
qnorm(1 - 0.05)

# Tosidig
L <- qnorm(0.05/2)
U <- qnorm(1 - 0.05/2)
c(U,L)
```

Alternativt er det bare å pugge tallene $1.64$ og $1.96$.

#### Kritiske verdier i $\chi^2$-fordelingen {-}


```{r, eval = TRUE}

# Kritisk verdi, 5% nivå, ensidig test, nedre hale, 30 frihetsgrader

qchisq(0.05, df = 30)

```
og du forkaster dersom testobservatoren er mindre enn dette tallet.

```{r, eval = TRUE}

# Kritisk verdi, 5% nivå, ensidig test, øvre hale, 30 frihetsgrader

qchisq(1 - 0.05, df = 30)
```
og du forkaster dersom testobservatoren er større enn dette tallet.

```{r, eval = TRUE}
# Kritisk verdi, 5% nivå, tosidig test, 30 frihetsgrader

L <- qchisq(0.05/2, df = 30)
U <- qchisq(1 - 0.05/2, df = 30)
c(L, U)
```
og du forkaster nullhypotesen dersom testobservatoren havner utenfor dette intervallet.

#### Kritiske verdier i F-fordelingen {-}
F-fordelingen trenger vi når vi skal teste om to varianser er like. Skal du gjøre denne testen manuelt er det lurt å sette den største variansen i telleren av testobservatoren

$$F = \frac{S_{1}^2}{S_{2}^2}.$$

  Uavhengig om det er en ensidig eller tosidig test, trenger vi da bare å sjekke om testobservatoren overstiger den kritiske verdien i den øvre halen i F-fordelingen.

Har vi brukt $30$ observasjoner til å regne ut $S_{1}^2$ og $25$ observasjoner til å regne ut $S_{1}^2$ blir kritisk verdi i en to-sidig test der $H_1: \sigma_{1}^2 \neq \sigma_{2}^2$ :

```{r, eval = TRUE}
# Kritisk verdi, 5% nivå, tosidig test

qf(1 - 0.05/2, df1 = 30 - 1, df2 = 25 - 1)
```
Er det en ensidig test hvor $H_1: \sigma_{1}^2 > \sigma_{2}^2$ blir kritisk verdi:

```{r, eval = TRUE}
# Kritisk verdi, 5% nivå, ensidig test

qf(1 - 0.05, df1 = 30 - 1, df2 = 25 - 1)

```

Husk: Du kan definere hva som er $S_{1}^2$ og $S_{2}^2$, og med strategien over definerer du alltid $S_{1}^2$ til være den av variansene som er størst.












