
# Hypotesetesting

Hypotesetesting er et klassisk tema i statistikk. Vi skal først lære generelt om hva det egentlig vil si å *teste* en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting *ikke* er. Vi går så videre til å lære noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R.

I videoforelesningene går vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved å klikke på lenkene under:

[Slides til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-slides.html)

[R-script til "Hypotesetesting"](script-slides/hypotesetesting/hypotesetesting-script.R)

**TIPS:** Hvis du ønsker å laste ned lysbildene som PDF trykker du på linken over, velger "Skriv ut", og så skriver du ut som PDF. Før du gjør det bør du scrolle gjennom alle sidene slik at ligningene vises korrekt.

## Generelt om hypotesetesting

### Videoforelesninger 

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780028/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Her snakker vi om kapittel **11** i læreboken. Hvis du kan svare på følgende spørsmål har du i all hovedsak fått med deg de viktigste begrepene:

- Hva vil det si å gjennomføre en hypotesetest?
- Hva er Type I-feil og hva er Type II-feil? (Seksjon **11-1** forklarer dette greit)
- Hva er signifikansnivået ($\alpha$) til en test?
- Styrken (the power) til en test er definert som $1-P(\textrm{Type II-feil})=1-\beta$. Hvordan tolker du denne størrelsen? Se også **11-3d**.
- Hva er $p$-verdien til en test (Seksjon **11-2c**)? Les også **11-2d**, **e** og **f** om hvordan vi fortolker og snakker om $p$-verdien på en korrekt måte. Vi kommer tilbake til dette i kapittel \@ref(chap:enpop).

## Inferens om en populasjon {#chap:enpop}

### Videoforelesninger

<div style='padding:74.93% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780035/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Dette er i hovedsak dekket av kapittel **12** i læreboken. Sjekk om du kan svare på følgende kontrollspørsmål:

1. Hva er det vi tester når vi gjennomfører en $t$-test for én populasjon? Hva forutsetter vi?
2. Hva er forskjellen på en ensidig og en tosidig test? (**11-2j**)

Det kan også være greit å repetere konfidensintervaller i seksjon **11-2k** for de som har glemt det fra MET2.

I Seksjon **11-2g** går boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gjøre det samme i R. På kursets nettside finner du alle datasettene som følger med læreboken. I dette eksempelet er det snakk om `Xm11-01.xlsx`. Finn tak i denne filen (du kan også godt åpne den og se på den i Excel!), legg den i en mappe som du kan finne igjen, og åpne et nytt script i R-studio der du først sørger for å sette working directory til denne mappen slik vi gjorde i R-forelesningen.

Etterpå leser du inn datasettet ved å bruke `read_xlsx()`-funksjonen som under:

```{r, eval = F}
library(readxl)
data <- read_xlsx("Xm11-01.xlsx")     # Vi bruker read_xslx() fordi det er en .xlsx-fil
```

```{r, echo = F}
library(readxl)
data <- read_xlsx("datasett/Xm11-01.xlsx")     # Vi bruker read_xslx() fordi det er en .xlsx-fil
```

Konteksten til datasettet er gitt i eksempel 11.1. Det er altså balansen på 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer på om forventet balanse er større enn 170. Vi setter opp følgende test:

\begin{align*}
&H_0: \mu = 170 \\
&H_A: \mu > 170,
\end{align*}
der vi legger merke til at det blir brukt en ensidig test (hvorfor?).

For å regne ut testobservatoren for å enutvalgs $z$-test trenger vi fire tall: $\overline X$, $\mu_0$, $n$ og $\sigma$. Legger merke til at `data` har en kolonne som heter `Accounts`, og vi bruker dollartegnet til å hente den ut som en vektor. Regner ut observatoren:

```{r}
gj.snitt <- mean(data$Accounts)     # Gjennomsnittet av observasjonene
mu0      <- 170                     # Henter fra teksten
n        <- length(data$Accounts)   # Antall observasjoner
sigma    <- 65                      # Henter fra teksten

Z <- (gj.snitt - mu0)/(sigma/sqrt(n))   # Verdien av testobservatoren
Z                                       # Skriver ut testobservatoren
```
Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R:

```{r}
qnorm(0.95)
```

Uansett; vi forkaster $H_0$ siden testobservatoren er større enn kritisk verdi.

Kapittel **11-3a-d** gir enda mer forståelse for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre.

**Kapittel 12** presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du først og fremst må kunne fra dette kapitlet er å gjennomføre disse testene, både for hånd med penn og papir, og i R. Under følger kode for å gjøre noen av bokens eksempler i R (les i boken for kontekst):

**Eksempel 12.1:** 

\begin{align*}
&H_0: \mu = 2.0 \\
&H_A: \mu > 2.0,
\end{align*}

```{r, eval = F}
data <- read_xlsx("Xm12-01.xlsx")

# Manuell utregning
gj.snitt <- mean(data$Newspaper)
mu0      <- 2.0
n        <- length(data$Newspaper)
s        <- sd(data$Newspaper)

# Testobservator:
(gj.snitt - mu0)/(s/sqrt(n))
```

```{r, echo = F}
data <- read_xlsx("datasett/Xm12-01.xlsx")

# Manuell utregning
gj.snitt <- mean(data$Newspaper)
mu0      <- 2.0
n        <- length(data$Newspaper)
s        <- sd(data$Newspaper)

# Testobservator:
(gj.snitt - mu0)/(s/sqrt(n))
```

Signifikansnivået er satt til $\alpha = 1\%$ i eksempelet. Kritisk verdi finner vi i $t$-tabell eller rett fra R:

```{r}
qt(0.99, df = n-1)
```

Altså forkaster vi **ikke** nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som står i boken. Alternativt bruker vi `t.test()`-funksjonen direkte:

```{r}
t.test(data$Newspaper, alternative = "greater", mu = 2.0, conf.level = 0.99)
```

Resultatet blir selvsagt det samme. Når $p$-verdien er større enn signifikansnivået på 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om å lage kondidensintervall, noe du også kan prøve å gjøre ved å regne ut de nødvendige tallene i R. De som synes dette er greit kan kikke på seksjonene **12-1b-e** for å utvikle forståelsen enda litt mer.

**Eksempel 12.3:** 

\begin{align*}
&H_0: \sigma^2 = 1.0 \\
&H_A: \sigma^2 < 1.0.
\end{align*}

Testobservator:

$$\chi^2 = \frac{(n-1)s^2}{\sigma_0^2}.$$

```{r, eval = F}
data <- read_xlsx("Xm12-03.xlsx")

# Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis:
(length(data$Fills) - 1)*var(data$Fills)/1

# Kritisk verdi, 5% nivå, ensidig test, nedre hale:
qchisq(0.05, df = length(data$Fills) - 1)     
```

```{r, echo = F}
data <- read_xlsx("datasett/Xm12-03.xlsx")

# Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis:
(length(data$Fills) - 1)*var(data$Fills)/1

# Kritisk verdi, 5% nivå, ensidig test, nedre hale:
qchisq(0.05, df = length(data$Fills) - 1)     
```

Vi kan altså ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for å forstå bedre hva som skjer. Figur 12.4 viser på en fin måte hva tallene betyr.

**Eksempel 12.5** kan være grei å kikke på også. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste:

\begin{align*}
&H_0: p = 0.5 \\
&H_A: p > 0.5.
\end{align*}

Vi har en observert andel på $\widehat p = 407/765 = 0.532$ etter å ha spurt $n = 765$ personer. Testobservatoren er 
$$Z = \frac{\widehat p - p}{\sqrt{p(1-p)/n}}.$$

```{r}
p.hatt <- 407/765
p0     <- 0.5
n      <- 765

(p.hatt - p0)/sqrt(p0*(1-p0)/n)
```

Kritisk verdi for en ensidig z-test på 5% nivå er 1.645 (`qnorm(0.95)`), og vi kan forkaste nullhypotesen.

Seksjonene **12-3d-f** bør leses på egen hånd, mens vi hopper over **12-3g**.

## Inferens om to populasjoner

### Videoforelesninger

<div style='padding:74.64% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780048/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi har gått gjennom kapittel **13**, som i all hovedsak handler om å sammenligne to gjennomsnitt (som vi kan gjøre på tre forskjellige måter), to varianser og to andeler. Her følger noen kontrollspørsmål som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper:

- Hva er nullhypotesen når vi skal gjennomføre en t-test for to populasjoner?
- ... og hvilke antagelser må vi gjøre?
- Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør?
- Når kan vi bruke matchede par, og hva er hensikten?
- Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen?
- Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør?
- Hvilken test brukes for å teste om to andeler er like, og hva må du anta?

Videre bør du sjekke at du kan utføre **3** typer $t$-tester, test for like varianser og test for like andeler både for hånd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber).

Den enkleste måten å gjøre $t$-tester i R på er å bruke funksjonen `t.test()`. Kikk på eksempel 13.1 i lærebokens 11. utgave, der vi har observert årlige avkastninger til to aksjefond som er kjøpt henholdsvis med og uten megler. 

```{r, eval = F}
# Leser inn datasettet
funds <- read_xlsx("Xm13-01.xlsx")

# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = FALSE,
       conf.level = 0.95) 
```

```{r, echo = F}
# Leser inn datasettet
funds <- read_xlsx("datasett/Xm13-01.xlsx")

# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = FALSE,
       conf.level = 0.95) 
```

Du kan så sjekke at du får ut de samme tallene på s. 434--435. Videre kan du skrive inn `?t.test` i R-konsollen i RStudio for å lese mer om hvilke argumenter vi kan bruke i `t.test()`-funksjonen. Der ser vi at argumentene `paired`, `var.equal` og `conf.level` som utgangspunkt allerede er satt til `FALSE`, `FALSE` og `0.95` henholdsvis, så det hadde vi strengt tatt ikke trengt å spesifisere i funksjonskallet over.

Vi kan enkelt kjøre den samme testen under antakelsen om like varianser ved å sette `var.equal = TRUE`:

```{r}
# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = FALSE,
       var.equal = TRUE,
       conf.level = 0.95) 
```

Resultatet bli akkurat det samme. Siden testens $p$-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og slå fast at forskjellen i gjennomsnitt er statistisk signifikant.

I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner  i de to populasjonene, så vi kan tenke oss at målingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om *gjennomsittet av differansene* er signifikant forskjellig fra null. Enkelt:

```{r}
# Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at
# differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først 
# ulik varians og at vi ikke skal gjøre en paret test:
t.test(funds$Direct, funds$Broker,
       alternative = "greater",
       paired = TRUE,
       conf.level = 0.95) 
```

Da ser vi at $p$-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du prøve selv. Pass på at du kan gjøre beregningene manuelt også, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forstår hva som foregår. 

Kapittel **13-2** omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig å sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen vår av statistiske resultater. Det er et eksplisitt krav for å lykkes i MET4 at du er i stand til å sette resultatene inn i en fornuftig kontekst.

I kapittel **13-4** kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R:

```{r, eval = F}
bottle <- read_xlsx("Xm13-07.xlsx")
var.test(bottle$`Machine 1`, bottle$`Machine 2`,
         alternative = "greater")
```

```{r, echo = F}
bottle <- read_xlsx("datasett/Xm13-07.xlsx")
var.test(bottle$`Machine 1`, bottle$`Machine 2`,
         alternative = "greater")
```

Også her kan du sammenligne med tallene som fremgår av bokens gjennomgang, og sørg for at du får til dette på egen hånd, *spesielt* det å finne frem i tabellen, for det *må* du kunne på eksamen.

Til slutt har vi test for to andeler i kapittel **13-5**. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er *like* ($p_1 - p_2 = 0$), som er det vi har dett på i forelesning, men det går selvsagt like fint å sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall $D$. 

Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved å regne ut testobservatoren fra datasettet. Vi ser på eksempel 13.9, der vi får oppgitt salget av en del forskjellige varenummer, og vi ønsker å finne ut om andelen «9077» er større i Supermarked 1 enn i Supermarked 2:

```{r, eval = F}
# Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg 
# velger å lese inn de to kolonnene hver for seg:
soap1 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("A"))
soap2 <- read_xlsx("Xm13-09.xlsx", range = cell_cols("B"))

# Hvor stor andel utgjør «9077» i de to kolonnene?
p1 <- mean(soap1 == 9077)
p2 <- mean(soap2 == 9077)

# De to utvalgsstørrelsene:
n1 <- nrow(soap1)
n2 <- nrow(soap2)

# Felles estimat for p under nullhypotesen:
p <- (n1*p1 + n2*p2)/(n1 + n2)

# Testobservatoren:
z <- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2))

# Kritisk verdi på 5% nivå for en ensidig test:
qnorm(0.95)
```

```{r, echo = F}
# Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg 
# velger å lese inn de to kolonnene hver for seg:
soap1 <- read_xlsx("datasett/Xm13-09.xlsx", range = cell_cols("A"))
soap2 <- read_xlsx("datasett/Xm13-09.xlsx", range = cell_cols("B"))

# Hvor stor andel utgjør «9077» i de to kolonnene?
p1 <- mean(soap1 == 9077)
p2 <- mean(soap2 == 9077)

# De to utvalgsstørrelsene:
n1 <- nrow(soap1)
n2 <- nrow(soap2)

# Felles estimat for p under nullhypotesen:
p <- (n1*p1 + n2*p2)/(n1 + n2)

# Testobservatoren:
z <- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2))

# Kritisk verdi på 5% nivå for en ensidig test:
qnorm(0.95)
```

Siden $z = `r format(z, digits = 3)`$ forkaster vi nullhypotesen om at det er lik andel «9077» i de to populasjonene.

## Kjikvadrattester

### Videoforelesninger

<div style='padding:74.43% 0 0 0;position:relative;'><iframe src='https://vimeo.com/showcase/7780062/embed' allowfullscreen frameborder='0' style='position:absolute;top:0;left:0;width:100%;height:100%;'></iframe></div>

### Kommentarer

Vi må kunne *to* anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken:

1. Teste for om en gitt fordeling passer med obervasjoner (*"Goodness-of-fit"*).
2. Teste for uavhengighet.

I den første anvendelsen får vi oppgitt en *diskret* sannsynlighetsfordeling der vi har noen mulige utfall $u_1, \ldots, u_k$, med tilhørende sannsynligheter $p_1, \ldots,p_k$. Dersom vi skal observere $n$ utfall fra denne fordelingen, vil vi forvente $e_i = p_i\cdot n$ observasjoner av utfall $u_i$.

Nå har det seg slik at vi *har* observert $n$ utfall fra fordelingen, og utfall $u_i$ har skjedd $f_i$ ganger. **Vi lurer da på om de observerte frekvensene ($f_i$) er så forskjellige fra de *forventede* frekvensene ($e_i$) at vi ikke lenger tror at $p_1, \ldots,p_k$ er den sanne sannsynlighetsfordelingen.**

Vi kom frem til en fornuftig testobservator:

$$\chi^2 = \sum_{i=1}^k \frac{(f_i - e_i)^2}{e_i},$$
som er $\chi^2$-fordelt med $k-1$ frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan gå inn i $\chi^2$-tabellen for å sjekke om verdien av testobservatoren er for stor (dvs, $f$´ene er for forskjellige fra $e$`ene) at vi ikke lenger tror at $(p_1, \ldots, p_k)$ er den sanne sannsynlighetsfordelingen.

Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte følgende kommandoer:

```{r}
p0 <- c(0.45, 0.40, 0.15)  # Fordeling under H0
f  <- c(102, 82, 16)       # Observerte frekvenser

chisq.test(x = f, p = p0)
```

Den andre anvendelsen er å teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for «$A$ og $B$» som et produkt dersom de ar uavhengige: 

$$P(A \cap B) = P(A)\cdot P(B).$$

Vi kan regne ut hvor mange observasjoner vi forventer å se for hver kombinasjon av de to kjennetegnene ($e_{ij}$), og bruke kjikvadrattesten over til å sjekke om disse er langt fra det vi *faktisk* har observert ($f_{ij}$). Boken har et eksempel på dette som de regner ut både for hånd og i Excel. Slik kan vi gjøre det i R:

```{r, eval = F}
# Leser inn data
mba <- read_xlsx("Xm15-02.xlsx")

# Kikker på datasettet
mba
```

```{r, echo = F}
# Leser inn data
mba <- read_xlsx("datasett/Xm15-02.xlsx")

# Kikker på datasettet
mba
```

Vi legger merke til at strukturen på datasettet er litt annerledes enn krysstabellen som er vist s. 601 i læreboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av «bachelorgrad» og «masterprofil», har vi fått oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R:

```{r}
table(mba)
```

Det er denne som brukes som argument i `chisq.test()`:

```{r}
chisq.test(table(mba))
```

Her er det bare å sammenligne tallene med det som læreboken finner i Excel.

Noen kontrollspørsmål:

1. Vi har lært to veldig spesifikke anvendelser av kjikvadrattester. Hvilke?
2. Kan du gi en intuitiv forklaring på hvorfor testobservatoren vår er fornuftig?
3. **Litt mer vanskelig:** Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tilnærmet kjikvadratfordelt?

## Oppgaver

### Standard oppgaver

Introduksjon til hypotesetesting

1. For hvert av scenarioene i a og b, gjør følgende:
   -	Sett opp relevant nullhypotese og alternativhypotese (hint: nullhypotese avhenger av hvor ‘bevisbyrden’ bør ligge)
   -	Definer type I-og type II-feil. 
   -	Diskuter konsekvensene av type I-feil og type II-feil i det aktuelle scenarioet. 

   a. En ny type medisin skal vurderes for kommersialisering. Du sitter i et vurderingspanel som skal vurdere om medisinen kan     bli godkjent eller ikke. 

   b. Du blir presentert to ulike investeringer å velge mellom. En av dem er veldig risikabel, men med stor potensiell             profitt. Den andre er mindre risikabel, men med lavere potensiell profitt. 

<details><summary>Løsning</summary>

> a. $H_0$: Den nye medisinen er ikke trygg og effektiv. $H_1$: Den nye medisinen er trygg og effektiv. Type I-feil: Forkaste $H_0$ når $H_0$     er sann. Konsekvens: Risikerer at vi begynner å produsere en medisin som ikke er trygg og effektiv. Type II-feil: Forkaster *ikke* $H_0$     når $H_1$ er sann. Konsekvens: Vi lar være å produsere en medisin som faktisk er trygg og effektiv.
>
>Kommentar: Signifikansnivået ved produksjon av medisiner settes ofte lavt fordi konsekvensene av en type I-feil kan være svært alvorlige.


> b. $H_0$: Den mest risikable investeringen er mest lønnsom. $H_1$: Den mest risikable investeringen er ikke mest lønnsom. Type I-feil:          Forkaste $H_0$ når $H_0$ er sann. Konsekvens:Vi investerer i den minst risikable investeringen, som ikke er mest lønnsom. Type II-feil:      Forkaster *ikke* $H_0$ når $H_1$ er sann. Konsekvens: Vi investerer i den mest risikable investeringen, som ikke er mest lønnsom.


</details>

2. Vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 150$ mot $H_1: \mu \neq 150$. $\sigma = 10$, $n =100$, $\overline{x} = 150$.

   Bestem verdi av testobservator, forkastelsesområde dersom signifikansnivået er $\alpha = 0.05$, og p-verdi. Konkluder.

<details><summary>Løsning</summary>

>Her er $\sigma$ kjent så vi kan bruke en z-observator. Forkastelsesområde $Z < -z_{0.025}=-1.96$ eller $Z> z_{0.025}=1.96$.
>
>$$Z = \frac{\overline{x} - \mu}{\sigma/\sqrt{n}} = \frac{150 - 150}{10/\sqrt{100}}=0$$
>
> p-verdi$=2P(Z > 0) = 2\times0.5=1$. Vi kan ikke forkaste nullhypotesen $H_0: \mu = 0$. Faktisk er det ekstremt sannsynlig (p-verdi = 1) å observere det vi har observert dersom nullhypotesen er sann. 

</details>

3. Vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 55$ mot $H_1: \mu > 55$.
  $\sigma = 20$, $n = 25$, $\overline{x} = 67$.

    a.	Regn ut testobservatoren $Z$.

    b.	Regn ut p-verdi.

    c. 	Regn ut p-verdi, denne gangen med $\overline{x}$ = 63.

    d. 	Regn ut p-verdi, denne gangen med $\overline{x}$ = 59.

    e. 	Fastslå hva som skjer med verdien av testobservatoren (Z) og p-verdien når $\overline{x}$ nærmer seg $55$ (verdien av $\mu$ under $H_0$). 

<details><summary>Løsning</summary>

> a. $$Z = \frac{\overline{x} - \mu}{\sigma/\sqrt{n}} = \frac{67 - 55}{20/\sqrt{25}}=3$$
>
> b. $\text{p-verdi} = P(Z > 3.00) = 1 – P(Z<3) = 1 – 0.9987 = 0.0013$. Kommentar: Her kan du bruke `pnorm(3)` i R til å regne ut $P(Z<3)$.
>
> c. Ny verdi av testobservator blir da $Z = 2$. 
> $\text{p-verdi} = P(Z > 2.00) = 1 – 0.9772 = 0.0228$.
>
> d. Ny verdi av testobservator blir da $Z = 1$. 
> $\text{p-verdi} = P(Z > 1.00) = 1 – 0.8413 = 0.1587$.
>
> e. Vi ser at testobservatoren minker og p-verdien øker når $\overline{x}$ nærmer seg $55$. 
>
>Forklaring: La $\mu_0 = 55$ være verdien av $\mu$ under $H_0$. Z-observatoren måler avviket mellom antagelsen under $H_0$ og dataene vi observerer og avtar derfor når vår observasjon av $\overline{x}$ nærmer seg $\mu_0$. P-verdien sier hvor sannsynlig det er å observere de dataene vi har dersom $H_0$ er sann og øker følgelig når $\overline{x}$ nærmer seg $\mu_0$.  

</details>


4. Annta at vi har følgende hypoteser og informasjon om dataene: $H_0: \mu = 50$ mot $H_1: \mu > 50$. $\sigma = 10$, $n = 40$, $\alpha = 0.05$.

   Bestem $\beta$, altså sannsynligheten for en type-II feil, under antagelsen at $\mu = 55$. 

<details><summary>Løsning</summary>

> Forkastningsområdet blir da
>
>$$Z = \frac{\overline{X} - 50}{10/\sqrt{40}} > Z_{0.05} = 1.645 $$
>dvs at vi forkaster $H_0$ når
> $$\overline{X} > 50 + 1.645\times\frac{10}{\sqrt{40}}=52.6$$
>En type-II feil svarer til å *ikke* forkaste $H_0$ når $H_1$ er sann. For å regne på sannsynligheten for type-II feil må vi ikke bare anta at $H_1$ er sann, men være spesifike på hva verdien til $\mu$ er (i dette tilfellet 55). Vi lurer altså på hva sannsynligheten for at vi *ikke* er i forkastnings området ($\overline{X} < 52.6$) gitt at $\mu = 55$: 
> \begin{equation*}
\begin{split}
\beta &= P(\overline{X} < 52.6\quad\text{gitt at $\mu = 55$})\\
&= P(\frac{\overline{X} - 55}{10/\sqrt{40}} < \frac{52.6 - 55}{10/\sqrt{40}})\\
&=P(Z < -1.52) = 0.064
\end{split}
\end{equation*}
> Merk: Et begrep som ofte blir brukt om tester er *styrken* til testen $1-\beta$ som da er sannsynligheten for å forkaste $H_0$ når $H_1$ er sann. En god test har god (stor) styrke. Hadde vi gjentatt denne testen mange ganger ville vi ha forkastet $H_0$  i $(100 - 6.4)\% = 93.6\%$ av gangene dersom det faktisk er slik at sann $\mu$ er 55. 

</details>

5.  En leder frykter at den gjennomsnittlige tiden ansatte daglig bruker på sosiale medier overstiger 45 minutter. For å teste denne mistanken, plukker han ut et tilfeldig utvalg på 15 personer, og spør om tid brukt på sosiale medier etter en tilfeldig arbeidsdag. Resultatene er oppsummert nedenfor. 

          70, 96, 58, 88, 34, 42, 34, 56, 68, 46, 26, 18, 22, 60, 84

    a. Hvis samlingen av tider er normalfordelt med standardavvik på 20 minutter, kan lederen hevde at mistanken hans stemmer på et 1 % signifikans-nivå?

    b. Tror du observasjonene over er et representativt utvalg? Hva kunne lederen gjort annerledes?

<details><summary>Løsning</summary>

>   a. Lederen ønsker altså å teste $H_0: \mu = 45$ mot alternativ hypotesen $H_1: \mu > 45$. Testobservatoren er da gitt ved 
>
>$$Z = \frac{\overline{X} - \mu_0}{\sigma/\sqrt{n}} = \frac{53.46 - 45}{20/\sqrt{15}} = 1.64$$ 
>
>Sannsynligheten for å observerer noe minst like ekstremt og til fordel for $H_1$ (p-verdien) er da
>
>$$P-verdi = P(Z > 1.645) \approx 0.05 > 0.01$$.
>
> Lederen kan altså ikke trekke denne konklusjonen på 1 % signifikansnivå. For å forkaste null hypotesen på et 1 % signifikansnivå, måtte vi hatt p-verdi lavere enn 1 %. 
>
>   b. Dersom lederen spør ansatte fjes til fjes er det nærliggende å tro at de ansatte vil underdrive sin bruk av sosiale medier. En anonym spørreundersøkelse ville nok gitt et mer representativt utvalg.

</details>

6. Gjennomsnitt og standardavvik i et utvalg på $n=100$ er $\overline{x} = 20$ og $s = 2$.

    a. Finn 95 % konfidensintervall av gjennomsnitt ($\mu$) i populasjonen.

    b. Gjenta a. med $s = 5$.

    c. Gjenta a. med $s = 10$.

    d. Fastslå hvordan det estimerte konfidensintervallet endrer seg når vi øker $s$.

    e. Anta at $s=5$ og regn et 95 % konfidensintervall dersom størrelsen på utvalget er henholdsvis $n = 50$ og $n=10$. 

    f. Fastlå hvordan det estimerte konfidensintervallet endrer seg når vi øker $n$.

<details><summary>Løsning</summary>

>   a. $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 1.984\times 2/\sqrt{100} = [19.60 ,20.40]$$
>
>   b. $$ 20 \pm 1.984\times 5/\sqrt{100} = [19.01 ,20.99]$$
> 
>   c. $$ 20 \pm 1.984\times 10/\sqrt{100} = [18.02 ,21.98]$$
>
>   d. Konfidensintervallet blir større når $s$ øker.
> 
>   e. $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 2.09\times 5/\sqrt{50} = [18.58 ,21.42]$$
>    $$\overline{x} \pm t_{\alpha/2, n - 1}s/\sqrt{n} = 20 \pm 2.26\times 5/\sqrt{10} = [16.42 ,23.58]$$
>   
>   f. Vi ser at jo større $n$ er jo mindre blir konfidensintervallet. Flere observasjoner gjør at vi med større sikkerhet (smalere intervall) kan si hvor $\mu$ ligger.  

</details>

7. Med sterkt fall i flyreiser og passasjerer på grunn av koronakrisen virker det sannsynlig at det blir færre forsinkelser i flytrafikken. Før krisen hevdet et flyselskap at de landet presist 92 % av flyreisene. I et tilfeldig utvalg flyreiser hos det samme selskapet under krisen ble 143 av 165 vurdert til å være presise. Kan vi konkludere på 5 % signifikansnivå at det er færre forsinkelser under koronakrisen? 


<details><summary>Løsning</summary>
>La $p$ være den sanne andelen av flyreiser som blir forsinket under krisen. Vi skal da teste $H_0: p = 0.92$ mot $H_1: p < 0.92$. Vårt estimat på $p$ er $\hat{p}=148/165 \approx 0.90$ og testobservatoren er gitt ved

>$$z = \frac{\hat{p} - p_0}{\sqrt{p_0(1 - p_0)/n}} = \frac{0.90 - 0.92}{\sqrt{0.92(1 - 0.92)/165}} \approx -0.80$$
>Dersom vi bruker kritisk verdi ville forkastningsområdet vært $z < -1.645$ og siden $z> -1.645$ kan vi altså ikke forkaste $H_0$. Alternativt kan vi regne ut p-verdien som er "sannsynligheten for det vi har observert eller noe enda mer til fordel for $H_1$. En enda mer negativ verdi enn -0.80 ville vært til fordel for $H_1$, derfor er 

>$$p-verdi = P(Z < - 0.8) = 0.21$$
>og vi derfor *ikke* forkaste $H_0$ siden p-verdien *ikke* er mindre enn 0.05.

</details>

8. Vi har følgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: $\overline{x}_1 = 400$, $s_1 = 100$, $n_1 = 130$, $\overline{x}_2 = 390$, $s_2 = 50$, $n_2 = 130$. 

 a.	Kan vi hevde på et 5 % signifikansnivå at $\mu_1$ er større enn $\mu_2$? Det oppgis at
    
  $$\nu =  \frac{\left(\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}\right)^2}{\left(\frac{s^2_{1}}{n_1}\right)^2/(n_1 - 1) + \left(\frac{s^2_{2}}{n_2}\right)^2/(n_2 - 1)}\approx 166$$

 b.  Gjenta a., denne gangen med $s_1 = 30$ og $s_2 = 15$. Som over, oppgis det at $\nu \approx 190$.  
	 
 c.  Fastslå hva som skjer hvis utvalgenes standardavvik blir mindre.
	  
 d.  Gjenta a., denne gangen med utvalg på $n_1 = n_2 = 20$ observasjoner. Som over, oppgis det at $\nu \approx 28$. 
	  
 e.  Fastslå effekten av å redusere utvalgsstørrelser. 
	  
<details><summary>Løsning</summary>

a. Vi skal altså teste $H_0: \mu_1 - \mu_2 = 0$ mot $H_1: \mu_1 - \mu_2 > 0$. Siden variansene i utvalget er såpass ulike antar vi at vi må bruke varianten av testen med ulik varians. Testobservatoren er da gitt ved

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{130^2}{130} + \frac{50^2}{130}}} = 0.82$$
Antall frihetsgrader oppgis til å være $v \approx 166$. Vi forkaster $H_0$ dersom $T > t_{0.05, 166} = 1.654$, og siden dette *ikke* er tilfelle her kan vi *ikke* forkaste $H_0$ ved 5 % signifikansnivå. 

b. Testobservatoren blir i dette tilfellet

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{30^2}{130} + \frac{15^2}{130}}} = 3.40$$
Antall frihetsgrader oppgis til å være $v \approx 190$. Siden $T = 3.40 > t_{0.05, 190} = 1.653$ forkaster vi $H_0$ på 5 % signifikansnivå.   

c. Når standardavvikene i utvalgene blir mindre øker verdien av testobservatoren. Mindre standardavvik betyr at vi er mer sikre på at $\overline{x}_1 - \overline{x}_2$ ligger nær $\mu_1 - \mu_2$, og at en evt. differanse kan tyde på avvik fra $H_0$. Dette blir reflektert av en større testobservator. 

d. Testobservatoren blir da

$$T = \frac{\overline{x}_1 - \overline{x}_2 - 0}{\sqrt{\frac{s^2_{1}}{n_1} + \frac{s^2_{2}}{n_2}}}=\frac{400 - 390}{\sqrt{\frac{130^2}{20} + \frac{50^2}{20}}} = 0.40$$
Antall frihetsgrader oppgis til å være $v \approx 28$. Vi forkaster $H_0$ dersom $T > t_{0.05, 28} = 1.701$, og siden dette *ikke* er tilfelle her kan vi *ikke* forkaste $H_0$ ved 5 % signifikansnivå. 

e.  Få observasjoner representerer større usikkerhet om differansen $\overline{x}_1 - \overline{x}_2$ bare skyldes tilfeldighet, og dette reflekteres av testobservatoren som vil synke når utvalgsstørrelsen reduseres.

<!-- m1 <- 400 -->
<!-- m2 <- 390 -->
<!-- s1 <- 100 -->
<!-- s2 <- 50 -->
<!-- n1  <- n2 <- 20 -->
<!-- t <- (m1 - m2)/sqrt(s1^2/n1 + s2^2/n2) -->
<!-- v <- (s1^2/n1 + s2^2/n2)^2/((s1^2/n1)^2/(n1 - 1) + (s2^2/n2)^2/(n2 - 1)) -->
<!-- qt(0.95, v) -->

</details>

9. Et nystartet firma har utviklet to løsninger for automatisk registrering av av antall lus på oppdrettslaks. Metode A er litt dyrere enn metode B, men firmaet mener Metode A en den raskeste metoden. For å teste ut denne hypotesen blir begge metodene brukt til å registrere lus på 11 basseng av ulik størrelse og med forskjellig antall fisk. Antall minutter hver metode tar blir registrert for hvert basseng. 

    a. Under er det gitt en R-utskrift fra en to-utvalgs t-test. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå.

```{r,echo=F}
set.seed(2)
mu1 <- 80
mu2 <- 75
sigma1 <- 15
n <- 11
t_kritisk <- 2.228
mu0 <- 90
metodeB <- rnorm(n, mean = mu1, sd = sigma1)
barmetodeB <- round(mean(metodeB), 2)
sdmetodeB <- round(sd(metodeB), 2)
lower <- round(barmetodeB - t_kritisk*sdmetodeB/sqrt(n), 2)
upper <- round(barmetodeB + t_kritisk*sdmetodeB/sqrt(n), 2)
t <- round((barmetodeB - 90)/(sdmetodeB/sqrt(n)), 2)
metodeA <- metodeB - rnorm(n, mean = 10, sd = 5)
d <- metodeB - metodeA
bard <- round(mean(d), 2)
sdd <- round(sd(d), 2)
t2 <- round((bard - 0)/(sdd/sqrt(n)),2)
t_kritisk2 <- 1.812

t.test(metodeB, metodeA, alternative = "greater")
```
  b. Under er det gitt en R-utskrift fra en paret t-test for de samme dataene. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Formuler testobservatoren og bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå.
    
```{r, echo=F}
t.test(metodeB, metodeA, paired = TRUE, alternative = "greater" )
```

c. Hvilke av de to foregående testene bør en bruke i dette tilfellet? 

<details><summary>Løsning</summary>
a. La $\mu_1$ og $\mu_2$ være forventet tid til registrering av lus i et basseng for hhv metode B og metode A. Da er R-utskriften en test av $H_0: \mu_1 - \mu_2 = 0$ mot det enside alternativet $H_1: \mu_1-\mu_2 > 0$. Fra utskriften ser vi at $p-value= 0.06164 > 0.05$, altså kan vi ikke forkaste $H_0$ ved $5\%$ signifikansnivå.

Praktisk tolkning: Vi kan ikke konkludere med at det er noe forskjell i tiden de to metodene bruker.

b.I en paret t-test baserer vil testen på de parvise differansene $d_i = x_i - y_i$, der $x_i$ og $y_i$ er tiden hhv metode B og A bruker på å registrere lus i basseng nr. i. Utskriften viser en test av $H_0: \mu_d = 0$ mot det ensidige alternativet $H_1: \mu_d > 0$. Testobservatoren er da gitt ved

 $$T=\frac{\overline{d}-0}{s_d/\sqrt{n}}$$ 
 Fra utskriften ser vi at $p-value= 0.0001409 < 0.05$, altså kan vi forkaste $H_0$ ved $5\%$ signifikansnivå.

Praktisk tolkning: Det ser ut til at metode A er raskere enn metode B.

c. En paret t-test er generelt det riktige valget dersom observasjonene som blir "paret" er avhengige. I dette tilfellet er det naturlig å tro at tiden metode A og B bruker på et basseng er avhengige størrelser (f.eks vil et basseng med mye fisk ta lang tid å registrere for begge metodene). I en to-utvalgs t-test antar vi derimot at tiden det tar for metode A og B å registrere lus for et basseng er uavhengige. 


</details>

<!-- 10. Vi har følgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: $s_{1}^2 = 1400$,	$n_1 = 60$,		$s_{2}^2 = 700$,	$n_2 = 60$.  -->

<!--     a.	Kan vi hevde at de to utvalgene har ulik varians? Bruk 10 % signifikansnivå.  -->

<!--     b. 	Gjenta a., denne gangen med $n_1 = 30$ og $n_2 = 30$.  -->

<!-- 	  c. Fastslå hva som er effekten på verdi av testobservator og konklusjon av testen når vi reduserer           utvalgsstørrelse.  -->

<!-- <details><summary>Løsning</summary> -->
<!-- a. Her ønsker vi å test $H_0: \sigma_{1}^2/\sigma_{2}^2 = 1$ mot $H_1: \sigma_{1}^2/\sigma_{2}^2 \neq 1$. Testobservatoren er gitt ved -->

<!-- $$F = s_{1}^2/s_{2}^2 = 1400/700 = 2$$ -->


</details>

### Nøtter





  
  **Flere oppgaver kommer!**
<!-- **På Canvas finner du en .zip-fil som inneholder alle datasettene, samt løsningsforslag til oppgavene i læreboken.** -->

<!-- ```{r, echo = FALSE, message = FALSE} -->

<!-- library(dplyr) -->
<!-- options(knitr.kable.NA = '') -->

<!-- "oppgaver/oppgaver-hypotesetesting.xlsx" %>%  -->
<!--     readxl::read_excel() %>%  -->
<!--     kableExtra::kbl() %>%  -->
<!--     kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed")) -->

<!-- ``` -->


