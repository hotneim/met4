[["index.html", "MET4 - Empiriske Metoder Innledning", " MET4 - Empiriske Metoder Håkon Otneim og Geir Drage Berentsen Innledning Velkommen til hjemmesiden for kurset MET4 - Empiriske metoder, som er et obligatorisk kurs på Bachelorprogrammet i Økonomi og Administrasjon ved Norges Handelshøyskole. Her vil du finne undervisningsmaterialet  Videobasert. Innledning til kurset, detaljer om datoer, hvordan jobbe, hvor finne informasjon, følge med på Canvas osv. "],["introduksjon-til-r.html", " 1 Introduksjon til R", " 1 Introduksjon til R Vi skal i dette kurset bruke programmeringsspråket R til å gjøre beregninger og gjennomføre de ulike statistiske analysene som vi skal lære etter hvert. Dette vil være nytt for mange. Vi skal først og fremst skal skrive kode og kommandolinjer for å få ut resultater i R, noe som kan oppleves uvant siden vi ellers er vant med å klikke oss frem i et menysystem når vi jobber med ulike programmer. Trøsten kan være at ferdigheter i programmering blir stadig viktigere i mange yrker, spesielt innen økonomifaget. Vi må installere to ting på maskinen vår før vi går videre; selve programeringsspråket R, samt programmet RStudio som vi skal bruke til å skrive og kjøre koden. Begge deler er gratis, og begge deler fungerer fint på både Windows og Mac (og Linux!). Det er greiest å gjøre dette i riktig rekkefølge: Gå til r-project.org for å laste ned R til ditt operativsystem, og installer på vanlig måte uten å forandre på foreslåtte innstillinger. Gå til rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (Open source edition) for ditt operativsystem og installere på vanlig måte. Det er heller ikke her nødvendig å forandre på de foreslåtte innstillingene. Du kan så åpne RStudio, og følge sekvensen av videoforelesniger som følger under. Merk at disse videoene er lånt fra seminaret BAN420 - Introduction to R som gis på masterprogrammet ved NHH. De er derfor spilt inn på engelsk. Det resterende videomaterialet i kurset gis på norsk. "],["en-gjennomgang-av-rstudio.html", "1.1 En gjennomgang av RStudio", " 1.1 En gjennomgang av RStudio I denne videoen åpner vi opp Rstudio og rusler gjennom det grafiske grensesnittet. "],["enkle-beregninger-og-variabler.html", "1.2 Enkle beregninger og variabler", " 1.2 Enkle beregninger og variabler Vi går videre og skriver våre første kommandoer i R. Det er kritisk at vi allerede nå setter i gang med å få programmeringen inn i fingrene, og det gjøres best ved å skrive inn kodelinjene slik det gjøres i videoen, og passe på at du får ut de samme resultatene. Når du er ferdig med det kan du prøve deg på følgende lille oppgave: Oppgave: Velg dine tre favorittall og lagre dem i tre forskjellige variabler. Beregn så ditt magiske tall, som er summen av favorittallene dine. Lagre ditt magiske tall i en ny variabel, og gi denne variabelen et informativt navn som identifiserer hva det er. Fikk du det til? Kikk på løsningen under for å sjekke. Løsning tall1 &lt;- 1 tall2 &lt;- 87 tall3 &lt;- 101 magisk_tall &lt;- tall1 + tall2 + tall3 "],["vektorer.html", "1.3 Vektorer", " 1.3 Vektorer Vi introduserer begrepet vektorer som er svært viktig i statistikk generel og R spesielt. En vektor er ganske enkelt en samling med tall, og når vi senere begynner å jobbe med data kommer vi til å lagre observasjoner av ulikt slag i vektorer. Vi ser også at vi kan gjøre operasjoner på vektorer ved å bruke funksjoner. For eksempel bruker vi sum()-funksjonen til å regne ut summen av alle tallene som er lagret i en vektor. Oppgave: Beregn maksimum- og minimumsverdien av vector1, samt medianen, ved å bruke funksjoner i R. (Hint: en dårlig skjult hemmelighet i anvendt programmering er at dersom vi ikke vet navnet på funksjonen vi skal bruke, så er Google vår beste venn!) Løsning # Relevante Google-søk: &quot;minimum value r&quot;, &quot;maximum r&quot;, &quot;median r&quot; min(vector1) max(vector1) median(vector1) "],["pakker.html", "1.4 Pakker", " 1.4 Pakker Vi lærer at når vi laster ned R så følger det med et grunnleggende sett av funksjoner (base R), men at det finnes et stort antall tilleggspakker. Vi kan enkelt laste ned og installere disse pakkene ved å skrive kommandoen install.packages(\"pakkenavn\"). Det trenger vi bare gjøre en gang på datamaskinen vår. For å bruke pakken må vi skrive kommandoen library(pakkenavn), og det må vi gjøre hver gang i restarter R. Oppgave: Installer følgende pakker, som vi kommer til å bruke senere i kurset: ggplot2 dplyr stargazer Løsning install.packages(&quot;ggplot2&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;stargazer&quot;) "],["mappesti.html", "1.5 Mappesti", " 1.5 Mappesti Vi kommer til å forholde oss til filer på flere måter. Vi skal lese inn datafiler, og vi kommer til å produsere ulike former for output, slik som figurer og tabeller. Vi må da ha kontroll på hva R bruker som gjeldende mappesti (working directory) der filer som skal leses inn ligger, og der ulike output-filer havner. Vi kan bruke funksjonen getwd() til å sjekke hva som er gjeldende mappesti. For å forandre mappestien kan vi bruke menysystemet (Session -&gt; Set Working Directory -&gt; Choose Directory), eventuelt funksjonen setwd() med ønsket mappesti som argument. Oppgave: Pass på at du har gjort følgende før du går videre til neste leksjon: Du har laget en dedikert mappe på datamaskinen din der du skal samle alt materiale som vi bruker i dette kapitlet. Du har lastet ned filen testdata.xls og lagt den i den nye mappen din. Du har endret gjeldende mappesti til denne mappen. Du har bekreftet at gjeldende mappesti nå er korrekt. "],["innlesing-av-data.html", "1.6 Innlesing av data", " 1.6 Innlesing av data Vi leser inn tabellen i excelfilen som en tabell (data frame) i R ved hjelp av funksjonen read_xls() i readxl-pakken og ser på noen enkle kommandoer for å jobbe med en slik tabell. Oppgave: Hvor mange kolonner har datasettet vårt? Kan du finne en måte å skrive ut en vektor som inneholder summen av X1- og X2-kolonnene i datasettet? (Altså, vi vil vite summen av de to første elementene i X1 og X2, summen av de to andre elementene, osv.) Hva er summen av alle tallene i X1- og X2-kolonnene itestdata? Løsning # 1 ncol(testdata) # 2 testdata$X1 + testdata$X2 # 3 sum(testdata$X1 + testdata$X2) "],["statistiske-analyser.html", "1.7 Statistiske analyser", " 1.7 Statistiske analyser Den første kommentaren i denne videoen er selvsagt ikke sann for MET4. For oss er det motsatt: Det er ikke R som er poenget med kurset, men de statistiske metodene som vi skal lære. R er bare verktøyet vi skal bruke. Vi ser på et eksempel der vi kjører en enkel statistisk analyse (en \\(t\\)-test) på datasettet vårt, og hvordan vi kan gjøre ulike valg ved å endre argumenter i funksjonskallet. Vi bruker også hjelpefilene til å lese mer om funksjonen vi bruker. Oppgave: Hva er verdien av testobservatoren i testen som vi gjorde i denne videoen? Hint: Bruk hjelpefilene til t.test()-funksjonen. Løsning test_result$statistic "],["plotting.html", "1.8 Plotting", " 1.8 Plotting Vi lager vår første figur i R ved å bruke den innebygde plot()-funksjonen. Vi går så over til å se hvordan vi kan lage det samme plottet ved å bruke ggplot-pakken, som er det vi kommer til å bruke til å lage figurer i dette kurset. Vi ser også hvordan vi kan gå frem for å lagre plottet som en pdf-fil i arbeidsmappen vår. Oppgave: Klarer du, for eksempel ved å søke etter relevante ggplot-kommandoer på nettet, å få prikkene i plottet til å bli større, og samtidig gjøre dem blå? Løsning ggplot(testdata, aes(x = X1, y = X2)) + geom_point(colour = &quot;blue&quot;, size = 5) "],["script.html", "1.9 Script", " 1.9 Script I stedet for å skrive kommandoene rett inn i konsollen, hopper vi nå over til teksteditoren i RStudio og lager et script i stedet. Her kan vi samle alle kommandoene våre i en fil, som vi kan lagre og kjøre igjen senere. Vi ser også hvordan vi enkelt kan kjøre enkeltlinjer i scriptet vårt i R-konsollen ved hjelp av Ctrl-Enter (Command-Enter på Mac). Vi ser at vi kan skrive kommentarer i scriptene våre ved å bruke `#-tegnet, som kan være nyttig for å holde oversikten. Til slutt lagrer vi scripet i arbeidsmappen. Oppgave: Pass på at du nå har lagret scriptet som en .R-fil i mappen som vi laget for denne R-leksjonen. Lukk RStudio. Naviger så til denne mappen i filutforskeren og dobbelklikk på skriptet. Forhåpentligvis åpnes RStudio nå (Hvis ikke, eller hvis filen åpnes i det som heter R GUI, høyreklikker du på filen og velger Åpne i, og deretter RStudio. Du kan også gjerne sette RStudio som standarsprogram for .R-filer). Finn ut hva gjeldende arbeidsmappe nå er i RStudio. Hva skjedde nå? Hvorfor er dette nyttig? Løsning Når vi åpner RStudio ved å dobbeltklikke på skriptfilen, så blir arbeidsstien satt automastisk til mappen der skriptfilen ligger. Dette er veldig nyttig når vil kommer tilbake og skal jobbe videre med prosjektet vårt. "],["oppsummering-og-ekstra-oppgaver.html", "1.10 Oppsummering og ekstra oppgaver", " 1.10 Oppsummering og ekstra oppgaver I denne modulen har vi gått gjennom noen helt grunnleggende funksjoner i R. Du har lært at R er navner på et programmeringsspråk, RStudio er navnet på et program der vi kan skrive og kjøre R-kode, og identifisert fire forskjellige vindu i RStudio: konsollen (der R-koden kjøres), teksteditoren (der vi skriver script), samt to vinduer der vi kan se en oversikt over hva som er i dataminnet og få opp plott og figurer som vi lager. Videre har du kjørt noen enkle kommandoer, lagret tall og vektorer ved hjelp av variabelnavn, prøvd ut noen innebygde R-funksjoner for å regne ut f.eks. gjennomsnitt og standardavvik av tallvektorer, laget et spredningsplott, lært hva et working directory (arbeidsmappe) er, og installert R-pakker, f.eks readxl som vi brukte den til å lese inn et lite datasett i R. Til slutt har du kjørt en \\(t\\)-test, og skrevet et script (et lite program om du vil) der vi har lagret flere av kommandoene over i en tekstfil. Dersom du har fulgt modulen selv har du nå kanskje skrevet et lite script i tekstvinduet som ser ut omtrent som koden under. Når du har gjort alt riktig, skal du nå kunne kjøre gjennom disse kodelinjene uten feilmeldinger ved hjelp av Ctrl-Enter. Dette er helt grunnleggende (Spør om hjelp! Gi hjelp!). Har du problemer her, sørg for å få dem ordnet. Spør først en medstudent om hjelp, og deretter eventuelt studentassistent eller foreleser. Studenter som har god erfaring med data og/eller programmering, kan lære mye av å hjelpe medstudenter løse feilmeldinger. # Introduksjon til R # ------------------- # Laster inn nødvendige pakker library(readxl) library(ggplot2) # Laster inn datasettet testdata &lt;- read_xls(&quot;testdata.xls&quot;) # Gjør t-testen til spørsmål F i den første dataøvingen testresultat &lt;- t.test(testdata$X1, testdata$X2, var.equal = TRUE, alternative = &quot;two.sided&quot;) # Skriver ut resultatet av denne t-testen testresultat # Lager et plott av variabelen X1 mot X2 p &lt;- ggplot(testdata, aes(x = X1, y = X2)) + geom_point() # Lagrer plottet ggsave(&quot;testplot.pdf&quot;, plot = p) Lagre scriptet ditt. I RStudio velger du File -&gt; Save og trykker Ok dersom det kommer opp et vindu om character encoding e.l. Finn en fornuftig plassering (gjerne i samme mappe som øvelsesdatasettet) og gi filen et fornuftig navn. Standard filending for R-script er .R, men det er skjult for de fleste Windowsbrukere. Lukk RStudio. Du kan nå åpne skriptfilen i RStudio igjen. Enten ved å dobbeltklikke på den, eller ved å åpne RStudio, velge File -&gt; Open file, og så videre (dersom skriptet ikke allerede ligger åpnet). Du kan også åpne skriptfilen i en hvilken som helst notatbok (Notebook e.l.) og se at det er en helt standard, ren tekstfil. Hva er fordelen med å lagre en analyse som et skript versus å gjøre ting i et menydrevet grafisk grensesnitt? Løsning Når vi lagrer koden vår i et skript sørger vi for at hele analysen vår er lagret, ikke bare resultatene. Med andre ord, dersom du på et senere tidspunkt ønsker å komme tilbake til et analyseprosjekt og gjøre noen enkle forandringer, så er det fort gjort å gjøre det i skriptet, og så kjøre hele analysen på nytt. Dersom du i stedet hadde brukt et menydrevet system for å gjennomføre analysen (pek og klikk) kunne du risikere å måtte gjøre alt sammen på nytt (hvis du da husker hvordan du gjorde det), fordi du ikke like enkelt kan lagre hvert eneste museklikk. Vi skal nå pynte på plottet og gjøre det riktig pent. Det gjør vi ved å legge til nye linjer i ggplot-kommandoen. Erstatt den nest siste linjen i skriptet med kommandoen under, og se at du får en figur omtrent som den som følger under det igjen (vi bruker aksetitler i henhold til oppgavene i den første datalabben, der vi får vite at datasettet representerer kvalitet på kaffeavlingen før og etter en omlegging i produksjonsmetode): ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2) + xlab(&quot;Produksjonsmetode 1&quot;) + ylab(&quot;Produksjonsmetode 2&quot;) + theme_classic() Merk at vi pruker +-tegnet til å legge til flere lag med grafiske egenskaper til plottet. Hvert lag består av en funksjon, som ofte kan ta argumenter; f.eks. brukes funksjonen geom_point() til å lage prikker, og så kan vi f.eks. bruke argumentet size til å styre størrelsen på prikkene. Kan du finne ut hva hvert enkelt av disse lagene gjør? Hint: ta bort en linje av gangen, og se hva som skjer. Pass på at det er et pluss mellom hvert lag. Prøv å endre på noen av lagene eller legg til nye. For eksempel kan du lage en tittel ved å legge til funksjonen ggtitle() som et lag, og du kan endre aksetitlene. Prøv også å bruke argumentet shape i geom_point() til å bytte ut prikkene med en annen form. Det finnes flere andre tema i tillegg til theme_classic(), f.eks. theme_bw(), theme_dark(), etc. Forslag Prøv for eksempel dette: ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2, shape = 4) + ggtitle(&quot;Produksjonskvalitet&quot;) + xlab(&quot;Ny aksetittel&quot;) + ylab(&quot;Enda en aksetittel&quot;) + theme_light() Det følger med omfattende dokumentasjon med R. Du kan lese om alle R-funksjoner ved å skrive ? før funksjonsnavnet i konsollen. Prøv for eksempel å skrive ?mean i konsollen og trykk enter. "],["grunnleggende-statistikk.html", " 2 Grunnleggende statistikk", " 2 Grunnleggende statistikk I denne modulen introduserer vi en del grunnleggende statistiske begreper. Mye vil oppleves som repetisjon, mens noe vil være nytt. Noe er veldig praktisk ved at vi kan bruke det direkte i eksempler, mens andre ting er mer teoretisk av natur. Felles for det vi skal se på her er at vi kommer til å bruke mange av begrepene vi lærer senere i kurset. "],["deskriptiv-statistikk.html", "2.1 Deskriptiv statistikk", " 2.1 Deskriptiv statistikk 2.1.1 Videoforelesninger 2.1.2 Kommentarer Deskriptiv statistikk handler ikke om analyse eller regning, men om å presentere kompleks informasjon på en effektiv måte. Det er altså noe ganske annet enn det vi ellers snakker om i kurset, men det er likevel et av de nyttigste læringspunktet vi har. Hvem kan ikke regne med å måtte presentere tall og resultater i løpet av sin karriere? Eller selge inn forslag og planer for overordnede i håp om å bli lyttet til? Det kan være direkte avgjørende for din egen gjennomslagskraft at du er i stand til å produsere overbevisende tabeller og figurer i slike situasjoner, og det er det dette temaet handler om. I læreboken er det kapitlene 24 som behandler deskriptiv statistikk, men det er veldig Excel-fokusert, som ikke er så relevant for oss. Det er likevel ikke dumt å lese gjennom stoffet for å se hva det går i, og legg spesielt merke til følgende punkter: Ulike datatyper i avsnitt 2-1. 3-4: The art and science of graphical presentations. Hva er det som gjør en grafisk illustrasjon god? Prøv å ta inn over dere all informasjonen som vi lett kan lese ut av bildet på side 75 om Napoleons felttog mot Moskva. Her presenteres informasjon om tid, antall, geografi og temperatur på en helt eksepsjonelt effektiv måte! Videre er det noen grelle eksempler på hvordan vi kan bruke grafiske virkemidler til å gi skjeve fremstillinger. I videoforelesningen gir vi flere eksempler på dette. Kapittel 4 går litt mer i dypden om numeriske deskriptive teknikker, som gjennomsnitt, median, standardavvik, korrelasjon, osv. Dette skal være dekket greit i forelesningen, men boken går litt mer i dybden. Det kan være en fin øvelse å kikke på eksemplene i læreboken og forsøke å gjenskape noen av Excel-figurene i R. Se på eksempel 3.2, der man skal lage to histogrammer over historiske avkastninger for to ulike investeringsstrategier. Vi leser inn datasettet (last ned fra Canvas) som under og kikker på det: library(readxl) returns &lt;- read_xlsx(&quot;Xm03-02.xlsx&quot;) returns ## # A tibble: 50 x 2 ## `Return A` `Return B` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 30 30.3 ## 2 -2.13 -30.4 ## 3 4.3 -5.61 ## 4 25 29 ## 5 12.9 -26.0 ## 6 -20.2 0.46 ## 7 1.2 2.07 ## 8 -2.59 29.4 ## 9 33 11 ## 10 14.3 -25.9 ## # ... with 40 more rows Hver stategi har sin kolonne. Merk at variabelnavnene har mellomrom i seg, noe som er upraktisk når vi jobber med et seriøst programmeringsspråk. En god vane er å rett og slett gi dem nye navn, ved f.eks. å kjøre colnames(returns) &lt;- c(\"returnA\", \"returnB\"), eller så må vi alltid referere til variabelnavnene ved å bruke slike backticks som vi ser under. Vi kan lage to enkle histogrammer slik vi gjorde det i forelesningen: ggplot(returns, aes(x = `Return A`)) + geom_histogram(bins = 10) ggplot(returns, aes(x = `Return B`)) + geom_histogram(bins = 10) Figur 2.1: To histogrammer "],["utvalg-og-estimering.html", "2.2 Utvalg og estimering", " 2.2 Utvalg og estimering You can, for example, never foretell what any one man will do, but you can say with presicion what an average number will be up to. Individuals vary, but percentages remain constant. So says the statistician.  Sherlock Holmes 2.2.1 Videoforelesninger 2.2.2 Kommentarer I videoforelesningene over gikk vi gjennom noen sentrale begreper i statistikk. Noen av dem skal vi bruke mye i fortsettelsen, mens andre er ment for å gi dere et solid teoretisk fundament når vi etter hvert skal begi oss ut på anvendt statistikk. Vi startet med å sette opp en liten agenda. Som et første steg kan du kikke på, og notere ned noen setninger til, disse punktene og se om du har fått med deg hva de betyr: Samplingfordelinger Forventning/varians Sentralgrenseteoremet Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Forventningsrett Konsistens I Boken er det kapittel 9 (Sampling distributions) og 10 (Introduction to estimation) som gjelder. Kapittel 6-8 omhandler stoff skal skal være greit dekket i MET2 (Sannsynlighet, fordelinger, stokastiske variable, osv.), men det kan være nyttig å skumme gjennom likevel hvis disse begrepene ligger langt bak i bevissheten din. Kapittel 9 starter med å diskutere samplingfordelingen til et gjennomsnitt. Dette er nyttig lesestoff, men de viktigste punktene er som følger: Dersom observasjonene \\(X_1, X_2, \\ldots, X_n\\) er normalfordelt, er også gjennomsnittet \\(\\overline X = \\frac{1}{n}\\sum_{i=1}^n X_i\\) normalfordelt. Dersom E\\((X_i) = \\mu\\) og Var\\((X_i) = \\sigma^2\\) for alle \\(i = 1,\\ldots,n\\), er E\\((\\overline X)=\\mu\\) og Var\\((\\overline X) = \\sigma^2/n\\). Dette regnet vi ut formelt. Dersom \\(n\\) er stor, er \\(\\overline X\\) tilnærmet normalfordelt, uavhengig av fordelingen til den enkelte \\(X_i\\). Dette følger av sentralgrensesetningen. Dette står i en boks på slutten av seksjon 9-1a. Hvor stor må \\(n\\) være for at denne tilnærmingen er god nok? Det finnes ikke et entydig svar på, men når vi passerer 50-100 observasjoner kan vi i våre MET4-problemer gjerne si at \\(n\\) er «stor nok». I 9-1b og 9-1c brukes sentralgrenseteoremet til å regne på normalsannsynligheter i MET2-stil. I 9-1d er det noen Excel-instruksjoner som du kan hoppe over hvis du vil. Tekstboksen i 9-2c oppsummerer det vi fant ut om samplingfordelingen til en observert andel. I seksjon 9-3 snakkes det om samplingfordelingen til differansen av to gjennomsnitt. Vi gikk ikke gjennom det eksplisitt i forelesningen, men det er ikke noe substansielt nytt her. Vi skal bruke dette reultatet i neste modul når vi skal sammenligne to gjennomsnitt. I seksjon 9-4 får vi forklart hva vi skal bruke samplingfordelinger til fremover. Bør leses. Kapittel 10 omhandler estimering, dvs hvordan vi bruker data til å «gjette» på verdien til en ukjent parameter. Vi forsøkte i forelesningen å gi litt intuisjon til begrepene forventningsrett estimator, variansen til en estimator, og konsistens. Vi kan lage et punktestimat av en forventningsverdi ved å ta gjennomsnittet av observasjoner, og vi kan lage et konfidensintervall ved å følge oppskriften i boksen på s. 316 (i 11. utgave). I eksempel 10.1 har vi 25 observasjoner fra en normalfordeling. Oppgaven er å estimere forventningsverdien med et tilhørende 95% konfidensuntervall. Pass på at du forstår den manuelle utregningen. I stedet for å bruke Excel (eller taste alle disse tallene inn på en kalkulator) kan du skrive et lite R-script som gjør det samme: # Vi skriver inn datasettet i en vektor demand &lt;- c(235, 374, 309, 499, 253, 421, 361, 514, 462, 369, 394, 439, 348, 344, 330, 261, 374, 302, 466, 535, 386, 316, 296, 332, 334) # Vi trenger 4 verdier for å regne ut konfidensintervallet: gj.snitt &lt;- mean(demand) # Regner ut gjennomsnittet z &lt;- 1.96 # Denne finner vi i tabellen sigma &lt;- 75 # Oppgitt i oppgaven n &lt;- length(demand) # Antall observasjoner # Vårt estimat av forventningsverdien er bare gjennomsnittet. # Regner ut nedre og øvre grense i konfidensintervallet (LCL, UCL): LCL &lt;- gj.snitt - z*sigma/sqrt(n) UCL &lt;- gj.snitt + z*sigma/sqrt(n) # Samler de tre tallene i en vektor og skriver ut: c(LCL, gj.snitt, UCL) ## [1] 340.76 370.16 399.56 I seksjon 10-2a forsøker boken å forklare fortolkningen av et konfidensintervall. Hovedpoengene her er at: Et 95%-konfidensintervall skal ikke tolkes som «sannsynligheten for at intervallet inneholder den sanne parameterverdien er 95%». Den korrekte tolkningen er: «Dersom vi hadde hatt tilgang til å trekke nye utvalg fra populasjonen med like mange observasjoner og bruker dem til å regne ut nye konfidensintervaller, vil 95 av 100 intervaller inneholde den sanne parameterverdien». Forskjellen på disse formuleringene er meget subtil, så subtil faktisk at det ikke er åpenbart at det er særlig god pedagogikk å peke på den. Problemet med den første formuleringen er at vi der kan få inntrykk av at det er den sanne parameterverdien som er stokastisk og avhengig av datasettet vi observerer, mens det strengt tatt er grensene til konfidensintervallet som er tilfeldige, og altså avhengige av datasettet. Det kommer klarere frem i den andre formuleringen. Bredden til et konfidensintervall er altså et uttrykk for usikkerhet, eller motsatt: presisjon. Seksjon 10-2b og 10-2c kan skummes raskt gjennom. Seksjon 10-3 handler om at vi først bestemmer oss for et presisjonsnivå (dvs bredde på konfiensintervallet) \\(B\\), og så regner ut hvor mange observasjoner vi trenger for å oppnå det. Vi kommer frem til en formelen \\[n = \\left(\\frac{z_{\\alpha/2}\\sigma}{B}\\right)^2,\\] men problemet i praksis er at vi gjerne ikke kjenner \\(\\sigma\\), og vi kan heller ikke estimere den fordi vi ikke har samlet inn data enda. Løsningen er at vi enten på bruke fornuften, eller eventuelt et tidligere estimat av \\(\\sigma\\) dersom det er tilgjengelig. 2.2.3 Ekstra øving i R Som demonstrert i forelesningen kan vi i R simulere standard normalfordelte observasjoner (dvs normalfordelte observasjoner med \\(\\mu = 0\\) og \\(\\sigma^2 = 1\\)) med kommandoen rnorm(n), der n er antallet observasjoner vi ønsker. For eksempel kan vi kjøre følgende kode for å generere 10 observasjoner (du vil helt sikkert få andre verdier): n &lt;- 10 rnorm(n) ## [1] 0.21909384 -0.45988189 -0.09266996 0.18129486 0.09588651 -0.75620686 ## [7] -0.36389698 -1.00674695 3.47520374 0.86717631 Ved å skrive mean(dnorm(n)) i stedet regner vi ut gjennomsnittet av observasjonene direkte. La oss gjøre dette 100 ganger og notere ned gjennomsnittet hver gang. I stedet for å gjøre det manuelt, kan vi skrive et lite program som gjør dette for oss ved å bruke en for-løkke. Det er ikke nødvendig (eller pendum) å forstå akkurat hvordan dette fungerer, men dersom du kjører følgende linjer vil du få en ny vektor gj.snitt som inneholder 100 slike gjennomsnitt: gj.snitt &lt;- rep(NA, 100) for(i in 1:100) { gj.snitt[i] &lt;- mean(rnorm(n)) } Skriv ut denne vektoren og kontroller at det ser korrekt ut. Vi husker at funksjonen sd() regner ut standardavviket til en vektor. Hvilket tall forventer du å få ut dersom du nå kjører sd(gj.snitt) i konsollen? Stemmer det? Hint Standardavviket til de enkelte observasjonene er \\(\\sigma = 1\\), og standardavviket til et gjennomsnitt bestående av 10 observasjoner er \\(\\sigma/\\sqrt{n} = 1/\\sqrt{10} \\approx 0.32\\). Med andre ord skal det empiriske standardavviket sd(gj.snitt) være omtrent lik 0.32, pluss/minus en estimeringsfeil. Du kan gjerne regne ut 1000 gjennomsnitt i stedet for 100 ved å erstatte erstatte 100 med 1000 på to steder i koden over. Stemmer det bedre da? Hint gj.snitt &lt;- rep(NA, 1000) # Lager en tom vektor med 1000 plasser for(i in 1:1000) { # Fyller hver plass med et gjennomsnitt av gj.snitt[i] &lt;- mean(rnorm(n)) # 10 standard normalfordelte observasjoner. } Prøv å forklare. Svar Dette er ganske enkelt, men også litt vanskelig på en inception-aktig måte. På samme måte som at gjennomsnittet blir en mer og mer presis estimator for forventningsverdien når vi øker antall observasjoner (målt ved at standardavviket \\(\\sigma/\\sqrt{n}\\) blir mindre når antall obserasjoner \\(n\\) blir større), blir det empiriske standardavviket en mer og mer presis estimator av det sanne standardavviket når vi øker antall observasjoner. Altså; det empiriske standardavviket har også et standardavvik som går mot null som \\(1/\\sqrt{n}\\)  "],["spørsmål-og-oppgaver.html", "2.3 Spørsmål og oppgaver", " 2.3 Spørsmål og oppgaver Kontrollspørsmål Hva er forskjellen på deskriptiv statistikk og statistisk inferens? Deskriptiv statistikk kan gjøres grafisk eller numerisk, eventuelt som tabeller av ulike numeriske mål. Nevn noen fordeler og ulemper man må veie mot hverandre når vi skal velge mellom grafisk og numerisk deskriptiv statistikk. Hva er en samplingfordeling? Hva sier sentralgrenseteoremet? Hva mener en statistiker når hen sier at gjennomsnittet konvergerer som \\(1/\\sqrt{n}\\)? Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Hva vil det si at et estimator er forventningsrett? Hva vil det si at et estimator er konsistent? Drilleoppgaver Ting fra boken, eventuelt litt bearbeidet. Skal vi også lage til løsning her? Oppgaver på (ca) eksamensnivå (EKS) = Først og fremst relevant for skoleeksamen. (HEKS) = Først og fremst relevant for hjemmeeksamen. Finne frem oppgaver fra gamle skoleeksamenssett. Noen av datasettene fra hjemmeeksamen; mange av førsteoppgavene har vært av typen Beskriv relevante deler av datasettet. Stargazer for summarytabeller. Summarise fra dplyr? "],["hypotesetesting.html", " 3 Hypotesetesting", " 3 Hypotesetesting Hypotesetesting er et klassisk tema i statistikk. Vi skal først lære generelt om hva det egentlig vil si å teste en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting ikke er. Vi går så videre til å lære noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R. "],["generelt-om-hypotesetesting.html", "3.1 Generelt om hypotesetesting", " 3.1 Generelt om hypotesetesting 3.1.1 Videoforelesninger 3.1.2 Kommentarer Her snakker vi om kapittel 11 i læreboken. Hvis du kan svare på følgende spørsmål har du i all hovedsak fått med deg de viktigste begrepene: Hva vil det si å gjennomføre en hypotesetest? Hva er Type I-feil og hva er Type II-feil? (Seksjon 11-1 forklarer dette greit) Hva er signifikansnivået (\\(\\alpha\\)) til en test? Styrken (the power) til en test er definert som \\(1-P(\\textrm{Type II-feil})=1-\\beta\\). Hvordan tolker du denne størrelsen? Se også 11-3d. Hva er \\(p\\)-verdien til en test (Seksjon 11-2c)? Les også 11-2d, e og f om hvordan vi fortolker og snakker om \\(p\\)-verdien på en korrekt måte. Vi kommer tilbake til dette i kapittel 3.2. "],["chap-enpop.html", "3.2 Inferens om en populasjon", " 3.2 Inferens om en populasjon 3.2.1 Videoforelesninger 3.2.2 Kommentarer Dette er i hovedsak dekket av kapittel 12 i læreboken. Sjekk om du kan svare på følgende kontrollspørsmål: Hva er det vi tester når vi gjennomfører en \\(t\\)-test for én populasjon? Hva forutsetter vi? Hva er forskjellen på en ensidig og en tosidig test? (11-2j) Det kan også være greit å repetere konfidensintervaller i seksjon 11-2k for de som har glemt det fra MET2. I Seksjon 11-2g går boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gjøre det samme i R. På kursets nettside finner du alle datasettene som følger med læreboken. I dette eksempelet er det snakk om Xm11-01.xlsx. Finn tak i denne filen (du kan også godt åpne den og se på den i Excel!), legg den i en mappe som du kan finne igjen, og åpne et nytt script i R-studio der du først sørger for å sette working directory til denne mappen slik vi gjorde i R-forelesningen. Etterpå leser du inn datasettet ved å bruke read_xslx()-funksjonen som under: library(readxl) data &lt;- read_xlsx(&quot;Xm11-01.xlsx&quot;) # Vi bruker read_xslx() fordi det er en .xlsx-fil Konteksten til datasettet er gitt i eksempel 11.1. Det er altså balansen på 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer på om forventet balanse er større enn 170. Vi setter opp følgende test: \\[\\begin{align*} &amp;H_0: \\mu = 170 \\\\ &amp;H_A: \\mu &gt; 170, \\end{align*}\\] der vi legger merke til at det blir brukt en ensidig test (hvorfor?). For å regne ut testobservatoren for å enutvalgs \\(z\\)-test trenger vi fire tall: \\(\\overline X\\), \\(\\mu_0\\), \\(n\\) og \\(\\sigma\\). Legger merke til at data har en kolonne som heter Accounts, og vi bruker dollartegnet til å hente den ut som en vektor. Regner ut observatoren: gj.snitt &lt;- mean(data$Accounts) # Gjennomsnittet av observasjonene mu0 &lt;- 170 # Henter fra teksten n &lt;- length(data$Accounts) # Antall observasjoner sigma &lt;- 65 # Henter fra teksten Z &lt;- (gj.snitt - mu0)/(sigma/sqrt(n)) # Verdien av testobservatoren Z # Skriver ut testobservatoren ## [1] 2.460462 Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R: qnorm(0.95) ## [1] 1.644854 Uansett; vi forkaster \\(H_0\\) siden testobservatoren er større enn kritisk verdi. Kapittel 11-3a-d gir enda mer forståelse for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre. Kapittel 12 presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du først og fremst må kunne fra dette kapitlet er å gjennomføre disse testene, både for hånd med penn og papir, og i R. Under følger kode for å gjøre noen av bokens eksempler i R (les i boken for kontekst): Eksempel 12.1: \\[\\begin{align*} &amp;H_0: \\mu = 2.0 \\\\ &amp;H_A: \\mu &gt; 2.0, \\end{align*}\\] data &lt;- read_xlsx(&quot;Xm12-01.xlsx&quot;) # Manuell utregning gj.snitt &lt;- mean(data$Newspaper) mu0 &lt;- 2.0 n &lt;- length(data$Newspaper) s &lt;- sd(data$Newspaper) # Testobservator: (gj.snitt - mu0)/(s/sqrt(n)) ## [1] 2.236869 Signifikansnivået er satt til \\(\\alpha = 1\\%\\) i eksempelet. Kritisk verdi finner vi i \\(t\\)-tabell eller rett fra R: qt(0.99, df = n-1) ## [1] 2.351983 Altså forkaster vi ikke nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som står i boken. Alternativt bruker vi t.test()-funksjonen direkte: t.test(data$Newspaper, alternative = &quot;greater&quot;, mu = 2.0, conf.level = 0.99) ## ## One Sample t-test ## ## data: data$Newspaper ## t = 2.2369, df = 147, p-value = 0.0134 ## alternative hypothesis: true mean is greater than 2 ## 99 percent confidence interval: ## 1.990716 Inf ## sample estimates: ## mean of x ## 2.180405 Resultatet blir selvsagt det samme. Når \\(p\\)-verdien er større enn signifikansnivået på 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om å lage kondidensintervall, noe du også kan prøve å gjøre ved å regne ut de nødvendige tallene i R. De som synes dette er greit kan kikke på seksjonene 12-1b-e for å utvikle forståelsen enda litt mer. Eksempel 12.3: \\[\\begin{align*} &amp;H_0: \\sigma^2 = 1.0 \\\\ &amp;H_A: \\sigma^2 &lt; 1.0. \\end{align*}\\] Testobservator: \\[\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2}.\\] data &lt;- read_xlsx(&quot;Xm12-03.xlsx&quot;) # Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis: (length(data$Fills) - 1)*var(data$Fills)/1 # Kritisk verdi, 5% nivå, ensidig test, nedre hale: qchisq(0.05, df = length(data$Fills) - 1) ## [1] 15.2 ## [1] 13.84843 Vi kan altså ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for å forstå bedre hva som skjer. Figur 12.4 viser på en fin måte hva tallene betyr. Eksempel 12.5 kan være grei å kikke på også. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste: \\[\\begin{align*} &amp;H_0: p = 0.5 \\\\ &amp;H_A: p &gt; 0.5. \\end{align*}\\] Vi har en observert andel på \\(\\widehat p = 407/765 = 0.532\\) etter å ha spurt \\(n = 765\\) personer. Testobservatoren er \\[Z = \\frac{\\widehat p - p}{\\sqrt{p(1-p)/n}}.\\] p.hatt &lt;- 407/765 p0 &lt;- 0.5 n &lt;- 765 (p.hatt - p0)/sqrt(p0*(1-p0)/n) ## [1] 1.771599 Kritisk verdi for en ensidig z-test på 5% nivå er 1.645 (qnorm(0.95)), og vi kan forkaste nullhypotesen. Seksjonene 12-3d-f bør leses på egen hånd, mens vi hopper over 12-3g. "],["inferens-om-to-populasjoner.html", "3.3 Inferens om to populasjoner", " 3.3 Inferens om to populasjoner 3.3.1 Videoforelesninger 3.3.2 Kommentarer Vi har gått gjennom kapittel 13, som i all hovedsak handler om å sammenligne to gjennomsnitt (som vi kan gjøre på tre forskjellige måter), to varianser og to andeler. Her følger noen kontrollspørsmål som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper: Hva er nullhypotesen når vi skal gjennomføre en t-test for to populasjoner?  og hvilke antagelser må vi gjøre? Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør? Når kan vi bruke matchede par, og hva er hensikten? Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen? Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør? Hvilken test brukes for å teste om to andeler er like, og hva må du anta? Videre bør du sjekke at du kan utføre 3 typer \\(t\\)-tester, test for like varianser og test for like andeler både for hånd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber). Den enkleste måten å gjøre \\(t\\)-tester i R på er å bruke funksjonen t.test(). Kikk på eksempel 13.1 i lærebokens 11. utgave, der vi har observert årlige avkastninger til to aksjefond som er kjøpt henholdsvis med og uten megler. # Leser inn datasettet funds &lt;- read_xlsx(&quot;Xm13-01.xlsx&quot;) # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = FALSE, conf.level = 0.95) ## ## Welch Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 97.489, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.79661 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Du kan så sjekke at du får ut de samme tallene på s. 434435. Videre kan du skrive inn ?t.test i R-konsollen i RStudio for å lese mer om hvilke argumenter vi kan bruke i t.test()-funksjonen. Der ser vi at argumentene paired, var.equal og conf.level som utgangspunkt allerede er satt til FALSE, FALSE og 0.95 henholdsvis, så det hadde vi strengt tatt ikke trengt å spesifisere i funksjonskallet over. Vi kan enkelt kjøre den samme testen under antakelsen om like varianser ved å sette var.equal = TRUE: # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = TRUE, conf.level = 0.95) ## ## Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 98, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.7967156 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Resultatet bli akkurat det samme. Siden testens \\(p\\)-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og slå fast at forskjellen i gjennomsnitt er statistisk signifikant. I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner i de to populasjonene, så vi kan tenke oss at målingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om gjennomsittet av differansene er signifikant forskjellig fra null. Enkelt: # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = TRUE, conf.level = 0.95) ## ## Paired t-test ## ## data: funds$Direct and funds$Broker ## t = 2.5178, df = 49, p-value = 0.007563 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.9716497 Inf ## sample estimates: ## mean of the differences ## 2.908 Da ser vi at \\(p\\)-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du prøve selv. Pass på at du kan gjøre beregningene manuelt også, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forstår hva som foregår. Kapittel 13-2 omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig å sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen vår av statistiske resultater. Det er et eksplisitt krav for å lykkes i MET4 at du er i stand til å sette resultatene inn i en fornuftig kontekst. I kapittel 13-4 kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R: bottle &lt;- read_xlsx(&quot;Xm13-07.xlsx&quot;) var.test(bottle$`Machine 1`, bottle$`Machine 2`, alternative = &quot;greater&quot;) ## ## F test to compare two variances ## ## data: bottle$`Machine 1` and bottle$`Machine 2` ## F = 1.3988, num df = 24, denom df = 24, p-value = 0.2085 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 0.7051295 Inf ## sample estimates: ## ratio of variances ## 1.398807 Også her kan du sammenligne med tallene som fremgår av bokens gjennomgang, og sørg for at du får til dette på egen hånd, spesielt det å finne frem i tabellen, for det må du kunne på eksamen. Til slutt har vi test for to andeler i kapittel 13-5. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er like (\\(p_1 - p_2 = 0\\)), som er det vi har dett på i forelesning, men det går selvsagt like fint å sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall \\(D\\). Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved å regne ut testobservatoren fra datasettet. Vi ser på eksempel 13.9, der vi får oppgitt salget av en del forskjellige varenummer, og vi ønsker å finne ut om andelen «9077» er større i Supermarked 1 enn i Supermarked 2: # Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg # velger å lese inn de to kolonnene hver for seg: soap1 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;A&quot;)) soap2 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;B&quot;)) # Hvor stor andel utgjør «9077» i de to kolonnene? p1 &lt;- mean(soap1 == 9077) p2 &lt;- mean(soap2 == 9077) # De to utvalgsstørrelsene: n1 &lt;- nrow(soap1) n2 &lt;- nrow(soap2) # Felles estimat for p under nullhypotesen: p &lt;- (n1*p1 + n2*p2)/(n1 + n2) # Testobservatoren: z &lt;- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2)) # Kritisk verdi på 5% nivå for en ensidig test: qnorm(0.95) ## [1] 1.644854 Siden \\(z = 2.9\\) forkaster vi nullhypotesen om at det er lik andel «9077» i de to populasjonene. "],["kjikvadrattester.html", "3.4 Kjikvadrattester", " 3.4 Kjikvadrattester 3.4.1 Videoforelesninger 3.4.2 Kommentarer Vi må kunne to anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken: Teste for om en gitt fordeling passer med obervasjoner (Goodness-of-fit). Teste for uavhengighet. I den første anvendelsen får vi oppgitt en diskret sannsynlighetsfordeling der vi har noen mulige utfall \\(u_1, \\ldots, u_k\\), med tilhørende sannsynligheter \\(p_1, \\ldots,p_k\\). Dersom vi skal observere \\(n\\) utfall fra denne fordelingen, vil vi forvente \\(e_i = p_i\\cdot n\\) observasjoner av utfall \\(u_i\\). Nå har det seg slik at vi har observert \\(n\\) utfall fra fordelingen, og utfall \\(u_i\\) har skjedd \\(f_i\\) ganger. Vi lurer da på om de observerte frekvensene (\\(f_i\\)) er så forskjellige fra de forventede frekvensene (\\(e_i\\)) at vi ikke lenger tror at \\(p_1, \\ldots,p_k\\) er den sanne sannsynlighetsfordelingen. Vi kom frem til en fornuftig testobservator: \\[\\chi^2 = \\sum_{i=1}^k \\frac{(f_i - e_i)^2}{e_i},\\] som er \\(\\chi^2\\)-fordelt med \\(k-1\\) frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan gå inn i \\(\\chi^2\\)-tabellen for å sjekke om verdien av testobservatoren er for stor (dvs, \\(f\\)´ene er for forskjellige fra \\(e\\)`ene) at vi ikke lenger tror at \\((p_1, \\ldots, p_k)\\) er den sanne sannsynlighetsfordelingen. Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte følgende kommandoer: p0 &lt;- c(0.45, 0.40, 0.15) # Fordeling under H0 f &lt;- c(102, 82, 16) # Observerte frekvenser chisq.test(x = f, p = p0) ## ## Chi-squared test for given probabilities ## ## data: f ## X-squared = 8.1833, df = 2, p-value = 0.01671 Den andre anvendelsen er å teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for «\\(A\\) og \\(B\\)» som et produkt dersom de ar uavhengige: \\[P(A \\cap B) = P(A)\\cdot P(B).\\] Vi kan regne ut hvor mange observasjoner vi forventer å se for hver kombinasjon av de to kjennetegnene (\\(e_{ij}\\)), og bruke kjikvadrattesten over til å sjekke om disse er langt fra det vi faktisk har observert (\\(f_{ij}\\)). Boken har et eksempel på dette som de regner ut både for hånd og i Excel. Slik kan vi gjøre det i R: # Leser inn data mba &lt;- read_xlsx(&quot;Xm15-02.xlsx&quot;) # Kikker på datasettet mba ## # A tibble: 152 x 2 ## Degree `MBA Major` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 2 2 ## 6 1 3 ## 7 3 1 ## 8 1 1 ## 9 2 1 ## 10 2 2 ## # ... with 142 more rows Vi legger merke til at strukturen på datasettet er litt annerledes enn krysstabellen som er vist s. 601 i læreboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av «bachelorgrad» og «masterprofil», har vi fått oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R: table(mba) ## MBA Major ## Degree 1 2 3 ## 1 31 13 16 ## 2 8 16 7 ## 3 12 10 17 ## 4 10 5 7 Det er denne som brukes som argument i chisq.test(): chisq.test(table(mba)) ## ## Pearson&#39;s Chi-squared test ## ## data: table(mba) ## X-squared = 14.702, df = 6, p-value = 0.02271 Her er det bare å sammenligne tallene med det som læreboken finner i Excel. Noen kontrollspørsmål: Vi har lært to veldig spesifikke anvendelser av kjikvadrattester. Hvilke? Kan du gi en intuitiv forklaring på hvorfor testobservatoren vår er fornuftig? Litt mer vanskelig: Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tilnærmet kjikvadratfordelt? "],["regresjon.html", " 4 Regresjon", " 4 Regresjon "],["avansert-regresjon-og-maskinlæring.html", " 5 Avansert regresjon og maskinlæring", " 5 Avansert regresjon og maskinlæring "],["tidsrekker.html", " 6 Tidsrekker", " 6 Tidsrekker "],["dataøvinger.html", " 7 Dataøvinger", " 7 Dataøvinger Blabla intro til øvinger "],["dataøving-1.html", "7.1 Dataøving 1", " 7.1 Dataøving 1 7.1.1 Innledning Velkommen til den første dataøvelsen i MET4. I denne øvelsen skal vi bli litt kjent med verktøyene R og Rstudio som brukes i datalabbene. Disse verktøyene er også essensielle for gjennomføringen av den obligatoriske innleveringen og på hjemmeksamen. Den første delen av øvingen inneholder praktisk informasjon om bruk av R og Rstudio etterfølgt av oppgaver. 7.1.2 Om R og Rstudio R er et program/programmeringsspråk som er spesialdesignet til å utføre statistiske analyser. R er basert på at du må skrive forskjellige kommandoer for å utføre utregninger og analyser. Gjennomsnittet av 3, 2 og 5 finner man for eksempel ved å skrive: mean(c(3,2,5)) Dette kan for mange være litt uvant i starten, men datalabbene vil gi deg god trening på denne type tankegang. Rstudio er et program som gjør det enklere å bruke R. På samme måte som Word kan hjelpe deg til å lage fine og oversiktlige tekster, kan Rstudio hjelpe deg til å utføre fine og oversiktlige statistiske analyser. Rstudio er et redigeringsprogram som vi i dette kurset skal bruke til å redigere og utføre R-kommandoer. 7.1.2.1 Installere R og Rstudio Bruker du din egen datamaskin kan du enkelt laste ned og installere R og Rstudio. Begge programvarene er gratis og kan installeres med å følge instruksene under. Får du problemer kan du få en av studentassistentene til å hjelpe deg. Start med å installere R: Gå til r-project.org Last ned versjonen som passer ditt operativsystem (Windows/Mac/Linux) Kjør installasjonsfilen og følg instruksene. Standard innstillingene skal være greie å bruke, så du kan trykke neste/ok til installasjonen er ferdig. Installer så RStudio: rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (Open source edition) for ditt operativsystem og installere på vanlig måte. Kjør installasjonsfilen som lastes ned og følg instruksene 7.1.2.2 Vinduene i Rstudio og det å jobbe med R Første gang du åpner Rstudio vil du se tre vinduer. Et fjerde vindu åpner du med å klikke på File i menyen, så New File, og så R Script. Figur 7.1 viser en oversikt over de fire vinduene. Det er viktig at du forstår forskjellen på de to vinduene til venstre. Figur 7.1: Oversikt over vinduene i RStudio. Nederste vindu til venstre (b) viser R-konsollen og det er her alle utregninger blir gjennomført. I dette vinduet kan du for eksempel skrive (3*5 - 3/4)*(2 + 2) ## [1] 57 Her er \\((3*5 - 3/4)*(2 + 2)\\) en såkalt kommando og det er programmet R som finner ut hva du mener med kommandoen og gir deg svaret \\(57\\) i retur. Du kan se at R tillater standard matteoperasjoner som gange, deling, pluss og minus (*, /, +, -). R er det vi kaller objektbasert, som betyr at du kan definere objekter. Utregningen over kan for eksempel også regnes ut ved å skrive: a &lt;- 3*5 - 3/4 b &lt;- 2 + 2 a*b ## [1] 57 Her er a og b objekter som vi definerer ved bruk av tildelingspilen &lt;- (du kan også bruke =). Det går an å lagre objekter i egne filer, men vi skal se at det stort sett er smartere å lagre oppskriften (selve koden) på hvordan de lages i en egen .R fil. Det øverste vinduet til venstre (a) viser en .R fil (et skript). En .R fil fungerer som et manuskript med R-kommandoer (kode) og kan lagres slik at du kan senere kan se hvilke kommandoer du har brukt i analysen og eventuelt fortsette der du slapp. I Del 2 av denne dataøvingen skal du selv lage en .R fil som inneholder alle kommandoer som brukes i en enkel analyse. Når du vil at R skal utføre noen av kommandoene du har skrevet i .R filen markerer du bare disse (eller lar pekeren stå i linjen du vil kjøre) og trykker ctrl + Enter (Cmd + Enter på Mac): Figur 7.2: Utførelse av kommandoer du har skrevet i R filen. Marker eller la pekeren stå i linjen du vil kjøre og trykk ctrl + Enter (Cmd + Enter på Mac) Vinduet nederst til høyre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet øverst til høyre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en nærmere titt på et datasett du har lest inn. Vinduet nederst til høyre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet øverst til høyre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en nærmere titt på et datasett du har lest inn. Det er viktig at du forstår forskjellen på de to vinduene til venstre, altså .R filen og konsollen. R kode du ønsker å ta vare på og som er en essensiell del av analysen skriver og lagrer du i .R filen, mens små eksperimenter og undersøkelser kan du gjerne gjøre direkte i konsollen. For de av dere som er glad i hurtigtaster finnes det en oversikt i Rstudio som kommer opp dersom du trykker Alt + Shift + K (Option + Shift + K på Mac). Ofte vil man f.eks måtte skifte musepeker fra R-filen til konsoll og motsatt, og hurtigtaster for å veksle mellom disse er Ctrl + 1 (R-fil) og Ctrl + 2 (konsoll). Hurtigtasten du kommer til å bruke desidert mest er ctrl + Enter for å kjøre kode fra R-skriptet ditt i konsollen (På Mac erstatter du ctrl med command over alt). 7.1.2.3 Funksjoner, dokumentasjon og R-pakker I R kan man lage egne funksjoner som utfører det en måtte ønske, f.eks en funksjon som regner ut t-observatoren gitt en vektor med observasjoner x og en gitt \\(\\mu_0\\): t.observator &lt;- function(x, mu0){ t &lt;- (mean(x) - mu0)/(sd(x)/sqrt(length(x))) return(t) } R kommer med en rekke innebygde funksjoner som kan utføre ulike statistiske analyser. For eksempel kan en t-test utføres med å bruke en funksjon som heter nettopp t.test. Alle slike funksjoner kommer med en dokumentasjon som viser hva funksjonen gjør og hvordan den skal brukes. For å tilgang til denne dokumentasjonen skriver man ? foran funksjonen i konsollen. Skriver du f.eks ?t.test ser du at det dukker opp en side i vinduet nede til høyre: Figur 7.3: Dokumentasjon av funksjoner dukker opp i et vindu nede til høyre. Dette vinduet kan åpnes til et større vindu som vist over Dokumentasjonen vil som hovedregel inneholder en kort beskrivelse av hva funksjonen gjør, hvilke argumenter funksjonen tar og hva den gir ut. Helt i slutten av dokumentasjonen er det ofte et eksempel på hvordan funksjonen kan brukes og er ofte svært nyttig å se på. Selv om det finnes mange funksjoner som allerede er innebygget i R, må man noen ganger installere ekstra pakker for å få tilgang til spesielle funksjoner. I oppgave 2.2 i denne øvelsen vil vi gå gjennom hvordan dette gjøres for en bestemt pakke. 7.1.2.4 Skriv pen R-kode! Det er viktig at R-koden du skriver er veldokumentert og skrevet på en oversiktlig og pen måte. Hvis vi ønsker å skrive kommentarer til koder som står i .R filen bruker vi tegnet # foran kommentaren. Dette gjør at R ikke prøver å evaluere kommentaren som en R-kode. Det finnes en rekke konvensjoner når det kommer til mellomrom, linjeskift, navngivning av objekter og lignende. Vi anbefaler tipsene som er oppsummert på (http://adv-r.had.co.nz/Style.html)[http://adv-r.had.co.nz/Style.html], men det er selvsagt lov å ha sine egne preferanser. Under ser du et eksempel på dårlig praksis ved R-koding. Her er det manglende dokumentasjon, dårlig navngivning og ingen luft i form av mellomrom og linjeskift. Dette gjør at du eller andre vil måtte bruke unødvendig tid på å finne ut hva koden faktisk gjør på et senere tidspunkt. # Dårlig praksis: library(readxl) library(tidyverse) d&lt;-readxl(file=&quot;financedata.xlsx&quot;,sheetIndex = 1) %&gt;% na.omit() Ø95&lt;-mean(d$value)-qt(0.975,df=length(d$value)-1)*sd(d$value) N95&lt;-mean(d$value)+qt(0.975,df=length(d$value)-1)*sd(d$value) Følgende R kode gir det samme resultatet men er mye mer oversiktlig siden den er mer luftig, er brutt ned i biter, er godt dokumentert og har fornuftige objektnavn: # God praksis: # ---------- Analyse av data # Nødvendige pakker i analysen library(readxl) library(tidyverse) # Les data, fjern NA-verdier og hent ut gjeld my_data &lt;- readxl(file = &quot;financedata.xlsx&quot;, sheetIndex = 1) %&gt;% na.omit() debt &lt;- my_data$debt # Konfidensintervall n_obs &lt;- length(debt) # antall observasjoner alpha &lt;- 0.05 # signifikansnivå average &lt;- mean(debt) # gjennomsnitt st_dev &lt;- sd(debt) # standardavvik lower &lt;- average - qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # nedre grense upper &lt;- average + qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # øvre grense Vi oppfordrer deg til å prøve å skrive R-kode som er pen og oversiktlig i datalabbene fremover. Dårlige vaner kan være vonde å vende! 7.1.3 Oppgaver til øvingen 7.1.3.1 Oppgave 1: Interaktiv øvelse Her skal du bruke et læringsverktøy kalt swirl som vil ta deg gjennom en interaktive øvelse hvor du må utføre forskjellige oppgaver i konsollen. I flere av dataøvingene vil det være en slik interaktiv del. Her er tanken at du skal leke deg litt med R. Før du kan begynne må du installere swirl. Kopier derfor følgende tre linjer og lim dem inn i R-konsollen: install.packages(&quot;swirl&quot;) library(swirl) install_course(&quot;R Programming&quot;) For å starte swirl skriver du så følgende i konsollen: swirl() Du vil i starten bli bedt om å skrive inn ditt navn og så følger litt info om hvordan swirl fungerer. Du blir så bedt om å velge kurs. Her skal du velge alternativet R Programming (1 og så enter). Du får så se alle modulene dette kurset inneholder: I denne øvingen skal du prøve deg på modul 1 Basic Building Blocks, modul 4 Vectors (kun første halvdel), og modul 12 Looking at Data. I modul 1 vil du lære litt om de mest grunnleggende operasjonene som kan gjøres i R. Modul 4 ser nærmere på vektorer og her er første halvdel av modulen mest relevant. Modul 12 tar for seg det å utforske strukturen på et datasett. Start med modul 1 (1 og så enter). Du vil bli bedt om å gjøre enkle operasjoner i R og av og til må du svare på multiple choice spørsmål: Merk at det helt til høyre vil står hvor langt du har kommet i prosent. Står du helt fast med et punkt kan du skrive skip() for å hoppe over dette punktet. Når du har fullført en modul blir du spurt om du vil motta credit for å ha fullført modulen. Her kan du svare nei. Ønsker du å avbryte underveis skriver du bye(). Skriver du inn det samme navnet når du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk å avslutt swirl (esc) før du begynner på del to av øvingen. Lykke til! 7.1.3.2 Oppgave 2: Innlesning av data og deskriptiv statistikk i R I denne oppgaven skal vi lese inn noen data og produsere enkel deskriptiv statistikk av disse dataene. Dataene kommer fra et amerikansk forsøk hvor man ville undersøke påstanden om at voldelige dataspill fører til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det voldelige dataspillet var oppdraget å skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spilleøkt ble deltakernes aggresjonsnivå målt på en skala fra 1 til 9 ved hjelp av en standard psykologisk test. Dette datasettet ble brukt i eksamensoppgaven vårsemesteret 2019. Oppgave 2.1 Last ned filen violence.xslx. Denne filen lagrer du fortrinnsvis i en egen mappe der du ønsker at filer fra denne øvingen skal ligge. Åpne så RStudio, velg File -&gt; New File -&gt; R Script for å åpne et nytt Rscript. Lagre så scriptet ditt i samme mappen som du har lagt datasettet, slik at du nå har en mappe som ser ut som figuren under: Når vi skal lese inn data, lagre figurer og andre ting har R en standard mappesti (working directory) den leter/lagrer i. Du kan se hva denne stien peker på ved å skrive i konsollen. Du skal nå spesifisere denne mappestien til mappen du har opprettet. Dette gjør du raskest ved å velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du åpne RStudio ved å dobbeltklikke på dataøving1.R, og mappestien skal da settes automatisk til riktig mappe. Lag gjerne en liten overskrift ved hjelp av kommentartegnet # slik at .R filen din ser omtrent slik ut: Oppgave 2.2 Du skal nå lese inn excel filen du lagret i over i R. Selv om det finnes mange funksjoner som allerede er innebygget i R, må man noen ganger installere ekstra pakker for å få tilgang til spesielle funksjoner. For å lese inn en excel fil trenger du nettopp en slik ikke standard funksjon. Denne finnes i pakken readxl. Selve installeringen kan du gjøre direkte i konsollen med å skrive (hvis du ikke har gjort det allerede): install.packages(&quot;readxl&quot;) Pakken legger seg da i en bibliotekmappe der R er installert. For å gi R beskjed om å laste inn funksjonene til pakken du nettopp installerte bruker du funksjonen library. Du har nå tilgang til en funksjon kalt read_excel() som du kan bruke til å lese inn excel filen: # MET4 - Dataøving 1 # ------------------ # les inn data library(readxl) violence &lt;- read_excel(&quot;violence.xlsx&quot;) Marker linjene du nettopp skrev i R-skriptet ditt og trykk ctrl + enter (cmd + enter), for å opprette objektet violence som inneholder datasettet. Funksjonen ls lister opp alle objekter som har blitt definert. Du kan prøve selv å skrive følgende i konsollen: ls() ## [1] &quot;violence&quot; Du ser at det har kommet et nytt objekt som heter violence. En tilsvarende oversikt finner du i vinduet øverst til høyre i Rstudio (se Figur 7.1) hvor du også kan klikke på objektet for å se nærmere på det. Oppgave 2.3 Ta en titt på strukturen til datasettet du nettopp leste inn. Husker du kanskje noe fra den interaktive øvelsen Looking at Data? Når du gjør slike små utforskninger kan du gjerne jobbe direkte i konsollen, og det du gjør i dette punktet trenger nødvendigvis ikke være med i .R-filen din. Gå til konsollen og bruk funksjoner som class, dim, names, head og str for å utforske strukturen på dataene. Vi ser at det er 5 variabler: id er bare et tall som identifiserer forsøkspersonen. aggression_level er aggresjonsnivået som ble målt rett etter at forsøkspersonen hadde spilt en viss tid. violent_treatment er varianten av dataspillet som forsøkspersonen ble utsatt for; enten Violent eller Less Violent. difficulty_treatment er vanskelighetsgraden av spillet, som enten var Easy eller Hard. En mulig forklaring på aggressiv adferd er at vanskelige spill fører til høyere stressnivå, som igjen kan føre til aggressivitet. experienced_violence er svaret til forsøkspersonen på spørsmålet om vedkommende oppfattet spillet som Violent eller Less Violent. Forsøkspersonene visste ikke selv hva forssøket gikk ut på, eller at det var flere varianter av det samme spillet. Oppgave 2.4 Vi skal se nærmere på om aggresjonsnivået er forskjellig i de to gruppene. Da må vi trekke ut de aktuelle tallene fra datasettet. Vi ønsker å velge ut to vektorer for å gjøre denne sammenligningen: en vektor som inneholder aggresjonsnivået til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsnivået til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene få navn voldelig og ikke_voldelig, og lag dem ved å skrive følgende kodelinjer: # Vektorer med aggresjonsnivå til gruppen som har spilt voldelig/ikke-voldelig spill voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] ikke_voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Less Violent&quot;] Sjekk nå at dette har fungert ved å skrive voldelig og ikke_voldelig inn i konsollen for å se at det faktisk er vektorer som inneholder tallene 1  9. Bruk også noen minutter til å prøve å forstå hva kodelinjene over faktisk gjør. Her er noen punkter som kan hjelpe til med å obdusere den første linjen: violence$aggression_level henter ut kolonnen aggression_level fra datasettet violence. Vi kan bruke firkantparantes [ ] til å hente ut spesifikke elementer fra en vektor. Her skal vi hente ut bestemte elementer fra vektoren violence$aggression_level, og vi kan for eksempel skrive violence$aggression_level[1], violence$aggression_level[1:10] eller violence$aggression_level[c(1, 5)] for å hente ut henholdsvis det første, de ti første, eller det første og det femte tallet i vektoren. (Prøv!) Vi skal hente ut noen helt bestemte tall fra violence$aggression, nemlig de målingene som tilhører testpersonene som har violent_treatment lik \"Violent\". Alle disse kan vi finne ved å skrive inn violence$violent_treatment == \"Violent\". Prøv det. Du vil da få ut en vektor fylt med enten TRUE eller FALSE, alt etter om den tilhørende forsøkspersonen har violent_treatment lik Violent eller ikke. Denne vektoren kan vi bruke til å hente ut tall som svarer til TRUE fra violence$aggression_level ved å putte den i firkantparanteser. Det er det som står til høyre for tilordningen &lt;-. Til slutt lagrer vi resultatet i vektoren voldelig. (NB! Pass på at du skriver Violent og Less Violent helt riktig med store og små bokstaver, ellers vil det ikke fungere!) Oppgave 2.5 I eksamensoppgaven fra 2019 får vi oppgitt deskriptiv statistikk over aggresjonsnivået for de to gruppene i følgende tabell: Bruk funksjoner som min(), max(), median(), mean(), length() og summary() til å finne ut om tallene stemmer. Hvordan kan det ha seg at tallene ikke er identiske? Oppgave 2.6 Vi skal nå lage et histogram av hver av gruppene du lagret som vektorer i tidligere, og vi skal gjøre det på to måter: Først skal vi bruke plottefunksjonene som følger med R (Base R). Så skal vi gjøre det samme ved hjelp av ggplot-pakken. Vi skal først bruke funksjonen hist() som altså følger med R-installasjonen din. De fleste R-funksjoner har flere argumenter slik de kan utføre forskjellige operasjoner. Om vi for eksempel ønsker at histogrammet skal vise andel og ikke frekvens, må vi angi dette i ett av argumentene. For å ta en titt på hvilke argument hist() har å tilby skriver ?hist i konsollen. Det vil da poppe opp en dokumentasjonside i vinduet nede til høyre. Skroll ned å les om argumentet freq. Hva skal du erstatte spørsmålstegnene under med for at histogrammene skal vise andel? # Skalert Histogram, vi velger breaks = 9 fordi det er 9 mulige utfall: 1 -- 9. hist(voldelig, freq = ?, breaks = 9, main = &quot;Voldelig&quot;) hist(ikke_voldelig, freq = ?, breaks = 9, main = &quot;Ikke-voldelig&quot;) De fullførte linjene over skal være med i .R-filen din. For å se histogrammene kan du kjøre kommandoene en etter en i konsoll med å trykke ctrl + enter. Figurene dukker da opp i vinduet nede til høyre. Du kan også prøve å eksperimentere med argumentet breaks. La oss så forsøke å gjenta denne operasjonen ved å bruke ggplot-pakken. Vi kan først kikke på Figur 2.1 og koden som lagde disse figurene for å få en idé om hva vi må gjøre. Et svært viktig punkt er føgende: ggplot-funksjonen skal alltid ha hele datasettet (en data frame) som argument!! Det betyr at vi ikke skal bruke de to vektorene voldelig og ikke_voldelig, slik som i hist()-funksjonen, men bruke hele datasettet violence. Vi ser av oversikten over at variabelen som inneholder aggresjonsnivået er aggression_level, så det er den vi skal bruke som \\(x\\)-argument. Ved å ta utganspunkt i koden som lagde Figur 2.1, kan vi gjøre et første forsøk (der vi husker å laste inn ggplot2-pakken først): library(ggplot2) ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) Nesten! Det eneste problemet er at vi har ett histogram for alle observasjonene, mens det vi egebntlig ønsket var å lage et histogram for hver av gruppene. Dette er såre enkelt i ggplot2. Det eneste vi trenger å gjøre er å identifisere den variabelen i datasettet som angir gruppetilhørighet (sjekk variabeloversikten over, svaret er experienced_violence), og så plusse på en funksjon som heter facet_wrap() som vist under. ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) + facet_wrap(~ experienced_violence) Dersom vi i stedet ønsker et skalert histogram kan vi spesifisere y-argumentet på følgende vis: ggplot(violence, aes(x = aggression_level, y = ..density.. )) + geom_histogram(bins = 9) + facet_wrap(~ experienced_violence) Oppgave 2.7 Når man skal sammenligne sentrum og spredning i to grupper er et boxplott et ypperlig alternativ og vi kan da bruke funksjonen boxplot() i base R, eller funksjonen geom_boxplot() hvis vi heller ønsker å benytte ggplot2. Vi holder oss til det siste alternativet her, og ser at kodelinjene ligner på det vi laget over. Dersom vi ønsker å lage et enkelt boxplot av en variabel for å sammenligne spredingen i to eller flere grupper kan vi skrive ggplot(a, aes(x = b, y = c)) + geom_boxplot() Her må du selv erstatte bokstavene a, b og c i henhold til følgende regel: a er navnet på datasettet. b er variabelen som inneholder gruppeinndelingen. c er variabelen som inneholder målingene. De ferdige kodelinjene skal være med i .R-skriptet ditt. For å se boxplottet kan du som vanlig kjøre kommandoene med å trykke ctrl + enter. Ser det ut til å være noe forskjell på sentrum og spredning i de to gruppene? Bonusoppgave Bytt ut geom_boxplot() over med geom_jitter() og geom_violin(). Hva viser disse plottene? "],["dataøving-2.html", "7.2 Dataøving 2", " 7.2 Dataøving 2 7.2.1 Interaktiv øvelse Før vi tar fatt på dataanalysen begynner vi med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(\"swirl\") i konsoll hvis ikke) starter du opp swirl med å skrive følgende i konsollen: library(swirl) swirl() Du vil i starten bli bedt om å skrive inn ditt navn. Hvis du bruker samme navn som tidligere får du kanskje tilbud om å starte opp igjen der du slapp, men da kan du bare velge det nederste valget No. Let me start something new. Du velger så alternativet R Programming hvor du får se alle modulene dette kurset inneholder. I denne øvingen skal du prøve deg på modul 6 Subsetting Vectors og modul 8 Logic. Husk at det helt til høyre vil står hvor langt du har kommet i prosent. Står du helt fast med et punkt kan du skrive skip() for å hoppe over dette punktet. Når du har fullført en modul blir du spurt om du vil motta credit for å ha fullført modulen. Her kan du svare nei. Ønsker du å avbryte underveis skriver du bye(). Skriver du inn det samme navnet når du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk å avslutt swirl () før du begynner på neste del av datalabben. Lykke til! 7.2.2 Data til dataøvelsen I denne dataøvelsen skal vi ved hjelp av R gjennomføre en del av testene som vi har lært i praksis. Vi skal gjøre både ett- og to-utvalgs tester, og vi skal bruke \\(\\chi^2\\)-testen Vi skal jobbe med tre ulike datasett i denne øvingen, og alle sammen kan lastes ned ved å klikke på lenkene under: testdata.xls violence.xlsx roubik_2002_coffee_yield.xlsx Last ned disse filene og legg dem i en mappe på datamaskinen din. Åpne så RStudio, velg File -&gt; New File -&gt; R Script for å åpne et nytt Rscript, og lag gjerne en liten overskrift ved hjelp av kommentartegnet #. Lagre så scriptet ditt i samme mappen som du har lagt datasettene, slik at du nå har en mappe som ser ut som figuren under: Det neste du må gjøre er å sørge for at du har satt opp riktig mappesti (working directory) i RStudio, og det gjør du raskest ved å velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du åpne RStudio ved å dobbeltklikke på dataøving2.R, og mappestien skal da settes automatisk til riktig mappe. I alle tilfeller skal vinduet ditt se omtrent slik ut: 7.2.3 Oppgaver til øvingen: 7.2.3.1 Oppgave 1 Costa Rica er en stor kaffeprodusent med moderne produksjon. Kaffeprodusentene har over lengre tid benyttet en standardisert miks av sprøytemidler som skal ta knekken på ugress og skadelige insekter, men uten å skade avlingen eller miljøet ellers. En liten kaffeplantasje i Costa Rica har begynt å eksperimentere med en ny kombinasjon av sprøytemidler som skal være like effektiv mot ugress, men samtidig enda mer skånsom mot kaffeplantene, slik at avlingen blir større. Innehaveren av plantasjen ønsker å sette opp et eksperiment for å undersøke denne påstanden. Han velger ut 25 tilfeldige jordlapper fordelt på hele eiendommen der han bruker de nye sprøytemidlene gjennom en hel sesong. Lang erfaring har vist at avlingen ved bruk av gammel metode er normalfordelt med forventning \\(\\mu = 100\\) og varians \\(\\sigma^2 = 10\\), der vi har brukt en standardisert enhet for mengde avling per arealenhet. Hjelp bonden, ved å løse følgende oppgaver: Oppgave 1.1: Les inn datasettet testdatasdata.xsl i RStudio og se på de første par radene. Det kan du gjøre ved å kjøre følgende kodelinjer: library(readxl) # Pakke for å lese excel-filer data &lt;- read_excel(&quot;testdata.xls&quot;) # Leser inn datasettet data # Ser på datasettet ## # A tibble: 25 x 4 ## X1 X2 A1 A2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 122. 121. 1 1 ## 2 101. 105 1 1 ## 3 114. 108 1 1 ## 4 103 99.1 1 0 ## 5 97.6 96.2 0 0 ## 6 85.9 95.4 0 0 ## 7 93.5 101. 0 1 ## 8 92 97 0 0 ## 9 98.8 106. 0 1 ## 10 99.9 100. 0 1 ## # ... with 15 more rows Det er kolonnen X2 som inneholder de observerte avlingene på de 25 forsøksseksjonene. Oppgave 1.2: Er forventet avling ved bruk av den nye metoden større enn forventet avling ved bruk av den gamle metoden? Hint: Forelesningsnotatene/scriptet inneholder koden du trenger for å løse denne og neste oppgave. Oppgave 1.3: Det er viktig for kaffebonden at avlingen ikke varierer for mye mellom de ulike delene av farmen. En viktig måleparameter for denne type produksjon er derfor variansen. Kan vi slå fast at variansen til avlingen har forandret seg etter omlegging til ny metode? Oppgave 1.4: Kaffebonden er skeptisk til påstanden om at forventet avling med den gamle metoden er \\(\\mu = 100\\), og mener at det vil variere med for eksempel jordsmonn. For å ta høyde for dette gjennomførte han året i forveien tilsvarende målinger på de samme jordlappene, med med gammel sprøytemetode. Disse målingene finner du i kolonne X1 i datasettet. Test om avlingene er forskjellige, både med og uten paring av observasjonene. Kommenter resultatet. 7.2.3.2 Oppgave 2 Vi skal i denne oppgaven se på oppgave 1a og 1b som ble gitt på skoleeksamen i MET4 vårsemesteret 2019. Dette er det samme datasettet som vi så på i forrige dataøving. I et amerikansk forsøk ville man undersøke påstanden om at voldelige dataspill fører til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det voldelige dataspillet var oppdraget å skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spilleøkt ble deltakernes aggresjonsnivå målt på en skala fra 1 til 9 ved hjelp av en standard psykologisk test. I denne oppgaven skal vi i hovedsak finne ut om gruppen som spilte de voldelige dataspillet hadde signifikant høyere aggresjonsnivå enn kontrollgruppen. Oppgave 2.1: Les inn datasettet violence.xslx på samme måte som over. Hvis du allerede har kjørt library(readxl) trenger du ikke gjøre det igjen med mindre du har startet RStudio på nytt. Gi datasettet et passende navn, f.eks violence &lt;- read_excel(&quot;violence.xlsx&quot;) Vi skal altså teste om aggresjonsnivået er forskjellig i de to gruppene. Da må vi trekke ut de aktuelle tallene fra datasettet. Som vi husker fra forelesningsnotatene trenger vi to vektorer for å gjøre en to-utvags \\(t\\)-test: en vektor som inneholder aggresjonsnivået til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsnivået til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene få navn voldelig og ikke_voldelig, og lag dem ved å skrive følgende kodelinjer: voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] ikke_voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Less Violent&quot;] For en forklaring på disse kodelinjene, se Dataøving 1. Oppgave 2.2: Vi er nå klare til å gjøre en to-utvalgs \\(t\\)-test for om aggresjonsnivået er det samme i de to gruppene. Prøv å gjøre det nå, men vær bevisst på hvilke valg du gjør underveis, og som du mater inn i t.test()-funksjonen, f.eks: Antar du lik varians i de to gruppene? Hvorfor/Hvorfor ikke? Bruker du ensidig eller tosidig test? Hvorfor? Oppgave 2.3: En avgjørende detalj i studien som vi ser på i denne oppgaven er at forskerne også spurte forsøkspersonene hvorvidt de selv syntes spillet de spilte var voldelig. For å kunne trekke noen som helst lærdom fra et slikt forsøk er det viktig at den voldelige spillvarianten faktisk blir oppfattet som voldelig og vice versa. Vi ønsker dermed å undersøke nullhypotesen om at variablene violence_tratment og experienced_violence er uavhengige av hverandre. Den hypotesen er vi nødt til å forkaste for at forsøket skal være gyldig: hvis det ikke er noen sammenheng mellom opplevd og faktisk voldelighet er forsøket helt klart ugyldig. Første steg er å lage et nytt datasett der vi bare ta med oss de to kolonnene vi er interessert i. Kall det hva du vil, f.eks. violence_redusert: violence_redusert &lt;- violence[c(&quot;violent_treatment&quot;, &quot;experienced_violence&quot;)] Vi fortsetter som i videoforelesningen og lager en krysstabell for disse variablene krysstabell &lt;- table(violence_redusert) krysstabell ## experienced_violence ## violent_treatment Less Violent Violent ## Less Violent 114 9 ## Violent 33 93 Oppgave 2.4: Heldigvis ser det ut til at det er en klar sammenheng mellom faktisk og opplevd voldelighet ved at de fleste forsøkspersonene havner på diagonalen i krysstabellen. Bruk funksjonen chisq.test() på samme måte som i forelesningen til å teste nullhypotesen om uavhengighet formelt. 7.2.3.3 Oppgave 3 Vi skal i denne oppgaven returnere til kaffeproduksjon. Vi skal gjøre statistiske tester i R som i de tidligere oppgavene i denne øvingen, men vanskelighetsgraden går opp fordi vi også må tenke nøye over hvordan vi anvender metodene korrekt i en gitt kontekst. I 2002 publiserte det prestisjetunge tidsskriftet Nature en kort artikkel skrevet av David W. Roubik1, som handler om den kjente kaffebønnen Arabica. Arabicabønnen kommer opprinnelig fra Afrika, og er en selvpollinerende plante. Det vil si at den ikke er avhengig av insekter for å formere seg, og man trodde lenge at den heller ikke hadde noen fordeler av insektspollinering. For å undersøke denne påstanden samlet Roubik inn historiske data over arabicaavlinger fra hele verden. Han delte verdens kaffeproduserende land inn i to kategorier: Old world som omfatter afrikanske og asiatiske land, og New world som omfatter land i Latin-Amerika. Han registrerte videre gjennomsnittlig årlig avling (målt i kg/hektar) i to perioder: 196180 og 19812001. Nøkkelen til analysen er at den afrikanske honningbien var en viktig pollinator i Afrika og Asia både i den første og andre perioden, men knapt eksisterte i Amerika før 1980. Etter 1980, derimot, økte utbredelsen av denne bien i Amerika, og ble fort naturalisert. Kan vi sette denne utviklingen i sammenheng med økt kaffeavling i Latin-Amerika etter 1980, og dermed skrote teorien om at kaffeplanter ikke drar nytte av insektspollinering? Oppgave 3.1: For å undersøke dette kan vi bruke datasettet som Roubik brukte, som finnes i filen roubik_2002_coffe_yield.xlsx. Last datasettet inn i R på vanlig måte, og se på det: yield &lt;- read_excel(&quot;roubik_2002_coffe_yield.xlsx&quot;) yield ## # A tibble: 28 x 4 ## world country yield_61_to_80 yield_81_to_01 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 new Costa_Rica 9139 14620 ## 2 new Bolivia 7686 8767 ## 3 new El_Salvador 9996 8729 ## 4 new Guatemala 5488 8231 ## 5 new Colombia 5920 7740 ## 6 new Honduras 4096 7264 ## 7 new Nicaragua 4566 6408 ## 8 new Brazil 4965 6283 ## 9 new Peru 5487 5740 ## 10 new Mexico 5227 5116 ## # ... with 18 more rows Vi ser at det er fire kolonner i datasettet: world angir om det er snakk om New world (new) eller Old world (old). country angir navnet på landet. yield_61_to_80 angir avlingen i perioden 196180. yield_81_to_01 angir avlingen i perioden 19812001. Oppgave 3.2: Kall den første tidsperioden p1 og den andre tidsperioden p2. Lag så fire vektorer, en for hver kombinasjon av world og tidsperiode ved å bruke samme teknikk som i oppgave 2.2 over. Når du er ferdig, skal du ha laget følgende vektorer: new_p1: inneholder avling for alle land med world == new i første periode. new_p2: inneholder avling for alle land med world == new i andre periode. old_p1: inneholder avling for alle land med world == old i første periode. old_p2: inneholder avling for alle land med world == old i andre periode. Dersom du har gjort det riktig, ser vektorene slik ut når du er ferdig: new_p1 ## [1] 9139 7686 9996 5488 5920 4096 4566 4965 5487 5227 2347 3089 1938 new_p2 ## [1] 14620 8767 8729 8231 7740 7264 6408 6283 5740 5116 4124 3240 ## [13] 2789 old_p1 ## [1] 4251 10522 3509 10028 5667 17064 5904 4001 6604 4738 5716 3824 ## [13] 3525 3393 3213 old_p2 ## [1] 13380 11561 9652 9593 8797 7869 7354 7288 6055 5432 5394 3576 ## [13] 3141 2391 2136 Oppgave 3.3: Bruk en paret \\(t\\)-test til å finne ut om kaffeavlingen i den gamle verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.4: Bruk en paret \\(t\\)-test til å finne ut om kaffeavlingen i den nye verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.5 (Diskusjonsopgave): Dersom du har gjort de to foregående oppgavene riktig vil du se at den gjennomsnittlige kaffeavlingen ikke har endret seg signifikant i den gamle verden, mens økningen i den nye verden er klart statistisk signifikant. Vi har brukt parrede \\(t\\)-tester, slik at vi kontrollerer for eventuelle landeffekter (denne terminologien blir skal vi bruke mer når vi skal jobbe med regresjon). Roubik omtaler funnet som følger: A substantial increase in Latin American coffee yield partly coincided with the establishment of African honeybees in those countries, although there was no such change in the Old World, where honeybees originated []. This comparison underlines a possible cause-and-effect relationship between the presence of social bees and cofee yield. Dette er intet mindre enn en kortslutning, på minst to forskjellige måter. Hvorfor? Diskuter med dine medstudenter. Kan det gjennomføres en enkel test som gir et bedre bilde av situasjonen? 7.2.4 BONUS: En alternativ teknikk for datamanipulering (Gjør bare om du har overskudd til det!) Se på denne kodelinjen: voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] Vi skrev denne linjen for å hente ut noen bestemte verdier fra et bestemt datasett. Det er kanskje ikke så lett å se hva kodelinjen gjør ved å bare kaste et raskt blikk på den, og det er spesielt to grunner til det: den er lang, og du må lese den delvis innenfra og ut (alstå, begynne innerst i parantesene) og delvis fra høyre mot venstre. Spesielt det siste punktet er kontraintuitivt, siden det er motsatt av slik vi vanligvis leser. Mye arbeid i R går ut på å manipulere datasett på ulike vis (hente ut kolonner og rader, lage nye kolonner), og derfor er det utviklet noen alternative verktøy for å gjøre slike jobber mye mer effektivt. Vi vil i dette avsnittet gi en kort og meget grunleggende innføring i slike teknikker. Merk at dette ikke er pensum i klassisk forstand. Det viktigste er at jobben blir gjort korrekt. Hvordan du gjør det er i så måte underordnet. For å gjennomføre øvelsen under må du installere og laste inn en ny pakke: dplyr: install.packages(&quot;dplyr&quot;) library(dplyr) KONSEPT 1: Pipe-operatoren %&gt;% Tenk deg at vi skal regne ut logaritmen til kvadratroten av 2. Vi må da anvende to funksjoner i riktig rekkefølge. Vi kan alltids bruke en mellomregning: kvadratroten_til_2 &lt;- sqrt(2) log(kvadratroten_til_2) ## [1] 0.3465736 Eventuelt kjører vi alt sammen i en linje: log(sqrt(2)) ## [1] 0.3465736 Nå er ikke den siste linjen spesielt lang, men den er som sagt ikke helt intuitiv. Grunnen er at hvis vi skal lese høyt hva den gjør, så må vi begynne innerst i parantesene: Vi starter med tallet 2, så tar vi kvadratroten, så tar vi logaritmen I dplyr-pakken finnes en såkalt pipe-operator som gjør at vi kan skrive dette som kode i den rekkefølgen ting skal skje. Eksempelet over skrives slik: 2 %&gt;% sqrt %&gt;% log ## [1] 0.3465736 Det som skjer er at R leser linjen fra venstre, og ved hver pipe/%&gt;% sendes det som står på venstre side inn som argument i funksjonen på høyre side. Når du leser kode, kan denne operatoren uttales som så (then på engelsk): Først har vi tallet 2, så tar vi kvadratroten, så tar vi logaritmen. Tenk når vi har en sekvens av 10 eller 20 eller 50 steg (ikke uvanlig i den virkelige verden), hvor mye enklere det blir å kode på denne måten fremfor å ha 10, 20 eller 50 nivå med paranteser! Tips: Hurtigtasten for %&gt;% i RStudio er Ctrl - Shift - M (Bytt ut Ctrl med Cmd på Mac). KONSEPT 2: Datamanipuleringsfunksjoner i dplyr I dplyr finnes det noen meget praktiske funksjoner som vi kan bruke til å manipulere datasatt i R. La oss ta utgangspunkt i datasettet violence og prøve å skrive om den aktuell kodelinjen over ved hjelp av pipe-operatoren. I klartekst skal vi gjøre følgende operasjoner: Starte med datasettet violence Plukke ut alle radene som har verdi \"Violent\" i kolonnen violent_treatment. Plukke ut kolonnen aggression_level For å velge ut bestemte rader kan vi bruke funksjonen filter(). Ved hjelp av pipe-operatoren kan vi skrive steg 1 og 2 som violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) ## # A tibble: 126 x 5 ## id aggression_level violent_treatment difficulty_treatm~ experienced_viol~ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 4 Violent Easy Less Violent ## 2 2 5 Violent Hard Violent ## 3 5 2 Violent Easy Violent ## 4 6 9 Violent Hard Less Violent ## 5 10 4 Violent Hard Violent ## 6 18 4 Violent Hard Violent ## 7 21 4 Violent Easy Violent ## 8 22 9 Violent Hard Less Violent ## 9 25 7 Violent Easy Violent ## 10 26 1 Violent Hard Less Violent ## # ... with 116 more rows Nå ser vi at vi bare har 126 rader igjen, og det er nettopp de radene som i kolonnen violent_treatment har verdi \"Violent\". Det neste steget er å velge ut kolonnen aggression_level. Det gjør vi ved å bruke funksjonen select(), og hele sekvensen ser da slik ut (linjeskift gjør det enda mer lesbart): violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) ## # A tibble: 126 x 1 ## aggression_level ## &lt;dbl&gt; ## 1 4 ## 2 5 ## 3 2 ## 4 9 ## 5 4 ## 6 4 ## 7 4 ## 8 9 ## 9 7 ## 10 1 ## # ... with 116 more rows Man kan velge flere kolonner ved å sette komma mellom kolonnenavn, og man kan i stedet velge bort kolonner ved å sette minustegn foran kolonnenavnet, f.eks: violence %&gt;% select(id, aggression_level) violence %&gt;% select(-id) Nå har det seg slik at vi gjerne ønsker å hente ut den aktuelle kolonnen som en vektor. Det gjør vi enkelt ved å slenge på en pull på slutten av en pipe-sekvens. Til slutt må vi passe på å lagre vektoren med riktig navn, slik at vi får: voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull Denne koden er ekvivalent med den som startet dette avsnittet i øvingen. Den er derimot mye enklere å lese, og veldig mye enklere å utvide til å inkludere flere operasjoner. La oss se på enda en funksjon som vil være svært nyttig for oss senere. Vi kan bruke mutate() til å lage nye kolonner. La oss for eksempel si at vi vil lagre kvadratet av aggression_level eller summen av aggression_level og id som egne kolonner (som selvsagt er helt meningsløst i dette tilfellet, kun et eksempel). Det kan vi gjøre slik: violence %&gt;% mutate(ny1 = aggression_level^2) eller violence %&gt;% mutate(ny2 = id + aggression_level) Her er ny1 og ny2 navn på de nye kolonnene, som vi kan velge selv. Oppgave: Gjenta Oppgave 3.2, men ved å bruke teknikkene i dette avsnittet. Interaktiv øving i dplyr Hvis du ønsker å trene mer på dette så finnes det en interaktiv modul i swirl som omhandler datamanipulasjon ved hjelp av dplyr. Hvis du ikke har gjort det alledede, skriv install.packages(\"swirl\") i konsoll. Start du opp swirl med å skrive følgende: library(swirl) install_course(&quot;Getting_and_Cleaning_Data &quot;) # legger til nytt kursmateriale swirl() Du vil i starten bli bedt om å skrive inn ditt navn og så følger litt info om hvordan swirl fungerer. Du blir så bedt om å velge kurs. Her skal du først velge alternativet Getting and Cleaning Data. Du får så se alle modulene dette kurset inneholder. I denne øvingen skal du prøve deg på modul 1 Manipulating Data with dplyr. David W. Roubik: The value of bees to the coffee harvest. Nature (2002) "]]
