[["index.html", "MET4 - Empiriske Metoder - V√•r 2023 Innledning", " MET4 - Empiriske Metoder - V√•r 2023 H√•kon Otneim og Geir Drage Berentsen Innledning H√•kon Velkommen til hjemmesiden for kurset MET4 - Empiriske metoder, som er et obligatorisk kurs p√• Bachelorprogrammet i √òkonomi og Administrasjon ved Norges Handelsh√∏yskole. Dette er et kurs i anvendt statistikk, spesielt tilpasset √∏konomistudiet, og vi skal fokusere p√• korrekt bruk av statistisk metodikk for √• l√∏se relevante problemstillinger i en verden der innsamlet data utgj√∏r en stadig st√∏rre del av beslutningsgrunlaget i bedrifts- og samfunnsstyring. Kursansvarlige er H√•kon Otneim og Geir Drage Berentsen, som begge jobber ved Institutt for Foretaks√∏konomi ved NHH. Geir P√• denne siden vil du finne alle videosnuttene med kommentarer til l√¶rebokens fremstilling, regneoppgaver, samt supplementer og referanser til andre b√∏ker der l√¶reverket v√•rt ikke strekker til (s√¶rlig mot slutten av kurset). Fremdriftsplan Vi har laget et forslag til progresjon i tabellen under. Kolonnen ‚Äújobbe med‚Äù refererer til tema p√• denne siden som dere finner igjen i menyen til venstre. I hovedsak bruker vi to uker p√• hvert tema i kurset og aktivitetene i disse ukene er i all hovedsag strukturert som f√∏lger: Uke 1: Selvstudie av det respektive temaet ved hjelp av videoer, regneoppgaver og teori p√• denne nettsiden. Vi tar derfor en dag uten noen organisert aktivitet, og s√• tar vi en dag i 2. etasje p√• biblioteket der dere kan jobbe sammen i grupper med regneoppgaver. Vi passer p√• at alle har noen √• jobbe med, s√• du m√• gjerne komme selv om du ikke har noen spesifikke som du har planlagt √• sitte med. Regneoppgavene finner du under hvert tema til venstre. Foreleser vil v√¶re tilgjengelig. Uke 2: Vi gir en oversiktsforelesning i temaet og tar et seminar med mer utfordrende oppgaver i fellesskap, begge deler i Aud A (se Avsnitt 8 for seminaroppgavene). Ingen av de fysiske aktivitetene vil bli tatt opp eller streamet. Videoene og teorien p√• denne nettsiden er et mer en godt nok digitalt tilbud. Notatene fra oversiktsforelesningene og oppgaveseminar (Se 8) vil bli lagt ut p√• Canvas. Selv om det n√• legges opp til et fleksibelt undervisningsopplegg der tempo og progresjon til dels kan tilpasses den enkeltes timeplan og studieteknikk, er det viktig √• jobbe jevnt med kurset. MET4 er et krevende kurs som krever full innsats fra f√∏rste til siste dag. For eksempel f√•r en mye bedre utbytte av av de fysiske aktivitetene dersom man p√• forh√•nd har sett videoene og gjort noen av regneoppgavene relatert til temaet. Praktisk bruk av statistiske metoder st√•r sentralt i MET4, og denne delen dekker vi gjenom data√∏vinger med studentassistenter. I kalenderen under har vi markert ukene der vi har tid p√• datasal med studentassistenter med gr√∏nn farge. Du finner oppgaver til data√∏vingene i menyen til venstre. Legg merke til f√∏lgende viktige datoer: 30. januar: Siste frist for oppmelding av grupper til obligatorisk √∏velse og hjemmeeksamen. 10. mars: Frist for innlevering av den obligatoriske innleveringen. 24.‚Äì26. april: Gruppebasert hjemmeeksamen. 8. mai: Individuell hjemmeeksamen. Uke Jobbe med Mandag 12:15 - 14:00 Onsdag 10:15 - 12:00 2 Introduksjon til R 09.01: Introduksjon til MET4 i Aud A 11.01: Introduksjon til R i Aud A 3 Grunnleggende statistikk 16.01: Regnegrupper i 2. etg bibliotek 18.01: Oppgaveseminar 1 i Aud A. Se 8 for oppgaver. 4 Data√∏ving 1 23.01: (Ingen aktivitet) 25.01: Regnegrupper i 2. etg bibliotek 5 Hypotesetesting 30.01: Oversiktsforelesning: Hypotesetesting i Aud A 01.02: Oppgaveseminar 2 i Aud A. Se 8 for oppgaver. 6 Hypotesetesting og Data√∏ving 2 06.02: (Ingen aktivitet) 08.02: Regnegrupper i 2. etg bibliotek 7 Regresjon 13.02: Oversiktsforelesning Regresjon i Aud A 15.02: Oppgaveseminar 3 i Aud A. Se 8 for oppgaver. 8 Regresjon 20.02: (Ingen aktivitet) 22.02: Oppgaveseminar 4 i Aud A. Se 8 for oppgaver. 9 Data√∏ving 3 27.02: (Ingen aktivitet) 01.03: Regnegrupper i 2. etg bibliotek 10 Tidsrekker/Obligatorisk innlevering 06.03: Oversiktsforelesning Tidsrekker i Aud A 08.03: (Ingen aktivitet) 11 Data√∏ving 4 13.03: Regnegrupper i 2. etg bibliotek 15.03: Gjesteforelesning med Ole-Petter Moe Hansen, Tryg forsikring i Aud A 12 Avansert regresjon og maskinl√¶ring 20.03: Regnegrupper i 2. etg bibliotek 24.03: (Ingen aktivitet) 13 Avansert regresjon og maskinl√¶ring 27.03: Oversiktsforelesning Avansert regresjon og maskinl√¶ring i Aud A 29.03: Oppgaveseminar 6 i Aud A. Se 8 for oppgaver. 14 P√ÖSKE 15 Data√∏ving 5 10.04: (Ingen aktivitet) 12.04: Oppgaveseminar 7 i Aud A. 16 Repetisjon 17.04: Vi avtaler passende aktivitet n√•r det n√¶rmer seg 19.04: Vi avtaler passende aktivitet n√•r det n√¶rmer seg L√¶rebok og pensum Second EMEA edition. Vi bruker l√¶reboken Statistics for Management and Economics av Gerald Keller, som n√• foreligger i en relansert utgave (Second EMEA edition). I utgangspunktet er f√∏lgende kapitler pensum: 1‚Äì5, 9‚Äì13, 15‚Äì18 og 20. Mot slutten av kurset g√•r vi gjennom noen tema som ikke er dekket i l√¶reboken (logistisk regresjon, maskinl√¶ring, paneldatamodeller, tidrekkemodeller). Der finner du referanser til andre kilder, samt en del materiale som vi har skrevet selv. I pensumgjennomgangen p√• denne siden finner du ogs√• en del kommentarer til l√¶reboken, som for eksempel hva som er viktig, og hva som er mindre viktig for oss. Eldre utgaver av l√¶reboken g√•r bra. Vi har sluttet √• bruke regneoppgaver fra boken, s√• vi trenger ikke lenger oppdatere oppgavenummer etc. for hver nye utgave. Regneoppgaver finner du her p√• denne siden under hvert tema. "],["introduksjon-til-r.html", " 1 Introduksjon til R", " 1 Introduksjon til R Vi skal i dette kurset bruke programmeringsspr√•ket R til √• gj√∏re beregninger og gjennomf√∏re de ulike statistiske analysene som vi skal l√¶re etter hvert. Dette vil v√¶re nytt for mange. Vi skal f√∏rst og fremst skal skrive kode og kommandolinjer for √• f√• ut resultater i R, noe som kan oppleves uvant siden vi ellers er vant med √• klikke oss frem i et menysystem n√•r vi jobber med ulike programmer. Tr√∏sten kan v√¶re at ferdigheter i programmering blir stadig viktigere i mange yrker, spesielt innen √∏konomifaget. Vi m√• installere to ting p√• maskinen v√•r f√∏r vi g√•r videre; selve programeringsspr√•ket R, samt programmet RStudio som vi skal bruke til √• skrive og kj√∏re koden. Begge deler er gratis, og begge deler fungerer fint p√• b√•de Windows og Mac (og Linux!). Det er greiest √• gj√∏re dette i riktig rekkef√∏lge: G√• til r-project.org for √• laste ned R til ditt operativsystem, og installer p√• vanlig m√•te uten √• forandre p√• foresl√•tte innstillinger. G√• til rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (‚ÄúOpen source edition‚Äù) for ditt operativsystem og installere p√• vanlig m√•te. Det er heller ikke her n√∏dvendig √• forandre p√• de foresl√•tte innstillingene. Du kan s√• √•pne RStudio, og f√∏lge sekvensen av videoforelesniger som f√∏lger under. "],["en-gjennomgang-av-rstudio.html", "1.1 En gjennomgang av RStudio", " 1.1 En gjennomgang av RStudio I denne videoen snakke vi litt om forskjellen mellom programmeringsspr√•ket R og programmet RStudio. Vi √•pner opp Rstudio og rusler gjennom det grafiske grensesnittet. "],["enkle-beregninger-og-variabler.html", "1.2 Enkle beregninger og variabler", " 1.2 Enkle beregninger og variabler Vi g√•r videre og skriver v√•re f√∏rste kommandoer i R. Det er kritisk at vi allerede n√• setter i gang med √• f√• programmeringen inn i fingrene, og det gj√∏res best ved √• skrive inn kodelinjene slik det gj√∏res i videoen, og passe p√• at du f√•r ut de samme resultatene. # Vi kan bruke R som en kalkulator: 2+2 # Det var enkelt! Vi m√• bruke paramteser dersom vi har mer kompliserte uttrykk: (2+8)/2 2+8/2 # Variabler er viktige i R. Vi kan lagre mer eller mindre hva som helst i # dataminnet ved √• gi det navn: a &lt;- 5 a a*5 b &lt;- 3 # R gjennomf√∏rer alle operasjoner p√• h√∏yresiden f√∏r verdien blir tilordnet # variabelen c: c &lt;- a+b c # Ingen feilmeldinger, advarsler eller sp√∏rsm√•l ved overskriving: c &lt;- 4 c &lt;- c + 2 c # La oss lage en feilmelding! d # Vi kan navngi omtrens slik vi vil, og dette er ikke et trivielt problem i # st√∏rre prosjekter! hva_som_helst &lt;- &quot;hello world&quot; hva_som_helst N√•r du er ferdig med det kan du pr√∏ve deg p√• f√∏lgende lille oppgave: Oppgave: Velg dine tre favorittall og lagre dem i tre forskjellige variabler. Beregn s√• ditt magiske tall, som er summen av favorittallene dine. Lagre ditt magiske tall i en ny variabel, og gi denne variabelen et informativt navn som identifiserer hva det er. Fikk du det til? Kikk p√• l√∏sningen under for √• sjekke. L√∏sning tall1 &lt;- 1 tall2 &lt;- 87 tall3 &lt;- 101 magisk_tall &lt;- tall1 + tall2 + tall3 "],["vektorer.html", "1.3 Vektorer", " 1.3 Vektorer Vi introduserer begrepet vektorer som er sv√¶rt viktig i statistikk generel og R spesielt. En vektor er ganske enkelt en samling med tall, og n√•r vi senere begynner √• jobbe med data kommer vi til √• lagre observasjoner av ulikt slag i vektorer. Vi ser ogs√• at vi kan gj√∏re operasjoner p√• vektorer ved √• bruke funksjoner. For eksempel bruker vi sum()-funksjonen til √• regne ut summen av alle tallene som er lagret i en vektor. # Vi kan lage en vektor p√• f√∏lgende m√•te: vector1 &lt;- c(3, 5, 7.8, 10, 2, 0.16, -3) # Skriv ut: vector1 # Plukke ut verdier vector1[1] # Plukker ut verdier med hakeparanteser vector1[10] # Out-of-range error vector1[2:5] # Plukke ut en sekvens vector1[c(1,3)] # Plukke ut verdier basert p√• en ny vektor! # Bokstaven &quot;c&quot; st√•r for combine. R gj√∏r det veldig enkelt √• jobbe med # vektorer: vector1 - 1 vector1*3 # Vi kan bruke *funksjoner* til √• regne ut forskjellige ting: length(vector1) mean(vector1) sum(vector1) sd(vector1) # Vi kan lage vektorer av andre ting enn tall: vector2 &lt;- c(&quot;hello&quot;, &quot;world&quot;) # ... men en vektor kan bare inneholde en datatype. # Kanksje trenger vi standardavviket senere? sd_vector1 &lt;- sd(vector1) sd_vector1 Oppgave: Beregn maksimum- og minimumsverdien av vector1, samt medianen, ved √• bruke funksjoner i R. (Hint: en d√•rlig skjult hemmelighet i anvendt programmering er at dersom vi ikke vet navnet p√• funksjonen vi skal bruke, s√• er Google v√•r‚Äô beste venn!) L√∏sning # Relevante Google-s√∏k: &quot;minimum value r&quot;, &quot;maximum r&quot;, &quot;median r&quot; min(vector1) max(vector1) median(vector1) "],["pakker.html", "1.4 Pakker", " 1.4 Pakker Vi l√¶rer at n√•r vi laster ned R s√• f√∏lger det med et grunnleggende sett av funksjoner (‚Äúbase R‚Äù), men at det finnes et stort antall tilleggspakker. Vi kan enkelt laste ned og installere disse pakkene ved √• skrive kommandoen install.packages(\"pakkenavn\"). Det trenger vi bare gj√∏re en gang p√• datamaskinen v√•r. For √• bruke pakken m√• vi skrive kommandoen library(pakkenavn), og det m√• vi gj√∏re hver gang i restarter R. # For √• installere pakken s√• kj√∏rer vi f√∏lgende kommando. Denne kj√∏res # bare en gang per masking, den blir installert en gang for alle. install.packages(&quot;readxl&quot;) # N√•r vi skal bruke pakken s√• laster vi den inn ved √• bruke &quot;library()&quot;-, # funksjonen, og den m√• kj√∏res hver gang vi starter R: library(readxl) Oppgave: Installer f√∏lgende pakker, som vi kommer til √• bruke senere i kurset: ggplot2 dplyr stargazer L√∏sning install.packages(&quot;ggplot2&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;stargazer&quot;) "],["mappesti.html", "1.5 Mappesti", " 1.5 Mappesti Vi kommer til √• forholde oss til filer p√• flere m√•ter. Vi skal lese inn datafiler, og vi kommer til √• produsere ulike former for output, slik som figurer og tabeller. Vi m√• da ha kontroll p√• hva R bruker som gjeldende mappesti (‚Äúworking directory‚Äù) der filer som skal leses inn ligger, og der ulike output-filer havner. Vi kan bruke funksjonen getwd() til √• sjekke hva som er gjeldende mappesti. For √• forandre mappestien kan vi bruke menysystemet (Session -&gt; Set Working Directory -&gt; Choose Directory), eventuelt funksjonen setwd() med √∏nsket mappesti som argument. Oppgave: Pass p√• at du har gjort f√∏lgende f√∏r du g√•r videre til neste leksjon: Du har laget en dedikert mappe p√• datamaskinen din der du skal samle alt materiale som vi bruker i dette kapitlet. Du har lastet ned filen testdata.xls og lagt den i den nye mappen din. Du har endret gjeldende mappesti til denne mappen. Du har bekreftet at gjeldende mappesti n√• er korrekt. "],["innlesing-av-data.html", "1.6 Innlesing av data", " 1.6 Innlesing av data Vi leser inn tabellen i excelfilen som en tabell (‚Äúdata frame‚Äù) i R ved hjelp av funksjonen read_xls() i readxl-pakken og ser p√• noen enkle kommandoer for √• jobbe med en slik tabell. # Datasettet er i .xls-formatet, s√• vi trenger readxl-pakker for √• laste det inn # i R. library(readxl) # Inne i denne pakken s√• er det en funksjon som heter read_excel: read_excel(&quot;testdata.xls&quot;) # Det gikk bra, men for √• bruke dette datasettet, s√• m√• vi lagre det til en # variabel. testdata &lt;- read_excel(&quot;testdata.xls&quot;) # Skriver ut (toppen av) datasettet. testdata # N√• ser vi datasettet i vinduet oppe til h√∏yre. Vi kan se p√• det ved √• # skrive navnet til datasettet i konsollen, og vi kan hente ut individuelle # kolonner som vektorer ved √• bruke dollartegnet $: testdata$X1 # Regner ut gjennomsnittet for X1 og X2: mean(testdata$X1) mean(testdata$X2) # Hvor mange rekker/observasjoner har vi? nrow(testdata) Oppgave: Hvor mange kolonner har datasettet v√•rt? Kan du finne en m√•te √• skrive ut en vektor som inneholder summen av X1- og X2-kolonnene i datasettet? (Alts√•, vi vil vite summen av de to f√∏rste elementene i X1 og X2, summen av de to andre elementene, osv.) Hva er summen av alle tallene i X1- og X2-kolonnene itestdata? L√∏sning # 1 ncol(testdata) # 2 testdata$X1 + testdata$X2 # 3 sum(testdata$X1 + testdata$X2) "],["statistiske-analyser.html", "1.7 Statistiske analyser", " 1.7 Statistiske analyser Vi ser p√• et eksempel der vi kj√∏rer en enkel statistisk analyse (en \\(t\\)-test) p√• datasettet v√•rt, og hvordan vi kan gj√∏re ulike valg ved √• endre argumenter i funksjonskallet. Vi bruker ogs√• hjelpefilene til √• lese mer om funksjonen vi bruker. # En grunnleggende t-test for likhet mellom to forventningsverdier: t.test(testdata$X1, testdata$X2) # Antar lik varians og kj√∏rer tosidig test (dette kommer vi tilbake til): t.test(testdata$X1, testdata$X2, var.equal = TRUE, alternative = &quot;two.sided&quot;) # Du kan lese mer om enhver funksjon i R, inkludert om alle mulige argumenter og # eksempler p√• bruk, ved √• skrive et sp√∏rsm√•lstegn foran funksjonsnavnet i # konsollen: ?t.test # Kanksje √∏nsker vi √• hente ut p-verdien for testen og bruke den til noe senere. # Vi kan lagre testresultatet i en variabel f√∏rst, og s√• bruke $-tegnet til √• hente # ut p-verdien p√• f√∏lgende m√•te: testresult &lt;- t.test(testdata$X1, testdata$X2, var.equal = TRUE, alternative = &quot;two.sided&quot;) testresult$p.value # Hvilken annen informasjon finner vi i dette testobjektet? str(testresult) Oppgave: Hva er verdien av testobservatoren (test statistic) i testen som vi gjorde i denne videoen? Hint: Bruk hjelpefilene til t.test()-funksjonen. L√∏sning test_result$statistic "],["r-plotting.html", "1.8 Plotting", " 1.8 Plotting Vi lager v√•r f√∏rste figur i R ved √• bruke den innebygde plot()-funksjonen. Vi g√•r s√• over til √• se hvordan vi kan lage det samme plottet ved √• bruke ggplot-pakken, som er det vi kommer til √• bruke til √• lage figurer i dette kurset. Vi ser ogs√• hvordan vi kan g√• frem for √• lagre plottet som en pdf-fil i arbeidsmappen v√•r. # Et viktig element i dataanalyse er √• lage grafiske presentasjoner av datasett. # La oss lage et enkelt spredningsplott av v√•re to variabler ved √• bruke den # innebygde plottefunksjonen i R. plot(testdata$X1, testdata$X2) # Gj√∏r noen justeringer: plot(testdata$X1, testdata$X2, pch = 20, bty = &quot;l&quot;, xlab = &quot;X1&quot;, ylab = &quot;X2&quot;) # I dette kurset skal vi heller bruke ggplot2-pakken til plotting: library(ggplot2) # Her er koden for √• lage et enkelt spredningsplott for X1 og X2-kolonnenene i # datasettet v√•rt: ggplot(testdata, aes(x = X1, y = X2)) + geom_point() # Vi lagrer plottet ved √• kj√∏re ggsave-kommandoen rett etter plottekommandoen: ggsave(&quot;testplot.pdf&quot;) # En mer fleksibel m√•te √• gj√∏re dette p√• er √• lagre plottet i en variabel, og s√• # gi navnet til plottet inn som et argument i ggsave-funksjonen. p &lt;- ggplot(testdata, aes(x = X1, y = X2)) + geom_point() ggsave(&quot;testplot.pdf&quot;, p) # P√• den m√•ten s√• kan vi lagre plottet p n√•r som helst, vi trenger ikke # n√∏dvendigvis gj√∏re det rett etter plottekommandoene. Oppgave: Klarer du, for eksempel ved √• s√∏ke etter relevante ggplot-kommandoer p√• nettet, √• f√• prikkene i plottet til √• bli st√∏rre, og samtidig gj√∏re dem bl√•? L√∏sning ggplot(testdata, aes(x = X1, y = X2)) + geom_point(colour = &quot;blue&quot;, size = 5) "],["script.html", "1.9 Script", " 1.9 Script I stedet for √• skrive kommandoene rett inn i konsollen, hopper vi n√• over til teksteditoren i RStudio og lager et script i stedet. Her kan vi samle alle kommandoene v√•re i en fil, som vi kan lagre og kj√∏re igjen senere. Vi ser ogs√• hvordan vi enkelt kan kj√∏re enkeltlinjer i scriptet v√•rt i R-konsollen ved hjelp av Ctrl-Enter (Command-Enter p√• Mac). Vi ser at vi kan skrive kommentarer i scriptene v√•re ved √• bruke #-tegnet, som kan v√¶re nyttig for √• holde oversikten. Til slutt lagrer vi scripet i arbeidsmappen. Oppgave: Pass p√• at du n√• har lagret scriptet som en .R-fil i mappen som vi laget for denne R-leksjonen. Lukk RStudio. Naviger s√• til denne mappen i filutforskeren og dobbelklikk p√• skriptet. Forh√•pentligvis √•pnes RStudio n√• (Hvis ikke, eller hvis filen √•pnes i det som heter R GUI, h√∏yreklikker du p√• filen og velger ‚Äú√Öpne i‚Äù, og deretter RStudio. Du kan ogs√• gjerne sette RStudio som standarsprogram for .R-filer). Finn ut hva gjeldende arbeidsmappe n√• er i RStudio. Hva skjedde n√•? Hvorfor er dette nyttig? L√∏sning N√•r vi √•pner RStudio ved √• dobbeltklikke p√• skriptfilen, s√• blir arbeidsstien satt automastisk til mappen der skriptfilen ligger. Dette er veldig nyttig n√•r vil kommer tilbake og skal jobbe videre med prosjektet v√•rt. "],["pipe.html", "1.10 Pipe-operatoren %&gt;% og enkel datavask", " 1.10 Pipe-operatoren %&gt;% og enkel datavask Vi g√•r gjennom to nyttige programmeringsteknikker som begge er inneholdt i dplyr-pakken: Pipe-operatoren %&gt;%. som gj√∏r at vi kan skrive opp en sekvens av funksjonskall i den rekkef√∏lgen de skal kj√∏res, og uten √• miste oversikten i et hav av paranteser. Funksjoner for enkel datavask: select() for √• velge ut kolonner i et datasett, filter() for √• filtrere rader basert p√• kriterier, og mutate() for √• lage nye kolonner. Her er et par ekstra tips i denne sammenhengen: N√•r du bruker select(), s√• kan du bruke minustegnet for √• spesifisere kolonner som du ikke vil ha med: testdata %&gt;% select(-X1). I filter()-funksjonen s√• kan vi bruke andre kriterier enn st√∏rre enn (&gt;): &lt; = ‚Äúmindre enn‚Äù &gt;= = ‚Äúst√∏rre enn eller lik‚Äù &lt;= = ‚Äúmindre enn eller lik‚Äù == = ‚Äúer lik‚Äù != = ‚Äúer ikke lik‚Äù # Vi kan bruke klammeparantesen til √• hente ut enkelttall, kolonner eller rader: testdata[1,2] testdata[1,] testdata[,2] testdata[, c(&quot;X1&quot;, &quot;X2&quot;)] # Vi kan ogs√• filtrere ut rader basert p√• kriterier: testdata[testdata$X1 &gt; 100,] # Eller vi kan legge til en ny kolonne, som er summen av to kolonner testdata$sum &lt;- testdata$X1 + testdata$X2 # Det finnes en enklere m√•te √• gj√∏re dette p√• ved hjelp av den s√•kalte # &quot;pipe&quot;-operatoren og egne funksjoner for datamanipulasjon. Begge deler # er inkludert i dplyr-pakken, som du eventuelt p√• installere: # install.packages(&quot;dplyr&quot;) library(dplyr) # Det f√∏rste konseptet er pipen, og det er en veldig fin kommando n√•r vi # skal bruke flere funksjoner etter hverandre. La oss si at vi skal regne ut # logaritmen til kvadratroten til 2. I base R kan vi skrive: log(sqrt(2)) # Kvadratroten av 2 skrevet som en pipe blir 2 %&gt;% sqrt # ... og logaritmen til kvadratroten til 2 blir da 2 %&gt;% sqrt %&gt;% log # Dette kan vi lese fra venstre mot h√∏yre i den rekkef√∏lgen det skjer, og vi trenger # ikke holde styr p√• flere lag med paranteser. # Dette er en teknikk som gj√∏r det veldig greit √• jobbe med tabeller av data, og # vi skal se p√• tre veldig sentrale funksjoner i dplyr-pakken: # Bruk &quot;select()&quot; til √• velge kolonner i et datasett: testdata %&gt;% select(X1, X2) # Bruk &quot;filter()&quot; for √• filtrere ut rader basert p√• kriterier: testdata %&gt;% filter(X1 &gt; 100) # Bruk &quot;mutate()&quot; for √• lage nye kolonner, gjerne basert p√• de vi allerede har: testdata %&gt;% mutate(sum = X1 + X2) # Legg merke til at vi her bare skriver navnet p√• datasettet en gang, nemlig helt i # starten. Vi kan ogs√• kj√∏re flere slike pipes etter hverandre, og lagre resultatet # i en ny variabel: ny_testdata &lt;- testdata %&gt;% select(X1, X2) %&gt;% filter(X1 &gt; 100) %&gt;% mutate(sum = X1 + X2) Oppgave: Basert p√• testdata, lag en tabell som bare inneholder radene der A1-kolonnen er lik 1 og A2-kolonnen er lik 0, men der vi bare skal ha med kolonnene X1 og X2. Lag til slutt en ny kolonne som inneholder differansen av tallene i X1 og X2-kolonnene. L√∏sning testdata %&gt;% filter(A1 == 1) %&gt;% filter(A2 == 0) %&gt;% select(X1, X2) %&gt;% mutate(differanse = X1 - X2) "],["r-ekstra.html", "1.11 Oppsummering og ekstra oppgaver", " 1.11 Oppsummering og ekstra oppgaver I denne modulen har vi g√•tt gjennom noen helt grunnleggende funksjoner i R. Du har l√¶rt at R er navner p√• et programmeringsspr√•k, RStudio er navnet p√• et program der vi kan skrive og kj√∏re R-kode, og identifisert fire forskjellige vindu i RStudio: konsollen (der R-koden kj√∏res), teksteditoren (der vi skriver script), samt to vinduer der vi kan se en oversikt over hva som er i dataminnet og f√• opp plott og figurer som vi lager. Videre har du kj√∏rt noen enkle kommandoer, lagret tall og vektorer ved hjelp av variabelnavn, pr√∏vd ut noen innebygde R-funksjoner for √• regne ut f.eks. gjennomsnitt og standardavvik av tallvektorer, laget et spredningsplott, l√¶rt hva et working directory (arbeidsmappe) er, og installert R-pakker, f.eks readxl som vi brukte den til √• lese inn et lite datasett i R. Til slutt har du kj√∏rt en \\(t\\)-test, skrevet et script (et lite program om du vil) der vi har lagret flere av kommandoene over i en tekstfil, og l√¶rt om pipe-operatoren og enkel datavask ved hjelp av funksjoner i dplyr-pakken. Dersom du har fulgt modulen selv har du n√• kanskje skrevet et lite script i tekstvinduet som ser ut omtrent som koden under. N√•r du har gjort alt riktig, skal du n√• kunne kj√∏re gjennom disse kodelinjene uten feilmeldinger ved hjelp av Ctrl-Enter. Dette er helt grunnleggende (Sp√∏r om hjelp! Gi hjelp!). Har du problemer her, s√∏rg for √• f√• dem ordnet. Sp√∏r f√∏rst en medstudent om hjelp, og deretter eventuelt studentassistent eller foreleser. Studenter som har god erfaring med data og/eller programmering, kan l√¶re mye av √• hjelpe medstudenter l√∏se feilmeldinger. # Introduksjon til R # ------------------- # Laster inn n√∏dvendige pakker library(readxl) library(ggplot2) # Laster inn datasettet testdata &lt;- read_xls(&quot;testdata.xls&quot;) # Gj√∏r t-testen til sp√∏rsm√•l F i den f√∏rste data√∏vingen testresultat &lt;- t.test(testdata$X1, testdata$X2, var.equal = TRUE, alternative = &quot;two.sided&quot;) # Skriver ut resultatet av denne t-testen testresultat # Lager et plott av variabelen X1 mot X2 p &lt;- ggplot(testdata, aes(x = X1, y = X2)) + geom_point() # Lagrer plottet ggsave(&quot;testplot.pdf&quot;, plot = p) Lagre scriptet ditt. I RStudio velger du File -&gt; Save og trykker Ok dersom det kommer opp et vindu om character encoding e.l. Finn en fornuftig plassering (gjerne i samme mappe som √∏velsesdatasettet) og gi filen et fornuftig navn. Standard filending for R-script er .R, men det er skjult for de fleste Windowsbrukere. Lukk RStudio. Du kan n√• √•pne skriptfilen i RStudio igjen. Enten ved √• dobbeltklikke p√• den, eller ved √• √•pne RStudio, velge File -&gt; Open file, og s√• videre (dersom skriptet ikke allerede ligger √•pnet). Du kan ogs√• √•pne skriptfilen i en hvilken som helst notatbok (Notebook e.l.) og se at det er en helt standard, ren tekstfil. Hva er fordelen med √• lagre en analyse som et skript versus √• gj√∏re ting i et menydrevet grafisk grensesnitt? L√∏sning N√•r vi lagrer koden v√•r i et skript s√∏rger vi for at hele analysen v√•r er lagret, ikke bare resultatene. Med andre ord, dersom du p√• et senere tidspunkt √∏nsker √• komme tilbake til et analyseprosjekt og gj√∏re noen enkle forandringer, s√• er det fort gjort √• gj√∏re det i skriptet, og s√• kj√∏re hele analysen p√• nytt. Dersom du i stedet hadde brukt et menydrevet system for √• gjennomf√∏re analysen (pek og klikk) kunne du risikere √• m√•tte gj√∏re alt sammen p√• nytt (hvis du da husker hvordan du gjorde det), fordi du ikke like enkelt kan lagre hvert eneste museklikk. Vi skal n√• pynte p√• plottet og gj√∏re det riktig pent. Det gj√∏r vi ved √• legge til nye linjer i ggplot-kommandoen. Erstatt den nest siste linjen i skriptet med kommandoen under, og se at du f√•r en figur omtrent som den som f√∏lger under det igjen (vi bruker aksetitler i henhold til oppgavene i den f√∏rste datalabben, der vi f√•r vite at datasettet representerer kvalitet p√• kaffeavlingen f√∏r og etter en omlegging i produksjonsmetode): ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2) + xlab(&quot;Produksjonsmetode 1&quot;) + ylab(&quot;Produksjonsmetode 2&quot;) + theme_classic() Merk at vi bruker ‚Äú+‚Äù-tegnet til √• legge til flere ‚Äúlag‚Äù med grafiske egenskaper til plottet. Hvert ‚Äúlag‚Äù best√•r av en funksjon, som ofte kan ta argumenter; f.eks. brukes funksjonen geom_point() til √• lage prikker, og s√• kan vi f.eks. bruke argumentet size til √• styre st√∏rrelsen p√• prikkene. Kan du finne ut hva hvert enkelt av disse ‚Äúlagene‚Äù gj√∏r? Hint: ta bort en linje av gangen, og se hva som skjer. Pass p√• at det er et pluss mellom hvert lag. Pr√∏v √• endre p√• noen av lagene eller legg til nye. For eksempel kan du lage en tittel ved √• legge til funksjonen ggtitle() som et lag, og du kan endre aksetitlene. Pr√∏v ogs√• √• bruke argumentet shape i geom_point() til √• bytte ut prikkene med en annen form. Det finnes flere andre ‚Äútema‚Äù i tillegg til theme_classic(), f.eks. theme_bw(), theme_dark(), etc. Forslag Pr√∏v for eksempel dette: ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2, shape = 4) + ggtitle(&quot;Produksjonskvalitet&quot;) + xlab(&quot;Ny aksetittel&quot;) + ylab(&quot;Enda en aksetittel&quot;) + theme_light() Det f√∏lger med omfattende dokumentasjon med R. Du kan lese om alle R-funksjoner ved √• skrive ? f√∏r funksjonsnavnet i konsollen. Pr√∏v for eksempel √• skrive ?mean i konsollen og trykk enter. "],["grunnleggende-statistikk.html", " 2 Grunnleggende statistikk", " 2 Grunnleggende statistikk I denne modulen introduserer vi en del grunnleggende statistiske begreper. Mye vil oppleves som repetisjon, mens noe vil v√¶re nytt. Noe er veldig praktisk ved at vi kan bruke det direkte i eksempler, mens andre ting er mer teoretisk av natur. Felles for det vi skal se p√• her er at vi kommer til √• bruke mange av begrepene vi l√¶rer senere i kurset. I videoforelesningene g√•r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved √• klikke p√• lenkene under: Slides til ‚ÄúGrunnleggende statistikk‚Äù R-script til ‚ÄúGrunnleggende statistikk‚Äù TIPS: Hvis du √∏nsker √• laste ned lysbildene som PDF trykker du p√• linken over, velger ‚ÄúSkriv ut‚Äù, og s√• skriver du ut som PDF. F√∏r du gj√∏r det b√∏r du scrolle gjennom alle sidene slik at ligningene vises korrekt. "],["deskriptiv-statistikk.html", "2.1 Deskriptiv statistikk", " 2.1 Deskriptiv statistikk 2.1.1 Videoforelesninger 2.1.2 Kommentarer Deskriptiv statistikk handler ikke om analyse eller regning, men om √• presentere kompleks informasjon p√• en effektiv m√•te. Det er alts√• noe ganske annet enn det vi ellers snakker om i kurset, men det er likevel et av de nyttigste l√¶ringspunktet vi har. Hvem kan ikke regne med √• m√•tte presentere tall og resultater i l√∏pet av sin karriere? Eller selge inn forslag og planer for overordnede i h√•p om √• bli lyttet til? Det kan v√¶re direkte avgj√∏rende for din egen gjennomslagskraft at du er i stand til √• produsere overbevisende tabeller og figurer i slike situasjoner, og det er det dette temaet handler om. I l√¶reboken er det kapitlene 2‚Äì4 som behandler deskriptiv statistikk, men det er veldig Excel-fokusert, som ikke er s√• relevant for oss. Det er likevel ikke dumt √• lese gjennom stoffet for √• se hva det g√•r i, og legg spesielt merke til f√∏lgende punkter: Ulike datatyper i avsnitt 2-1. 3-4: The art and science of graphical presentations. Hva er det som gj√∏r en grafisk illustrasjon god? Pr√∏v √• ta inn over dere all informasjonen som vi lett kan lese ut av bildet p√• side 75 om Napoleons felttog mot Moskva. Her presenteres informasjon om tid, antall, geografi og temperatur p√• en helt eksepsjonelt effektiv m√•te! Videre er det noen grelle eksempler p√• hvordan vi kan bruke grafiske virkemidler til √• gi skjeve fremstillinger. I videoforelesningen gir vi flere eksempler p√• dette. Kapittel 4 g√•r litt mer i dybden om numeriske deskriptive teknikker, som gjennomsnitt, median, standardavvik, korrelasjon, osv. Dette skal v√¶re dekket greit i forelesningen, men boken g√•r litt lenger. Det kan v√¶re en fin √∏velse √• kikke p√• eksemplene i l√¶reboken og fors√∏ke √• gjenskape noen av Excel-figurene i R. Se p√• eksempel 3.2, der man skal lage to histogrammer over historiske avkastninger for to ulike investeringsstrategier. Vi leser inn datasettet (last ned fra Canvas) som under og kikker p√• det: library(readxl) returns &lt;- read_xlsx(&quot;Xm03-02.xlsx&quot;) returns ## # A tibble: 50 √ó 2 ## `Return A` `Return B` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 30 30.3 ## 2 -2.13 -30.4 ## 3 4.3 -5.61 ## 4 25 29 ## 5 12.9 -26.0 ## 6 -20.2 0.46 ## 7 1.2 2.07 ## 8 -2.59 29.4 ## 9 33 11 ## 10 14.3 -25.9 ## # ‚Ä¶ with 40 more rows ## # ‚Ñπ Use `print(n = ...)` to see more rows Hver stategi har sin kolonne. Merk at variabelnavnene har mellomrom i seg, noe som er upraktisk n√•r vi jobber med et seri√∏st programmeringsspr√•k. En god vane er √• rett og slett gi dem nye navn, ved f.eks. √• kj√∏re colnames(returns) &lt;- c(\"returnA\", \"returnB\"), eller s√• m√• vi alltid referere til variabelnavnene ved √• bruke slike ‚Äúbackticks‚Äù som vi ser under. Vi kan lage to enkle histogrammer slik vi gjorde det i forelesningen: library(ggplot2) ggplot(returns, aes(x = `Return A`)) + geom_histogram(bins = 10) ggplot(returns, aes(x = `Return B`)) + geom_histogram(bins = 10) Figur 2.1: To histogrammer Her er noen kontrollsp√∏rsm√•l som du kan pr√∏ve deg p√•: Hva er forskjellen p√• deskriptiv statistikk og statistisk inferens? Deskriptiv statistikk kan gj√∏res grafisk eller numerisk, eventuelt som tabeller av ulike numeriske m√•l. Nevn noen fordeler og ulemper man m√• veie mot hverandre n√•r vi skal velge mellom grafisk og numerisk deskriptiv statistikk. "],["utvalg-og-estimering.html", "2.2 Utvalg og estimering", " 2.2 Utvalg og estimering You can, for example, never foretell what any one man will do, but you can say with presicion what an average number will be up to. Individuals vary, but percentages remain constant. So says the statistician. ‚Äî Sherlock Holmes 2.2.1 Videoforelesninger 2.2.2 Kommentarer I videoforelesningene over g√•r vi gjennom noen sentrale begreper i statistikk. Noen av dem skal vi bruke mye i fortsettelsen, mens andre er ment for √• gi dere et solid teoretisk fundament n√•r vi etter hvert skal begi oss ut p√• anvendt statistikk. Vi startet med √• sette opp en liten agenda. Som et f√∏rste steg kan du kikke p√•, og notere ned noen setninger til, disse punktene og se om du har f√•tt med deg hva de betyr: Samplingfordelinger Forventning/varians Sentralgrenseteoremet Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Forventningsrett Konsistens I Boken er det kapittel 9 (Sampling distributions) og 10 (Introduction to estimation) som gjelder. Kapittel 6‚Äì8 omhandler stoff skal skal v√¶re greit dekket i MET2 (Sannsynlighet, fordelinger, stokastiske variable, osv.), men det kan v√¶re nyttig √• skumme gjennom likevel hvis disse begrepene ligger langt bak i bevissheten din. Kapittel 9 starter med √• diskutere samplingfordelingen til et gjennomsnitt. Dette er nyttig lesestoff, men de viktigste punktene er som f√∏lger: Dersom observasjonene \\(X_1, X_2, \\ldots, X_n\\) er normalfordelt, er ogs√• gjennomsnittet \\(\\overline X = \\frac{1}{n}\\sum_{i=1}^n X_i\\) normalfordelt. Dersom E\\((X_i) = \\mu\\) og Var\\((X_i) = \\sigma^2\\) for alle \\(i = 1,\\ldots,n\\), er E\\((\\overline X)=\\mu\\) og Var\\((\\overline X) = \\sigma^2/n\\). Dette regnet vi ut formelt. Dersom \\(n\\) er stor, er \\(\\overline X\\) tiln√¶rmet normalfordelt, uavhengig av fordelingen til den enkelte \\(X_i\\). Dette f√∏lger av sentralgrensesetningen. Dette st√•r i en boks p√• slutten av seksjon 9-1a. Hvor stor m√• \\(n\\) v√¶re for at denne tiln√¶rmingen er god nok? Det finnes ikke et entydig svar p√•, men n√•r vi passerer 50-100 observasjoner kan vi i v√•re MET4-problemer gjerne si at \\(n\\) er ¬´stor nok¬ª. I 9-1b og 9-1c brukes sentralgrenseteoremet til √• regne p√• normalsannsynligheter i MET2-stil. I 9-1d er det noen Excel-instruksjoner som du kan hoppe over hvis du vil. Tekstboksen i 9-2c oppsummerer det vi fant ut om samplingfordelingen til en observert andel. I seksjon 9-3 snakkes det om samplingfordelingen til differansen av to gjennomsnitt. Vi gikk ikke gjennom det eksplisitt i forelesningen, men det er ikke noe substansielt nytt her. Vi skal bruke dette reultatet i neste modul n√•r vi skal sammenligne to gjennomsnitt. I seksjon 9-4 f√•r vi forklart hva vi skal bruke samplingfordelinger til fremover. B√∏r leses. Kapittel 10 omhandler estimering, dvs hvordan vi bruker data til √• ¬´gjette¬ª p√• verdien til en ukjent parameter. Vi fors√∏kte i forelesningen √• gi litt intuisjon til begrepene forventningsrett estimator, variansen til en estimator, og konsistens. Vi kan lage et punktestimat av en forventningsverdi ved √• ta gjennomsnittet av observasjoner, og vi kan lage et konfidensintervall ved √• f√∏lge oppskriften i boksen p√• s. 316 (i 11. utgave). I eksempel 10.1 har vi 25 observasjoner fra en normalfordeling. Oppgaven er √• estimere forventningsverdien med et tilh√∏rende 95% konfidensuntervall. Pass p√• at du forst√•r den manuelle utregningen. I stedet for √• bruke Excel (eller taste alle disse tallene inn p√• en kalkulator) kan du skrive et lite R-script som gj√∏r det samme: # Vi skriver inn datasettet i en vektor demand &lt;- c(235, 374, 309, 499, 253, 421, 361, 514, 462, 369, 394, 439, 348, 344, 330, 261, 374, 302, 466, 535, 386, 316, 296, 332, 334) # Vi trenger 4 verdier for √• regne ut konfidensintervallet: gj.snitt &lt;- mean(demand) # Regner ut gjennomsnittet z &lt;- 1.96 # Denne finner vi i tabellen sigma &lt;- 75 # Oppgitt i oppgaven n &lt;- length(demand) # Antall observasjoner # V√•rt estimat av forventningsverdien er bare gjennomsnittet. # Regner ut nedre og √∏vre grense i konfidensintervallet (LCL, UCL): LCL &lt;- gj.snitt - z*sigma/sqrt(n) UCL &lt;- gj.snitt + z*sigma/sqrt(n) # Samler de tre tallene i en vektor og skriver ut: c(LCL, gj.snitt, UCL) ## [1] 340.76 370.16 399.56 I seksjon 10-2a fors√∏ker boken √• forklare fortolkningen av et konfidensintervall. Hovedpoengene her er at: Et 95%-konfidensintervall skal ikke tolkes som ¬´sannsynligheten for at den sanne parameterverdien ligger i intervallet er 95%¬ª. Den korrekte tolkningen er: ¬´Dersom vi hadde hatt tilgang til √• trekke nye utvalg fra populasjonen med like mange observasjoner og bruker dem til √• regne ut nye konfidensintervaller, vil 95 av 100 intervaller inneholde den sanne parameterverdien¬ª. Forskjellen p√• disse formuleringene er meget subtil, s√• subtil faktisk at det ikke er √•penbart at det er s√¶rlig god pedagogikk √• peke p√• den. Problemet med den f√∏rste formuleringen er at vi der kan f√• inntrykk av at det er den sanne parameterverdien som er stokastisk og avhengig av datasettet vi observerer, mens det strengt tatt er grensene til konfidensintervallet som er tilfeldige, og alts√• avhengige av datasettet. Det kommer klarere frem i den andre formuleringen. Bredden til et konfidensintervall er alts√• et uttrykk for usikkerhet, eller motsatt: presisjon. Seksjon 10-2b og 10-2c kan skummes raskt gjennom. Seksjon 10-3 handler om at vi f√∏rst bestemmer oss for et presisjonsniv√• (dvs bredde p√• konfiensintervallet) \\(B\\), og s√• regner ut hvor mange observasjoner vi trenger for √• oppn√• det. Vi kommer frem til en formelen \\[n = \\left(\\frac{z_{\\alpha/2}\\sigma}{B}\\right)^2,\\] men problemet i praksis er at vi gjerne ikke kjenner \\(\\sigma\\), og vi kan heller ikke estimere den fordi vi ikke har samlet inn data enda. L√∏sningen er at vi enten p√• bruke fornuften, eller eventuelt et tidligere estimat av \\(\\sigma\\) dersom det er tilgjengelig. N√•r du har v√¶rt gjennom dette stoffet skal du forh√•pentligvis v√¶re i stand til √• diskutere f√∏lgende sp√∏rsm√•l med f.eks. en medstudent: Hva er en samplingfordeling? Hva sier sentralgrenseteoremet? Hva mener en statistiker n√•r hen sier at ‚Äúgjennomsnittet konvergerer som \\(1/\\sqrt{n}\\)‚Äù? Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Hva vil det si at et estimator er forventningsrett? Hva vil det si at et estimator er konsistent? 2.2.3 Ekstra √∏ving i R Som demonstrert i forelesningen kan vi i R simulere standard normalfordelte observasjoner (dvs normalfordelte observasjoner med \\(\\mu = 0\\) og \\(\\sigma^2 = 1\\)) med kommandoen rnorm(n), der n er antallet observasjoner vi √∏nsker. For eksempel kan vi kj√∏re f√∏lgende kode for √• generere 10 observasjoner (du vil helt sikkert f√• andre verdier): n &lt;- 10 rnorm(n) ## [1] 0.573245508 -0.613118044 0.012262608 -0.004925287 1.373210438 ## [6] -0.820385320 -0.090725122 1.100906760 0.316819324 1.806396912 Ved √• skrive mean(dnorm(n)) i stedet regner vi ut gjennomsnittet av observasjonene direkte. La oss gj√∏re dette 100 ganger og notere ned gjennomsnittet hver gang. I stedet for √• gj√∏re det manuelt, kan vi skrive et lite program som gj√∏r dette for oss ved √• bruke en for-l√∏kke. Det er ikke n√∏dvendig (eller pensum) √• forst√• akkurat hvordan dette fungerer, men dersom du kj√∏rer f√∏lgende linjer vil du f√• en ny vektor gj.snitt som inneholder 100 slike gjennomsnitt: gj.snitt &lt;- rep(NA, 100) for(i in 1:100) { gj.snitt[i] &lt;- mean(rnorm(n)) } Skriv ut denne vektoren og kontroller at det ser korrekt ut. Vi husker at funksjonen sd() regner ut standardavviket til en vektor. Hvilket tall forventer du √• f√• ut dersom du n√• kj√∏rer sd(gj.snitt) i konsollen? Stemmer det? Hint Standardavviket til de enkelte observasjonene er \\(\\sigma = 1\\), og standardavviket til et gjennomsnitt best√•ende av 10 observasjoner er \\(\\sigma/\\sqrt{n} = 1/\\sqrt{10} \\approx 0.32\\). Med andre ord skal det empiriske standardavviket sd(gj.snitt) v√¶re omtrent lik 0.32, pluss/minus en estimeringsfeil. Du kan gjerne regne ut 1000 gjennomsnitt i stedet for 100 ved √• erstatte erstatte 100 med 1000 p√• to steder i koden over. Stemmer det bedre da? Hint gj.snitt &lt;- rep(NA, 1000) # Lager en tom vektor med 1000 plasser for(i in 1:1000) { # Fyller hver plass med et gjennomsnitt av gj.snitt[i] &lt;- mean(rnorm(n)) # 10 standard normalfordelte observasjoner. } Pr√∏v √• forklare. Svar Dette er ganske enkelt, men ogs√• litt vanskelig p√• en inception-aktig m√•te. P√• samme m√•te som at gjennomsnittet blir en mer og mer presis estimator for forventningsverdien n√•r vi √∏ker antall observasjoner (m√•lt ved at standardavviket \\(\\sigma/\\sqrt{n}\\) blir mindre n√•r antall obserasjoner \\(n\\) blir st√∏rre), blir det empiriske standardavviket en mer og mer presis estimator av det sanne standardavviket n√•r vi √∏ker antall observasjoner. Alts√•; det empiriske standardavviket har ogs√• et standardavvik som g√•r mot null som \\(1/\\sqrt{n}\\) üòµ "],["oppgaverdeskriptiv.html", "2.3 Oppgaver", " 2.3 Oppgaver 2.3.1 Standard oppgaver Beskriv kort forskjellen mellom deskriptiv statistikk og statistisk inferens. L√∏sning Beskrivende statistikk bearbeider og presenterer data for √• belyse faktiske forhold. Statistisk inferens, ogs√• kalt slutningsstatistikk, er √• gj√∏re slutninger om populasjonen basert p√• det vi observerer i utvalget. Du skal spille kron og mynt. Motspilleren din er eieren av mynten, og hun p√•st√•r at den er rettferdig. Det vil si at om man flipper mynten sv√¶rt mange ganger vil den gi et likt antall kron som mynt. Beskriv et eksperiment som tester denne p√•standen. Hva er populasjonen i eksperimentet? Hva er utvalget? Hva er parameteren? Hva er estimatoren? Beskriv kort hvordan statistisk inferens kan bli brukt til √• teste p√•standen til motspilleren din. L√∏sning Kast mynten ett gitt antall ganger, for eksempel 100 ganger. Registrer hvor mange ganger den viser mynt og hvor mange ganger den viser kron. Populasjonen er det teoretiske resultatet av √• kaste mynten uendelig mange ganger og registrere hvor mange ganger den viser mynt og hvor mange ganger den gir kron. Utvalget er antall mynt og kron i eksperimentet. Parameteren er andelen mynt (eller kron) i populasjonen. Estimatoren er den registrerte andelen mynt (eller kron) i eksperimentet. Estimatoren kan brukes til √• vurdere om mynten faktisk er rettferdig. I neste modul av kurset skal dere l√¶re om hypotesetesting og om hvilken hypotesetest man kan utf√∏re for √• avgj√∏re om man kan forkaste nullhypotesen om at mynten er rettferdig. En fabrikant av maskindeler p√•st√•r at mindre enn 15% av produktene er defekte. N√•r 1000 deler ble trukket fra en stor produksjon, var 12% defekte. Hva er populasjonen i dette tilfellet? Hva er utvalget? Hva er parameteren? Hva er estimatoren? Forklar kort hvordan estimatoren kan bli brukt til √• gj√∏re inferens om parameteren for √• unders√∏ke p√•standen om at 15% av produktene er defekte. L√∏sning Populasjonen er alle de aktuelle maskindelene som lages av fabrikanten. Utvalget er de 1000 delene som ble trukket fra en stor produksjon. Parameteren er andelen defekte maskindeler i alle de aktuelle maskindelene som produseres. 15% er den p√•st√•tte parameter. Estimatoren er andelen defekte maskindeler i utvalget. 12% er den observerte estimatoren. Vi kan estimere at andelen defekte maskindeler i populasjonen er 12%. Ved √• bruke statistisk inferens kan vi unders√∏ke om vi har nok statistisk bevis til √• avvise p√•standen om at den sanne andelen defekte maskindeler er 15%. Avgj√∏r om de f√∏lgende datasettene inneholder forholdsdata, intervalldata, ordinale data eller dikotome og nominale data. Avgj√∏r ogs√• hvilke regneoperasjoner som er tillatt. Antall mil en gruppe joggere l√∏per hver uke Starl√∏nnen til nyutdannede fra masterprogrammet til NHH M√•nedene et selskaps ansatte velger √• ta ut ferie Temperatur i Celsius Bokstavkarakterene til studentene i MET4 De daglige aksjeprisene til Tesla Klesst√∏rrelser (S, M, L) Antallet Toyota som er importert m√•nedlig til USA de siste 5 √•rene Stillingene i Kjernestyret i NHHS (Leder, Prosjektansvarlig, Internansvarlig osv) Dato L√∏sning Forholdsdata: =, ‚â†, &lt;, &gt;, +, -, *, / Forholdsdata: =, ‚â†, &lt;, &gt;, +, -, *, / Nominale data: =, ‚â† Intervalldata: =, ‚â†, &lt;, &gt;, +, - Ordinale data: =, ‚â†, &lt;, &gt; Forholdsdata: =, ‚â†, &lt;, &gt;, +, -, *, / Ordinale data: =, ‚â†, &lt;, &gt; Forholdsdata: =, ‚â†, &lt;, &gt;, +, -, *, / Nominale data: =, ‚â† Intervalldata: =, ‚â†, &lt;, &gt;, +, - Skattebetalere som fyller ut egenmeldingen sin blir spurt de f√∏lgende sp√∏rsm√•lene. Hvilken type data utgj√∏r svarene og hvilke regneoperasjoner er tillatt? Er det f√∏rste gang du fyller ut egenmeldingen din? Hvor lang tid brukte du p√• √• fylle ut egenmeldingen? Hvor enkelt/vanskelig var det √• fylle ut egenmeldingen? (Veldig enkelt, noks√• enkelt, hverken enkelt eller vanskelig, noks√• vanskelig, veldig vanskelig) L√∏sning Nominale data: =, ‚â† Intervalldata: =, ‚â†, &lt;, &gt;, +, - Ordinale data: =, ‚â†, &lt;, &gt; Du f√•r oppgitt at gjennomsnittlig startl√∏nn for NHH studenter etter endt utdanning er 560 000kr. Median startl√∏nnen er 520 000kr. Hva forteller disse tallene deg? L√∏sning Selv om den gjennomsnittlige startl√∏nnen er 560 000kr, s√• f√•r halvparten av arbeidstakerne 520 000kr eller mindre. Det forteller ogs√• at det er noen arbeidstakere som drar gjennomsnittet opp. En videreg√•ende skole rapporterer at gjennomsnittsfrav√¶ret i antall dager i l√∏pet av ett skole√•r er 10 dager. Medianen er 3,5 dager. Hva forteller de to m√•lene oss, og hvilke av de to beskriver best frav√¶ret? Hvorfor? L√∏sning Det gjennomsnittlige frav√¶ret er h√∏yere enn medianen. Dette forteller oss at noen elever har h√∏yt frav√¶r som drar gjennomsnittet opp. Disse elevene er ikke representative for det store flertallet. Halvparten av elevene har 3.5 eller mindre dagers frav√¶r. Derfor er medianen et mer robust senterm√•l, som ikke blir p√•virket av store uteliggere. Du skal ta en spr√•ktest f√∏r utveksling og kan velge mellom to ulike spr√•kkurs som skal forberede deg til testen. Begge kursene har rapportert kvartilene til testresultatene oppgitt i antall poeng studentene deres fikk p√• testene: Kvartil Kurs nummer 1 Kurs nummer 2 F√∏rste kvartil 230 225 Andre kvartil 240 235 Tredje kvartil 250 270 Hvordan tolker du kvartilene og hvilket kurs ville du ha valgt? L√∏sning Kvartilene kan fortelle oss noe om niv√•et og variasjonen i poengsummene til studentene som har tatt de to kursene. Vi ser at kurs nummer 1 har en symmetrisk fordeling med en median som er h√∏yere enn kurs nummer 2. P√• en annen side har poengfordelingen til kurs nummer 2 en lengre h√∏yre hale hvor tredje kvantilen tilsier at hele 25 % vil f√• 270 poeng eller mer. Det tilsvarende tallet for kurs nummer √©n er 250. Samlet sett er det kanskje ‚Äútryggere‚Äù med kurs nummer 1, mens det potensielle l√¶ringsutbytte har ‚Äúst√∏rre tak‚Äù i kurs nummer to. MET4 ble et √•r rettet av to sensorer og et boxplot av poengene de ga sine respektive kandidater var som f√∏lger: Hva kan du si karakterfordelingen til de to sensorene? L√∏sning De to sensorene har begge en median rundt 60 poeng, s√• halvparten av alle studenter f√•r under 60 poeng og den andre halvdelen f√•r over 60 poeng. Men Sensor 2 har st√∏rre spredning i sine poeng og vil f√∏lgelig fordele studentene ut mer p√• karakterskalaen sammenlignet med Sensor 1. Du er kvalitetsansvarlig for et produkt og samler inn data p√• levetiden i m√•neder til produktet. Et histogram over disse dataene ser ut som f√∏lger: Hva sier histogrammet deg om produktet? L√∏sning Her ser vi en slags badekar-formet fordeling som ofte g√•r igjen for levetiden til produkter. En rekke produkter g√•r i stykker de f√∏rste m√•nedene. Dette kan v√¶re pga av produksjonsfeil som da sl√•r ut tidlig i bruksperioden. Resten av produktene har en mer normalfordelt levetid med et gjennomsnitt rundt 120 m√•neder. Kovariansen til to variabler fra et utvalg har blitt beregnet til -150. Videre f√•r du vite at empirisk standardavviket til den ene variabelen er 12 og 16 for den andre. Regn ut (utvalgs-) korrelasjonskoeffisienten \\(r\\) og bruk denne til √• beskrive sammenhengen mellom variablene. L√∏sning Utvalgs korrelasjonskoeffisient er definert som utvalgskovariansen mellom to variabler delt p√• de empiriske standardavvikene til variablene. \\[r=s_{xy}/(s_x s_y )=-150/(16\\cdot12)=-0,7813\\] Korrelasjonskoeffisienten er alltid mellom -1 og 1 og m√•ler graden av line√¶r sammenheng mellom variablene. N√•r korrelasjonskoeffisienten er -1 er det en perfekt negativ line√¶r sammenheng, og n√•r den er 1 vil det si at det er en perfekt positiv line√¶r sammenheng mellom variablene. N√•r korrelasjonskoeffisienten er 0 vil det si at ikke er noen line√¶r sammenheng mellom variablene, men vi kan allikevel ikke si at de er uavhengige. Korrelasjonskoeffisienten -0,78 indikerer en moderat til sterk negativ line√¶r sammenheng mellom variablene. Betrakt spredningsplottene for datasett a-d under, og par hvert datasett med en av de f√∏lgende korrelasjonene: \\[r_1 = -0.37,\\quad r_2 = 0.81,\\quad r_3 = -0.02,\\quad r_4 = -0.96 \\] L√∏sning Datasett a: \\(r_2 = 0.81\\), Datasett b: \\(r_1 = -0.37\\), Dasett c: \\(r_4 = -0.96\\), Datasett d: \\(r_3 = -0.02\\) Datasett d er et eksempel p√• at korrelasjonen mellom to variabler kan v√¶re sv√¶rt n√¶r 0, selv om det er en tydelig (ikke-line√¶r) sammenheng mellom dem. Det som skjer n√•r vi regner ut \\(r\\) i dette tilfellet er at den negative avhengigheten vi ser til venstre i figuren kanselleres av den positive avhengigheten til h√∏yre i figuren. En normalfordelt populasjon har gjennomsnitt 40 og standardavvik 12. Hva sier sentralgrenseteoremet om gjennomsnittet av et utvalg p√• 100 observasjoner fra denne populasjonen? Dersom populasjonen ikke var normalfordelt, hvordan endrer dette svaret ditt i a? L√∏sning Dersom populasjonen er normalfordelt s√• vil ogs√• gjennomsnittet av et utvalg av populasjonen v√¶re normalfordelt. Gjennomsnittet vil ha forventning \\(40\\) og ha standardavvik \\(12/\\sqrt{100} = 1.2\\). Sentralgrenseteoremet sier at fordelingen til gjennomsnittet vil for alle praktiske form√•l n√¶rme seg normalfordelingen n√•r antall observasjoner √∏ker, uavhengig av fordelingen til populasjonen. Dette endrer alts√• ikke konklusjonen om fordelingen til utvalget. La \\(X_1, X_2,\\dots X_n\\) v√¶re utfallet av en rekke kast med en tilfeldig terning. Hva er \\(P(X_1 = 1)\\) og \\(P(X_1 = 6)\\)? Hva er \\(P(\\overline{X} = 1)\\) og \\(P(\\overline{X} = 6)\\) dersom \\(n = 2\\)? Hva er \\(P(\\overline{X} = 1)\\) og \\(P(\\overline{X} = 6)\\) dersom \\(n = 5\\)? L√∏sning \\(P(X_1 = 1) = P(X_2 = 6) = 1/6\\) Det er bare en m√•te at gjennomsnittet av to kast kan bli \\(1\\) og det er at begge kastene blir \\(1\\): \\(P(\\overline{X} = 1) = P(X_1 = 1, X_2 = 1) = P(X_1 = 1)P(X_2 = 1) = 1/36\\), og tilsvarende for \\(P(\\overline{X} = 6)\\). Det er bare en m√•te at gjennomsnittet av 5 kast kan bli \\(1\\) og det er at alle fem kastene blir \\(1\\):\\(P(\\overline{X} = 1) = P(X_1 = 1)P(X_2 = 1)P(X_3 = 1)P(X_4 = 1)P(X_5 = 1) = 0.00013\\), og tilsvarende for \\(P(\\overline{X} = 6)\\). Denne oppgaven illustrerer hvordan gjennomsnittet, uavhengig av fordelingen til \\(X\\) som i dette tilfellet er uniformt fordelt p√• \\({1,2,3,4,5,6}\\), er normalfordelt \\(\\overline{X}\\sim N(\\mu, \\sigma^2/n)\\) og beveger seg mot forventningen til \\(X\\) (som i dette tilfellet er \\(\\mu = 3.5\\)). Det at variansen til gjennomsnittet \\(\\sigma^2/n\\) blir mindre n√•r \\(n\\) √∏ker ser vi er sv√¶rt logisk her: Det er v√¶rre for gjennomsnittet til terningkastene √• oppn√• ‚Äúekstreme‚Äù verdier som \\(\\overline{X} = 1\\) eller \\(\\overline{X} = 6\\) siden dette inneb√¶rer at alle kastene m√• enten v√¶re 1 eller 6. Derimot er det en hel rekke kombinasjoner av kast som gir et gjennomsnitt n√¶r \\(3.5\\), s√• slike verdier av gjennomsnittet er mye mer sannsynlig. Under ser du et histogram over gjennomsnittene dersom vi gjentar terningkasteksperimentet med henholdsvis \\(n=1,2, 5\\) kast 2000 ganger. Allerede for \\(n=5\\) ser vi at de fleste gjennomsnitt ligger n√¶r det sanne gjennomsnittet p√• 3.5. La \\(\\hat{p}=X/n\\) v√¶re den estimerte suksessannsynligheten i et binomisk eksperiment \\(X\\) med \\(n=300\\) fors√∏k og (populasjons) suksessannsynlighet \\(p\\). Hva er sannsynligheten for at \\(\\hat{p}\\) er h√∏yere enn 60% dersom \\(p = 0.5\\)? Gjenta oppgave a med \\(p = 0.55\\). Gjenta oppgave a med \\(p = 0.60\\). L√∏sning Her bruker vi sentralgrenseteoremet som sier at \\(\\hat{p}\\sim N(p, p(1-p))\\): \\[P(\\hat{p} &gt; 0.60) = P\\left(\\frac{\\hat{p} - p}{\\sqrt{p(1 - p)/n}} &gt; \\frac{0.60 - 0.5}{\\sqrt{0.5(1 - 0.5)/300}}\\right) = P(Z &gt; 3.46)\\approx 0\\]. \\[\\begin{equation*} \\begin{split} P(\\hat{p} &gt; 0.60) &amp;= P\\left(\\frac{\\hat{p} - p}{\\sqrt{p(1 - p)/n}} &gt; \\frac{0.60 - 0.55}{\\sqrt{0.55(1 - 0.55)/300}}\\right)\\\\ &amp;= P(Z &gt; 1.74)= 1 - P(Z &lt; 1.74) = 1 - 0.9591 = 0.0409. \\end{split} \\end{equation*}\\] \\[\\begin{equation*} \\begin{split} P(\\hat{p} &gt; 0.60) &amp;= P\\left(\\frac{\\hat{p} - p}{\\sqrt{p(1 - p)/n}} &gt; \\frac{0.60 - 0.60}{\\sqrt{0.60(1 - 0.60)/300}}\\right)\\\\ &amp;= P(Z &gt; 0)= 0.5\\quad\\text{(p.g.a. $Z$&#39;s symmetri rundt 0)}. \\end{split} \\end{equation*}\\] Vi ser at for \\(n=300\\) vil \\(\\hat{p}\\) sin normalfordeling v√¶re sv√¶rt konsentrert rundt \\(p\\) (variansen er \\(p(1-p)/n\\)) og at en overstigelse p√• 0.05 eller mer fra den sanne suksessannsynligheten (som i oppgave a.) er sv√¶rt usannsynlig. Anta at vi har to normalfordelte populasjoner hvor observasjoner fra populasjon 1 f√∏lger en \\(N(40, 6^2)\\) og observasjoner fra populasjon 2 f√∏lger en \\(N(38, 8^2)\\). Dersom man trekker 25 tilfeldige observasjoner fra hver populasjon, hva er sannsynligheten for at gjennomsnittet til trekningen fra populasjon 1 er st√∏rre enn gjennomsnittet til trekningen fra populasjon 2? L√∏sning Vi vet da at \\(\\overline{X}_1 - \\overline{X}_2 &gt; 0\\) og utnytter at denne st√∏rrelsen er normalfordelt: \\[\\begin{equation*} \\begin{split} P(\\overline{X}_1 - \\overline{X}_2 &gt; 0) &amp;= P\\left(\\frac{\\overline{X}_1 - \\overline{X}_2 - (40 - 38)}{\\sqrt{\\frac{6^2}{25} + \\frac{8^2}{25}}} &gt; \\frac{0 - (40 - 38)}{\\sqrt{\\frac{6^2}{25} + \\frac{8^2}{25}}} \\right)\\\\ &amp;= P(Z &gt; -1) = 1 - P(Z &lt; -1) = 1 - 0.1587 = 0.8413 \\end{split} \\end{equation*}\\] Produsenten av en kaviar forteller deg at hver tube er reklamert til √• veie 65 gram, men at maskinen som produserer kaviaren gir en vekt som er en normalfordelt med gjennomsnitt lik 65,5 gram og standardavvik 3.6 gram. La oss si at du trekker et tilfeldig utvalg av 40 tuber for √• unders√∏ke denne p√•standen og at det tilfeldige utvalget har en gjennomsnittlig vekt lavere enn 64. Hva er sannsynligheten for dette utfallet? Kommenter p√•standen til produsenten. L√∏sning \\[P(\\overline{X} &lt; 64) = P\\left(\\frac{\\overline{X} - 65.5}{3.6/\\sqrt{40}} &lt; \\frac{64 - 65.5}{3.6/\\sqrt{40}}\\right) = P(Z &lt; - 2.63) = 0.004\\] Det er sv√¶rt usannsynlig at vi observerer et gjennomsnitt mindre enn 64 dersom det er sant at maskinen produserer tuber som er normalfordelt med gjennomsnitt 65.5 og standardavvik 3.6. S√• p√•standen er nok feil. Enten produserer maskinen vekter som er mindre, eller s√• er standardavviket st√∏rre. En selger av robotgressklippere p√•st√•r at bare 4% av produktene m√• p√• service innen det f√∏rste √•ret etter installasjon. Du skal unders√∏ke om p√•standen stemmer og sp√∏r et tilfeldig utvalg av 100 husholdninger som har kj√∏pt robotgressklippere om de hadde den p√• service det f√∏rste √•ret. Hva vil du si om selgerens p√•stand dersom mer enn 6% svarer at de har hatt behov for service? Anta n√• at du istedet spurte 400 hustander. Hva vil du si om selgerens p√•stand dersom mer enn 6% svarer at de har hatt behov for service? L√∏sning Da har vi alts√• en estimert service sannsynlighet p√• \\(\\hat{p} = 0.06\\) eller mer. For √• finne ut om dette avviket fra 0.04 skyldes naturlig variasjon eller om den faktiske service raten er st√∏rre enn 0.04 regner vi ut sannsynligheten for dette utfallet: \\[\\begin{equation*} \\begin{split} P(\\hat{p}&gt;0.06) &amp;= P\\left(\\frac{\\hat{p} - 0.04}{\\sqrt{0.04(1-0.04)/100}}&gt; \\frac{0.06 - 0.04}{\\sqrt{0.04(1-0.04)/100}}\\right)\\\\ &amp;= P(Z &gt; 1.02) = 1 - P(Z &lt; 1.02) = 1 - 0.8561 = 0.1539 \\end{split} \\end{equation*}\\] Det er alts√• ikke s√• usannsynlig at \\(\\hat{p} = 0.06\\) eller mer. Vi kan se for oss at vi gjentar den samme sp√∏rreunders√∏kelsen mange ganger. Da kan vi forvente at rundt 15 % av unders√∏kelsene gi en \\(\\hat{p} = 0.06\\) ved ren tilfeldighet selv om populasjonsverdien er \\(p=0.04\\). Selgerens p√•stand er ikke urimelig ved et slikt resultat. Sannsynligheten for et slikt utfall er da \\[\\begin{equation*} \\begin{split} P(\\hat{p}&gt;0.06) &amp;= P\\left(\\frac{\\hat{p} - 0.04}{\\sqrt{0.04(1-0.04)/300}}&gt; \\frac{0.06 - 0.04}{\\sqrt{0.04(1-0.04)/300}}\\right)\\\\ &amp;= P(Z &gt; 2.04) = 1 - P(Z &lt; 2.04) = 1 - 0.9793 = 0.02 \\end{split} \\end{equation*}\\] N√• har vi spurt flere husstander og vi ser at den samme estimerte service sannsynligheten (6 %) n√• er mye mer usannsynlig √• f√• dersom det faktisk er slik at bare 4 % trenger service. Selgerens p√•stand ville alts√• v√¶rt mer tvilsom ved et slik resultat. Forventningsrette estimatorer. Hva vil det si at en estimator er forventningsrett? Vis at hvis \\(X_1, X_2,\\dots X_n\\) er observasjoner fra en populasjon der \\(E(X_i) = \\mu\\) s√• er gjennomsnittet \\(\\overline{X}\\) en forventningsrett estimator av \\(\\mu\\). Vis at hvis \\(X\\) er et binomisk fors√∏k med \\(n\\) fors√∏k og suksessannsynlighet \\(p\\) s√• er \\(\\hat{p} = X/n\\) en forventningsett estimator av \\(p\\). L√∏sning Hvis \\(\\hat{\\theta}\\) er en estimator av \\(\\theta\\) s√• er \\(\\hat{\\theta}\\) en forventningsrett estimator dersom \\(E(\\hat{\\theta}) = \\theta\\). \\[\\begin{equation*} \\begin{split} E(\\overline{X}) &amp;= E\\left(\\frac{1}{n}(X_1 + X_2 + .. + X_n)\\right) = \\frac{1}{n}(E(X_1) + E(X_2) + ... + E(X_n))\\\\ &amp;= \\frac{1}{n}(\\mu + \\mu + ... + \\mu) = \\frac{1}{n}\\cdot n\\mu = \\mu \\end{split} \\end{equation*}\\] Vi husker at en binomisk variabel \\(X\\) har forventning \\(np\\). Alts√• er \\[E\\left(\\frac{X}{n}\\right) = \\frac{1}{n}E(X) = \\frac{1}{n}\\cdot np = p\\] Konsistente estimatorer. Hva vil det si at en estimator er konsistent? Vis at hvis \\(X_1, X_2,\\dots X_n\\) er observasjoner fra en populasjon der \\(\\text{Var}(X_i) = \\sigma^2\\) s√• er \\(\\text{Var}(\\overline{X}) = \\sigma^2/n\\). Bruk dette resultatet sammen med resultatet i 19 b til √• forklare at \\(\\overline{X}\\) er en konsistent estimator av \\(\\mu\\). Vis at hvis \\(X\\) er et binomisk fors√∏k med \\(n\\) fors√∏k og suksessannsynlighet \\(p\\) s√• er \\(\\text{Var}(\\hat{p}) = p(1-p)/n\\). Bruk dette resultatet sammen med resultatet fra 19 c til √• forklare at \\(\\hat{p}\\) er en konsistent estimator av \\(p\\). L√∏sning En estimator er konsistent hvis forskjellen mellom estimatoren og parameteren blir mindre n√•r st√∏rrelsen p√• utvalget √∏ker. \\[\\begin{equation*} \\begin{split} \\text{Var}(\\overline{X}) &amp;= \\text{Var}\\left(\\frac{1}{n}(X_1 + X_2 + .. + X_n)\\right) = \\left(\\frac{1}{n}\\right)^2(\\text{Var}(X_1) + \\text{Var}(X_2) + \\dots + \\text{Var}(X_n))\\\\ &amp;= \\left(\\frac{1}{n}\\right)^2(\\sigma^2 + \\sigma^2 + ... + \\sigma^2) = \\left(\\frac{1}{n}\\right)^2\\cdot n\\sigma^2 = \\frac{\\sigma^2}{n} \\end{split} \\end{equation*}\\] Vi vet fra f√∏r at \\(E(\\overline{X}) = \\mu\\). Vi ser av utrykket over at variansen til \\(\\overline{X}\\) avtar n√•r \\(n\\) √∏ker alts√• vil forskjellen mellom \\(\\overline{X}\\) og \\(\\mu\\) bli mindre jo st√∏rre utvalg vi f√•r. Vi husker at en binomisk variabel har varians \\(\\text{Var}(X) = np(1 - p)\\). Alts√• er \\[\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\frac{X}{n}\\right) = \\left(\\frac{1}{n}\\right)^2 \\cdot\\text{Var}(X) = \\left(\\frac{1}{n}\\right)^2\\cdot np(1 - p) = \\frac{p(1 - p)}{n}\\] Igjen ser vi at variansen avtar n√•r \\(n\\) √∏ker alts√• vil forskjellen mellom \\(\\hat{p}\\) og \\(p\\) bli mindre jo st√∏rre utvalg vi f√•r. 2.3.2 N√∏tter N√∏tt 1. Korrelasjon er enten knyttet til et bestemt utvalg, eller en populasjon/modell, men vi sier sjelden ‚Äúutvalgskorrelasjon‚Äù eller ‚Äúpopulasjonskorrelasjon‚Äù og vi m√• ofte bare forst√• dette ut fra situasjonen eller notasjonen (\\(r\\) versus \\(\\rho\\)). Men utvalgskorrelasjonen \\[r = s_{xy}/(s_xs_y)=\\frac{\\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\overline{x})^2\\frac{1}{n-1}\\sum_{i = 1}^n(y_i - \\overline{y})^2}}\\] et alts√• en estimator av populasjonskorrelasjonen \\[\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x\\sigma_y} = \\frac{E\\left[(X - E(X))(Y - E(Y))\\right]}{\\sigma_x\\sigma_y}\\]. Det betyr i praksis at \\(r\\) kommer med en usikkerhet siden den er basert p√• data. Det kan vises at dersom den simultane fordelingen til \\(X\\) og \\(Y\\) er en s√•kalt bivariat normalfordeling s√• vil vi for store utvalg ha at samplingfordelingen til \\(r\\) er tiln√¶rmet normalfordelt med forventning \\(\\rho\\) og standardavvik \\(\\frac{(1 - \\rho^2)}{\\sqrt{n}}\\): \\[r\\sim N\\left(\\rho, \\frac{(1 - \\rho^2)^2}{n}\\right)\\] Anta at \\(X\\) og \\(Y\\) er bivariat normalfordelt. Forklar at \\(r\\) er en konsistent estimator av \\(\\rho\\). Hva kjennetegner populasjoner hvor \\(\\rho\\) kan estimeres med stor sikkerhet ved hjelp av \\(r\\) fra et utvalg? Beskriv en test av \\(H_0: \\rho = 0\\), mot \\(H_1: \\rho \\neq 0\\). L√∏sning Vi ser at n√•r \\(n\\) blir stor g√•r standardavviket til \\(r\\) mot null, og \\(r\\) vil derfor n√¶rme seg den sanne korrelasjonen \\(\\rho\\) i populasjonen. Vi ser ogs√• at standardavviket til \\(r\\) er mindre jo n√¶rmere \\(\\rho\\) er \\(\\pm 1\\). Utregninger av \\(r\\) basert p√• utvalg fra populasjoner med sterk positiv eller negativ line√¶r avhengighet (\\(\\rho\\) n√¶r \\(\\pm 1\\)) kommer derfor med mindre usikkerhet. En test observator som vil v√¶re tiln√¶rmet normalfordelt er da: \\[Z^* = \\frac{r - 0}{\\frac{(1 - r^2)}{\\sqrt{n}}}\\] og ved et \\(5\\%\\) signifikansniv√• forkaster vi \\(H_0\\) dersom \\(|Z^*|&gt;1.96\\). Merk at sammenlignet med det sanne standardavviket har vi her erstattet \\(\\rho\\) med \\(r\\). Dette er litt som n√•r vi erstatter \\(\\sigma\\) med \\(s\\) i den vanlige \\(Z\\) observatoren (\\(T\\) observatoren). Pga av sentralgrenseteoremet g√•r dette fint for store utvalg. Obs: Det kommer mer om hypotesetesting i neste modul, s√• her foregriper vi begivenhetene litt. N√∏tt 2. Anta at vi har f√∏lgende deterministiske sammenheng mellom variablene \\(X\\) og \\(Y\\): \\[Y = X^2\\] og at \\(X\\) er normalfordelt med forventning \\(0\\). Bruk definisjonen p√• kovarians til √• vise at \\(\\text{cov}(X,Y)=0\\) og at korrelasjonen derfor ogs√• vil v√¶re \\(0\\) mellom disse variablene. Hint: Hvis \\(X\\) er symmetrisk fordelt og har forventning 0, s√• er \\(E(X^3) = 0\\). Hva sier dette resultatet oss om korrelasjon? L√∏sning Bruk definisjonen, erstatt \\(Y\\) med \\(X^2\\) og utnytt at \\(E(X) = E(X^3) = 0\\): \\[\\begin{equation*} \\begin{split} \\text{cov}(X,Y) &amp;= E(XY) - E(X)E(Y)\\\\ &amp;= E(X^3)- E(X)E(X^2)= 0 + 0*E(X^2)=0 \\end{split} \\end{equation*}\\] Dette er et ekstremt eksempel der avhengigheten mellom \\(X\\) og \\(Y\\) er deterministisk (Vet du \\(X\\) s√• vet du \\(Y\\) med 100 % sikkerhet), men korrelasjonen \\(\\rho = \\text{cov}(X,Y)/(\\sigma_X\\sigma_Y)\\) mellom variablene er allikevel 0. Alts√• er det fullt mulig at \\(X\\) og \\(Y\\) er avhengige selv om korrelasjonen mellom \\(X\\) og \\(Y\\) er null. N√∏tt 3. Rulett er et sjansespill der et ruletthjul har 37 nummererte lommer der en kule kan lande. 18 av disse lommene er r√∏de, 18 er svarte og 1 er gr√∏nn (iallefall i Europa). Hvis du f.eks satser 1 krone p√• r√∏d og r√∏d intreffer s√• vinner vi kronen v√•r tilbake og 1 krone til (1 krone i gevinst), mens hvis svart eller gr√∏nn intreffer s√• taper vi hele kronen (-1 krone i gevinst). Du satser 1 krone p√• r√∏d. Hva er forventet gevinst? Hva er variansen til denne gevinsten? Hva er sannsynligheten for en positiv gevinst? Du fortsetter denne strategien \\(n = 50\\) ganger. Bruk sentralgrenseteoremet til √• svare p√• sp√∏rsm√•lene i a. for den gjennomsnittlige gevinsten. Finnes det en (teoretisk) satsingsstrategi for √• sikre positiv gevinst uansett? L√∏sning La \\(X\\) v√¶re gevinsten. Dette er en diskret variabel som bare kan ta to utfall, og den har f√∏lgende sannsynlighetsfordeling: \\(x_i\\) 1 -1 P(X = x_i) 18/37 19/37 For diskret fordelinger som dette har vi at \\[\\mu = E(X) = \\sum_{i = 1}^2 x_i P(X = x_i) = 1\\cdot(18/37) + (-1)\\cdot(19/37) = -0.027\\] For √• finne variansen finner vi f√∏rst \\[E(X^2) = \\sum_{i = 1}^2 x_{i}^2 P(X = x_i) = 1^2\\cdot(18/37) + (-1)^2\\cdot(19/37) = 1\\] og bruker regneregelen \\[\\sigma^2 = \\text{Var}(X) = E(X^2) - (E(X))^2 = 1 - (-0.027)^2 = 0.999\\] Sannsynligheten for positiv gevinst svarer til sannsynligheten for at ballen treffer r√∏d, alts√• \\(18/37 = 0.4864\\). Sentralgrenseteoremet sier at n√•r vi spiller et relativt stort antall runder s√• er \\(\\overline{X}\\) normalfordelt med forventning \\(E(\\overline{X}) = \\mu = -0.027\\) og varians \\(\\text{Var}(\\overline{X})=\\sigma^2/n = 0.999/50 = 0.02\\). Sannsynligheten for at den gjennomsnittlige gevinsten er positiv blir alts√• \\[\\begin{equation*} \\begin{split} P(\\overline{X}&gt;0) &amp;= P\\left(\\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} &gt; \\frac{0 - \\mu}{\\sigma/\\sqrt{n}}\\right) = P\\left(Z &gt; \\frac{0 - (-0.027)}{\\sqrt{0.02}}\\right)\\\\ &amp;= P(Z&gt;0.19) = 1 - P(Z &lt; 0.19) = 0.4246 \\end{split} \\end{equation*}\\] Kasinoer vet med andre ord √• utnytte sentralgrenseteoremet. Har du noen penger (som du har r√•d til √• tape) s√• sett hele bel√∏pet p√• en farge og spill 1 gang, framfor √• plassere sm√•bel√∏p over lang tid. Det finnes noen strategier som kan sikre positiv gevinst, men som i praksis krever sv√¶rt mye egenkapital og at det ikke er noe tak for hvor mye du kan satse ved bordet. Den s√•kalte Martingal strategien g√•r ut p√• at du dobler innsatsen etter hvert tap og gir deg ved f√∏rste gevinst. Gevinsten vil da svare til det f√∏rste bel√∏pet du satset. "],["relevant-r-grunnleggende.html", "2.4 Relevante R-kommandoer", " 2.4 Relevante R-kommandoer Under f√∏lger en liste over hvilke oppgaver du skal klare i R fra denne modulen. V√•r policy fra og med v√•rsemesteret 2022 er at R-kommandoene under er tilstrekkelige for √• l√∏se oppgavene i datalabber og hjemmeeksamen i MET4. Det er med andre ord ikke n√∏dvendig √• l√¶re seg teknikker utover det som er listet opp eksplisitt i listen under. Eventuelle nye teknikker som trengs for √• l√∏se en bestemt oppgave vil bli oppgitt og forklart dersom det er n√∏dvendig. Det antas i tillegg at du kan den grunnleggende R-syntaksen som er dekket under Introduksjon til R. Antakelser om datasett Det antas at du har kontroll p√• hvilken mappesti R bruker, og at du kan forandre den dersom n√∏dvendig. I denne modulen kan du anta at alle datasett best√•r av \\(p\\) kolonner (variabler) med variabelnavn og \\(n\\) rader (observasjoner). Datasettene blir gitt enten som Excel-filer (.xls elle .xlsx) eller som .csv-filer. Dersom du √∏nsker √• pr√∏ve p√• kommandoene selv, kan du laste ned f√∏lgende eksempelfiler: data.xls, data.xlsx, data.csv. Excel-filer kan leses inn i R ved hjelp av read_excel() som ligger i readxl-pakken: library(readxl) data &lt;- read_excel(&quot;data.xls&quot;) # ...eller dersom det er en .xlsx-fil: data &lt;- read_excel(&quot;data.xlsx&quot;) .csv-filer kan lastes inn i R ved hjelp av read_csv() som ligger i readr-pakken: library(readr) data &lt;- read_csv(&quot;data.csv&quot;) ‚Äúcsv‚Äù er en forkortelse for ‚Äúcomma separated values‚Äù, og grunnen til det kan du se ved √• √•pne opp data.csv i en ren tekst-editor. Da ser du at verdiene p√• rekken er separert med et komma. Av og til har disse filene litt andre formater, s√• vi m√• kunne h√•ndtere f√∏lgende varianter: Dersom det ikke er komma som er brukt til √• separere verdiene (det kan du alltid sjekke ved √• se p√• filen i en tekst-editor), s√• kan du bruke funksjonen read_delim i stedet for read_csv, og bruke et argument for √• spesifisere hvilket tegn som er brukt. Dersom det for eksempel er brukt semikolon ‚Äú;‚Äù, kan du lese datasettet ved √• bruke read_delim(\"data.xlsx\", delim = \";\"). Dersom komma er brukt for √• skille desimaler fra heltall, som er vanlig i europeiske datasett, kan du bruke f√∏lgende kommando (der vi fortsatt antar at semikolon blir brukt til √• skille mellom kolonner): read_delim(\"data.xlsx\", delim = \";\", locale = locale(decimal_mark = \",\"). Dersom en bestemt tekst-streng blir brukt til √• indikere manglende verdier i datasettet kan du bruke argumentet na i read_csv() og read_delim() til √• spesifisere denne tekst-strengen, slik at den blir tolket riktig ved innlesingen som manglende verdi. Dette argumentet fungerer ogs√• i read_excel(). Numerisk deskriptiv statistikk Vi bruker eksempeldatasettene data_survey.csv og data_fishermen_mercury.csv som eksempler. Du skal kunne bruke f√∏lgende funksjoner for √• regne ut numerisk deskriptiv statistikk: survey &lt;- read_csv(&quot;data_survey.csv&quot;) fishermen &lt;- read_csv(&quot;data_fishermen_mercury.csv&quot;) mean(survey$age) # Gjennomsnitt median(survey$age) # Median table(survey$party) # Kan lese av typetallet manuelt. which.max(table(survey$party)) # Eller bruke funksjonen which.max() sd(fishermen$total_mercury) # Standardavvik quantile(fishermen$total_mercury, 0.20) # Kvantiler quantile(fishermen$total_mercury) # Kvartilene cor(fishermen$height, fishermen$weight) # Korrelasjonskoeffisient table(survey$religious) # Frekvenstabell survey %&gt;% # Krysstabell av to variabler (krever select(party, religious) %&gt;% # pipe-operatoren og select()-funks. table # fra dplyr-pakken) Grafisk deskriptiv statistikk med ggplot2 Du skal kunne lage f√∏lgende plott ved hjelp av ggplot2-pakken; library(ggplot2) # Boksplott fishermen %&gt;% ggplot + geom_boxplot(aes(y = total_mercury)) # Deler opp i grupper basert p√• en annen variabel fishermen %&gt;% ggplot + geom_boxplot(aes(y = total_mercury, x = as.factor(fisherman))) # S√∏ylediagram survey %&gt;% ggplot + geom_bar(aes(x = as.factor(religious))) # Histogram survey %&gt;% ggplot + geom_histogram(aes(x = age)) # Spredningsplott fishermen %&gt;% ggplot + geom_point(aes(x = height, y = weight)) Du skal kunne grunnleggende bearbeiding av ggplot-figurer: # En bearbeidet variant fishermen %&gt;% ggplot + geom_point(aes(x = height, y = weight)) + # Dette er selve figuren xlab(&quot;H√∏yde&quot;) + # Tittel x-akse ylab(&quot;Vekt&quot;) + # Tittel y-akse ggtitle(&quot;Sammenheng mellom h√∏yde og vekt&quot;) + # Tittel plott theme_classic() # Ryddig layout "],["hypotesetesting.html", " 3 Hypotesetesting", " 3 Hypotesetesting Hypotesetesting er et klassisk tema i statistikk. Vi skal f√∏rst l√¶re generelt om hva det egentlig vil si √• teste en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting ikke er. Vi g√•r s√• videre til √• l√¶re noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R. I videoforelesningene g√•r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved √• klikke p√• lenkene under: Slides til ‚ÄúHypotesetesting‚Äù R-script til ‚ÄúHypotesetesting‚Äù TIPS: Hvis du √∏nsker √• laste ned lysbildene som PDF trykker du p√• linken over, velger ‚ÄúSkriv ut‚Äù, og s√• skriver du ut som PDF. F√∏r du gj√∏r det b√∏r du scrolle gjennom alle sidene slik at ligningene vises korrekt. "],["generelt-om-hypotesetesting.html", "3.1 Generelt om hypotesetesting", " 3.1 Generelt om hypotesetesting 3.1.1 Videoforelesninger 3.1.2 Kommentarer Her snakker vi om kapittel 11 i l√¶reboken. Hvis du kan svare p√• f√∏lgende sp√∏rsm√•l har du i all hovedsak f√•tt med deg de viktigste begrepene: Hva vil det si √• gjennomf√∏re en hypotesetest? Hva er Type I-feil og hva er Type II-feil? (Seksjon 11-1 forklarer dette greit) Hva er signifikansniv√•et (\\(\\alpha\\)) til en test? Styrken (the power) til en test er definert som \\(1-P(\\textrm{Type II-feil})=1-\\beta\\). Hvordan tolker du denne st√∏rrelsen? Se ogs√• 11-3d. Hva er \\(p\\)-verdien til en test (Seksjon 11-2c)? Les ogs√• 11-2d, e og f om hvordan vi fortolker og snakker om \\(p\\)-verdien p√• en korrekt m√•te. Vi kommer tilbake til dette i kapittel 3.2. "],["enpop.html", "3.2 Inferens om en populasjon", " 3.2 Inferens om en populasjon 3.2.1 Videoforelesninger 3.2.2 Kommentarer Dette er i hovedsak dekket av kapittel 12 i l√¶reboken. Sjekk om du kan svare p√• f√∏lgende kontrollsp√∏rsm√•l: Hva er det vi tester n√•r vi gjennomf√∏rer en \\(t\\)-test for √©n populasjon? Hva forutsetter vi? Hva er forskjellen p√• en ensidig og en tosidig test? (11-2j) Det kan ogs√• v√¶re greit √• repetere konfidensintervaller i seksjon 11-2k for de som har glemt det fra MET2. I Seksjon 11-2g g√•r boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gj√∏re det samme i R. P√• kursets nettside finner du alle datasettene som f√∏lger med l√¶reboken. I dette eksempelet er det snakk om Xm11-01.xlsx. Finn tak i denne filen (du kan ogs√• godt √•pne den og se p√• den i Excel!), legg den i en mappe som du kan finne igjen, og √•pne et nytt script i R-studio der du f√∏rst s√∏rger for √• sette working directory til denne mappen slik vi gjorde i R-forelesningen. Etterp√• leser du inn datasettet ved √• bruke read_xlsx()-funksjonen som under: library(readxl) data &lt;- read_xlsx(&quot;Xm11-01.xlsx&quot;) # Vi bruker read_xslx() fordi det er en .xlsx-fil Konteksten til datasettet er gitt i eksempel 11.1. Det er alts√• balansen p√• 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer p√• om forventet balanse er st√∏rre enn 170. Vi setter opp f√∏lgende test: \\[\\begin{align*} &amp;H_0: \\mu = 170 \\\\ &amp;H_A: \\mu &gt; 170, \\end{align*}\\] der vi legger merke til at det blir brukt en ensidig test (hvorfor?). For √• regne ut testobservatoren for √• enutvalgs \\(z\\)-test trenger vi fire tall: \\(\\overline X\\), \\(\\mu_0\\), \\(n\\) og \\(\\sigma\\). Legger merke til at data har en kolonne som heter Accounts, og vi bruker dollartegnet til √• hente den ut som en vektor. Regner ut observatoren: gj.snitt &lt;- mean(data$Accounts) # Gjennomsnittet av observasjonene mu0 &lt;- 170 # Henter fra teksten n &lt;- length(data$Accounts) # Antall observasjoner sigma &lt;- 65 # Henter fra teksten Z &lt;- (gj.snitt - mu0)/(sigma/sqrt(n)) # Verdien av testobservatoren Z # Skriver ut testobservatoren ## [1] 2.460462 Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R: qnorm(0.95) ## [1] 1.644854 Uansett; vi forkaster \\(H_0\\) siden testobservatoren er st√∏rre enn kritisk verdi. Kapittel 11-3a-d gir enda mer forst√•else for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre. Kapittel 12 presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du f√∏rst og fremst m√• kunne fra dette kapitlet er √• gjennomf√∏re disse testene, b√•de for h√•nd med penn og papir, og i R. Under f√∏lger kode for √• gj√∏re noen av bokens eksempler i R (les i boken for kontekst): Eksempel 12.1: \\[\\begin{align*} &amp;H_0: \\mu = 2.0 \\\\ &amp;H_A: \\mu &gt; 2.0, \\end{align*}\\] data &lt;- read_xlsx(&quot;Xm12-01.xlsx&quot;) # Manuell utregning gj.snitt &lt;- mean(data$Newspaper) mu0 &lt;- 2.0 n &lt;- length(data$Newspaper) s &lt;- sd(data$Newspaper) # Testobservator: (gj.snitt - mu0)/(s/sqrt(n)) ## [1] 2.236869 Signifikansniv√•et er satt til \\(\\alpha = 1\\%\\) i eksempelet. Kritisk verdi finner vi i \\(t\\)-tabell eller rett fra R: qt(0.99, df = n-1) ## [1] 2.351983 Alts√• forkaster vi ikke nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som st√•r i boken. Alternativt bruker vi t.test()-funksjonen direkte: t.test(data$Newspaper, alternative = &quot;greater&quot;, mu = 2.0, conf.level = 0.99) ## ## One Sample t-test ## ## data: data$Newspaper ## t = 2.2369, df = 147, p-value = 0.0134 ## alternative hypothesis: true mean is greater than 2 ## 99 percent confidence interval: ## 1.990716 Inf ## sample estimates: ## mean of x ## 2.180405 Resultatet blir selvsagt det samme. N√•r \\(p\\)-verdien er st√∏rre enn signifikansniv√•et p√• 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om √• lage kondidensintervall, noe du ogs√• kan pr√∏ve √• gj√∏re ved √• regne ut de n√∏dvendige tallene i R. De som synes dette er greit kan kikke p√• seksjonene 12-1b-e for √• utvikle forst√•elsen enda litt mer. Eksempel 12.3: \\[\\begin{align*} &amp;H_0: \\sigma^2 = 1.0 \\\\ &amp;H_A: \\sigma^2 &lt; 1.0. \\end{align*}\\] Testobservator: \\[\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2}.\\] data &lt;- read_xlsx(&quot;Xm12-03.xlsx&quot;) # Regner ut testobservatoren direkte denne gangen, uten √• lagre tallene underveis: (length(data$Fills) - 1)*var(data$Fills)/1 # Kritisk verdi, 5% niv√•, ensidig test, nedre hale: qchisq(0.05, df = length(data$Fills) - 1) ## [1] 15.2 ## [1] 13.84843 Vi kan alts√• ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for √• forst√• bedre hva som skjer. Figur 12.4 viser p√• en fin m√•te hva tallene betyr. Eksempel 12.5 kan v√¶re grei √• kikke p√• ogs√•. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste: \\[\\begin{align*} &amp;H_0: p = 0.5 \\\\ &amp;H_A: p &gt; 0.5. \\end{align*}\\] Vi har en observert andel p√• \\(\\widehat p = 407/765 = 0.532\\) etter √• ha spurt \\(n = 765\\) personer. Testobservatoren er \\[Z = \\frac{\\widehat p - p}{\\sqrt{p(1-p)/n}}.\\] p.hatt &lt;- 407/765 p0 &lt;- 0.5 n &lt;- 765 (p.hatt - p0)/sqrt(p0*(1-p0)/n) ## [1] 1.771599 Kritisk verdi for en ensidig z-test p√• 5% niv√• er 1.645 (qnorm(0.95)), og vi kan forkaste nullhypotesen. Seksjonene 12-3d-f b√∏r leses p√• egen h√•nd, mens vi hopper over 12-3g. "],["inferens-om-to-populasjoner.html", "3.3 Inferens om to populasjoner", " 3.3 Inferens om to populasjoner 3.3.1 Videoforelesninger 3.3.2 Kommentarer Vi har g√•tt gjennom kapittel 13, som i all hovedsak handler om √• sammenligne to gjennomsnitt (som vi kan gj√∏re p√• tre forskjellige m√•ter), to varianser og to andeler. Her f√∏lger noen kontrollsp√∏rsm√•l som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper: Hva er nullhypotesen n√•r vi skal gjennomf√∏re en t-test for to populasjoner? ‚Ä¶ og hvilke antagelser m√• vi gj√∏re? Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj√∏r? N√•r kan vi bruke matchede par, og hva er hensikten? Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen? Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj√∏r? Hvilken test brukes for √• teste om to andeler er like, og hva m√• du anta? Videre b√∏r du sjekke at du kan utf√∏re 3 typer \\(t\\)-tester, test for like varianser og test for like andeler b√•de for h√•nd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber). Den enkleste m√•ten √• gj√∏re \\(t\\)-tester i R p√• er √• bruke funksjonen t.test(). Kikk p√• eksempel 13.1 i l√¶rebokens 11. utgave, der vi har observert √•rlige avkastninger til to aksjefond som er kj√∏pt henholdsvis med og uten megler. # Leser inn datasettet funds &lt;- read_xlsx(&quot;Xm13-01.xlsx&quot;) # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = FALSE, conf.level = 0.95) ## ## Welch Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 97.489, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.79661 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Du kan s√• sjekke at du f√•r ut de samme tallene p√• s. 434‚Äì435. Videre kan du skrive inn ?t.test i R-konsollen i RStudio for √• lese mer om hvilke argumenter vi kan bruke i t.test()-funksjonen. Der ser vi at argumentene paired, var.equal og conf.level som utgangspunkt allerede er satt til FALSE, FALSE og 0.95 henholdsvis, s√• det hadde vi strengt tatt ikke trengt √• spesifisere i funksjonskallet over. Vi kan enkelt kj√∏re den samme testen under antakelsen om like varianser ved √• sette var.equal = TRUE: # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = TRUE, conf.level = 0.95) ## ## Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 98, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.7967156 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Resultatet bli akkurat det samme. Siden testens \\(p\\)-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og sl√• fast at forskjellen i gjennomsnitt er statistisk signifikant. I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner i de to populasjonene, s√• vi kan tenke oss at m√•lingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om gjennomsittet av differansene er signifikant forskjellig fra null. Enkelt: # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = TRUE, conf.level = 0.95) ## ## Paired t-test ## ## data: funds$Direct and funds$Broker ## t = 2.5178, df = 49, p-value = 0.007563 ## alternative hypothesis: true mean difference is greater than 0 ## 95 percent confidence interval: ## 0.9716497 Inf ## sample estimates: ## mean difference ## 2.908 Da ser vi at \\(p\\)-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du pr√∏ve selv. Pass p√• at du kan gj√∏re beregningene manuelt ogs√•, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forst√•r hva som foreg√•r. Kapittel 13-2 omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig √• sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen v√•r av statistiske resultater. Det er et eksplisitt krav for √• lykkes i MET4 at du er i stand til √• sette resultatene inn i en fornuftig kontekst. I kapittel 13-4 kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R: bottle &lt;- read_xlsx(&quot;Xm13-07.xlsx&quot;) var.test(bottle$`Machine 1`, bottle$`Machine 2`, alternative = &quot;greater&quot;) ## ## F test to compare two variances ## ## data: bottle$`Machine 1` and bottle$`Machine 2` ## F = 1.3988, num df = 24, denom df = 24, p-value = 0.2085 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 0.7051295 Inf ## sample estimates: ## ratio of variances ## 1.398807 Ogs√• her kan du sammenligne med tallene som fremg√•r av bokens gjennomgang, og s√∏rg for at du f√•r til dette p√• egen h√•nd, spesielt det √• finne frem i tabellen, for det m√• du kunne p√• eksamen. Til slutt har vi test for to andeler i kapittel 13-5. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er like (\\(p_1 - p_2 = 0\\)), som er det vi har dett p√• i forelesning, men det g√•r selvsagt like fint √• sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall \\(D\\). Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved √• regne ut testobservatoren fra datasettet. Vi ser p√• eksempel 13.9, der vi f√•r oppgitt salget av en del forskjellige varenummer, og vi √∏nsker √• finne ut om andelen ¬´9077¬ª er st√∏rre i Supermarked 1 enn i Supermarked 2: # Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, s√• jeg # velger √• lese inn de to kolonnene hver for seg: soap1 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;A&quot;)) soap2 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;B&quot;)) # Hvor stor andel utgj√∏r ¬´9077¬ª i de to kolonnene? p1 &lt;- mean(soap1 == 9077) p2 &lt;- mean(soap2 == 9077) # De to utvalgsst√∏rrelsene: n1 &lt;- nrow(soap1) n2 &lt;- nrow(soap2) # Felles estimat for p under nullhypotesen: p &lt;- (n1*p1 + n2*p2)/(n1 + n2) # Testobservatoren: z &lt;- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2)) # Kritisk verdi p√• 5% niv√• for en ensidig test: qnorm(0.95) ## [1] 1.644854 Siden \\(z = 2.9\\) forkaster vi nullhypotesen om at det er lik andel ¬´9077¬ª i de to populasjonene. "],["kjikvadrattester.html", "3.4 Kjikvadrattester", " 3.4 Kjikvadrattester 3.4.1 Videoforelesninger 3.4.2 Kommentarer Vi m√• kunne to anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken: Teste for om en gitt fordeling passer med obervasjoner (‚ÄúGoodness-of-fit‚Äù). Teste for uavhengighet. I den f√∏rste anvendelsen f√•r vi oppgitt en diskret sannsynlighetsfordeling der vi har noen mulige utfall \\(u_1, \\ldots, u_k\\), med tilh√∏rende sannsynligheter \\(p_1, \\ldots,p_k\\). Dersom vi skal observere \\(n\\) utfall fra denne fordelingen, vil vi forvente \\(e_i = p_i\\cdot n\\) observasjoner av utfall \\(u_i\\). N√• har det seg slik at vi har observert \\(n\\) utfall fra fordelingen, og utfall \\(u_i\\) har skjedd \\(f_i\\) ganger. Vi lurer da p√• om de observerte frekvensene (\\(f_i\\)) er s√• forskjellige fra de forventede frekvensene (\\(e_i\\)) at vi ikke lenger tror at \\(p_1, \\ldots,p_k\\) er den sanne sannsynlighetsfordelingen. Vi kom frem til en fornuftig testobservator: \\[\\chi^2 = \\sum_{i=1}^k \\frac{(f_i - e_i)^2}{e_i},\\] som er \\(\\chi^2\\)-fordelt med \\(k-1\\) frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan g√• inn i \\(\\chi^2\\)-tabellen for √• sjekke om verdien av testobservatoren er for stor (dvs, \\(f\\)¬¥ene er for forskjellige fra \\(e\\)`ene) at vi ikke lenger tror at \\((p_1, \\ldots, p_k)\\) er den sanne sannsynlighetsfordelingen. Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte f√∏lgende kommandoer: p0 &lt;- c(0.45, 0.40, 0.15) # Fordeling under H0 f &lt;- c(102, 82, 16) # Observerte frekvenser chisq.test(x = f, p = p0) ## ## Chi-squared test for given probabilities ## ## data: f ## X-squared = 8.1833, df = 2, p-value = 0.01671 Den andre anvendelsen er √• teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for ¬´\\(A\\) og \\(B\\)¬ª som et produkt dersom de ar uavhengige: \\[P(A \\cap B) = P(A)\\cdot P(B).\\] Vi kan regne ut hvor mange observasjoner vi forventer √• se for hver kombinasjon av de to kjennetegnene (\\(e_{ij}\\)), og bruke kjikvadrattesten over til √• sjekke om disse er langt fra det vi faktisk har observert (\\(f_{ij}\\)). Boken har et eksempel p√• dette som de regner ut b√•de for h√•nd og i Excel. Slik kan vi gj√∏re det i R: # Leser inn data mba &lt;- read_xlsx(&quot;Xm15-02.xlsx&quot;) # Kikker p√• datasettet mba ## # A tibble: 152 √ó 2 ## Degree `MBA Major` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 2 2 ## 6 1 3 ## 7 3 1 ## 8 1 1 ## 9 2 1 ## 10 2 2 ## # ‚Ä¶ with 142 more rows ## # ‚Ñπ Use `print(n = ...)` to see more rows Vi legger merke til at strukturen p√• datasettet er litt annerledes enn krysstabellen som er vist s. 601 i l√¶reboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av ¬´bachelorgrad¬ª og ¬´masterprofil¬ª, har vi f√•tt oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R: table(mba) ## MBA Major ## Degree 1 2 3 ## 1 31 13 16 ## 2 8 16 7 ## 3 12 10 17 ## 4 10 5 7 Det er denne som brukes som argument i chisq.test(): chisq.test(table(mba)) ## ## Pearson&#39;s Chi-squared test ## ## data: table(mba) ## X-squared = 14.702, df = 6, p-value = 0.02271 Her er det bare √• sammenligne tallene med det som l√¶reboken finner i Excel. Noen kontrollsp√∏rsm√•l: Vi har l√¶rt to veldig spesifikke anvendelser av kjikvadrattester. Hvilke? Kan du gi en intuitiv forklaring p√• hvorfor testobservatoren v√•r er fornuftig? Litt mer vanskelig: Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tiln√¶rmet kjikvadratfordelt? "],["oppgaver.html", "3.5 Oppgaver", " 3.5 Oppgaver 3.5.1 Standard oppgaver Introduksjon til hypotesetesting For hvert av scenarioene i a og b, gj√∏r f√∏lgende: Sett opp relevant nullhypotese og alternativhypotese (hint: nullhypotese avhenger av hvor ‚Äòbevisbyrden‚Äô b√∏r ligge) Definer type I-og type II-feil. Diskuter konsekvensene av type I-feil og type II-feil i det aktuelle scenarioet. En ny type medisin skal vurderes for kommersialisering. Du sitter i et vurderingspanel som skal vurdere om medisinen kan bli godkjent eller ikke. Du blir presentert to ulike investeringer √• velge mellom. En av dem er veldig risikabel, men med stor potensiell profitt. Den andre er mindre risikabel, men med lavere potensiell profitt. L√∏sning \\(H_0\\): Den nye medisinen er ikke trygg og effektiv. \\(H_1\\): Den nye medisinen er trygg og effektiv. Type I-feil: Forkaste \\(H_0\\) n√•r \\(H_0\\) er sann. Konsekvens: Risikerer at vi begynner √• produsere en medisin som ikke er trygg og effektiv. Type II-feil: Forkaster ikke \\(H_0\\) n√•r \\(H_1\\) er sann. Konsekvens: Vi lar v√¶re √• produsere en medisin som faktisk er trygg og effektiv. Kommentar: Signifikansniv√•et ved produksjon av medisiner settes ofte lavt fordi konsekvensene av en type I-feil kan v√¶re sv√¶rt alvorlige. \\(H_0\\): Den mest risikable investeringen er mest l√∏nnsom. \\(H_1\\): Den mest risikable investeringen er ikke mest l√∏nnsom. Type I-feil: Forkaste \\(H_0\\) n√•r \\(H_0\\) er sann. Konsekvens:Vi investerer i den minst risikable investeringen, som ikke er mest l√∏nnsom. Type II-feil: Forkaster ikke \\(H_0\\) n√•r \\(H_1\\) er sann. Konsekvens: Vi investerer i den mest risikable investeringen, som ikke er mest l√∏nnsom. Vi har f√∏lgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 150\\) mot \\(H_1: \\mu \\neq 150\\). \\(\\sigma = 10\\), \\(n =100\\), \\(\\overline{x} = 150\\). Bestem verdi av testobservator, forkastelsesomr√•de dersom signifikansniv√•et er \\(\\alpha = 0.05\\), og p-verdi. Konkluder. L√∏sning Her er \\(\\sigma\\) kjent s√• vi kan bruke en z-observator. Forkastelsesomr√•de \\(Z &lt; -z_{0.025}=-1.96\\) eller \\(Z&gt; z_{0.025}=1.96\\). \\[Z = \\frac{\\overline{x} - \\mu}{\\sigma/\\sqrt{n}} = \\frac{150 - 150}{10/\\sqrt{100}}=0\\] p-verdi\\(=2P(Z &gt; 0) = 2\\times0.5=1\\). Vi kan ikke forkaste nullhypotesen \\(H_0: \\mu = 0\\). Faktisk er det ekstremt sannsynlig (p-verdi = 1) √• observere det vi har observert dersom nullhypotesen er sann. Vi har f√∏lgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 55\\) mot \\(H_1: \\mu &gt; 55\\). \\(\\sigma = 20\\), \\(n = 25\\), \\(\\overline{x} = 67\\). Regn ut testobservatoren \\(Z\\). Regn ut p-verdi. Regn ut p-verdi, denne gangen med \\(\\overline{x}\\) = 63. Regn ut p-verdi, denne gangen med \\(\\overline{x}\\) = 59. Fastsl√• hva som skjer med verdien av testobservatoren (Z) og p-verdien n√•r \\(\\overline{x}\\) n√¶rmer seg \\(55\\) (verdien av \\(\\mu\\) under \\(H_0\\)). L√∏sning \\[Z = \\frac{\\overline{x} - \\mu}{\\sigma/\\sqrt{n}} = \\frac{67 - 55}{20/\\sqrt{25}}=3\\] \\(\\text{p-verdi} = P(Z &gt; 3.00) = 1 ‚Äì P(Z&lt;3) = 1 ‚Äì 0.9987 = 0.0013\\). Kommentar: Her kan du bruke pnorm(3) i R til √• regne ut \\(P(Z&lt;3)\\). Ny verdi av testobservator blir da \\(Z = 2\\). \\(\\text{p-verdi} = P(Z &gt; 2.00) = 1 ‚Äì 0.9772 = 0.0228\\). Ny verdi av testobservator blir da \\(Z = 1\\). \\(\\text{p-verdi} = P(Z &gt; 1.00) = 1 ‚Äì 0.8413 = 0.1587\\). Vi ser at testobservatoren minker og p-verdien √∏ker n√•r \\(\\overline{x}\\) n√¶rmer seg \\(55\\). Forklaring: La \\(\\mu_0 = 55\\) v√¶re verdien av \\(\\mu\\) under \\(H_0\\). Z-observatoren m√•ler avviket mellom antagelsen under \\(H_0\\) og dataene vi observerer og avtar derfor n√•r v√•r observasjon av \\(\\overline{x}\\) n√¶rmer seg \\(\\mu_0\\). P-verdien sier hvor sannsynlig det er √• observere de dataene vi har dersom \\(H_0\\) er sann og √∏ker f√∏lgelig n√•r \\(\\overline{x}\\) n√¶rmer seg \\(\\mu_0\\). Annta at vi har f√∏lgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 50\\) mot \\(H_1: \\mu &gt; 50\\). \\(\\sigma = 10\\), \\(n = 40\\), \\(\\alpha = 0.05\\). Bestem \\(\\beta\\), alts√• sannsynligheten for en type-II feil, under antagelsen at \\(\\mu = 55\\). L√∏sning Forkastningsomr√•det blir da \\[Z = \\frac{\\overline{X} - 50}{10/\\sqrt{40}} &gt; Z_{0.05} = 1.645 \\] dvs at vi forkaster \\(H_0\\) n√•r \\[\\overline{X} &gt; 50 + 1.645\\times\\frac{10}{\\sqrt{40}}=52.6\\] En type-II feil svarer til √• ikke forkaste \\(H_0\\) n√•r \\(H_1\\) er sann. For √• regne p√• sannsynligheten for type-II feil m√• vi ikke bare anta at \\(H_1\\) er sann, men v√¶re spesifike p√• hva verdien til \\(\\mu\\) er (i dette tilfellet 55). Vi lurer alts√• p√• hva sannsynligheten for at vi ikke er i forkastnings omr√•det (\\(\\overline{X} &lt; 52.6\\)) gitt at \\(\\mu = 55\\): \\[\\begin{equation*} \\begin{split} \\beta &amp;= P(\\overline{X} &lt; 52.6\\quad\\text{gitt at $\\mu = 55$})\\\\ &amp;= P(\\frac{\\overline{X} - 55}{10/\\sqrt{40}} &lt; \\frac{52.6 - 55}{10/\\sqrt{40}})\\\\ &amp;=P(Z &lt; -1.52) = 0.064 \\end{split} \\end{equation*}\\] Merk: Et begrep som ofte blir brukt om tester er styrken til testen \\(1-\\beta\\) som da er sannsynligheten for √• forkaste \\(H_0\\) n√•r \\(H_1\\) er sann. En god test har god (stor) styrke. Hadde vi gjentatt denne testen mange ganger ville vi ha forkastet \\(H_0\\) i \\((100 - 6.4)\\% = 93.6\\%\\) av gangene dersom det faktisk er slik at sann \\(\\mu\\) er 55. En leder frykter at den gjennomsnittlige tiden ansatte daglig bruker p√• sosiale medier overstiger 45 minutter. For √• teste denne mistanken, plukker han ut et tilfeldig utvalg p√• 15 personer, og sp√∏r om tid brukt p√• sosiale medier etter en tilfeldig arbeidsdag. Resultatene er oppsummert nedenfor. 70, 96, 58, 88, 34, 42, 34, 56, 68, 46, 26, 18, 22, 60, 84 Hvis samlingen av tider er normalfordelt med standardavvik p√• 20 minutter, kan lederen hevde at mistanken hans stemmer p√• et 1 % signifikans-niv√•? Tror du observasjonene over er et representativt utvalg? Hva kunne lederen gjort annerledes? L√∏sning Lederen √∏nsker alts√• √• teste \\(H_0: \\mu = 45\\) mot alternativ hypotesen \\(H_1: \\mu &gt; 45\\). Testobservatoren er da gitt ved \\[Z = \\frac{\\overline{X} - \\mu_0}{\\sigma/\\sqrt{n}} = \\frac{53.46 - 45}{20/\\sqrt{15}} = 1.64\\] Sannsynligheten for √• observerer noe minst like ekstremt og til fordel for \\(H_1\\) (p-verdien) er da \\[P-verdi = P(Z &gt; 1.645) \\approx 0.05 &gt; 0.01\\]. Lederen kan alts√• ikke trekke denne konklusjonen p√• 1 % signifikansniv√•. For √• forkaste null hypotesen p√• et 1 % signifikansniv√•, m√•tte vi hatt p-verdi lavere enn 1 %. Dersom lederen sp√∏r ansatte fjes til fjes er det n√¶rliggende √• tro at de ansatte vil underdrive sin bruk av sosiale medier. En anonym sp√∏rreunders√∏kelse ville nok gitt et mer representativt utvalg. Gjennomsnitt og standardavvik i et utvalg p√• \\(n=100\\) er \\(\\overline{x} = 20\\) og \\(s = 2\\). Finn 95 % konfidensintervall av gjennomsnitt (\\(\\mu\\)) i populasjonen. Gjenta a. med \\(s = 5\\). Gjenta a. med \\(s = 10\\). Fastsl√• hvordan det estimerte konfidensintervallet endrer seg n√•r vi √∏ker \\(s\\). Anta at \\(s=5\\) og regn et 95 % konfidensintervall dersom st√∏rrelsen p√• utvalget er henholdsvis \\(n = 50\\) og \\(n=10\\). Fastl√• hvordan det estimerte konfidensintervallet endrer seg n√•r vi √∏ker \\(n\\). L√∏sning \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 1.984\\times 2/\\sqrt{100} = [19.60 ,20.40]\\] \\[ 20 \\pm 1.984\\times 5/\\sqrt{100} = [19.01 ,20.99]\\] \\[ 20 \\pm 1.984\\times 10/\\sqrt{100} = [18.02 ,21.98]\\] Konfidensintervallet blir st√∏rre n√•r \\(s\\) √∏ker. \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 2.09\\times 5/\\sqrt{50} = [18.58 ,21.42]\\] \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 2.26\\times 5/\\sqrt{10} = [16.42 ,23.58]\\] Vi ser at jo st√∏rre \\(n\\) er jo mindre blir konfidensintervallet. Flere observasjoner gj√∏r at vi med st√∏rre sikkerhet (smalere intervall) kan si hvor \\(\\mu\\) ligger. Med sterkt fall i flyreiser og passasjerer p√• grunn av koronakrisen virker det sannsynlig at det blir f√¶rre forsinkelser i flytrafikken. F√∏r krisen hevdet et flyselskap at de landet presist 92 % av flyreisene. I et tilfeldig utvalg flyreiser hos det samme selskapet under krisen ble 148 av 165 vurdert til √• v√¶re presise. Kan vi konkludere p√• 5 % signifikansniv√• at det er f√¶rre forsinkelser under koronakrisen? L√∏sning La \\(p\\) v√¶re den sanne andelen av flyreiser som blir forsinket under krisen. Vi skal da teste \\(H_0: p = 0.92\\) mot \\(H_1: p &lt; 0.92\\). V√•rt estimat p√• \\(p\\) er \\(\\hat{p}=148/165 \\approx 0.90\\) og testobservatoren er gitt ved \\[z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1 - p_0)/n}} = \\frac{0.90 - 0.92}{\\sqrt{0.92(1 - 0.92)/165}} \\approx -0.95\\] Dersom vi bruker kritisk verdi ville forkastningsomr√•det v√¶rt \\(z &lt; -1.645\\) og siden \\(z&gt; -1.645\\) kan vi alts√• ikke forkaste \\(H_0\\). Alternativt kan vi regne ut p-verdien som er ‚Äúsannsynligheten for det vi har observert eller noe enda mer til fordel for \\(H_1\\). En enda mer negativ verdi enn -0.95 ville v√¶rt til fordel for \\(H_1\\), derfor er \\[p-verdi = P(Z &lt; - 0.95) = 0.17\\] og vi kan derfor ikke forkaste \\(H_0\\) siden p-verdien ikke er mindre enn 0.05. Vi har f√∏lgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: \\(\\overline{x}_1 = 400\\), \\(s_1 = 130\\), \\(n_1 = 130\\), \\(\\overline{x}_2 = 390\\), \\(s_2 = 50\\), \\(n_2 = 130\\). Kan vi hevde p√• et 5 % signifikansniv√• at \\(\\mu_1\\) er st√∏rre enn \\(\\mu_2\\)? Det oppgis at \\[\\nu = \\frac{\\left(\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}\\right)^2}{\\left(\\frac{s^2_{1}}{n_1}\\right)^2/(n_1 - 1) + \\left(\\frac{s^2_{2}}{n_2}\\right)^2/(n_2 - 1)}\\approx 166\\] Gjenta a., denne gangen med \\(s_1 = 30\\) og \\(s_2 = 15\\). Som over, oppgis det at \\(\\nu \\approx 190\\). Fastsl√• hva som skjer hvis utvalgenes standardavvik blir mindre. Gjenta a., denne gangen med utvalg p√• \\(n_1 = n_2 = 20\\) observasjoner. Som over, oppgis det at \\(\\nu \\approx 28\\). Fastsl√• effekten av √• redusere utvalgsst√∏rrelser. L√∏sning Vi skal alts√• teste \\(H_0: \\mu_1 - \\mu_2 = 0\\) mot \\(H_1: \\mu_1 - \\mu_2 &gt; 0\\). Siden variansene i utvalget er s√•pass ulike antar vi at vi m√• bruke varianten av testen med ulik varians. Testobservatoren er da gitt ved \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{130^2}{130} + \\frac{50^2}{130}}} = 0.82\\] Antall frihetsgrader oppgis til √• v√¶re \\(v \\approx 166\\). Vi forkaster \\(H_0\\) dersom \\(T &gt; t_{0.05, 166} = 1.654\\), og siden dette ikke er tilfelle her kan vi ikke forkaste \\(H_0\\) ved 5 % signifikansniv√•. Testobservatoren blir i dette tilfellet \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{30^2}{130} + \\frac{15^2}{130}}} = 3.40\\] Antall frihetsgrader oppgis til √• v√¶re \\(v \\approx 190\\). Siden \\(T = 3.40 &gt; t_{0.05, 190} = 1.653\\) forkaster vi \\(H_0\\) p√• 5 % signifikansniv√•. N√•r standardavvikene i utvalgene blir mindre √∏ker verdien av testobservatoren. Mindre standardavvik betyr at vi er mer sikre p√• at \\(\\overline{x}_1 - \\overline{x}_2\\) ligger n√¶r \\(\\mu_1 - \\mu_2\\), og at en evt. differanse kan tyde p√• avvik fra \\(H_0\\). Dette blir reflektert av en st√∏rre testobservator. Testobservatoren blir da \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{130^2}{20} + \\frac{50^2}{20}}} = 0.32\\] Antall frihetsgrader oppgis til √• v√¶re \\(v \\approx 28\\). Vi forkaster \\(H_0\\) dersom \\(T &gt; t_{0.05, 28} = 1.701\\), og siden dette ikke er tilfelle her kan vi ikke forkaste \\(H_0\\) ved 5 % signifikansniv√•. F√• observasjoner representerer st√∏rre usikkerhet om differansen \\(\\overline{x}_1 - \\overline{x}_2\\) bare skyldes tilfeldighet, og dette reflekteres av testobservatoren som vil synke n√•r utvalgsst√∏rrelsen reduseres. Et nystartet firma har utviklet to l√∏sninger for automatisk registrering av av antall lus p√• oppdrettslaks. Metode A er litt dyrere enn metode B, men firmaet mener Metode A en den raskeste metoden. For √• teste ut denne hypotesen blir begge metodene brukt til √• registrere lus p√• 11 basseng av ulik st√∏rrelse og med forskjellig antall fisk. Antall minutter hver metode tar blir registrert for hvert basseng. Under er det gitt en R-utskrift fra en to-utvalgs t-test. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Bruk ogs√• utskriften til √• formulere en konklusjon for en test med 5% signifikansniv√•. ## ## Welch Two Sample t-test ## ## data: metodeB and metodeA ## t = 1.6129, df = 18.969, p-value = 0.06164 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## -0.7959228 Inf ## sample estimates: ## mean of x mean of y ## 83.44886 72.41662 Under er det gitt en R-utskrift fra en paret t-test for de samme dataene. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Formuler testobservatoren og bruk ogs√• utskriften til √• formulere en konklusjon for en test med 5% signifikansniv√•. ## ## Paired t-test ## ## data: metodeB and metodeA ## t = 5.4477, df = 10, p-value = 0.0001409 ## alternative hypothesis: true mean difference is greater than 0 ## 95 percent confidence interval: ## 7.361811 Inf ## sample estimates: ## mean difference ## 11.03225 Hvilke av de to foreg√•ende testene b√∏r en bruke i dette tilfellet? L√∏sning La \\(\\mu_1\\) og \\(\\mu_2\\) v√¶re forventet tid til registrering av lus i et basseng for hhv metode B og metode A. Da er R-utskriften en test av \\(H_0: \\mu_1 - \\mu_2 = 0\\) mot det enside alternativet \\(H_1: \\mu_1-\\mu_2 &gt; 0\\). Fra utskriften ser vi at \\(p-value= 0.06164 &gt; 0.05\\), alts√• kan vi ikke forkaste \\(H_0\\) ved \\(5\\%\\) signifikansniv√•. Praktisk tolkning: Vi kan ikke konkludere med at det er noe forskjell i tiden de to metodene bruker. b.I en paret t-test baserer vil testen p√• de parvise differansene \\(d_i = x_i - y_i\\), der \\(x_i\\) og \\(y_i\\) er tiden hhv metode B og A bruker p√• √• registrere lus i basseng nr. i. Utskriften viser en test av \\(H_0: \\mu_d = 0\\) mot det ensidige alternativet \\(H_1: \\mu_d &gt; 0\\). Testobservatoren er da gitt ved \\[T=\\frac{\\overline{d}-0}{s_d/\\sqrt{n}}\\] Fra utskriften ser vi at \\(p-value= 0.0001409 &lt; 0.05\\), alts√• kan vi forkaste \\(H_0\\) ved \\(5\\%\\) signifikansniv√•. Praktisk tolkning: Det ser ut til at metode A er raskere enn metode B. En paret t-test er generelt det riktige valget dersom observasjonene som blir ‚Äúparet‚Äù er avhengige. I dette tilfellet er det naturlig √• tro at tiden metode A og B bruker p√• et basseng er avhengige st√∏rrelser (f.eks vil et basseng med mye fisk ta lang tid √• registrere for begge metodene). I en to-utvalgs t-test antar vi derimot at tiden det tar for metode A og B √• registrere lus for et basseng er uavhengige. Vi har f√∏lgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: \\(s_{1}^2 = 1400\\), \\(n_1 = 60\\), \\(s_{2}^2 = 700\\), \\(n_2 = 60\\). Kan vi hevde at de to utvalgene har ulik varians? Bruk 5 % signifikansniv√•. Gjenta a., denne gangen med \\(n_1 = 30\\) og \\(n_2 = 30\\). Fastsl√• hva som er effekten p√• verdi av testobservator og konklusjon av testen n√•r vi reduserer utvalgsst√∏rrelse. L√∏sning Her √∏nsker vi √• test \\(H_0: \\sigma_{1}^2/\\sigma_{2}^2 = 1\\) mot \\(H_1: \\sigma_{1}^2/\\sigma_{2}^2 \\neq 1\\). Husk at for en tosidig test er det smart √• formulere null- og alternativ hypotesen slik at den st√∏rste utvalgsvariansen kommer i telleren til testobservatoren: \\[F = s_{1}^2/s_{2}^2 = 1400/700 = 2\\] Da trenger vi nemlig kun √• sammenligne testobservatoren med den √∏vre kvantilen i F-fordelingen. Forkastningsomr√•det blir i dette tilfellet \\(F &gt; F_{0.025, 59, 59} = 1.67\\). Siden \\(F = 2\\) er st√∏rre enn \\(1.67\\) kan vi alts√• forkaste \\(H_0\\) til fordel for \\(H_1\\) p√• et 5 % signifikansniv√•. Forkastningsomr√•det er da \\(F &gt; F_{0.025, 29, 29} = 2.1\\) og siden \\(F &lt; 2.1\\) kan vi ikke forkaste \\(H_0\\) p√• et 5 % signifikansniv√•. Testobservatoren forblir uendret, men vi ser at den kritiske verdien som m√• overstiges for √• f√• forkastning √∏ker n√•r antall observasjoner avtar. Konklusjonen blir derfor motsatt i oppgave b. Skulle vi f√•tt forkastning ogs√• i b. m√•tte det reduserte utvalget blitt kompensert av et st√∏rre avvik mellom \\(s_1\\) og \\(s_2\\). En bedrift som har en dyr leieavtale av en parkeringsplass vurderer innkj√∏p av elektroniske sparkesykler. Tanken er at de som bor n√¶r bedriften da kan benytte seg av disse istedenfor √• kj√∏re bil. I et pr√∏veprosjekt f√•r bedriften leid en rekke sparkesykler i 20 arbeidsdager og antall biler p√• parkeringsplassen blir registrert daglig. Den samme registreringen blir gjort de 20 p√•f√∏lgende arbeidsdagene n√•r sparkesyklene ikke er tilgjengelig. En ansatt som er ansvarlig for pr√∏veprosjektet bruker R til √• utf√∏re to tester basert p√• data fra disse to registreringene. Formuler null- og alternativhypotesen til den f√∏rste testen. Hvorfor utf√∏rer den ansatte denne testen? Formuler null- og alternativhypotesen samt testobservatoren til den andre testen. Trekk en praktisk konklusjon om innf√∏ringen av sparkesykler ut fra utskriften. ## ## F test to compare two variances ## ## data: uten_sparkesykkel and med_sparkesykkel ## F = 1.5385, num df = 19, denom df = 19, p-value = 0.3559 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.6089665 3.8870052 ## sample estimates: ## ratio of variances ## 1.538524 ## ## Two Sample t-test ## ## data: uten_sparkesykkel and med_sparkesykkel ## t = 2.4621, df = 38, p-value = 0.009232 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 2.525173 Inf ## sample estimates: ## mean of x mean of y ## 39.91587 31.90524 L√∏sning La \\(\\sigma^2_{1}\\) og \\(\\sigma^2_{2}\\) v√¶re populasjonsvariansene til antall biler som kommer for √• parkere p√• henholdsvis dager der sparkesykler ikke er tilgjengelig og dager der sparkesykler er tilgjengelig. Utskriften viser da en test av \\(H_0: \\sigma^2_{1}/\\sigma^2_{2} = 1\\) mot \\(H_1: \\sigma^2_{1}/\\sigma^2_{2} \\neq 1\\). Den ansatte utf√∏rer denne testen for √• se om han kan bruke varianten av to-utvalgs t-test som antar lik varians n√•r vedkommende tester om innf√∏ringen av sparkesykler har noen effekt (se b.). Ut fra p-verdien p√• 0.3559 (alts√• ingen forkastning av \\(H_0\\)) vil det v√¶re greit √• bruke en slik test i dette tilfellet. Tips: variabel navnet som st√•r f√∏rst i testen (‚Äúuten_sparkesykkel‚Äù) indikerer hvilke av de to variansen som st√•r i telleren av \\(\\sigma^2_{1}/\\sigma^2_{2}\\) (i \\(H_0\\)) og \\(s^2_{1}/s^2_{2}\\) (i testobservatoren) i testen R utf√∏rer. La \\(\\mu_1\\) og \\(\\mu_2\\) v√¶re forventet antall biler p√• henholdsvis dager der sparkesykler ikke er tilgjengelig og dager der sparkesykler er tilgjengelig. Utskriften viser en en-sidig, to-utvalgs t-test av hypotesen \\(H_0: \\mu_1 - \\mu_2 = 0\\) mot \\(H_1: \\mu_1 - \\mu_2 &gt; 0\\). \\(H_1\\) er alts√• om det forventes ferre biler p√• dager med sparkesykler enn p√• dager uten sparkesykler. ‚ÄúTwo sample t-test‚Äù betyr at vi har antatt lik varians (ellers ville det st√•tt ‚ÄúWelch two sample t-test‚Äù), og testobservatoren er derfor gitt ved: \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{s^2_{P}(1/n_1 + 1/n_2)}}\\] der \\[s^2_{P} = \\frac{(n_1 - 1)s^2_{1} + (n_2 - 1)s^2_{2}}{n_1 + n_2 -2}\\] Ut fra p-verdien p√• 0.009232 forkaster vi \\(H_0\\) p√• 1 % (!) signifikansniv√•. Vi har med andre ord god grunn til √• tro at en innf√∏ring av sparkesykler vil redusere antall biler p√• parkeringsplassen. Tips: Variabelnavnet som st√•r f√∏rst (‚Äúuten_sparkesykkel‚Äù) indikerer hva som er f√∏rste verdi i differansene \\(\\mu_1 - \\mu_2\\) (i hypotesene) og \\(\\overline{x}_1 - \\overline{x}_2\\) (i testobservatoren) i testen R utf√∏rer. Vi har f√∏lgende informasjon om fra to tilfeldige utvalg fra to populasjoner: I utvalg 1 har \\(x_1 = 100\\) av \\(n_1 = 200\\) individer et spesielt kjennetegn, mens i utvalg 2 er det det tilsvarende tallet \\(x_2 = 90\\) av \\(n_2 = 200\\). Utf√∏r en test for √• unders√∏ke om de to populasjonene har ulik andel av kjennetegnet. Bruk 5 % signifikansniv√•. Regn ut p-verdien for testen over. Gjenta a., denne gangen med \\(x_1 = 190\\) og \\(x_2 = 180\\). Fastsl√• effekten p√• p-verdien av √• √∏ke andelene (dersom differansen er uendret). L√∏sning Vi skal her teste hypotsen \\(H_0: p_1 - p_2 = 0\\) mot \\(H_1: p_1 - p_2 \\neq 0\\). Med \\(\\hat{p_1} = 100/200 = 0.5\\), \\(\\hat{p}_2 = 90/200 = 0.45\\) og \\(\\hat{p} = (100 + 90)/(200 + 200) = 0.475\\) er testobservatoren er gitt ved \\[Z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})(1/n_1 + 1/n_2)}} = \\frac{0.5 - 0.45}{\\sqrt{0.475(1-0.475)(1/200 + 1/200)}}=1.00\\] Siden dette er en tosidig test er forkastningsomr√•det til testen \\(|Z| &gt; z_{\\alpha/2} = z_{0.025}=1.96\\). Siden 1 &lt; 1.96 kan vi alts√• ikke forkaste \\(H_0\\) ved 5 % signifikansniv√•. P-verdier for tosidige tester kan v√¶re litt tricky √• forst√•. Vi er alts√• ute etter sannsynligheten for at noe ‚Äúminst like ekstremt og til fordel for \\(H_1\\) intreffer‚Äù. For en tosidig test ville vi ogs√• reagert p√• store negative verdier av \\(Z\\), og ‚Äúminst like ekstremt‚Äù i negativ retning ville v√¶rt \\(Z &lt; - 1.00\\). Alts√• blir p-verdien \\[p-verdi = P(Z &lt; -1.00\\quad \\text{og/eller}\\quad Z &gt; 1.00)\\\\ = P(Z &lt; -1.00) + P(Z &gt; 1.00) = 2P(Z &gt; 1.00) = 2*(1 - 0.841) = 0.317\\] Testobservatoren er da gitt ved \\[Z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})(1/n_1 + 1/n_2)}} = \\frac{0.95 - 0.90}{\\sqrt{0.475(1-0.475)(1/200 + 1/200)}}=1.89\\] P-verdien er som f√∏r gitt ved \\[ P-value = 2P(Z &gt; 1.89) = 2*(1 - 0.97) = 0.06 \\] Vi ser at p-verdien avtar n√•r andelene blir st√∏rre. Vi er her ganske n√¶re p√• √• forkaste \\(H_0\\) selv om differansen mellom \\(\\hat{p}_1\\) og \\(\\hat{p}_2\\) er den samme som i oppgave a. I nevneren til testobservatoren ser vi at variansen til differansen \\(\\hat{p}_1 - \\hat{p}_2\\) er proposjonal med \\(\\hat{p}(1-\\hat{p})\\). Denne vil bli mindre n√•r \\(\\hat{p}\\) n√¶rmer seg 1 (eller 0), og er st√∏rst n√•r \\(\\hat{p} = 0.5\\). Vi er derfor sikrere p√• at differansen \\(\\hat{p}_1 - \\hat{p}_2\\) i oppgave b. ligger n√¶r den sanne differansen i populasjon sammenlignet med oppgave a. Bevismateriale mot \\(H_1\\) √∏ker (p-verdien g√•r ned), men i dette tilfellet holder det ikke til √• forkaste \\(H_0\\). En kredittutsteder gir kundene en rating basert p√• blant annet gjeld, formue og tidligere betalingsanmerkninger. Tanken er at en lav rating medf√∏rer h√∏yere sannsynlighet mislighold av l√•net sitt. For √• sjekke om ratingen gir en reell indikasjon p√• mislighold, blir det registrert antall mislighold i et utvalg med rating under 800, og i et utvalg med rating 800 eller h√∏yere. Rating &lt; 800 Rating &gt; 800 Utvalgsst√∏rrelse 612 854 Mislighold 14 9 Kan vi konkludere med at personer med rating lavere enn 800 har h√∏yere sannsynlighet for mislighold av l√•net sitt sammenlignet med de med rating over 800? Bruk 5 % signifikansniv√•. L√∏sning La \\(p_1\\) v√¶re sannsynlighet for mislighold for de med rating under 800 og la \\(p_2\\) v√¶re den samme sannsynligheten for de med rating over 800. Vi skal da teste \\(H_0: p_1 - p_2 = 0\\) mot det ensidige alternativet \\(H_1: p_1 - p_2 &gt; 0\\). Med \\(\\hat{p_1} = 14/612 = 0.0229\\), \\(\\hat{p}_2 = 0.0105\\), og \\(\\hat{p}=(14 + 9)/(612 + 854)=0.0157\\) er testobservatoren gitt ved \\[Z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})(1/n_1 + 1/n_2)}} = \\frac{0.0229 - 0.0105}{\\sqrt{0.0157(1-0.0157)(1/612 + 1/854)}}=1.874\\] Forkastningsomr√•det er gitt ved \\(Z &gt; z_\\alpha = 1.645\\), og siden 1.874 &gt; 1.645 forkaster vi \\(H_0\\). Det er grunn til √• tro at personer med rating lavere enn 800 har st√∏rre sannsynlighet for mislighold. To konkurrerende selskaper, A og B, dominerer et marked for et bestemt produkt og har historisk sett hatt markedsandeler p√• hhv. 40 % og 50 % (alts√• 10 % til andre markeder). Selskap A gjennomf√∏rer s√• en markedsf√∏ringskampanje. For √• avgj√∏re kampanjens effekt trekker et markedsanalyseselskap et tilfeldig utvalg av 300 kunder som sp√∏rres om deres produkt preferanse: Foretrukket selskap A B andre Frekvens 140 142 18 Har markedsandelene endret seg? L√∏sning Vi skal her test \\(H_0: p_1 = 0.4, p_2 = 0.5, p_3 = 0.1\\) mot \\(H_1:\\) minst to sannsynligheter er forskjellige. Utregning av testobservator blir da som f√∏lger: Foretrukket selskap \\(f_i\\) \\(e_i\\) \\((f_i - e_i)^2/e_i\\) A 140 \\(300\\times 0.4 = 120\\) 3.3333 B 142 \\(300\\times 0.5 = 150\\) 0.4266 andre 18 \\(300\\times 0.1 = 30\\) 4.8000 Forkastelsesomr√•det er \\(\\chi^2 &gt; \\chi^2_{\\alpha, k - 1} = \\chi^2_{0.05, 2} = 5.99\\). Siden \\(\\chi^2 = 8.564 &gt; 5.99\\) forkaster vi \\(H_0\\) p√• 5 % signifikansniv√•. Et produksjonsselskap har mulighet til √• bruke tre forskjellige kjemikalier for √• fremstille det samme produktet. Lederen ved produksjonsselskapet √∏nsker √• unders√∏ke hvorvidt det er forskjell p√• hvor mange mangelfulle produkter som blir produsert n√•r en varierer bruken av type kjemikalier. Hun gj√∏r et tilfeldig utvalg p√• 700 produkter og klassifiserer dem som enten tilfredsstillende eller mangelfull. Funnene er oppsummert i tabellen nedenfor: Klassifisering/kjemikalie Kjemikalie 1 Kjemikalie 2 Kjemikalie 3 sum Tilfredstillende 268 216 164 648 Mangelfull 15 17 20 52 sum 283 233 184 700 Utf√∏r en test for √• avgj√∏re om det er en sammenheng mellom mangelfulle produkter og kjemikalie brukt under produksjon. L√∏sning Vi skal alts√• teste \\(H_0:\\) De to variablene klassfisering og kjemikalie er uavhengige mot \\(H_1:\\) Variablene klassifisering og kjemikalie er avhengige. Vi begynner med √• regne ut de forventede frekvensene ved bruk av formelen \\(e_{ij} = f_{i.}f_{.j}/n\\): klas./kjem. Kjem 1 Kjem 2 Kjem 3 Tilfreds. \\(e_{11} = 648\\times 283/700 = 262.0\\) \\(e_{12} = 648\\times 233/700 = 215.7\\) \\(e_{13} = 648\\times 184/700 = 170.3\\) Mangel. \\(e_{21} = 52\\times 283/700 = 21.0\\) \\(e_{22} = 52\\times 233/700 = 17.3\\) \\(e_{23} = 52\\times 184/700 = 13.7\\) S√• regner vi ut hvert element \\((f_{ij} - e_{ij})^2/e_{ij}\\) som skal inn i summen til test observatoren: klas./kjem. Kjem 1 Kjem 2 Kjem 3 Tilfreds. \\((268 - 262.0)^2/262 = 0.1384\\) 0.0004 0.2353 Mangel. 1.7255 0.0055 2.9327 Testobservatoren er da gitt ved \\[\\chi^2 = \\sum_{i = 1}^2\\sum_{j = 1}^3(f_{ij} - e_{ij})^2/e_{ij} = 0.1385 + 0.0004 + 0.2352 + 1.7255 + 0.0055 + 2.9327 = 5.0378\\] Forkastelsesomr√•det er \\(\\chi^2 &gt; \\chi^2_{\\alpha, (r - 1)(s - 1)} = \\chi^2_{0.05, 2} = 5.99\\). Siden \\(\\chi^2 = 5.0378 &lt; 5.99\\) forkaster vi ikke \\(H_0\\) p√• 5 % signifikansniv√•. I R ville vi gjort f√∏lgende: f = matrix(c(268, 216, 164, 15, 17, 20), nrow = 2, ncol = 3, byrow = T) chisq.test(f) ## ## Pearson&#39;s Chi-squared test ## ## data: f ## X-squared = 5.038, df = 2, p-value = 0.08054 Individuell eksamen V21, oppgave 1 a - c: L√∏sning L√∏sningsforslag "],["relevante-r-testing.html", "3.6 Relevante R-kommandoer", " 3.6 Relevante R-kommandoer Under f√∏lger en liste over hvilke oppgaver du skal klare i R fra denne modulen. V√•r policy fra og med v√•rsemesteret 2022 er at R-kommandoene under er tilstrekkelige for √• l√∏se oppgavene i datalabber og hjemmeeksamen i MET4. Det er med andre ord ikke n√∏dvendig √• l√¶re seg teknikker utover det som er listet opp eksplisitt i listen under. Eventuelle nye teknikker som trengs for √• l√∏se en bestemt oppgave vil bli oppgitt og forklart dersom det er n√∏dvendig. Det antas i tillegg at du kan den grunnleggende R-syntaksen som er dekket under Introduksjon til R. Antakelser om datasett Di kan gj√∏re de samme antakelsene om datasettet som i den tilsvarende oversikten i forrige modul: Datasettene er inneholdt i Excel-filer (.xls eller xslx) eller .csv-filer, som kolonner av variabler, med variabelnavn i f√∏rste rad. \\(t\\)-tester Du m√• kunne gj√∏re de ulike \\(t\\)-testene ved hjelp av t.test()-funksjonen. vi bruker eksempeldatasettet testdata.xls som illustrasjon, som inneholder de to kolonnene X1 og X2. I bunn og grunn handler det om √• hente ut de relevante kolonnene i datasettet som vektorer, og s√• √• sette argumentene i t.test()-funksjonen riktig. # Tosidig, ett-utvalgs $t$-test for om forventningen til `X1` er lik 100: t.test(testdata$X1, mu = 100) # Samme testen, men ensidig med alternativhypotese om at $\\mu &gt; 100$ t.test(testdata$X1, mu = 100, alternative = &quot;greater&quot;) # For √• gj√∏re ensidig test den andre veien bytter du ut `&quot;greater&quot;` med `&quot;less&quot;`. # Vanlig to-utvalgs $t$-test for om forventningen til `X1` og `X2` er like: t.test(testdata$X1, testdata$X2) # Vanlig to-utvalgs t-test der vi antar at variansen i de to populasjonene er like: t.test(testdata$X1, testdata$X2, var.equal = TRUE) # Parret to-utvalgs $t$-test, som bare gir mening dersom de to vektorene med # observasjoner er like lange, og dersom observasjonene er matchet opp slik at # f√∏rste element i den f√∏rste vektoren skal matches mot f√∏rste elemenet i den # andre vektoret etc.: t.test(testdata$X1, testdata$X2, paired = TRUE) Vi kan bytte ut alternativhypotesen til ensidige tester over alt ved √• sette alternative = til √∏nskelig verdi. Videre kan vi tenke oss tilfeller der observasjonsvektorene ikke er like lange, og for eksempel kommer i en excel-fil slik som denne der den ene kolonnen inneholder flere tall enn den andre. Det gj√∏r ingenting. Vi kan lese inn datasettet p√• vanlig m√•te, og legger merke til at de ‚Äútomme‚Äù plassene i tabellen blir fylt med NA. Vi kan kj√∏re \\(t\\)-testene p√• vanlig m√•te. testdata2 &lt;- readxl::read_excel(&quot;ulik-lengde.xlsx&quot;) testdata2 t.test(testdata2$X1, testdata2$X2) ## # A tibble: 15 √ó 2 ## X1 X2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5 ## 2 2 6 ## 3 3 7 ## 4 4 8 ## 5 5 9 ## 6 6 10 ## 7 7 11 ## 8 8 12 ## 9 9 13 ## 10 10 14 ## 11 11 NA ## 12 12 NA ## 13 13 NA ## 14 14 NA ## 15 15 NA ## ## Welch Two Sample t-test ## ## data: testdata2$X1 and testdata2$X2 ## t = -1, df = 22.975, p-value = 0.3277 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -4.603173 1.603173 ## sample estimates: ## mean of x mean of y ## 8.0 9.5 Varianstester Varianstest for ett uvalg er ikke bygget inn i R som en egen funksjon. Da m√• vi gj√∏re den ‚Äúsemi-automatisk‚Äù og regne ut testobservatoren ved √• bruke formelen direkte. Her tester vi om variansen til X2-kolonnen i testdatasettet er lik 10: # Varianstest s &lt;- sd(testdata$X2) sigma_0 &lt;- 10 n &lt;- length(testdata$X2) # Testobservatoren T &lt;- (n-1)*s^2/sigma_0^2 # Kritiske verdier L &lt;- qchisq(0.025, df = n - 1) U &lt;- qchisq(0.975, df = n - 1) Vi m√• s√• sammenligne verdien av testobservatoren T med de kritiske verdiene L og U. Legg merke til at vi har brukt en funksjon i R (qchisq()) for √• finne de aktuelle kvantilene i kjikvadratfordelingen. Alternativt kan vi sl√• opp i tabell. For to-utvalgs varianstest kan vi bruke funksjonen var.test(): var.test(testdata$X1, testdata$X2) Vi kan ogs√• her gj√∏re ensidige tester ved √• sette alternative =-argumentet til enten \"less\" eller \"greater\". Tester for andeler B√•de for ett-utvalgs og to-utvalgs test for andeler kan vi fylle inn tall direkte i testobservatoren p√• denne m√•ten (sett inn for de n√∏dvendige verdiene): # Ett-utvalgs test for andeler p_hatt &lt;- mean(testdata$A1) p_null &lt;- 0.5 n &lt;- length(testdata$A1) Z &lt;- (p_hatt - p_null)/sqrt(p_null*(1-p_null)/n) # To-utvalgs test for andeler p1_hatt &lt;- mean(testdata$A1) p2_hatt &lt;- mean(testdata$A2) n1 &lt;- length(testdata$X1) n2 &lt;- length(testdata$X2) p_hatt &lt;- mean(c(testdata$A1, testdata$A2)) # &lt;- Regner ut felles p_hatt Z &lt;- (p1_hatt - p2_hatt)/sqrt((1/n1 + 1/n2)*p_hatt*(1-p_hatt)) Testobservatorene m√• da sammenlingnes med relevant kvantil i normalfordelingen, som du enten finner i tabell i l√¶reboken eller ved √• bruke funksjonen qnorm() med √∏nsket kvantil som argument. Kjikvadrattester Hvis vi skal teste for goodness-of-fit for en fordeling kan vi raskt regne ut testobservatoren direkte. Vi bruker eksempelet fra forelesningsvideoen: p0 &lt;- c(0.45, 0.40, 0.15) # Fordeling under H0 f &lt;- c(102, 82, 16) # Observerte frekvenser e &lt;- p0*sum(f) # Forv. frekv. under H0 T &lt;- sum((f - e)^2/e) # Testobservator c &lt;- qchisq(.95, df = 2) # Kritisk verdi # Forkast H0? T &gt; c Alternativt s√• kan vi bruke chisq.test()-funksjonen direkte. Pass p√• √• bruke riktige argumentnavn (x = og p =) n√•r du skal gj√∏re goodness-of-fit: # Eventuelt direkte chisq.test(x = f, p = p0) Dersom du skal teste for uavhengighet s√• kan du anta at datasettet kommer som en ferdig kontingenstabell, med den ene gruppeinndelingen langs kolonnene, og den andre gruppeinndelingen langs radene. En slik tabell kan du sende rett inn i chisq.test()-funksjonen for √• gj√∏re en test for uavhengighet: # Test for uavhengighet immigration &lt;- read_xls(&quot;immigration-wide.xls&quot;, range = &quot;B2:E12&quot;, col_names = c(&quot;many&quot;, &quot;some&quot;, &quot;few&quot;, &quot;none&quot;)) chisq.test(immigration) Kritiske verdier i R Som vi har sett over baserer tester i R seg stort sett p√• en eller annen datainput. Som output f√•r du b√•de testobservator og p-verdi. Hvis du allikevel av en eller annen grunn (f.eks. p√• en hjemmeeksamen) trenger √• finne en kritisk verdi i en fordeling, s√• kan det v√¶re nyttig √• vite hvordan man gj√∏r dette i R i stedet for √• sl√• opp i en eller annen tabell i en bok. De kritiske verdiene finner vi ved √• bruke kvantilfunksjonene til den respektive fordelingen. Disse funksjonene har alltid et argument p og har som output det tallet som har sannsynlighetsmasse p til venstre for seg. Du m√• derfor velge p ut fra signifikansniv√• og om det er en ensidig/tosidig test. Kritiske verdier i T-fordelingen Dersom du f.eks skal utf√∏re en t-test for \\(H_0: \\mu = \\mu_0\\) mot \\(H_1: \\mu &lt; \\mu_0\\), med signifikansniv√• \\(\\alpha = 0.05\\) og har \\(40\\) observasjoner er kritisk verdi: qt(0.05, df = 40 - 1) ## [1] -1.684875 og du forkaster da dersom din testobservator \\(T\\) er mindre enn dette tallet. Hadde alternativ hypotesen v√¶rt \\(H_1: \\mu &gt; \\mu_0\\) ville kritisk verdi v√¶rt qt(1 - 0.05, df = 40 - 1) ## [1] 1.684875 og du forkaster dersom din testobservator \\(T\\) er st√∏rre enn dette tallet. For en to-sidig test (\\(H_1: \\mu\\neq \\mu_0\\)) forkaster du dersom \\(T\\) faller uten for intervallet: L &lt;- qt(0.05/2, df = 40 - 1) U &lt;- qt(1 - 0.05/2, df = 40 - 1) c(U,L) ## [1] 2.022691 -2.022691 Kritiske verdier i standardnormalfordelingen Helt likt som for t-fordelingen bare at det ikke er noen frihetsgrader involvert: # Ensidig mu &lt; mu0, alpha = 0.05 qnorm(0.05) ## [1] -1.644854 # Ensidig mu &gt; mu0, alpha = 0.05 qnorm(1 - 0.05) ## [1] 1.644854 # Tosidig L &lt;- qnorm(0.05/2) U &lt;- qnorm(1 - 0.05/2) c(U,L) ## [1] 1.959964 -1.959964 Alternativt er det bare √• pugge tallene \\(1.64\\) og \\(1.96\\). Kritiske verdier i \\(\\chi^2\\)-fordelingen # Kritisk verdi, 5% niv√•, ensidig test, nedre hale, 30 frihetsgrader qchisq(0.05, df = 30) ## [1] 18.49266 og du forkaster dersom testobservatoren er mindre enn dette tallet. # Kritisk verdi, 5% niv√•, ensidig test, √∏vre hale, 30 frihetsgrader qchisq(1 - 0.05, df = 30) ## [1] 43.77297 og du forkaster dersom testobservatoren er st√∏rre enn dette tallet. # Kritisk verdi, 5% niv√•, tosidig test, 30 frihetsgrader L &lt;- qchisq(0.05/2, df = 30) U &lt;- qchisq(1 - 0.05/2, df = 30) c(L, U) ## [1] 16.79077 46.97924 og du forkaster nullhypotesen dersom testobservatoren havner utenfor dette intervallet. Kritiske verdier i F-fordelingen F-fordelingen trenger vi n√•r vi skal teste om to varianser er like. Skal du gj√∏re denne testen manuelt er det lurt √• sette den st√∏rste variansen i telleren av testobservatoren \\[F = \\frac{S_{1}^2}{S_{2}^2}.\\] Uavhengig om det er en ensidig eller tosidig test, trenger vi da bare √• sjekke om testobservatoren overstiger den kritiske verdien i den √∏vre halen i F-fordelingen. Har vi brukt \\(30\\) observasjoner til √• regne ut \\(S_{1}^2\\) og \\(25\\) observasjoner til √• regne ut \\(S_{1}^2\\) blir kritisk verdi i en to-sidig test der \\(H_1: \\sigma_{1}^2 \\neq \\sigma_{2}^2\\) : # Kritisk verdi, 5% niv√•, tosidig test qf(1 - 0.05/2, df1 = 30 - 1, df2 = 25 - 1) ## [1] 2.217443 Er det en ensidig test hvor \\(H_1: \\sigma_{1}^2 &gt; \\sigma_{2}^2\\) blir kritisk verdi: # Kritisk verdi, 5% niv√•, ensidig test qf(1 - 0.05, df1 = 30 - 1, df2 = 25 - 1) ## [1] 1.945259 Husk: Du kan definere hva som er \\(S_{1}^2\\) og \\(S_{2}^2\\), og med strategien over definerer du alltid \\(S_{1}^2\\) til v√¶re den av variansene som er st√∏rst. "],["regresjon.html", " 4 Regresjon", " 4 Regresjon I forrige modul fokuserte vi p√• bin√¶re sp√∏rsm√•l av typen ‚ÄúEr det en forskjell mellom disse to populasjonene, eller ikke?‚Äù, ‚ÄúEr disse kjennetegnene uavhengige, eller ikke?‚Äù, og s√• videre. I denne modulen skal vi pr√∏ve √• g√• et steg lenger og tillate mer interessante sp√∏rsm√•l. I stedet for bare √• sp√∏rre om en eller annen effekt er til stede (eller ikke), s√• vil vi heller finne ut hvor stor denne effekten er, hvilken retning den g√•r, og kanskje om vi kan bruke kunnskapen vi f√•r om statistiske sammenhenger til √• si noe fornuftig om hva som vil skje for noe som vi enda ikke har observert. Da er det regresjon som gjelder, og mer spesifikt for v√•r del: line√¶r regresjon. Regresjon er et hovedtema i MET4. Vi innf√∏rer en statistisk modell som i sin enkleste form sier at en forklaringsvariabel \\(X\\) henger sammen med en responsvariabel \\(Y\\) p√• en helt bestemt m√•te, nemlig gjennom ligningen \\[Y = \\beta_0 + \\beta_1 X + \\epsilon.\\] Ligningen over sier at det er en line√¶r sammenheng mellom \\(X\\) og \\(Y\\), men at det i tillegg kommer en uforutsigbar st√∏yvariabel \\(\\epsilon\\) som gj√∏r at vi ikke vil kunne observere den line√¶re sammenhengen direkte. Det vi derimot kan gj√∏re, er √• bruke de observerte \\(X\\)er og \\(Y\\)er til √• finne ut hvilke verdier av \\(\\beta_0\\) og \\(\\beta_1\\) som passer best. Til det bruker vi minste kvadraters metode, som beskrevet i videoforelesningene i denne modulen. Vi deler arbeidet med regresjon inn i tre deler. I den f√∏rste (og st√∏rste) delen g√•r vi grundig gjennom ulike sider vi den enkle line√¶re regresjonsmodellen over. I den andre delen ser vi p√• multippel regresjon som er en utvidelse av enkel regresjon der vi tillater flere forklaringsvariabler p√• h√∏yre side av likhetstegnet, og i den tredje delen ser vi p√• ulike praktiske aspekter ved regresjonsmodellering og modellbygging. I videoforelesningene g√•r vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved √• klikke p√• lenkene under: Slides til ‚ÄúRegresjon‚Äù R-script til ‚ÄúRegresjon‚Äù TIPS: Hvis du √∏nsker √• laste ned lysbildene som PDF trykker du p√• linken over, velger ‚ÄúSkriv ut‚Äù, og s√• skriver du ut som PDF. F√∏r du gj√∏r det b√∏r du scrolle gjennom alle sidene slik at ligningene vises korrekt. "],["enkel-regresjon.html", "4.1 Enkel regresjon", " 4.1 Enkel regresjon 4.1.1 Videoforelesninger 4.1.2 Kommentarer Vi har sett p√• en del figurer som illustrerer noen pedagogiske poenger, og l√¶rebokens kapittel 16 g√•r detaljert til verks n√•r de beskriver de ulike l√¶ringsmomentene: I kapittel 16.1 kan vi lese mer om den statistiske modellen som vi kaller enkel regresjon. I kapittel 16.2 introduseres minste kvadraters metode for √• estimere regresjonskoeffisientene ved hjelp av data. De viser til og med hvordan det kan gj√∏res manuelt ved hjelp av bildatasettet, men det er selvsagt kun for √• illustrere hvodan formlene ser ut. Vi estimerer ved hjelp av R, og vi har sett i videoforelesningen hvordan vi gj√∏r det ved hjelp av lm()-funksjonen. Det som gj√∏r regresjon til et statistisk problem er feilleddet \\(\\epsilon\\). Vi tenker oss at for en gitt verdi av \\(X\\), s√• vil ¬´naturen¬ª regne ut verdien av \\(Y\\) ved √• regne ut den line√¶re sammenhengen \\(Y = \\beta_0 + \\beta_1 X\\), og s√• legge til st√∏yvariabelen \\(\\epsilon\\) som trekkes fra en sannsynlighetsfordeling. Vi kan ikke observere direkte hvilke \\(\\epsilon\\) som ¬´naturen¬ª har ¬´trukket¬ª (for da ville vi med en gang kunne regnet oss frem til verdiene av \\(\\beta_0\\) og \\(\\beta_1\\)). For gitte estimater av regresjonskoeffisientene \\(\\widehat \\beta_0\\) og \\(\\widehat \\beta_1\\) (som vi kan finne f.eks. ved hjelp av minste kvadraters metode), s√• kan vi regne ut de observerte residualene \\[\\widehat\\epsilon_i = Y_i - \\widehat Y_i = Y_i - (\\widehat \\beta_0 + \\widehat \\beta_1 X_i).\\] Ved √• analysere residualene kan vi si mer om f.eks Er det egentlig en line√¶r sammenheng mellom \\(X\\) og \\(Y\\)? Hvis det er m√∏nstre og sammenhenger i de observerte residualene, tyder det p√• at den enkle line√¶re modellen ikke fanger opp hele sammenhengen mellom \\(X\\) og \\(Y\\). Vi kan g√• mer spesifikt til verks: n√∏yaktig hvilke antakelser om residualene er ser ut til √• v√¶re brutt? I senere √∏konometrikurs vil dere kunne l√¶re mer om hvordan vi h√•ndterer de ulike problemene. Hvor stor er variansen til \\(\\epsilon\\)? Det brukes videre til √• sette opp den viktige signifikanstesten for om stigningstallet i regresjonen er forskjellig fra null. Alt dette behandles grudig i bokens kapittel 16.3‚Äì16.6. Her b√∏r teksten leses godt. Kode til bileksempelet finnes i scriptet som f√∏lger med videoforelesningene. N√•r det gjelder enkel regresjon kan du sjekke om du har f√•tt med deg det vesentligste ved √• diskutere f√∏lgende sp√∏rsm√•l: Hva er responsvariabelen og hva er forklaringsvariabelen i enkel regresjon? Hva er fortolkningen av de to regresjonskoeffisientene? Hvilket prinsipp er det vi legger til grunn n√•r vi skal bestemme (estimere) verdien av koeffisientene ved hjelp av data? Skriv opp formlene for koeffisientestimatene. Kan du gi en intuitiv fortolkning av disse? Er de rimelige? Kan du ved hjelp av formelen for \\(\\widehat\\beta_1\\) utlede sammenhengen mellom stigningstallet \\(\\beta_1\\) og korrelasjonskoeffisienten* mellom \\(X\\) og \\(Y\\)? Hvilken rolle spiller feilleddet (\\(\\epsilon\\))? Skriv opp de 4 + 1 forutsetningene. N√•r m√• den siste v√¶re oppfylt? N√•r kan vi klare oss uten? Hva er testobservatoren n√•r vi tester H\\(_0: \\beta_1 = 0\\)? Kan du holde styr p√• de fire standardavvikene vi har jobbet med i denne forelesningen? Hva mener vi med √• diagnostisere en regresjonsmodell? Hva er \\(R^2\\), og hva m√•ler den? Hva sier \\(R^2\\) ikke noe om? Her er noen grunnleggende ferdigheter fra kapittel 16. Klarer du dette? Bruke til √• tilpasse en enkel regresjonsmodell for et datasett? Bruke til √• skrive ut oversiktlige regresjonstabeller? Tolke en regresjonsutskrift? Hente ut relevant informasjon etter en slik tilpasning? Bruke informasjon fra regresjonsutskriften til √• regne ut antall stjerner for h√•nd? Lage diagnoseplott i ? Diagnistisere en modell? Identifisere innflytelsesrike observasjoner? "],["multippel-regresjon.html", "4.2 Multippel regresjon", " 4.2 Multippel regresjon 4.2.1 Videoforelesninger 4.2.2 Kommentarer I kapittel 17 utvides regresjonsbegrepet til multippel regresjon, som i prasis betyr at vi kan ha flere enn en forklaringsvariable: \\[Y = \\beta_0 + \\beta_1X_1 + \\cdots \\beta_kX_k + \\epsilon,\\] men utover dette er alle detaljene vi har snakket om de samme. For eksempel: Tolkningen av regresjonskoeffisienten: En endring p√• en enhet i forklaringsvariabelen \\(X_j\\) henger sammen med \\(\\beta_j\\) enhets endring i responsvariabelen \\(Y\\) (merk at jeg ikke brukker begrepet ‚Äúf√∏rer til‚Äù, vi kan ikke uten videre fortolke sammenhengen som kausal!). Analysen av residualene \\(\\widehat \\epsilon_i = Y_i - \\widehat Y_i\\) er den samme og har samme form√•l 1‚Äì3 som over. \\(R^2\\) har samme fortolkning. R-kommandoen er den samme, vi bare sette pluss mellom forklaringsvariablene, f.eks reg &lt;- lm(Y ~ X1 + ... + Xk, data = x) I tillegg innf√∏rer vi noen nye begreper: Justert \\(R^2\\): Vi viste i forelesningen at vi vil alltid klare √• √∏ke \\(R^2\\) ved √• legge til forklaringsvariable, selv om de ikke har noe med problemet √• gj√∏re. Derfor innf√∏rte vi en justert \\(R^2\\) som tar h√∏yde for nettopp dette, ved √• bli st√∏rre bare dersom den aktuelle forklaringsvariebelen faktisk forklarer en reell mengde av variasjonen i responsvariabelen. Se avsnitt 17-2f i l√¶reboken. Multikolinearitet: Dersom en forklaringsvariabel er sterkt korrelert med en eller flere andre forklaringsvariabler har vi multikolinearitet. Det blir naturlig nok et problem √• skille effekter fra hverandre n√•r de i realiteten er helt eller nesten like. Ekstremtilfellet er perfekt multikolinearitet der en variabel er en eksakt line√¶r funksjon av en eller flere andre variable. Det typiske tilfellet er at vi har to kolonner der vi m√•ler det samme fenomenet, men med to ulike enheter, f.eks. cm og m. Selvsagt kan vi ikke klare √• identifisere en separat og uavhengig effekt av \\(X\\) p√• \\(Y\\) om vi skifter m√•leenhet, og vi vil f√• en feilmelding dersom vi pr√∏ver p√• det. Det er ekvivalent med √• dele p√• null (every time you divide by zero, God kills a kitten!). L√∏sning: fjern en av kolonnene fra regresjonsanalysen. Verre er det om to variable m√•ler nesten det samme, men ikke helt, som i skoledataeksempelet der vi kunne bruke b√•de innbyggertall og antall femteklassinger i kommunen som forklaringsvariabler. De henger tett sammen, men selvsagt ikke eksakt, og det virker rart √• kunne knytte separate efekter til disse to variablene. I dette tilfellet f√•r vi likevel ikke feilmeldinger, men konsekvensen kan fort bli at standardavvikene (usikkerheten!) til koeffisientestimatene eksploderer, og at ingen av variablene blir signifikant forskjellige fra null, selv det det faktisk er en sterk sammenheng mellom kommunest√∏rrelse og pr√∏veresultat (husk at testobservatoren: \\(t = \\widehat \\beta_k/\\sigma_{\\beta_k}\\) blir liten n√•r nevneren blir stor). F-test for multiple sammenligninger: Dette henger n√∏ye sammen med variansanalyse (analysis of variance, ANOVA), som n√• er tatt ut av pensum i kurset. For √• forst√• dette kan vi sette opp et eksempel, med to forklaringsvariabler: \\[Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2.\\] Etter √• ha brukt miste kvadraters metode for √• estimere de tre koeffisientene er vi kanskje interessert i √• vurdere den statsistiske signifikansene til de to stigningstallene separat. Da tester vi de to nullhypotesene \\(\\beta_1 = 0\\) og \\(\\beta_2 = 0\\), som vi i praksis gj√∏r ved √• se p√• hvor mange stjerner de f√•r i regresjonsutskriften. Men sett at ingen av koeffisientene er signifikant forskjellige fra null, kan vi da slutte at vi ikke kan forkaste hypotesen \\(\\beta_1 = \\beta_2 = 0\\), dvs at begge koeffisientene er lik null, og at ingen av forklaringsvariablene forklarer variasjon i \\(Y\\)? NEI, det kan vi ikke. Vi kan for eksempel lett tenke oss at vi p√• grunn av multikolinearitet ikke f√•r separate forkastninger av de to nullhypotesene, men at ved √• fjerne en variabel, s√• blir den andre signifikant. For √• virkelig forst√• dette problemet kan du godt lese starten p√• kapittel 14.1 samt kapittel 14.2 om multiple sammenligninger (som strengt tatt ikke er pensum), men essensen er alts√•: \\[\\textrm{√Ö forkaste H}_0: \\beta_1 = 0 \\textrm{ og H}_0: \\beta_2 = 0 \\textrm{ er ikke det samme som √• forkaste H}_0: \\beta_1 = \\beta_2 = 0!\\] For √• gjennomf√∏re den siste testen m√• vi sette opp en egen testobservator, som viser seg √• v√¶re \\(F\\)-fordelt. L√¶reboken lister opp noen detaljer i avsnitt 17-2f, og essensen er at vi setter opp en br√∏k p√• formen \\[F = \\frac{\\textrm{Variasjon i } Y \\textrm{ som fanges opp av regresjonsmodellen med } X_1 \\textrm{ og }X_2}{\\textrm{Variasjon i } Y \\textrm{ som fanges opp av regresjonsmodellen uten } X_1 \\textrm{ og }X_2}.\\] Dersom denne br√∏ken viser seg √• v√¶re stor (som definert av signifikansniv√• og frihetsgrader, se l√¶rebok), forkaster vi nullhypotesen om at begge koeffisientene begge kan v√¶re lik null. I en generell multippel regresjon med \\(k\\) forklaringsvariable rapporterer R F-statistic: etc, med verdien av \\(F\\)-observatoren i testen for \\[H_0: \\beta_1 = \\cdots = \\beta_k = 0,\\] og dersom den oppgitte \\(p\\)-verdien er mindre enn f.¬†eks. 5%, kan vi slutte at ikke alle koeffisientene kan v√¶re null samtidig (selv om ingen av koeffisientene i seg selv n√∏dvendigvis er signifikant forskjellig fra null). Som en s√•kalt fun fact kan vi nevne at det er enkelt √• teste for signifikansen til grupper av variable p√• denne m√•ten, f.eks hvis det er noen variable som m√•ler lignende ting (si \\(X_2, X_4\\) og \\(X_5\\)). I R kan du estimere to modeller, en modell som inkluderer variablene (f.eks. reg_stor) og en modell der du tar bort de aktuelle variablene (f.eks. reg_liten). Du kan da kj√∏re kommandoen anova(reg_stor, reg_liten) for √• teste \\[H_0: \\beta_2 = \\beta_4 = \\beta_5 = 0.\\] Kritikk av l√¶reboken: L√¶reboken har en tabell p√• s. 701 som viser sammenhengen mellom ulike statistiske st√∏rrelser som vi kan regne ut for en regresjonsmodell. \\(R^2\\) kjenner vi som forklaringsgraden, \\(s_{\\epsilon}\\) er standardavviket til residualene, \\(F\\) er testobservatoren for modellgyldighet som vi definerte uformelt over, og som er definert formelt nederst p√• s. 700, mens SSE (Sum of Squares Error) henger n√∏ye sammen med standardavviket, som vi ogs√• kan se p√• s. 700. P√• disse sidene ser vi mange ligninger som viser hvordan disse st√∏rrelsene formelt henger sammen, og i tabellen p√• s. 701 ser vi blant annet at dersom SSE er liten, er ogs√• \\(s_{\\epsilon}\\) liten, \\(R^2\\) er n√¶r null, og \\(F\\)-observatoren er stor. Det er greit nok, men de har en ekstra kolonne som sl√•r fast at regresjonsmodellen er good. Her menes det ikke at regresjonsmodellen er god i den forstand at vi skal reagere med glede eller lettelse (slik noen gjerne gj√∏r), men at variasjonen i datamaterialet i stor grad lar seg forklare av modellen v√•r. I et tenkt eksempel der den sanne sammenhengen mellom \\(Y\\) og \\(X\\) er gitt ved \\(Y = \\beta_0 + \\beta_1X + \\epsilon\\), men der \\(\\beta_1\\) er forholdsvis liten og \\(s_{\\epsilon}\\) er relativt stor, vil f.eks. \\(R^2\\) bli liten, selv om den enkle line√¶re regresjonsmodellen repsesenterer sannheten og av alle tenkende mennesker m√• sies √• v√¶re god. Det er desverre mange l√¶reb√∏ker som blander disse to fortolkningene, ikke gj√∏r det! Her er enda noen grunnleggende begreper. Har du f√•tt med deg dette? Hva mener vi med at en observasjon er innflytelsesrik? Hva er grunnen til at vi trenger justert \\(R^2\\) med flere forklaringsvariable? Hva er forskjellen p√• perfekt og tiln√¶rmet multikolinearitet i line√¶r regresjon? Hva blir konsekvensen i hvert av tilfellene? Kan du gi en praktisk og intuitiv forklaring p√• hvorfor multikolinearitet n√∏dvendigvis m√• v√¶re et problem? Hva er forskjellen p√• statistisk og √∏konomisk signifikans? Kan du sette opp konkrete eksempler der vi kan estimere statistisk signifikante, men ikke √∏konomisk signifikante effekter i multippel regresjon? Hva med den motsatte situasjonen, √∏konomisk signifikant, men ikke statistisk signifikant? Grunnleggende ferdigheter: Klarer du dette? Bruke R til √• tilpasse en multippel regresjonsmodell for et datasett? Bruke R til √• finne s√¶rlig innflytelsesrike observasjoner? Tolke en multippel regresjonsutskrift? "],["modellbygging.html", "4.3 Modellbygging", " 4.3 Modellbygging 4.3.1 Videoforelesninger 4.3.2 Kommentarer Kapittel 18 dekker de grunnleggende begrepene innen modellbygging. I kap. 18.1 snakkes det om polynomiske modeller, i kap. 18.2 behandles dummyvariabler. Kapittel 18.3 og 18.4 handler om hvordan vi i praksis kan jobbe for √• velge ut variable i en gitt situasjon. Forelesningene dekker i grunn greit det vi skal f√• med oss her. Som en sjekk om du har f√•tt med deg det vesentlige, kan du svare p√• f√∏lgende sp√∏rsm√•l: Vi har l√¶rt tre typer log-transformasjoner. Hva blir fortolkningen av koeffisientene for hver av disse? Kan du nevne tre gode grunner til at log-transformasjoner er nyttige? Hvorfor sier vi at f√∏lgende modell er line√¶r? \\(Y = \\beta_0 + \\beta_1X + \\beta_1X^2 + \\varepsilon\\) Vil vi ikke f√• problemer med multikolinearitet i modellen over? Nevn en veldig god grunn til at vi m√• v√¶re ytterst forsiktig med polynomtransformasjoner. Hva er en dummyvariabel? Hva er fortolkningen av regresjonskoeffisienten til en dummyvariabel? Hva er fortolkningen av regresjonskoeffisienten til et interaksjonsledd mellom m√•levariabelen \\(X\\) og dummyvariabelen \\(D\\)? Et utrolig viktig poeng, men bruk tid til √• tenke over og formulere et svar: Hvorfor er det viktig √• tenke p√• multippel testing i sammenheng med variabelutvelgelse? Grunnleggende ferdigheter: Klarer du dette? Bruke logtransformasjoner i R? Bruke poynomtransformasjner i R? Sette opp en fornuftig regresjonsmodell ved √• ta utgangspunkt i et datasett og et analyseform√•l, og argumentere godt for dine valg? Denne ferdigheten har blitt testet p√• hver eneste hjemmeeksamen i manns minne! "],["oppgaver-1.html", "4.4 Oppgaver", " 4.4 Oppgaver 4.4.1 Regresjon med en forklaringsvariabel Oppgave 1 Forskere har brukt statistikk til √• unders√∏ke om TV-titting er forbundet med overvekt. De har samlet inn data fra 15 10-√•ringer om antall timer TV-titting per uke og antall kilo overvekt hos barnet (rapportert som differanse fra normalvekt). De innsamlede dataene er oppsummert i tabellen: TV_titting Overvekt 42 17 35 5 28 -1 34 0 37 13 38 15 32 5 33 7 18 -7 28 7 36 6 29 7 29 4 34 15 18 -5 Bruk R til √• lage et spredningsplott av resultatene. Hva tror du om forholdet mellom de to variablene utfra figuren? Sett opp regresjonsuttrykket for √• unders√∏ke om overvekt er forbundet med TV-titting. La overvekt v√¶re responsvariabelen. Hva er betydningen av hver parameter i uttrykket? Bruk R til √• estimere parameterne. Hva kan koeffisientene fortelle deg om forholdet mellom overvekt og TV-titting? Beregn et 95 % konfidensintervall for \\(\\beta_1\\). Hint: Bruk ‚Äòsummary()‚Äô p√• regresjonsmodellen for √• finne \\(S(\\hat{\\beta}_1)\\) som da gitt i kolonnen ‚ÄúStd. Error‚Äù. Bruk R til √• beregne et 95 % prediksjonsintervall for overvekt i kilo for et barn som ser p√• TV 30 timer i uken. Hva forteller intervallet deg? Bruk R til √• beregne et 95 % konfidensintervall for gjennomsnittlig overvekt for barn som ser 30 timer p√• TV i uken. Hvordan er tolkningen av dette intervallet forskjellig fra det i oppgave d? Hva er forventet overvekt for barn som ser 0 timer p√• TV i uken utfra modellen? Hva kan v√¶re problematisk ved √• gj√∏re denne type analyser av en regresjonsmodell? L√∏sning df_tv &lt;- data.frame( TV_titting = c(42, 35, 28, 34, 37, 38, 32, 33, 18, 28, 36, 29, 29, 34, 18), Overvekt = c(17, 5, -1, 0, 13, 15, 5, 7, -7, 7, 6, 7, 4, 15, -5)) plot(df_tv$TV_titting, df_tv$Overvekt, type = &quot;p&quot;, xlab=&quot;TV-titting&quot;, ylab=&quot;Overvekt&quot;) Plottet viser en ganske tydelig trend om at TV-titting og overvekt er relaterte. Dette kan vi unders√∏ke n√¶rmere. Vi setter overvekt som responsvariabel og TV-titting som forklaringsvariabel. Uttrykket blir da: \\[\\begin{equation} \\text{Overvekt} = \\beta_0 + \\beta_1 \\text{TV-titting} + \\epsilon \\end{equation}\\] Ser vi bort fra dataene ville \\(\\beta_0\\) v√¶re forventet overvekt for personer som ikke ser p√• tv. Av spredningsplottet ser det derimot ut som at vi ikke har data ved 0 TV-titting og det er derfor ikke fornuftig med en direkte tolkning av denne parameteren. Under antagelsen om at regresjonsmodellen er gyldig forteller \\(\\beta_1\\) hvor mye vi forventer at overvekten √∏ker dersom man √∏ker TV-tittingen med 1 time. Vi estimerer en regresjonsmodell fra dataene og skriver ut tabellen med resultatene: reg &lt;- lm(Overvekt ~ TV_titting, df_tv) summary(reg) ## ## Call: ## lm(formula = Overvekt ~ TV_titting, data = df_tv) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.1917 -2.6147 0.2795 2.6785 6.8083 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -22.2124 5.1359 -4.325 0.000824 *** ## TV_titting 0.8942 0.1602 5.583 8.88e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.026 on 13 degrees of freedom ## Multiple R-squared: 0.7057, Adjusted R-squared: 0.683 ## F-statistic: 31.17 on 1 and 13 DF, p-value: 8.88e-05 # For en finere utskrift kan du bruke f√∏lgende: # library(stargazer) # stargazer(reg, type=&quot;text&quot;) Det er tydelig sigifikans for at hver av parameterne er ulik null. For \\(\\beta_1\\) betyr dette at trenden vi observerte i spredningplottet var signifikant. Videre kan vi tolke det positive fortegnet til \\(\\beta_1\\) som at flere timer TV-titting er relatert med √∏kt overvekt. Merk at vi ikke kan si utfra dataene at mer TV-titting f√∏rer til overvekt. En mer riktig tolkning er √• si at de forekommer samtidig i populasjonen. (Dersom vi √∏nsket √• finne ut av kausaliteten m√•tte man p√• et tilfeldig utvalg av barn satt noen til √• se mye p√• TV og noen til √• se mindre p√• TV, og deretter unders√∏kt om dette resulterte i statistisk signifikant h√∏yere overvekt hos en av gruppene. Dette krysser imidlertid noen etiske grenser om √• p√•f√∏re barn overvekt, dersom hypotesen er sann.) Fra R utskriften ser vi at \\(S(\\hat{\\beta}_1)=0.1602\\). Videre er \\(t_{0.025, 13} = 2.16\\). Et 95 % konfidensintervall for \\(\\beta_1\\) er da gitt ved: \\[\\left[\\hat{\\beta}_1 - t_{\\alpha/2, n - 2}S(\\hat{\\beta}_1), \\hat{\\beta}_1 + t_{\\alpha/2, n - 2}S(\\hat{\\beta}_1)\\right]\\\\ =\\left[0.8942 - 2.16\\times0.1602, 0.8942 + 2.16\\times0.1602\\right]\\\\ =\\left[0.5481, 1.2402\\right]\\] e) reg.pred &lt;- predict(reg, newdata = data.frame(TV_titting = c(30)), interval = &quot;predict&quot;) reg.pred ## fit lwr upr ## 1 4.614735 -4.380262 13.60973 # stargazer(reg.pred, type=&quot;text&quot;) Dersom vi trekker et nytt barn som ser 30 timer p√• TV per uke, vil barnet i 95 % av tilfellene v√¶re innenfor prediksjonsintervallet dersom vi hadde gjentatt dette mange ganger. reg.conf &lt;- predict(reg, newdata = data.frame(TV_titting = c(30)), interval = &quot;confidence&quot;) reg.conf ## fit lwr upr ## 1 4.614735 2.317582 6.911888 #evt # library(stargazer) # stargazer(reg.conf, type=&quot;text&quot;) Konfidensintervallet viser hvor gjennomsnittet av m√•linger p√• et nytt sett med barn som ser 30 timer p√• TV per uke vil ligge i 95 % av nye eksperimenter. reg.zero &lt;- predict(reg, newdata = data.frame(TV_titting = c(0)), interval = &quot;prediction&quot;) reg.zero ## fit lwr upr ## 1 -22.21237 -36.30997 -8.11477 # evt # library(stargazer) # stargazer(reg.zero, type=&quot;text&quot;) Beste gjetning er at barn som ser 0 timer p√• TV i uken er 22.2 kg under normalvekt (!). Et kjapt s√∏k viser at barn p√• 10 √•r veier mellom 25.5 og 39 kg. Det h√∏res urimelig ut at veldig lite TV-titting har sammenheng med ekstrem underern√¶ring blant den samme populasjonen av barn som ser rundt 30 timer p√• TV i uken. Det er flere ting som kan g√• galt n√•r man gj√∏r en slik analyse av en modell: Modellen kan v√¶re gal. Vi antar et line√¶r forhold mellom TV-titting og overvekt, noe som ikke trenger √• v√¶re riktig ved 0 timer TV-titting. Datasettet dekker ikke den gruppen barn som ser 0 timer p√• TV, s√• med mindre modellen er helt riktig (noe den sjelden er) vil den ikke kunne generalisere s√• langt utenfor omr√•det vi estimerte parameterne p√•. Med mindre forholdet mellom TV-titting og overvekt er kausalt, kan det v√¶re at sammenhengen som er observert mellom dem i dataene ikke vil v√¶re det samme langt utenfor det aktuelle data-omr√•det. Oppgave 2 Vi skal unders√∏ke om alder har sammenheng med hvor lang tid man bruker p√• et puslespill. Vi har data fra et tilfeldig utvalg av 210 voksne personer om alder og tid brukt p√• oppgaven. Uttrykk alder som \\(X\\) og tid i minutter som \\(Y\\). F√∏lgende deskriptive statistikker er beregnet for datasettet: \\(s_{xy}= 8, s_x^2, = 110, s_y^2 = 42, \\bar{x} = 40, \\bar{y} = 20\\) hvor \\(\\bar{x},\\bar{y}\\) er gjennomsnittene. Sett opp regresjonsuttrykket for sammenhengen mellom \\(X\\), \\(Y\\) og st√∏y \\(\\epsilon\\). Hva er antagelsen for sammenhengen mellom X og \\(\\epsilon\\)? Hva er uttrykket for beste gjetning/prediksjon \\(\\hat{Y}_i\\) gitt en verdi av forklaringsvariabelen \\(X_i\\) for regresjonsmodellen du har satt opp? Hva er uttrykket for residualene? Vis at hva uttrykket for regresjonsparameterne blir n√•r de estimeres med minste kvadraters metode. Regn ut minste kvadraters estimat av parameterne. L√∏sning Regresjonsuttrykket er \\[\\begin{equation} Y = \\beta_0 + \\beta_1 X + \\epsilon \\end{equation}\\] Vi antar at forklaringsvariabelen \\(X\\) er uavhenging st√∏yen \\(\\epsilon\\). Dermed vil ogs√• kovariansen v√¶re null, \\[\\begin{equation} \\text{Cov}(X, \\epsilon) = 0. \\end{equation}\\] Beste gjetning er forvetningen betinget p√• utfallet av forklaringsvariabelen \\(X\\): \\[\\begin{align} \\hat{Y}_i &amp;= E[Y|X = X_i] = E[\\beta_0 + \\beta_1 X + \\epsilon|X = X_i] \\\\ &amp;= \\beta_0 + \\beta_1 X_i + E[\\epsilon|X = X_i] \\\\ &amp;= \\beta_0 + \\beta_1 X_i + E[\\epsilon] \\\\ &amp;= \\beta_0 + \\beta_1 X_i \\end{align}\\] Residualene er forskjellen mellom data og prediksjon \\[\\begin{equation} r_i = \\hat{Y}_i - Y_i \\end{equation}\\] Minste kvadraters metode minimerer summen av residualene kvadrert, s√• \\[\\begin{align} SSE &amp;= \\sum_{i} r_i^2 \\\\ &amp;= \\sum_{i} (\\beta_0 + \\beta_1 X_i - Y_i)^2. \\end{align}\\] Minim√©r ved √• sette den deriverte for hver parameter til null: \\[\\begin{align} \\frac{dSSE}{d\\beta_0} &amp;= \\sum_{i} 2 (\\beta_0 + \\beta_1 X_i - Y_i) \\overset{!}{=} 0 \\\\ \\implies \\quad \\beta_0 &amp;+ \\beta_1 \\frac{\\sum_{i} X_i}{N} = \\frac{\\sum_{i} Y_i}{N} \\\\ \\implies \\quad \\beta_0 &amp;= \\frac{\\sum_{i} Y_i}{N} - \\beta_1 \\frac{\\sum_{i} X_i}{N}, \\end{align}\\] og \\[\\begin{align} \\frac{dSSE}{d\\beta_1} &amp;= \\sum_{i} 2 (\\beta_0 + \\beta_1 X_i - Y_i)X_i \\\\ &amp;= 2 \\beta_0 \\sum_{i} X_i + 2 \\beta_1 \\sum_{i} X_i^2 - 2\\sum_{i} X_i Y_i \\overset{!}{=} 0 \\\\ &amp;\\implies \\quad \\beta_0 \\frac{\\sum_{i} X_i}{N} + \\frac{\\sum_{i} X_i^2}{N} = \\frac{\\sum_{i} X_i Y_i}{N} . \\end{align}\\] Satt inn for \\(\\beta_0\\) blir det \\[\\begin{align} \\left ( \\frac{\\sum_{i} Y_i}{N} - \\beta_1 \\frac{\\sum_{i} X_i}{N} \\right ) \\frac{\\sum_{i} X_i}{N} + \\beta_1\\frac{\\sum_{i} X_i^2}{N} &amp;= \\frac{\\sum_{i} X_i Y_i}{N} \\\\ \\beta_1 \\left ( \\frac{\\sum_{i} X_i^2}{N} - \\left ( \\frac{\\sum_{i} X_i}{N} \\right )^2 \\right ) &amp;= \\frac{\\sum_{i} X_i Y_i}{N} - \\frac{\\sum_{i} X_i}{N}\\frac{\\sum_{i} Y_i}{N} \\\\ \\beta_1 S_X^2 &amp;= S_{XY}. \\end{align}\\] Da blir beta_1 &lt;- 8 / 110 beta_1 ## [1] 0.07272727 og beta_0 &lt;- 20 - beta_1 * 40 beta_0 ## [1] 17.09091 Oppgave 3 Figurene nedenfor viser residualene (feilleddene) vi f√•r ut fra et par ulike modeller. Ser plottene ut til √• tilfredsstille kravene for enkel regresjon? Hvis ikke, hva ser ut til √• v√¶re galt for hver av figurene? Hvordan kan man h√•ndtere brudd p√• betingelsene i de ulike situasjonene? L√∏sning Her ser st√∏yleddet ut som det har konstant varians og forventing lik null. Det betyr at antagelsene er oppfylt. St√∏yen er symmetrisk om null, men kan se ut som den √∏ker. Alts√• er det brudd p√• antagelsen om konstant varians. √òkningen ser ut til √• v√¶re jevn, og en log-transformasjon kunne i dette tilfellet v√¶rt til hjelp. Her ser det ut som at vi har perioder med h√∏y varians etterfulgt av perioder med lavere varians. Vi skal ikke se s√• mye n√¶rmere p√• hvordan dette kan h√•ndteres i MET4, men man kan komme over det i senere kurs. Her ser det ut som at st√∏yen har en relasjon i tid, og at h√∏ye/lave verdier henger sammen med h√∏ye/laver verdier. Det er ikke √•penbart at det er dette som foreg√•r, og vi burde unders√∏kt det n√¶rmere. Senere i kurset skal vi h√•ndtere dette ved bruk av tidsrekkemodeller. Merk at det ikke alltid er lett √• se direkte fra figurene hva som er galt. Riktig bruk av statistiske tester og diagnoseplott kan hjelpe med √• oppdage brudd p√• betingelsene. Figurene i denne oppgaven er generert ved simulering, vi kan derfor vite akkurat hva som er galt. For virkelige data vil kunne v√¶re vanskeligere √• tolke fordi det ikke n√∏dvendigvis er √©n ting som er galt om gangen. Man m√• ogs√• v√¶re p√• vakt for overtolkning av det som egentlig er tilfeldigheter. 4.4.2 Multippel regresjon og modellbygging Oppgave 1 Denne oppgaven skal gi et forhold til hvordan teorien funker i praksis. Vi skal simulere data fra konstruerte modeller gj√∏re analyser p√• dem. Fordelen med √• begynne her er at man f√•r er forhold til hvordan statistikk kan og b√∏r tolkes utfra teorien. Med virkelige data vil antagelsene som ligger til grunn for modellene stort sett v√¶re brutt, i st√∏rre eller mindre grad, og kjernen i god statistisk analyse er √• vite hva man kan og ikke kan gj√∏re likevel. God kjennskap til hvordan det burde funke i teorien er en viktig byggestein for statistisk forst√•else. Vi generer opp data som skal brukes til √• estimere en model. rnorm trekker tall fra en standard normalfordeling. mutate() legger til nye kolonner i dataframe-en basert p√• allerede eksisterende kolonner. set.seed() setter startpunktet for pseudotilfeldige tall, og om du setter samme seed f√•r du de samme tilfeldige tallene som vi har brukt. library(tidyverse) set.seed(4) df_mdl &lt;- data.frame( x1 = rnorm(100, sd = 2), x2 = rnorm(100, sd = 2), eps = rnorm(100) ) %&gt;% mutate( y = 2 * x1 + (-1) * x2 + eps ) Hva er de eksakte parameterne i modellen som passer til dataene vi har generert, og hva er fordelingen til hver av forklaringsvariablene og st√∏y-leddet? Er betingelsen om uavhengig feilledd oppfylt? Gener√©r opp dataene selv og estimer parameterne basert p√• dataene. Tolk estimatene. Lag 95 % konfidens- og prediksjonsintervaller for en prediksjon hvor \\(X_1=1, X_2=1\\) basert p√• estimatene dine. Hva er eksakt prediksjonsintervall basert p√• modellen vi har generert data fra? Ser dine prediksjonsintervaller rimelige ut utfra dette? Hvorfor er de ikke eksakt like? Stemmer konfidensintervallet overens med modellen? Tolk konfidensintervallet basert p√• at vi kan generere opp nye data (med et annet seed). Hva er P-verdien i F-test for at vi har en signifikant sammenheng mellom responsvariabelen og forklaringsvariablene? L√∏sning Fordelingen til forklaringsvariablene er \\[\\begin{align} X_1, X_2 \\sim N(0, 2) \\end{align}\\] fordi vi har trukket dem fra en normalfordeling med forventning 0 og standardavvik 2. Videre er fordelingen til st√∏yleddet en standard normalfordeling \\(\\epsilon\\sim N(0,1)\\). Betingelsen om uavhengig feilledd er oppfylt siden vi ikke har brukt feilleddet til √• generere forklaringsvariablene. Det er responsvariabelen, men den skal alts√• v√¶re avhengig av st√∏yleddet. Modellen tar formen \\[\\begin{align} Y = 2 X_1 - X_2 + \\epsilon,\\quad \\epsilon \\sim N(0, 1), \\end{align}\\] hvor parameterne er eksakt fordi vi har laget dataene selv. reg &lt;- lm(y ~ x1 + x2, data = df_mdl) stargazer(reg, type = &quot;text&quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## y ## ----------------------------------------------- ## x1 1.986*** ## (0.053) ## ## x2 -1.091*** ## (0.048) ## ## Constant -0.055 ## (0.096) ## ## ----------------------------------------------- ## Observations 100 ## R2 0.958 ## Adjusted R2 0.957 ## Residual Std. Error 0.956 (df = 97) ## F Statistic 1,094.997*** (df = 2; 97) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Vi ser at estimatene av koeffisientene er signifikante, og at sanne verdier er innenfor konfidensintervallet for hver av dem. Det er ikke et konstantledd i modellen v√•r, noe som stemmer overens med at den ikke er signifikant forskjellig fra null i regresjonsmodellen. new_df &lt;- data.frame(x1 = 1, x2 = 1) reg_pred &lt;- predict(reg, newdata = new_df, interval = &quot;predict&quot;) reg_conf &lt;- predict(reg, newdata = new_df, interval = &quot;confidence&quot;) ## ## Prediksjonsintervall ## ==================== ## fit lwr upr ## -------------------- ## 1 0.840 -1.073 2.752 ## -------------------- ## ## Konfidensintervall ## =================== ## fit lwr upr ## ------------------- ## 1 0.840 0.600 1.080 ## ------------------- Eksakt prediksjonsintervall for modellen som genererte dataene er \\[\\begin{align} \\bar{Y}|X_1,X_2 \\pm \\alpha_{0.025} \\sigma_{\\epsilon} &amp;= 2 \\cdot 1 - 1 \\cdot 1 \\pm 1.96 \\cdot 1 \\\\ &amp;= 1 \\pm 1.96 \\\\ &amp;= [-0.96, 2.96]. \\end{align}\\] Estimert prediksjonsintervall er bredere enn det estimerte intervallet. Dette kommer av usikkerhet knyttet til estimatene av forventning og standardfeil. Det er benyttet T-test i estimatet av prediksjonsintervallet for √• ta hensyn til denne usikkerheten. Man burde ikke f√• smalere prediksjonsintervaller enn det som faktisk er ‚Äúsant‚Äù med mindre noen av modellantagelsene er usann. Merk at n√•r vi generer opp data selv vet vi sannheten, det gj√∏r vi ikke for virkelige data. Vi burde f√• at \\(\\bar{Y}|X_1,X_2 = 1\\) er innenfor konfidensintervallet, noe ser ut til √• v√¶re oppfylt. Tolkningen er at dersom vi kj√∏rer analysen p√• mange ulike datasett vil \\(\\bar{Y}|X_1,X_2 = 1\\) havne innenfor konfidensintervallet i 95 % av tilfellene. Dette kan du pr√∏ve selv, bare pass p√• at du ikke setter seed-et f√∏r du generer opp et nytt datasett. Svaret gis i regresjonstabellen stargazer(reg, type = &quot;text&quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## y ## ----------------------------------------------- ## x1 1.986*** ## (0.053) ## ## x2 -1.091*** ## (0.048) ## ## Constant -0.055 ## (0.096) ## ## ----------------------------------------------- ## Observations 100 ## R2 0.958 ## Adjusted R2 0.957 ## Residual Std. Error 0.956 (df = 97) ## F Statistic 1,094.997*** (df = 2; 97) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 F-statistikken er angitt som \\(1094.997\\) med frihetsgrader \\(2, 97\\). P-verdien regnes som pf(1094.997, 2, 97, lower.tail = FALSE) ## [1] 2.716911e-67 som er veldig liten. Alts√• bekrefter analysen at det er sammenheng mellom forklaringsvariablene og responsvariabelen. Hva ville du tenkt var galt om vi ikke fikk denne konklusjonen fra F-testen, gitt den modellen vi har brukt til √• generere dataene? Hint: Det er faktisk en reell sammenheng her. 4.4.2.1 Oppgave 2 Denne oppgaven f√∏lger samme premiss som oppgave 1, men handler om kolinearitet. Last ned datasettene 1 og 2, hvor y er responsvariabel og forklaringsvariable er navngitt x. Finn kolinearitet Hva m√• man passe dersom man skal lage en regresjonsmodell for responsen Y? L√∏sning Vi kan begynne med √• plotte forholdet mellom de ulike variablene: pairs(y ~ ., data = df_colin1) corrplot(cor(df_colin1), method = &quot;number&quot;) Her ser det ut som vi har et forhold mellom \\((X_2, X_3)\\). Videre ser det ut som at alle tre forklaringsvariable har en sammenheng med responsvariablen \\(Y\\). reg_colin1 &lt;- lm(y ~ ., data = df_colin1) stargazer(reg_colin1, type = &quot;text&quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## y ## ----------------------------------------------- ## x1 1.348*** ## (0.053) ## ## x2 -0.695*** ## (0.064) ## ## x3 -0.208** ## (0.102) ## ## Constant -0.095 ## (0.097) ## ## ----------------------------------------------- ## Observations 100 ## R2 0.916 ## Adjusted R2 0.913 ## Residual Std. Error 0.960 (df = 96) ## F Statistic 346.946*** (df = 3; 96) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 \\(X_1\\) og \\(X_2\\) kommer ut som signifikante, og \\(X_3\\) ved lavere signifikansniv√•. Vi kan sjekke variance inflation factor (VIF) vif(reg_colin1) ## x1 x2 x3 ## 1.018945 1.785963 1.774712 som oppgir at estimeringen i seg selv ikke burde v√¶re noe problem. Kommentarer: Det reelle forholdet mellom variablene i dette eksempelet er \\[\\begin{align} X_1 &amp;\\sim N(0, 2) \\\\ X_2 &amp;\\sim N(0, 2) \\\\ X_3 &amp;= 0.5 X_2 + \\epsilon_3 \\quad \\epsilon_3 \\sim N(0,1) \\\\ Y &amp;= 1.3 X_1 - 0.8 X_2 + \\epsilon, \\quad \\epsilon \\sim N(0,1), \\end{align}\\] og vi kan tenke oss at dette representerer det kausale forholdet mellom variablene. Siden vi har generert dataene kan vi si det. Det er videre interessant √• merke seg i dette eksempelet at \\(X_3\\) kommer ut med en signifikant koeffisient selv om den rent kausalt ikke har noen sammenheng med \\(Y\\). \\(X_3\\) er kun relatert til \\(X_2\\). Dersom man √∏nsker √• gj√∏re prediksjon kan det v√¶re forklaringskraft i \\(X_3\\) for √• gj√∏re prediksjon av \\(Y\\), men i s√• tilfelle antas det at forholdet mellom \\((X_2, X_3)\\) ogs√• vedvarer i fremtiden. Dersom man skal gj√∏re inferens om en tenkt kausal sammenheng er det mulig √• g√• p√• en blemme i et tilfelle som dette. Hvis man √∏nsker √• forklare noe og det er sammenheng mellom to forklaringsvariable kan det fra √∏konomisk prespektiv v√¶re interessant √• sp√∏rre seg om man bryr seg om \\(X_3\\) i det hele tatt og skal ta den ut. Kanksje \\(X_3\\) er vanskelig √• samle inn data om eller den √•penbart ikke har sammenheng med Y. Om den √•penbart ikke skal ha sammenheng med \\(Y\\) kan st√∏yleddet \\(\\epsilon_3\\) ogs√• skape un√∏dig st√∏y i prediksjonene. Plott forholdet mellom de ulike variablene: pairs(y ~ ., data = df_colin2) corrplot(cor(df_colin2), method = &quot;number&quot;) Her ser vi et tydelig forhold mellom parene \\((X_3, X_4)\\), \\((X_4, X_5)\\), \\((X_3, X_5)\\) og \\((X_2, X_5)\\). Ellers ser det kun ut som det er et tydelig forhold mellom \\(Y\\) og \\(X_1, X_2\\). Med s√• mange forhold kan det v√¶re snakk om multikolinearitet, som ikke er s√• lett √• se utfra 2D-plott. reg_colin2 &lt;- lm(y ~ ., data = df_colin2) stargazer(reg_colin2, type = &quot;text&quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## y ## ----------------------------------------------- ## x1 2.049*** ## (0.053) ## ## x2 -1.179*** ## (0.111) ## ## x3 -0.198* ## (0.114) ## ## x4 0.101** ## (0.050) ## ## x5 0.092 ## (0.097) ## ## Constant -0.018 ## (0.095) ## ## ----------------------------------------------- ## Observations 100 ## R2 0.963 ## Adjusted R2 0.961 ## Residual Std. Error 0.932 (df = 94) ## F Statistic 486.175*** (df = 5; 94) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Vi ser p√• VIF for om det kan v√¶re problemer med estimering grunnet kolinearitet stargazer(vif(reg_colin2), type = &quot;text&quot;, title = &quot;VIF&quot;) ## ## VIF ## ============================= ## x1 x2 x3 x4 x5 ## ----------------------------- ## 1.062 5.731 5.517 1.662 7.769 ## ----------------------------- hvor vi ser at \\(X_5\\) n√¶rmer seg problematisk omr√•de for √• f√• en overdreven varians i estimatene. Dersom m√•let er √• estimere sammenheng mellom alle forklaringsvariable og \\(Y\\) vil dette kunne g√• gjennom siden VIF ikke er altfor h√∏y. Hvis det derimot er snakk om modellbygging b√∏r man tenke gjennom om noen av variablene ikke er s√• viktige og b√∏r tas ut. Kommentarer: Det reelle forholdet mellom variablene i dette eksempelet er \\[\\begin{align} X_1 &amp;\\sim N(0, 2) \\\\ X_2 &amp;\\sim N(0, 2) \\\\ X_3 &amp;\\sim N(0, 2) \\\\ X_4 &amp;= X_3 + \\epsilon_4, \\quad \\epsilon_4 \\sim N(0,2) \\\\ X_5 &amp;= X_2 + X_3 + \\epsilon_5, \\quad \\epsilon_5 \\sim N(0,1) \\\\ Y &amp;= 2 X_1 - X_2 + \\epsilon, \\quad \\epsilon \\sim N(0,1) \\end{align}\\] Her kan vi igjen merke oss at variablene \\(X_3, X_4, X_5\\) kommer inn i regresjonsmodellen med noen koeffisienter som er svakt signifikante. I dette tilfellet trenger ikke dette ha s√• mye √• si. Likevel, ettersom det ikke er noen direkte sammenheng mellom \\(X_3, X_4, X_5\\) ville det v√¶rt ideelt √• ikke ha dem med i regresjonsmodellen for √• unng√• feilestimering av koeffisientene til \\(X_1\\) og \\(X_2\\). Fra anvendt statistikk perspektiv b√∏r man tenke gjennom om det gir mening at \\(X_3, X_4, X_5\\) forklarer \\(Y\\). "],["relevante-r-regresjon.html", "4.5 Relevante R-kommandoer", " 4.5 Relevante R-kommandoer Under f√∏lger en liste over hvilke oppgaver du skal klare i R fra denne modulen. V√•r policy fra og med v√•rsemesteret 2022 er at R-kommandoene under er tilstrekkelige for √• l√∏se oppgavene i datalabber og hjemmeeksamen i MET4. Det er med andre ord ikke n√∏dvendig √• l√¶re seg teknikker utover det som er listet opp eksplisitt i listen under. Eventuelle nye teknikker som trengs for √• l√∏se en bestemt oppgave vil bli oppgitt og forklart dersom det er n√∏dvendig. Det antas i tillegg at du kan den grunnleggende R-syntaksen som er dekket under Introduksjon til R. Antakelser om datasett Du kan gj√∏re de samme antakelsene om datasettet som i den tilsvarende oversikten i forrige modul: Datasettene er inneholdt i Excel-filer (.xls eller xslx) eller .csv-filer, som kolonner av variabler, med variabelnavn i f√∏rste rad. Tilpasse en line√¶r regresjonsmodell Her er et lekedatasett med tre forklaringsvariabler x1, x2 og x3, samt en responsvariabel y: data-reg.xsls. # Last inn data library(readxl) df &lt;- read_excel(&quot;data-reg.xlsx&quot;) # Syntaksen for √• tilpasse en line√¶r regresjonsmodell med responsvariabel y og # forklaringsvariabler x1, x2, x3 i datasettet df er som f√∏lger: reg1 &lt;- lm(y ~ x1 + x2 + x3, data = df) # Dersom vi vil ha med interaksjonsledded mellom x1 og x3 kan vi skrive # kommandoen under. Da vil ogs√• x1 og x3 automatisk bli med som variabler i # tillegg til interaksjonsledde x1*x3. reg2 &lt;- lm(y ~ x1 + x2*x3, data = df) # Log transformasjoner kan vi skrive rett inn i formelen reg3 &lt;- lm(log(y) ~ x1 + log(x2) + x3, data = df) # Andre transformasjoner, som for eksempel dersom vi √∏nsker √• ta med # andregradsleddet x1^2, er greiest √• f√• til dersom vi f√∏rst lager en ny kolonne # med kvadratene til x1, og s√• lager til regresjonen p√• vanlig m√•te: df_ny &lt;- df %&gt;% mutate(x1_kvadrat = x1^2) reg4 &lt;- lm(y ~ x1 + x1_kvadrat+ x2 + x3, data = df_ny) # Vi kan skrive ut et sammendrag for regresjonsmodellen ved hjelp av summary(): summary(reg1) # Pakken stargazer inneholder en funksjon for √• lage pene regresjonstabeller: library(stargazer) stargazer(reg1, reg2, type = &quot;text&quot;) # Man kan endre type-argumentet til &quot;html&quot;, og sette out-argumentet til et # filnavn hvis du vil skrive ut tabellen til en fil. Prediksjoner, med konfidens- og prediksjonsintervall La oss si at vi √∏nsker √• predikere verdien av responsvariabelen for f√∏lgende verdier av forklaringsvariablene: x1 x2 x3 10 95 1 20 96 1 30 100 0 Da m√• vi f√∏rst samle verdiene av forklaringsvariablene i en data frame; det kan vi enten gj√∏re direkte i R: ny_data &lt;- data.frame(x1 = c(10, 20, 30), x2 = c(95, 96, 100), x3 = c(1,1,0)) Et alternativ kan v√¶re √• lage til et regneark i Excel, og s√• lese det inn ved hjelp av read_excel(). Det er viktig at variabelnavnene i det nye datasettet er eksakt de samme som forklaringsvariablene i datasettet du brukte til √• estimere regresjonsmodellen! Vi kan lage prediksjon med 95% konfidensintervall ved hjelp av predict(): prediksjoner &lt;- predict(reg1, newdata = ny_data, interval = &quot;confidence&quot;, level = 0.95) Resultatet blir en ny data frame med kolonnene fit (prediksjoner), samt lwr og upr, som inneholder nedre og √∏vre grense i konfidensintervallet henholdsvis. Du kan endre til prediksjonsintervaller ved √• bytte ut \"confidence\" med \"prediction\" (eventuelt \"none\" hvis du ikke √∏nsker noe intervall). Lage residualplott Vi m√• kunne lage f√∏lgende residualplott i R, her demonstrert med regresjonsmodellen reg1 som vi laget over: # Henter ut residualer og predikerte verdier fra modellen, og setter de inn som # kolonner i en dataframe: residualer &lt;- data.frame(residualer = reg1$residuals, predikert = reg1$fitted.values) # Spredningsplott, residualer mot predikerte verdier ggplot(residualer, aes(x = predikert, y = residualer)) + geom_point() # Autokorrelasjonsplott acf(reg1$residuals) # Histogram for √• sjekke normalantakelsen ggplot(residualer, aes(x = residualer)) + geom_histogram() # QQ-plott, observasjonene ligger langs en rett linje hvis de er normalfordelte ggplot(residualer, aes(sample = residualer)) + stat_qq() + stat_qq_line() # Regner ut og plotter Cooks avstand: infl &lt;- influence.measures(reg1) # Lager enkelt plott av Cooks avstand cooks_avstand &lt;- data.frame(obs = 1:nrow(df), cook = infl$infmat[, &quot;cook.d&quot;], cook_infl = infl$is.inf[, &quot;cook.d&quot;]) ggplot(cooks_avstand, aes(x = obs, y = cook)) + geom_col() Alle plottene over kan justeres og pyntes, for eksempel ved √• gj√∏re endringer som i R-videoen om plotting. Se ogs√• forelesningsscriptet for flere tips om presentasjon av residualplott. "],["tidsrekker.html", " 5 Tidsrekker", " 5 Tidsrekker Den neste MET4 handler om tidsrekker. I motsetning til modulene vi har jobbet med frem til n√•, der vi separerte teorivideoene og data√∏vingene, er disse to elementene n√• blandet sammen. Vi har delt stoffet opp i en serie overskrifter, der du finner videosnuttene fulgt av en guide til relevante R-funksjoner, programmerings√∏velser og noen regneoppgaver. Data√∏vingen til denne modulen er ogs√• laget for √• passe inn i BED4-opplegget. I √∏vingen skal vi lage prognoser av noen tidsrekker som kommer til √• bli nyttige i en av casene i BED4. Hvis du ikke tar BED4 dette semesteret s√• er det ogs√• helt greit ‚Äì data√∏vingen v√•r st√•r st√∏tt p√• egne bein. Fagl√¶rer og studentassistenter vil v√¶re tilgjengelig p√• vanlig m√•te for konsultasjon, diskusjon og probleml√∏sning. Lykke til! "],["intro.html", "5.1 Introduksjon til tidsrekker", " 5.1 Introduksjon til tidsrekker 5.1.1 Kontrollsp√∏rsm√•l Hvilke forskjeller er det mellom en tidsrekke og et sett med samtidige observasjoner? Nevn noen typiske m√∏nstre som vi kan se etter i en tidsrekke. Hvorfor er det nyttig √• identifisere slike m√∏nstre? Hvorfor kan det v√¶re nyttig √• glatte en tidsrekke? Beskriv kort hvordan man regner ut et glidende gjennomsnitt. Hvorfor kan vi ikke bruke det glidende gjennomsnittet til √• predikere neste observasjon i en tidsrekke? Beskriv kort hvordan eksponensiell glatting fungerer, og hvorfor denne teknikken kan brukes til prediksjon. 5.1.2 Oppgaver fra l√¶rebok Keller: Statistics for Management and Economics, 11. utg a) Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 3 for f√∏lgende tidsrekke: L√∏sning t Glidende gjennomsnitt 1 NA 2 (48+41+37)/3 = 42.00 3 (41+37+32)/3 = 36.67 4 (37+32+36)/3 = 35.00 5 (32+36+31)/3 = 33.00 6 (36+31+43)/3 = 36.67 7 (31+43+52)/3 = 42.00 8 (43+52+60)/3 = 51.67 9 (52+60+48)/3 = 53.33 10 (60+48+41)/3 = 49.67 11 (48+41+30)/3 = 39.67 12 NA b) Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 5 for tidsrekken over. L√∏sning t Glidende gjennomsnitt 1 NA 2 NA 3 (48 +41+37+32+36)/5 = 38.8 4 (41+37+32+36+31)/5 = 35.4 5 (37+32+36+31+43)/5 = 35.8 6 (32+36+31+43+52)/5 = 38.8 7 (36+31+43+52+60)/5 = 44.4 8 (31+43+52+60+48)/5 = 46.8 9 (43+52+60+48+41)/5 = 48.8 10 (52+60+48+41+30)/5 = 46.2 11 NA 12 NA c) Tegn inn tidsrekken over med de to glattingene inn i samme figur. L√∏sning ‚ÄúManuelt‚Äù i R: # Les f√∏rst inn dine utregninger time &lt;- seq(12) y &lt;- c(48, 41, 37, 32, 36, 31, 43, 52, 60, 48, 41, 30) glatt3 &lt;- c(NA, 42, 36.67, 35, 33, 36.67, 42, 51.67, 53.33, 49.67, 39.67, NA) glatt5 &lt;- c(NA, NA, 38.8, 35.4, 35.8, 38.8, 44.4, 46.8, 48.8, 46.2, NA, NA) # Med base-R plot plot(time, y) lines(time, glatt3, col = &quot;red&quot;) lines(time, glatt5, col = &quot;blue&quot;) # eller med ggplot library(ggplot2) df &lt;- data.frame(time = rep(time, 2), y = rep(y, 2), glatting = c(glatt3, glatt5), vindulengde = factor(c(rep(&quot;3&quot;, 12), rep(&quot;5&quot;, 12)))) ggplot(df) + geom_point(aes(x = time , y = y)) + geom_line(aes(x = time, y = glatting, color = vindulengde)) d) Regn ut eksponensiell glatting for tidsrekken under med glattefaktor \\(w = 0.1\\): L√∏sning t Eksponensiell glatting 1 38.00 2 0.1(43) + 0.9(38) = 38.50 3 0.1(42) + 0.9(38.50) = 38.85 4 0.1(45) + 0.9(38.85) = 39.47 5 0.1(46) + 0.9(39.47) = 40.12 6 0.1(48) + 0.9(40.12) = 40.91 7 0.1(50) + 0.9(40.91) = 41.82 8 0.1(49) + 0.9(41.82) = 42.53 9 0.1(46) + 0.9(42.53) = 42.88 10 0.1(45) + 0.9(42.88) = 43.09 e) Gjenta oppgaven over med glattefaktor \\(w = 0.8\\). L√∏sning t Glidende gjennomsnitt 1 38 2 0.8(43) + 0.2(38) = 42.00 3 0.8(42) + 0.2(42.00) = 42.00 4 0.8(45) + 0.2(42.00) = 44.40 5 0.8(46) + 0.2(44.40) = 45.68 6 0.8(48) + 0.2(45.68) = 47.54 7 0.8(50) + 0.2(47.54) = 49.51 8 0.8(49) + 0.2(49.51) = 49.10 9 0.8(46) + 0.2(49.10) = 46.62 10 0.8(45) + 0.2(46.62) = 45.32 f) Tegn tidsrekken over inn i samme figur som de to glattede versjonene. Ser det ut til √• v√¶re en trend i denne tidsrekken? L√∏sning ‚ÄúManuelt‚Äù i R: # Les f√∏rst inn dine utregninger time &lt;- seq(10) y &lt;- c(38, 43, 42, 45, 46, 48, 50, 49, 46, 45) exp01 &lt;- c(38, 38.50, 38.85, 39.47, 40.12, 40.91, 41.82, 42.53, 42.88, 43.09) exp08 &lt;- c(38, 42, 42, 44.40, 45.68, 47.54, 49.51, 49.10, 46.62, 45.32) # Med base-R plot plot(time, y) lines(time, exp01, col = &quot;red&quot;) lines(time, exp08, col = &quot;blue&quot;) # eller med ggplot library(ggplot2) df &lt;- data.frame(time = rep(time, 2), y = rep(y, 2), glatting = c(exp01, exp08), glattefaktor = factor(c(rep(&quot;0.1&quot;, 10), rep(&quot;0.9&quot;, 10)))) ggplot(df) + geom_point(aes(x = time , y = y)) + geom_line(aes(x = time, y = glatting, color = glattefaktor)) Det ser ut til at det er en stigende trend som avtar mot de siste observasjonene i tidsrekken. bonussp√∏rsm√•l) Hva blir prediksjonen av \\(Y_{11}\\) n√•r du bruker modellen i henholdsvis oppgave d) og e)? L√∏sning V√•re prediksjoner av \\(Y_{11}\\) blir da henholdsvis \\(43.09\\) og \\(45.32\\). 5.1.3 R-√∏ving Vi har lastet ned den daglige prisen p√• Eqinoraksjen over en 5-√•rs periode fra Oslo B√∏rs‚Äô hjemmeside. Vi laster inn datasettet som f√∏r ved hjelp av readxl-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker rev()-funksjonen til √• reversere rekkef√∏lgen til observasjonene slik at den f√∏rste verdien kommer f√∏rst: library(readxl) equinor &lt;- read_excel(&quot;equinor.xlsx&quot;) pris &lt;- rev(equinor$Siste) Du kan s√• lage et raskt plott av tidsrekken: plot(pris, type = &quot;l&quot;) B√•de glidende gjennomsnitt og eksponensiell glatting har flere ulike implementeringer i R. For glidende gjennomsnitt skal vi bruke funksjonen rollmean() i pakken zoo. Du m√• f√∏rst installere pakken og laste den inn; install.packages(&quot;zoo&quot;) library(zoo) Hvis du leser litt p√• dokumentasjonen til rollmean() ved √• kj√∏re ?rollmean vil du se at du kan regne ut f.eks et glidende gjennomsnitt for Equinoraksjen med vindusst√∏rrelse 5 ved √• kj√∏re pris_glatt5 &lt;- rollmean(pris, k = 5, fill = NA) Da f√•r vi ut en ny vektor med lik lengde som den vi hadde, og som inneholder den glattede versjonen. Den fyller opp verdiene i starten og slutten som vi ikke kan regne ut med et glidende gjennomsnitt med NA, slik at vi kan tegne inn den glattede versjonen i samme plott som vi viste selve tidsrekken: lines(pris_glatt5, col = &quot;red&quot;) Dersom du er interessert kan du lese mer her om hvordan det glidende gjennomsnittet blir brukt som en investeringsstrategi. Tanken er at det glidende gjennomsnittet representerer den langsiktige trenden. Dersom tidrekken ligger under det glidende gjennomsnittet tolkes det som at aksjen er p√• vei nedover, og motsatt: dersom prisen ligger over det glidende gjennomsnittet, s√• er det et tegn p√• at aksjen er p√• vei oppover. N√•r de to seriene krysser hverandre g√•r ‚Äúalarmen‚Äù, og man tar stilling til om man skal kj√∏pe eller selge. Vindusst√∏rrelsen velger man ut fra hvor hyppig man handler. For profesjonelle investorer som driver med handel i h√∏y hastighet kan kanskje 5-dagersviduet som vi regnet ut over v√¶re nok. Andre med mellomlang og lang sikt vil gjerne bruke et vindu p√• 50 eller 200 dager. Oppgave: Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 200 for Equinoraksjen, og tegn det inn i figuren du har laget. Hjelper denne figuren deg til √• lage en investeringsstrategi? L√∏sning Forutsatt at du har gjort det over kan du skrive pris_glatt200 &lt;- rollmean(pris, k = 200, fill = NA) plot(pris, type = &quot;l&quot;) lines(pris_glatt200, col = &quot;red&quot;) N√• kan vi jo ikke se det glidende gjennomsnittet for de siste observasjonene, s√• ved bare √• sammenligne de siste observasjonene hvor vi ogs√• har det glidende gjennomsnittet s√• ligger prisen under det glidende gjennomsnittet, alts√• b√∏r vi ikke investere (evt. selge, shorte etc.). Et problem med analysen over er at vi trenger fremtidige observasjoner til √• regne ut den glattede tidsrekken. Det betyr at vi kjenner den glattede versjonen av tidsrekken ved tid \\(t\\) f√∏rst ved tid \\(t+200\\). Vi kan enkelt lage en annen variant der vi glatter tidsrekken ved tid \\(t\\) ved √• ta gjennomsnittet av \\(Y_{t-200}, Y_{t-199}, \\ldots, Y_{t-1}\\) i stedet for \\(Y_{t-100}, \\ldots, Y_{t}, \\ldots, Y_{t+100}\\), alts√• at vi bare bruker fortiden. Det gj√∏r du i R ved √• legge til det ekstra argumentet align = \"right\" i funksjonen rollmean. Fordelen n√• er at vi ved hvert tidspunkt kjenner b√•de prisen p√• aksjen og den glattede varianten. Oppgave: Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 200 for Equinoraksjen som hele tiden bruker tidligere observasjoner i glattingen. Tegn glattingen inn i figuren. Hvordan ser investeringsstrategien din ut n√•? L√∏sning pris_glatt200 &lt;- rollmean(pris, k = 200, fill = NA, align = &quot;right&quot;) plot(pris, type = &quot;l&quot;) lines(pris_glatt200, col = &quot;red&quot;) I denne figuren ligger de siste prisene over det glidende gjennomsnittet noe som er indikasjon p√• en stigende trend. Alts√• kan en strategi v√¶re √• investere i aksjen. Eksponensiell glatting har ogs√• et annet navn: Holt Winters Metode. En funksjon for √• gjennomf√∏re den finnes innebygget i R, og heter HoltWinters(). I denne funksjonen er vektparameteren \\(w\\) representert ved argumentet alpha. Funksjonen har noen flere argumenter som ikke vi skal bruke, s√• dersom vi √∏nsker √• regne ut den eksponensielle glattingen for Equinoraksjen med \\(w = 0.5\\), kj√∏rer vi: pris_exp1 &lt;- HoltWinters(pris, alpha = .5, beta = FALSE, gamma = FALSE) For √• hente ut den glattede versjonen skriver vi pris_exp1$fitted[,&quot;xhat&quot;] Oppgave: Lag en ny figur der du tegner inn aksjeprisen, samt den eksponensielle glattingen med hhv. \\(w = 0.5\\), \\(w = 0.01\\) og \\(w = 0.99\\). L√∏sning pris_exp1 &lt;- HoltWinters(pris, alpha = .5, beta = FALSE, gamma = FALSE) pris_exp2 &lt;- HoltWinters(pris, alpha = .01, beta = FALSE, gamma = FALSE) pris_exp3 &lt;- HoltWinters(pris, alpha = .99, beta = FALSE, gamma = FALSE) plot(pris, type = &quot;l&quot;) lines(pris_exp1$fitted[,&quot;xhat&quot;], col = &quot;red&quot;) lines(pris_exp2$fitted[,&quot;xhat&quot;], col = &quot;blue&quot;) lines(pris_exp3$fitted[,&quot;xhat&quot;], col = &quot;green&quot;) "],["trend-og-sesong.html", "5.2 Trend og sesong", " 5.2 Trend og sesong 5.2.1 Kontrollsp√∏rsm√•l Hvilke tre komponenter kan en tidsrekke typisk best√• av? 5.2.2 R-√∏ving 1. Data. I pakken fpp finnes en tidsrekke som heter ausbeer, som er den kvartalsvise produksjonen av √∏l i Australia fra 1956 til 2008. Du kan f√• tak i det og se p√• tidsrekken ved √• kj√∏re f√∏lgende kommandoer: install.packages(&quot;fpp&quot;) library(fpp) plot(ausbeer) Vi ser at det er en klar trendkomponent, selv om den ikke er line√¶r, samt en √•rlig sesongvariasjon. 2. Dekomponering. Funksjonen stl dekomponerer tidsrekken i de tre komponentene: trend, sesong, og tilfeldig variasjon. For √• f√• tilgang p√• denne funskjonen trenger vi pakken forecast: install.packages(&quot;forecast&quot;) library(forecast) Vi s√• kan kj√∏re funksjonen slik: dekomponert &lt;- stl(ausbeer, s.window = &quot;periodic&quot;) Vi kan hente ut de ulike komponentene ved √• bruke dollartegnet: dekomponert$time.series. Pakken forecast har en egen plottefunksjon, autoplot som er spesialdesignet for tidsrekkeobjekter. Pr√∏v √• plotte de tre komponentene hver for seg ved √• kj√∏re: autoplot(dekomponert) 3. Predikere. For predikering bruker vi funksjonen forecast(), som tar en estimert modell som input, og som bruker modellen til √• skrive frem tidsrekken ved √• estimere fremtidige verdier. Dekomponeringen over utgj√∏r ogs√• en modell som vi kan bruke til √• predikere fremtidige observasjoner med. Kodesnutten under viser hvordan man predikerer \\(10\\) tidssteg frem i tid ved √• sette h = 10 i funksjonen. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi level = 0.95 for \\(95\\%\\) prediksjonsintervall. Resultatet lagrer vi i objektet prediksjon. Dette objektet kan vi plotte ved bruk av autoplot-funksjonen: prediksjon &lt;- forecast(dekomponert, h = 10, level = 0.95) autoplot(prediksjon) "],["ar.html", "5.3 AR(p)", " 5.3 AR(p) 5.3.1 Kontrollsp√∏rsm√•l Hva er definisjonen p√• en Hvit-st√∏y-prosess? Hva er definisjonen p√• en AR(1)-prosess? Hvilken effekt har parameteren \\(\\phi\\) p√• egenskapene til en AR(1)-prosess? Hva er forskjellen p√• en AR(1)-prosess og en generell AR(\\(p\\))-prosess? Hvorfor kan vi si at AR(\\(p\\)) er en utvidelse/generalisering av hvit st√∏y? 5.3.2 R-√∏ving 1. Simulere. La oss f√∏rst se hvordan vi kan simulere noen realiseringer fra disse tidsrekkene. Hvit st√∏y best√•r av ukorrelerte trekninger som alle har samme forventningsverdi og varians, noe vi kan simulere i R ved √• bare trekke \\(n\\) uavhengige observasjoner fra hvilken som helst fordeling og kalle det en tidsrekke. For eksempel har vi tidligere trukket standard normalfordelte observasjoner ved hjelp av rnorm()-funsksjonen. La oss gj√∏re det igjen, og plotte det som en tidsrekke. Merk at din trekning ikke vil v√¶re identisk som den under: n &lt;- 50 hvit_st√∏y &lt;- rnorm(n) plot(hvit_st√∏y, type = &quot;b&quot;) Vi kan bruke funksjonen arima.sim() til √• simulere tidsrekker fra AR-modellen (og den mer generelle ARIMA-modellen, mer om det senere). Du kan for eksempel simulere \\(n\\) observasjoner fra en AR(1)-prosess med \\(\\phi = 0.95\\) ved hjelp av f√∏lgende kommandoer: ar1 &lt;- arima.sim(model = list(ar = 0.95), n) plot(ar1, type = &quot;b&quot;) I det siste eksempelet trekker arima.sim()-funskjonen hvit-st√∏y-prosessen \\(u_t\\) fra rnorm()-funksjonen, men det kan vi endre p√• hvis vi vil, se hjelpesiden ?arima.sim. Videre kan vi bruke denne funksjonen til √• simulere fra hvit st√∏y ved √• sette model-argumentet til en tom liste (model = list()), eller vi kan simulere fra en AR(2)-prosess med \\(\\phi_1 = 0.2\\) og \\(\\phi_2 = 0.1\\) ved √• sette model = list(ar = c(0.2, 0.1)). 2. Estimere. La oss i f√∏rste omgang si at vi har observert tidsrekken ar1 som vi simulerte over, at vi mistenker at den f√∏lger en AR(1)-prosess \\(Y_t = \\phi Y_{t-1} + u_t\\), og at vi √∏nsker √• estimere den ukjente parameteren \\(\\phi\\) ved hjelp av observasjonene. Som vi antydet i AR-videoen kan vi i dette tilfellet betrakte det som et regresjonsproblem med \\(Y_t\\) som responsvariabel og \\(Y_{t-1}\\) som forklaringsvariabel. La oss lage en data.frame med disse to kolonnene, og se hva vi f√•r n√•r vi bruker lm()-funksjonen. . df &lt;- data.frame(Y = ar1[2:n], lagged_Y = ar1[1:(n-1)]) summary(lm(Y ~ lagged_Y, data = df)) ## ## Call: ## lm(formula = Y ~ lagged_Y, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8538 -0.6840 -0.1112 0.4233 2.5894 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.36830 0.19310 -1.907 0.0626 . ## lagged_Y 0.86468 0.06545 13.211 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9659 on 47 degrees of freedom ## Multiple R-squared: 0.7878, Adjusted R-squared: 0.7833 ## F-statistic: 174.5 on 1 and 47 DF, p-value: &lt; 2.2e-16 Vi ser at v√•rt estimat av \\(\\phi\\), som i regresjonutskriften er koeffisienten til lagged_Y, er i n√¶rheten av den sanne verdien 0.95, men med s√• f√• observasjoner kan det godt hende at ditt estimat er noe forskjellig. Poenget er: vi kan bruke line√¶r regresjon til √• estimere koeffisientene i en AR-modell basert p√• observasjoner. Som i forrige oppgave er pakken forecast sv√¶rt nyttig for estimering og predikering: library(forecast) Denne pakken inneholder en funskjon Arima for √• estimere koeffisientene i en AR-modell (egentlig den mer generelle klasssen av ARIMA-modeller som vi kommer tilbake til senere). Denne funksjonen kan vi andvende direkte p√• tidsrekken ved √• skrive Arima(ar1, order = c(1, 0, 0)) ## Series: ar1 ## ARIMA(1,0,0) with non-zero mean ## ## Coefficients: ## ar1 mean ## 0.8935 -1.7696 ## s.e. 0.0613 1.1203 ## ## sigma^2 = 0.9728: log likelihood = -70.04 ## AIC=146.08 AICc=146.6 BIC=151.81 I f√∏rste omgang kan vi legge merke til at vi har spesifisert hvilken modell vi √∏nsker √• estimere gjennom argumentet order = c(1, 0, 0), der ett-tallet angir AR-modellens orden \\(p\\), som i dette tilfellet er 1. Dersom du mistenker at AR(2)-modellen gir en bedre beskrivelse av tidsrekken din, kan du endre til order = c(2, 0, 0). Vi kommer tilbake til sp√∏rsm√•let om hvordan du kan velge den beste modellen for et gitt praktisk problem. Legg merke til at de to estimatene ikke er identiske selv om vi bruker det samme tidsrekken. Det er fordi arima()-funksjonen ikke bruker minste kvadraters metode til √• regne ut estimatene (slik lm() gj√∏r), men heller bruker en annen estimeringsteknikk som heter maximum likelihood. 3. Predikere. For predikering bruker vi funksjonen forecast(), som tar en estimert modell som input, og som bruker modellen til √• skrive frem tidsrekken ved √• estimere fremtidige verdier. I kodesnutten under bruker vi den simulerte tidsrekken, og estimerer en AR(1)-modell som over som vi lagrer i objektet ar1_estimat. S√• bruker vi det som argument i forecast(), der vi ogs√• spesifiserer hvor mange tidssteg fremover vi √∏nsker √• predikere, her velger vi h = 10. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi level = 0.95 for \\(95\\%\\) prediksjonsintervall. Resultatet lagrer vi i objektet prediksjon. ar1_estimat &lt;- Arima(ar1, order = c(1, 0, 0)) prediksjon &lt;- forecast(ar1_estimat, h = 10, level = 0.95) Vi kan plotte resultatet i en pen liten figur ved √• bruke funksjonen autoplot som under: # Plotter den opprinnerlige tidsrekken, sammen med prediksjon og # prediksjonsintervall autoplot(prediksjon) "],["stasjonaritet.html", "5.4 Stasjonaritet", " 5.4 Stasjonaritet 5.4.1 Kontrollsp√∏rsm√•l Hva er definisjonen p√• en stasjon√¶r tidsrekke? Hva er poenget med √• innf√∏re stasjonaritet som et konsept i tidsrekkeanalyse? Er AR(1) prosessen \\(X_t = 1.5 X_{t - 1} + u_t\\) stasjon√¶r? 5.4.2 Merk En AR-prosess kan vi definere ogs√• med et konstantledd \\(c\\), f.eks: \\(Y_t = c + \\phi Y_{t-1} + u_t\\). Vi kan ikke forvente at alle tidsrekkene vi observerer i praksis vil ligge √• variere rundt null (dvs at E\\((Y_t) = 0\\)). Vi kan flytte den opp og ned ved √• legge til den samme konstanten \\(c\\) i hver tidssteg. I forrige oppgavesett, der vi estimerte parameteren \\(\\phi\\) i en AR(1)-modell, kom det (p√• samme m√•te som n√•r vi gj√∏r regresjon) ut et estimat av et intercept, som alts√• er denne \\(c\\)‚Äôen. I den simulerte tidsrekken vi jobbet med der, var det ikke noe konstantledd (alts√•, \\(c = 0\\)), som vi ser igjen i estimatene ved at de ikke er signifikant forskjellige fra null. Vi kunne tvunget estimeringsfunksjonene til √• sette \\(c = 0\\), f.eks ved √• inkludere argumentet include.mean = FALSE i arima()-funksjonen. "],["autokorrelasjon.html", "5.5 Autokorrelasjon", " 5.5 Autokorrelasjon 5.5.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Formuler med egne ord: Hva er autokorrelasjon? Hva kan vi l√¶re ved √• se p√• autokorrelasjonsplottet til en tidsrekke? Kan du komme p√• noe vi ikke kan finne ut av ved √• se p√• korrelasjoneplottet til en tidsrekke? 5.5.2 R-√∏ving 1. Utregning av ACF I R bruker vi funsksjonen acf() til √• lage autokorrelasjonsplott. La oss i f√∏rste omgang gjenskape noen av figurene fra videoen ved hjelp av simuleringer. For eksempel kan vi laget til to tidsrekker som p√• forrige oppgavesett, en hvit st√∏y og en AR(1): n &lt;- 50 hvit_st√∏y &lt;- rnorm(n) ar1 &lt;- arima.sim(model = list(ar = 0.95), n) Autokorrelasjonsplottene til disse to tidsrekkene kan vi f√• frem ved √• anvende acf()-funksjonen p√• dem: acf(hvit_st√∏y) acf(ar1) Vi ser igjen m√∏nsteret fra videoen: Hvit st√∏y best√•r av ukorrelerte observasjoner, mens AR(1)-modellen best√•r av observasjoner som bygger p√• forrige observasjon, slik at det er en viss korrelasjon, og dermed avhengighet fra dag til dag. Det ser vi igjen i autokorrelasjonsplottet som gir tydelig utslag, og der korrelasjonen g√•r gradvis mot null med √∏kende avstand mellom observasjonene. 2. ACF som sjekk av modell En sjekk vi gjerne gj√∏r for √• se om en estimert tidsrekkemodell passer dataene v√•re, er √• se autokorrelasjonen til residualene i modellen er liten. Det betyr nemlig at modellen plukker opp den (line√¶re) avhengigheten i tidsrekken. For en AR(1) modell er residualene f.eks gitt ved \\(\\hat{u}_t = Y_t - \\hat{\\phi}Y_{t-1}\\), men disse er tilgjengelig direkte fra modell estimeringen i R: library(forecast) ar1_estimat &lt;- Arima(ar1, order = c(1, 0, 0)) acf(ar1_estimat$residuals) 3. Oppgave: Pr√∏v n√• √• plotte autokorrelasjonsfunksjonen for for f√∏lgende tre tidsrekker, og knytt en kort kommentar til hver av dem om hva du l√¶rer om tidsrekken ved √• se p√• autokorrelasjonsplottet til: Prisen p√• Equinor-aksjen, som vi jobbet med i det f√∏rste oppgavesettet. L√∏sning library(readxl) equinor &lt;- read_excel(&quot;equinor.xlsx&quot;) pris &lt;- rev(equinor$Siste) acf(pris) Vi ser at det er h√∏y positiv autokorrelasjon selv for store avstander (lag). En lav pris (historisk sett) vil v√¶re assosiert med lave priser de foreg√•ende dagene og tilsvarende for h√∏ye priser. Dette stemmer bra med teorien med at dersom markedet er effisient (ikke pensum, slapp av!) skal prisen f√∏lge en tilfeldig gang, selv om dette ikke alltid er tilfellet. Det kan alts√• se ut til at prisen idag er tiln√¶rmet prisen i g√•r pluss ny st√∏y. Equinoraksjens prosentvise avkastning (som er tiln√¶rmet lik diff(log(pris)) fra dag til dag. L√∏sning pr_avkastning &lt;- diff(log(pris))) acf(pr_avkastning) Her ser vi at autokorrelasjon er sv√¶rt lav uansett lag. Det virker alts√• ikke √• v√¶re noen line√¶r sammenheng mellom avkastningen fra en dag til den neste (og den om 2, 3, .. dagen). Dette stemmer bra med at prisen i teorien skal f√∏lge en tilfeldig gang og at det i et effisient marked ikke skal g√• an √• predikere avkastningen for en aksje, noe som i teorien hadde v√¶rt mulige hadde det v√¶rt en positiv autokorrelasjon. Tidsrekken som er igjen etter at du fjernet trend og sesong fra √∏lproduksjonstidsrekken i det andre oppgavesettet. L√∏sning library(fpp) library(forecast) dekomponert &lt;- stl(ausbeer, s.window = &quot;periodic&quot;) acf(dekomponert$time.series[ ,3], na.action = na.pass) Figuren er litt misvisende siden ett lag i figuren svarer til ett √•r, og siden vi har kvartalsvise observasjoner har vi 4 acf verdier per √•r. Det kan se ut til at det er en √•rlig sesongvariasjon som ikke har blitt dekomponert fullt ut av tidsrekken pga av disse toppene i acf som kommer 1,2,3. .. √•ret. Til slutt: husk at ogs√• autokorrelasjonsplottene m√• pyntes og ordnes p√• hvis vi skal vise dem til andre i rapporter, innleveringer etc. Du kan stort sett bruke de samme argumetene som i vanlige plott: xlab =, ylab =, main = osv. "],["ma.html", "5.6 MA(q)", " 5.6 MA(q) 5.6.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Hva er definisjonen p√• en MA(1)- og en MA(\\(q\\))-modell? Hvordan skiller definisjonen av en MA-prosess seg fra definisjonen av en AR-prosess? P√• hvilken m√•te er autokorrelasjonsfunksjonene til AR- og MA-prosesser forskjellige? Kan du, med egne ord, beskrive en type reelle fenomener som kan modelleres som en MA-prosess? 5.6.2 R-√∏ving 1. Estimering og predikering. P√• samme m√•te som for AR-prosessen kan vi n√• simulere og estimere en MA(1)-prosess med \\(\\theta = 0.95\\): library(forecast) # Trengs for estimering n &lt;- 100 # Antall observasjoner ma1 &lt;- arima.sim(model = list(ma = 0.95), n) # Simuler tidsrekken plot(ma1, type = &quot;b&quot;) # Lag et plott Arima(ma1, order = c(0,0,1)) # Estimer theta Stemmer estimatet overens med den sanne \\(\\theta\\)? Sjekk ut dokumentasjonen ?Arima og se hva du m√• gj√∏re for √• spesifisere at modellen ikke har noe konstantledd \\(c\\). Pr√∏v ogs√• √• modifisere koden fra AR-oppgavene slik at du predikerer den simulerte MA(1)-tidsrekken 10 steg frem. 2. Analyse av global temperatur. La oss n√•r ta for oss eksempelet fra videoen der vi ser p√• den globale m√•nendlige gjennomsnittstemperaturen fra 1880 til 2016. Last ned temp.csv, som er en CSV-fil med datasettet. Se p√• de f√∏rste par radene: temp &lt;- read.csv(&quot;temp.csv&quot;) head(temp) ## Date Mean ## 1 1880-01-06 0.0009 ## 2 1880-02-06 -0.1229 ## 3 1880-03-06 -0.1357 ## 4 1880-04-06 -0.0499 ## 5 1880-05-06 -0.0738 ## 6 1880-06-06 -0.1692 F√∏rste kolonne inneholder informasjon om tidspunkt, og temperaturen er inneholdt i andre kolonne. La oss plotte b√•de temperaturrekken og den differensierte temperaturrekken (dvs. forskjellen fra dag til dag). Hvis vi avsl√∏rer at den differensierte tidsrekken kan regnes ut ved √• kj√∏re difftemp &lt;- diff(temp$Mean), skulle det n√• v√¶re grei skuring √• produsere f√∏lgende to enkle plott: difftemp &lt;- diff(temp$Mean) plot(temp$Mean, type = &quot;l&quot;) plot(difftemp, type = &quot;l&quot;) Lag videre autokorrelasjonsplottet som vist i videoen for den differensierte tidsrekken: I autokorrelasjonsplottet ser vi nettopp et slikt MA-m√∏nster som vi s√• i videoen; nemlig at autokorrelasjonen plutselig blir null (eller omtrent null) for et gitt lag. I dette tilfellet har vi at f√∏rste ordens autokorrelasjon er klart forskjellig fra null, men at den fra og med \\(k = 2\\) nesten ikke har utslag. Hvis de differensierte temperaturm√•lingene faktisk er MA(1), kan den skrives slik: \\[Y_t = c + \\theta u_{t-1} + u_t,\\] der \\(\\theta\\) er en ukjent parameter. Vi kan bruke datasettet v√•rt til √• estimere \\(\\theta\\) ved √• bruke Arima()-funksjenen p√• samme m√•te som da vi estimerte en AR(1)-modell. Den eneste forandringen vi m√• gj√∏re er √• endre order-argumentet fra c(1, 0, 0) til c(0, 0, 1): Arima(difftemp, order = c(0, 0, 1)) ## Series: difftemp ## ARIMA(0,0,1) with non-zero mean ## ## Coefficients: ## ma1 mean ## -0.4988 0.0005 ## s.e. 0.0251 0.0012 ## ## sigma^2 = 0.009078: log likelihood = 1532.11 ## AIC=-3058.23 AICc=-3058.21 BIC=-3042.01 Hvis du har tid til slutt og vil ha litt ekstra trening kan du pr√∏ve deg p√• f√∏lgende oppgave: Prediker den differensierte temperaturrekken tre m√•neder frem i tid. Lag en figur der du plotter de 12 siste m√•nedene i den observerte tidsrekken sammen med prediksjonene dine med prediksjonsintervaller. Bonuspoeng: Husk at vi n√• har predikert forandringen i den globale gjennomsnittstemperaturen fra m√•ned til m√•ned. Kan du heller lage en figur med selve temperaturserien og bruke prediksjonene dine til √• heller plotte inn de tilh√∏rende predikerte temperaturene? Pynt s√• figuren slik at du kan sende den fra deg. "],["arma-arima.html", "5.7 ARMA og ARIMA", " 5.7 ARMA og ARIMA 5.7.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Hva er sammenhengen mellom AR-, MA-, og ARMA-modellene? Hva er en ARIMA-modell? Hvilken modell er dette: \\[y_t = \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\theta u_{t-1} + u_t\\] 5.7.2 R-√∏ving 1. Data Vi tar en ny titt p√• den daglige prisen p√• Eqinoraksjen over en 5-√•rs periode som vi s√• p√• i introduksjonen til tidsrekker. Vi laster inn datasettet som f√∏r ved hjelp av readxl-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker rev()-funksjonen til √• reversere rekkef√∏lgen til observasjonene slik at den f√∏rste verdien komme f√∏rst: library(readxl) equinor &lt;- read_excel(&quot;equinor.xlsx&quot;) pris &lt;- rev(equinor$Siste) plot(pris, type = &quot;l&quot;) Vi kan lage en figur av den differensierte tidsrekken p√• f√∏lgende m√•te: # Sjekk av differanse diff_pris &lt;- diff(pris) plot(diff_pris, type = &quot;l&quot;) Oppgave: Vurder om en ARIMA modell er bedre egnet enn en ARMA modell ut fra de to figurene over. L√∏sning I forhold til prisen ser den differensierte prisen stasjon√¶r ut og det er derfor rimelig med en ARIMA model. I et effisient marked skal prisen i teorien f√∏lge en tilfeldig gang slik at den differensierte tidsrekken bare er st√∏y, alts√• at prisen f√∏lger en ARIMA(0, 1, 0) modell. 2. Estimering av ARIMA modeller Vi bruker den samme funksjonen Arima fra forecast pakken til √• estimere b√•de ARMA og ARIMA modeller og spesifisering av modellen gj√∏r vi via argumentet order. Skal du estimerer en ARMA(1,1) modell setter du f.eks dette argumentet til c(1, 0, 1). Elementet i midten av denne vektoren spesifiserer hvor mange ganger tidsrekken skal differensieres i ARIMA modellen. Estimering av en ARIMA modell med en enkelt differensiering og ett MA og AR ledd kan gj√∏res slik: library(forecast) arima111 &lt;- Arima(pris, order = c(1, 1 , 1)) 3. Hvordan skal vi velge p, d og q i en ARIMA(p,d,q) modell? Etter √• ha tilpasset en ARIMA modell kan vi bruke modellen til √• predikere de samme observasjonene vi har brukt til √• tilpasse modellen. Vi kan s√• sammenligne hvor n√¶r prediksjoner fra forskjellige modeller er de sanne dataene. Dette heter p√• godt norsk √• gj√∏re en ‚Äúin-sample‚Äù vurdering av modellen. N√•r du har tilpasset en modell, kan du ved √• bruke summary funksjonen f√• opp flere m√•l p√• hvor god modellen er in-sample under fanen ‚ÄúTraining set error measure‚Äù: summary(arima111) ## Series: pris ## ARIMA(1,1,1) ## ## Coefficients: ## ar1 ma1 ## 0.5121 -0.5780 ## s.e. 0.1680 0.1584 ## ## sigma^2 = 6.614: log likelihood = -2958.16 ## AIC=5922.32 AICc=5922.34 BIC=5937.72 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.03973471 2.568719 1.949446 0.009091475 1.251353 0.9955157 ## ACF1 ## Training set 0.02035596 Her er f.eks \\(RMSE = \\sqrt{1/T\\sum_{t = 1}^T (\\hat{y}_t - y_t)^2}\\) et slags gjennomsnittlig avvik mellom prediksjonene og observasjonene. Litt lenger oppe i summary utskriften er det ogs√• en st√∏rrelse som heter AIC som m√•ler hvor sannsynlig hver observasjon er gitt modelvalget ditt. Sammenligner du flere modeller er du p√• jakt etter den modellen som har minst RMSE og/eller AIC. Det krever en del arbeid skal du sammenligne mange ARIMA(p,d,q) modeller ettersom det er s√• mange m√•ter √• kombinere p,d og q p√• selv om du bestemmer en maksverdi for hver av dem. Det finnes heldigvis en veldig smart R funksjon kalt auto.arima som f√∏lger med pakken forecast som estimerer mange modeller og gir deg ut den modellen med minst AIC: arima_best_AIC &lt;- auto.arima(pris) summary(arima_best_AIC) ## Series: pris ## ARIMA(0,1,2) ## ## Coefficients: ## ma1 ma2 ## -0.0421 -0.0947 ## s.e. 0.0282 0.0281 ## ## sigma^2 = 6.581: log likelihood = -2955.04 ## AIC=5916.09 AICc=5916.1 BIC=5931.48 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0398931 2.56232 1.948444 0.009249629 1.249956 0.9950042 ## ACF1 ## Training set -0.001297121 Hva slags modell har auto.arima valgt her? 4. Prediksjon Prediksjon gj√∏res som tidligere med forecast funksjonen, s√• hvis en vil predikere 10 tidssteg frem i tid gj√∏r man f√∏lgende: pred_arima111 &lt;- forecast(arima111, h = 10) autoplot(pred_arima111, include = 100) merk at i autoplot har vi valgt √• bare vise 100 observasjoner av tidsrekken sammen med prediksjonene. Kommentar: I et effisient marked skal prisutviklingen i teorien f√∏lge en tilfeldig gang og dagens pris vil da v√¶re det beste du kan tippe p√• for morgendagens pris. Vi ser her at dette blir reflektert i prediksjonen gjort av Arima(1,1,1) modellen. "],["modellbygging-1.html", "5.8 Modellbygging", " 5.8 Modellbygging Vi har allerede sett p√• hvordan vi kan sammenligne modeller ‚Äúin-sample‚Äù. For √• sammenligne tidsrekkemodeller bruker en ofte ogs√• √• sammenligne hvor godt modellene predikerer observasjoner som ikke har v√¶rt inkludert n√•r man tilpasser modellen. Dette heter p√• godt norsk √• vurdere ‚Äúout-of-sample‚Äù egenskapene ved modellen. Det finnes mange varianter for √• unders√∏ke dette, og under skal vi ta en titt p√• en enkel variant. Oppgave Vi viser hvordan dette gj√∏res for en modell med eksponensiell glatting. Du skal gjenta prosedyren, men for en ARIMA-modell (velg den med best AIC, hint: auto.arima). Sammenlign s√• out-of-sample egenskapene til til disse to modellene. 5.8.1 R-√∏ving 1. Data Vi skal i denne √∏vingen pr√∏ve √• finne en god modell for dax-indeksen: library(forecast) dax &lt;- EuStockMarkets[ ,1] plot(dax) 2. Trening og test data Vi √∏nsker f.eks √• teste hvor god modellen er til √• predikere de 10 siste observasjonene i datasettet. Vi deler derfor dataene inn i et treningssett best√•ende av alle observasjoner utenom disse 10 siste observasjonene, og et testsett best√•ende av de 10 siste observasjonene: trening &lt;- head(dax, length(dax) - 10) test &lt;- tail(dax, 10) 3. Estimering og prediksjon Vi tilpasser s√• en modell til treningssettet ved bruk av eksponensiell glatting og predikerer 10 tidssteg frem for √• f√• prediksjoner av testsettet: fit_exp &lt;- HoltWinters(trening) pred_exp &lt;- forecast(fit_exp, h = 10) Merk at n√•r vi ikke spesifiserer noen argumenter i HoltWinters vil en mer avansert modell bli tilpasset, samtidig som glattingsparameteren faktisk vil bli estimert ved √• minimerer MSE. 3. Out-of-sample vurdering Vi kan s√• sammenligne disse prediksjonene pred_exp med de faktiske observasjonene test ved √• ‚Äúm√•le‚Äù hvor langt disse er fra hverandre. Funksjonen accuracy som kommer med forecast pakken regner ut flere forskjellig m√•l p√• avstand: accuracy(pred_exp, test) ## ME RMSE MAE MPE MAPE MASE ## Training set 1.251117 35.82454 23.42652 0.03438446 0.8276219 0.04295353 ## Test set -317.477645 350.63504 317.47765 -5.82900543 5.8290054 0.58210884 ## ACF1 Theil&#39;s U ## Training set 0.07394258 NA ## Test set 0.62441059 3.510695 Hver kolonne i utskriften over representerer et slikt m√•l, og det er rad nummer to med navn ‚ÄúTest set‚Äù som vi er interessert i siden det er utregningen av disse m√•lene mellom prediksjonene og testsettet (Den f√∏rste raden representerer in-sample egenskapene). Jo mindre disse verdiene er jo mindre er avstanden mellom prediksjonene og de sanne verdiene i v√•rt testsett. "],["oppgaver-2.html", "5.9 Oppgaver", " 5.9 Oppgaver F√∏rste ordens autokorrelasjon til en tidsrekke \\(Y_t\\) er lik \\(-0.5\\). Andre ordens autokorrelasjon er lik \\(0.3\\). Tegn opp grafen til autokorrelasjonsfunksjonen til \\(Y_t\\). Forklar med ord hva det vil si at autokorrelasjonsfunksjonen til \\(Y_t\\) ser slik ut for observerte verdier av \\(Y_t\\). Forklar hva som er forskjellen p√• autokorrelasjonsfunksjonen til \\(Y_t\\) og den empiriske autokorrelasjonen til \\(Y_t\\) som vi har regnet ut for eksempel ved hjelp av 100 observerte realiseringer av tidsrekken. Tegn opp en graf som kunne v√¶rt den empiriske autokorrelasjonsfunksjonen til \\(Y_t\\) regnet ut for eksempel ved hjelp av 100 observerte realiseringer av tidsrekken. L√∏sning Graf av autokorrelasjonen: F√∏rste ordens autokorrelasjon er lik \\(-0.5\\), noe som betyr at korrelasjonen mellom p√•f√∏lgende observerte verdier av \\(Y_t\\) er lik \\(-0.5\\). I praksis betyr det at to p√•f√∏lgende observasjoner vil ha en tendens til √• v√¶re ganske forskjellige fra hverandre. Hvis \\(Y_t\\) er ‚Äúliten‚Äù (p√• en eller annen relevant skala), s√• vil \\(Y_{t+1}\\) ha en tendens til √• v√¶re ‚Äústor‚Äù. Og hvis \\(Y_{t+1}\\) er ‚Äústor‚Äù, ja da vil \\(Y_{t+2}\\) igjen ha en tendens til √• v√¶re ‚Äúliten‚Äù. Andre ordens autokorrelasjon er lik \\(0.3\\), noe som betyr at korrelasjonen mellom to observasjoner som er observert med ett tidssteg mellom seg er lik \\(0.3\\). I praksis betyr det at dersom \\(Y_t\\) er ‚Äúliten‚Äù, s√• vil \\(Y_{t+2}\\) ogs√• ha en tendens til √• v√¶re ‚Äúliten‚Äù, men denne tendensen er noe svakere enn den som er mellom to p√•f√∏lgende observasjoner, der absoluttverdien til autokorrelasjonen er \\(0.5\\). For eksempel kan vi tenke oss at en realisering av \\(Y_t\\) ser slik ut: Dette er samme type sp√∏rsm√•l som vi kjenner til med forventningsverdi/gjennomsnitt, samt teoretisk og empirisk varians. En stokastisk variabel \\(X\\) har en forventningsverdi \\(\\mu\\) og en varians \\(\\sigma^2\\), men disse er i praksis ukjente. Vi kan derimot estimere forventningsverdien ved √• ta et gjennomsnitt \\(\\overline X\\), og vi kan estimere den teoretiske variansen ved √• regne ut den empiriske variansen \\(s^2\\). Store talls lov garanterer at dette er gode estimater, ved at \\(\\overline X \\rightarrow \\mu\\) og \\(s^2 \\rightarrow \\sigma^2\\) n√•r antall observasjoner g√•r mot uendelig. Vi har n√∏yaktig det samme forholdet mellom empiriske og teoretiske autokorrelasjoner. Autokorrelasjonsfunksjonen til \\(Y_t\\) som vi beskrev over er den teoretiske, og den er ikke kjent i praksis med mindre vi simulerer fra en kjent tidsrekkemodell. For et gitt datasett kan vi derimot regne ut den empiriske autokorrelasjonsfunksjonen, som er et estimat av det sanne, teoretiske autokorrelasjonsfunksjonen. Vi vet, fra store talls lov, at dette er et godt estimat som vil konvergere mot sannheten etter hvert som vi f√•r flere og flere observasjoner. Den empiriske autokorrelasjonsfunksjonen vil ligne p√• den sanne autokorrelasjonsfunksjonen som vi tegnet opp over, men det vil v√¶re noe estimeringsfeil i tillegg som kommer av at vi bare har et endelig antall observasjoner. Laggene med null korrelasjon vil ikke m√•les til √• ha eksakt null autokorrelasjon, men bare om lag 5% av dem vil havne utenfor forkastningsgrensene p√• 5% signifikansniv√•. Vi tegner ogs√• inn noen tenkte forkastningsgrenser i figuren. Vurdere hvilke(n) tidsrekkemodell(er) som passer til de empiriske autokorrelasjonsplottene under, regnet ut ved hjelp av \\(n=500\\) observasjoner. L√∏sning Vi har et statistisk signifikant negativt utslag p√• f√∏rste lag, og et statistisk signifikant positivt utslag p√• andre lag. Det er ingen flere lags der autokorrelasjonsfunksjonen er stiatistisk signifikant forskjellig fra null. Det kan tyde p√• en MA(2)-prosess, med \\(\\theta_1 &lt;0\\) og \\(\\theta_2&gt;0\\). Autokorrelasjonsfunksjonen g√•r sakte mot null med √∏kende lag. Det kan tyde p√• en autoregressiv prosess, muligens en AR(1)-prosess med \\(\\phi_1 &gt; 0\\). Autokorrelasjonsfunksjonen alternerer mellom positive og negative verdier, men i absoluttverdi ser de ut til √• avta sakte mot null. Det kan tyde p√• en autoregressiv prosess, muligens en AR(1)-prosess med \\(\\phi_1 &lt; 0\\). Det er ikke mulig √• entydig fastsl√• hvilken modell som er ‚Äúkorrekt‚Äù ut fra et autokorrelasjonsplott. I alle tilfellene kan det v√¶re AR- eller MA-ledd som har for sm√• koeffisienter, til at vi klarer √• estimere dem til √• v√¶re statistisk signifikant forskjellig fra null ved hjelp av datasettet som vi har. Det er ogs√• vanskelig √• visuelt skille h√∏yere ordens prosesser fra hverandre kun ved √• se p√• autokorrelasjonsplottet. I det midterste plottet over for eksempel, kunne det like gjerne v√¶rt med andre- og tredjeordens AR-ledd, uten at vi ville klart √• se s√• stor forskjell p√• plottet. (I denne oppgaven er datasettene 500 observasjoner simulert fra henholdsvis en MA(2)-modell med \\(\\theta_1 = -0.2279\\) og \\(\\theta_2 = 0.2488\\), en AR(1)-modell med \\(\\phi_1 = 0.588\\), og en AR(1)-modell med \\(\\phi_1 = -0.5\\).) Under har vi anvendt funksjonen auto.arima fra forecast-pakken for fire tidsrekker. Identifiser hvilken modell som er plukket ut i hvert tilfelle, og skriv den opp: ## Series: ts ## ARIMA(1,0,1) with zero mean ## ## Coefficients: ## ar1 ma1 ## 0.4307 -0.6955 ## s.e. 0.2427 0.1922 ## ## sigma^2 = 0.8962: log likelihood = -135.48 ## AIC=276.97 AICc=277.22 BIC=284.78 ## Series: ts ## ARIMA(2,0,1) with zero mean ## ## Coefficients: ## ar1 ar2 ma1 ## 0.3037 0.4736 -0.5945 ## s.e. 0.1447 0.0871 0.1489 ## ## sigma^2 = 0.9683: log likelihood = -139.01 ## AIC=286.01 AICc=286.43 BIC=296.43 ## Series: ts ## ARIMA(1,1,0) ## ## Coefficients: ## ar1 ## 0.3568 ## s.e. 0.0933 ## ## sigma^2 = 1.01: log likelihood = -141.96 ## AIC=287.92 AICc=288.04 BIC=293.13 ## Series: ts ## ARIMA(2,1,2) with drift ## ## Coefficients: ## ar1 ar2 ma1 ma2 drift ## -0.0001 0.4345 0.2207 0.8386 -0.7286 ## s.e. 0.0996 0.1023 0.0609 0.0730 0.3520 ## ## sigma^2 = 1.027: log likelihood = -142.71 ## AIC=297.43 AICc=298.33 BIC=313.06 L√∏sning En ARMA(1,1)-modell: \\[Y_t = 0.4307Y_{t-1} - 0.6955u_{t-1} + u_t,\\] En ARMA(2,1)-modell: \\[Y_t = 0.3037Y_{t-1} + 0.4736Y_{t-2} - 0.5945u_{t-1} + u_t,\\] En ARIMA(1,1,0)-modell: \\[\\Delta Y_t = 0.3568\\Delta Y_{t-1} + u_t,\\] der \\(\\Delta Y_t\\) er tidsrekken \\(Y_t\\) differensiert en gang. Med andre ord er f√∏rstedifferansen til \\(Y_t\\) en AR(1) prosess med \\(\\phi_1 = 0.3568\\). En ARIMA(2,1,2)-modell: \\[\\Delta Y_t = -0.0001\\Delta Y_{t-1} + 0.4345\\Delta Y_{t-2} + 0.8386u_{t-1} - 0.7286u_{t-2},\\] Med andre ord er f√∏rstedifferansen til \\(Y_t\\) en ARMA(2,2)-modell. I alle tilfellene er \\(u_t\\) hvit st√∏y. Regn ut forventning og varians til f√∏lgende tidsrekkemodeller og avgj√∏r om de er stasjon√¶re. I alle tilfeller er \\(u_t\\) hvit st√∏y der \\(E(u_t)=0\\) og \\(Var(u_t)=\\sigma^2\\). \\(Y_t = t + u_t\\) \\(Y_t = 3 + u_t\\) \\(Y_t = t\\cdot u_t\\) \\(Y_t = u_1 + u_2 + \\dots + u_t\\) L√∏sning \\[E(Y_t) = E(t + u_t) = E(t) + E(u_t) = t + 0 = t.\\] \\[Var(Y_t) = Var(t + u_t) = Var(t) + Var(u_t) = 0 + \\sigma^2 = \\sigma^2\\] Siden forventningsverdien ikke er konstant kan ikke dette v√¶re en stasjon√¶r tidsrekke. \\[E(Y_t) = E(3 + u_t) = E(3) + E(u_t) = 3 + 0 = 3.\\] \\[Var(Y_t) = Var(3 + u_t) = Var(3) + Var(u_t) = 0 + \\sigma^2 = \\sigma^2\\] Her er b√•de forventning og varians konstant i tid s√• dette kan v√¶re en stasjon√¶r tidsrekke (vi m√• formelt ogs√• sjekke at autokorrelasjonen er konstant) \\[E(Y_t) = E(t\\cdot u_t) = t \\cdot E(u_t) = t\\cdot 0 = 0.\\] \\[Var(Y_t) = Var(t\\cdot u_t) = t^2\\cdot Var(u_t) = t^2\\sigma^2 \\] Siden varians ikke er konstant i tid kan ikke dette v√¶re en stasjon√¶r tidsrekke. \\[E(Y_t) = E(u_1 + u_2 + \\dots + u_t) = E(u_1) + E(u_2) + \\cdot + E(u_t) = 0 + 0 + \\dots + 0 = 0.\\] \\[\\begin{align*} Var(Y_t) &amp;= Var(u_1 + u_2 + \\dots + u_t) \\\\ &amp; = Var(u_1) + Var(u_2) + \\dots + Var(u_t) = \\sigma^2 + \\sigma^2 + \\dots + \\sigma^2 = t\\sigma^2 \\end{align*}\\] Siden variansen ikke er konstant i tid kan ikke dette v√¶re en stasjon√¶r tidsrekke. Individuell eksamen V21, oppgave 3 L√∏sning L√∏sningsforslag Individuell eksamen V20, oppgave 3 L√∏sning L√∏sningsforslag "],["relevante-r-tidsrekker.html", "5.10 Relevante R-kommandoer", " 5.10 Relevante R-kommandoer Antakelser om datasettet Vi skal n√• ha rimelig grei kontroll p√• de ulike datastrukturene i R, og det er bra, fordi i denne siste modulen om tidsrekker s√• er vi n√∏dt til √• kunne administrere data i litt forskjellige formater. I hovedtrekke m√• vi kunne: Lese inn data fra en Excel- eller .csv-fil til en data frame p√• samme m√•te som tidligere, der vi i tidsrekker typisk vil ha en kolonne for dato eller tidspunkt, og en eller flere kolonner med tidsrekker nedover. Hente ut tidsrekkene i en data frame som en vektor. Akseptere at en del tidsrekkedata (spesielt de som f√∏lger med ulike pakker i R) er lagret i andre typer mer spesialiserte datatyper. Equinordatafilen (equinor.xlsx) f√∏lger den f√∏rste formen og kan leses inn p√• vanlig m√•te ved hjelp av read_excel() i readxl-pakken. ausbeer-datasettet fra fpp-pakken, derimot, har en spesiell tidsrekke-klasse (pr√∏v √• skrive class(ausbeer) i konsollen), noe vi ser ved √• bare skrive ut tidsrekken i konsollen. Da ser vi at datasettet er p√• en slags matrisestruktur, men kvartal kolonnevis og √•r radvis. N√∏dvendige R-funksjoner N√∏dvendige R-funksjoner for denne modulen sammenfaller eksakt med gjennomgangen under forelesningsvideoene, s√• det er ikke n√∏dvendig √• gjenta det her. "],["avansert-regresjon-og-maskinl√¶ring.html", " 6 Avansert regresjon og maskinl√¶ring", " 6 Avansert regresjon og maskinl√¶ring I denne modulen tar vi en titt p√• noen litt mer avanserte statistiske metoder. De to f√∏rste temaene, logistisk regresjon og ‚ÄúK-nearest-neighbor‚Äù-metoden (kNN), har til felles at de kan brukes n√•r responsvariabelen er en kategorisk variabel med kun to kategorier. Begge disse metodene faller inn under det som popul√¶rt kalles maskinl√¶ring og er s√•ledes en introduksjon til dette temaet. I det siste temaet, paneldata, skal vi se hvordan vi kan bygge regresjonsmodeller n√•r hvert individ er observert flere ganger etter hverandre i tid. R-script til ‚ÄúLogistisk Regresjon‚Äù R-script til ‚ÄúKNN‚Äù R-script til ‚ÄúPaneldata‚Äù "],["logistisk-regresjon.html", "6.1 Logistisk regresjon", " 6.1 Logistisk regresjon 6.1.1 Videoforelesninger 6.1.2 Kontrollsp√∏rsm√•l I hvilke situasjoner bruker vi logistisk regresjon? Hva er det vi modellerer? Hvordan tolker vi √®n enhets √∏kning i forklaringsvariabelen? Hvilken metode brukes til √• estimere en logistisk regresjonsmodell? Hva betyr klassifisering og hvordan gj√∏res dette? Hvis vi har flere modeller, hvilke(n) metode(r) kan vi bruker til √• velge den beste? 6.1.3 Teori I denne forelesningen ser vi p√• situasjonen der vi √∏nsker √• forklare utfallet av en bin√¶r variabel (en dummyvariabel) ved hjelp av et sett med forklaringsvariabler. Vi s√• at vanlig line√¶r regresjon ikke er s√¶rlig passende her fordi utfallet bare kan ta to verdier (0 eller 1, FALSE eller TRUE etc.), og fordi vi heller ikke kan tolke et kontinuerlig utfall direkte som en sannsynlighet fordi vi kan f√• ut verdier utenfor intervallet \\([0, 1]\\). L√∏sningen er √• heller forklare log-oddsen til suksessansynligheten. Sagt p√• en annen m√•te: p√• venstresiden i regresjonsligningen plasserer vi en transformasjon av suksessansynligheten, som gir oss en kontinuerlig variabel som kun kan variere mellom 0 og 1. Pensumboken v√•r behandler desverre ikke logistisk regresjon. Heldigvis finnes det et meget godt alternativ, An Introduction to Statistical Learning (ISLR) av James m.fl. som kan lastes ned gratis her: An introduction to statistical learning (trykk p√• ‚ÄúDownload the first edition‚Äù) Denne boken er for √∏vrig pensum i BAN404. Logistisk regresjon er omhandlet i kapittel 4.3 (avsnitt 4.3.5 er ikke pensum). Eksempelet v√•rt er tatt herfra, og datasettet er, som vist i forelesningsscriptet, inkludert i bokens egen R-pakke ISLR. Bruk litt tid p√• √• lese gjennom disse sidene, konseptet er ganske godt forklart. Bli ogs√• kjent med R-syntaksen, som ligner p√• den vi allerede kan for vanlig line√¶r regresjon. Vi bruker f.eks. reg1 &lt;- glm(default ~ balance, data = Default, family = &quot;binomial&quot;) N√•r du er klar til √• pr√∏ve selv, kan du se p√• oppg 10a, b og f√∏rste del av d p√• s. 171 i ISLR. Dette datasettet er ogs√• inneholdt i ISLR-pakken. "],["introduksjon-til-maskinl√¶ring-med-knn.html", "6.2 Introduksjon til maskinl√¶ring med kNN", " 6.2 Introduksjon til maskinl√¶ring med kNN 6.2.1 Videoforelesninger 6.2.2 Kontrollsp√∏rsm√•l For hvilke typer responsvariabler bruker vi KNN? Hvordan fungerer KNN teoretisk sett? Hva er den praktiske tolkningen av KNN? Hvordan p√•virker valget av \\(k\\) m√•ten KNN fungerer p√•? Hvordan velger vi \\(k\\)? 6.2.3 Teori Kanskje har du allerede h√∏rt om maskinl√¶ring, ‚Äúdata science‚Äù, prediktiv modellering, ‚Äúbusiness analytics‚Äù, etc., og kanskje har du f√•tt med deg at disse tingene virkelig er i vinden for tiden. Som akademisk institusjon skal vi selvsagt v√¶re p√• vakt mot √• la popularitet v√¶re en avgj√∏rende faktor for hva vi driver med, men, som en kollega s√• treffende uttrykte seg: ‚ÄúInternett er kommet for √• bli.‚Äù Det skjer utrolig mye verdiskapning n√•r vi f√•r tak i den verdifulle informasjonen som ligger gjemt i de store datamengdene, og n√¶ringslivet skriker etter kompetanse. NHH har som svar p√• dette opprettet masterprofilen ‚ÄúBusiness Analytics (BAN)‚Äù (som ironisk nok er blitt superpopul√¶r!), og det er naturlig √• gi en liten smakebit p√• hva det g√•r ut p√• i MET4. Det herlige er at vi ikke trenger √• dykke s√• dypt i detaljene for √• f√• brukbar innsikt i hva som skjer. Overgangen fra logistisk regresjon er naturlig. Vi bruker det vi kan fra regresjonsanalyse til √• sette opp en modell der vi forklarer utfallet i en dummyvariabel ved hjelp av et sett forklaringsvariable i allerede observerte data. I f√∏rste omgang kan vi si at den moderne anvendelsen av logistisk regresjon (kall det gjerne en form for maskinl√¶ring) er √• bruke data til √• estimere sammenhengen mellom \\(X\\)-ene og responsvariabelen \\(Y\\), og s√• bruke denne sammengengen til √• predikere \\(Y\\) for nye \\(X\\). Artikkelen To explain or to predict av Galit Shmueli forklarer distinksjonen mellom det √• forklare og det √• predikere godt, og skal v√¶re noenlunde lesbar for en interessert student. Eksempelet fra logistisk regresjon er et godt eksempel p√• en anvendelse: Vi predikerer sannsynligheten for at kunder vil misligholde gjelden i fremtiden, basert p√• karakteristika vi kan observere n√•. Slike sannsynligheter kan vi mate inn i en strategisk analyse for √• bestemme oss hvem som skal f√• innvilget nye l√•n, men p√• en systematisk m√•te der vi s√∏rger for at vi oppn√•r n√∏dvendige profittmarginer og h√•ndterer risiko p√• en fornuftig m√•te, og kan ta hensyn til f.eks. etiske avveininger. Selv om vi ut fra eget behov for profitt og innenfor en akseptabel risikoprofil kan tilby nye l√•n til kunder med 15% sannsynlighet for √• havne i betalingsproblemer, b√∏r vi likevel gj√∏re det? Poenget her er at du ikke kan gj√∏re slike vurderinger f√∏r du faktisk kan estimere sannsynligheten for mislighold! Statistikken er bunnplanken, og blir mer og mer relevant etter hvert som vi innser at svarene ligger i √• analysere data. Vi g√•r videre til et annet eksempel. En teleoperat√∏r med abonnementskunder ser at det er en systematikk i hvilke kunder som sier opp avtalene sine. Ved √• se p√• spredningsplottet under (r√∏d prikk = kunde som har sagt opp abonnementet), ser det ut til at nye kunder med dyre abonnementer har en tendens til √• forlate oss. Kan vi sette opp en klassifiseringsregel der som vi kan anvende p√• alle kundene v√•re, som automatisk plukker ut kunder som har f.eks. mer enn 50% sannsynlighet for √• si opp? Denne listen kan vi s√• sende videre til markedsavdelingen, som kan sette i verk forebyggende tiltak (f.eks. lokke de inn i bindende avtaler‚Ä¶?), og vi kan oppn√• en umiddelbar gevinst. Figur 6.1: R√∏de prikker er kunder som har sagt opp abbonnementet sitt, svarte prikker er kunder som ikke har gjort det. Finn den optimale avveiningen mellom systematikk og tilfeldig variasjon. Vi kan angripe dette datasettet p√• to m√•ter: Vi estimerer sannsynligheter ved hjelp av logistisk regresjon. Den stramme strukturen gj√∏r at klassifiseringsgrensen alltid utgj√∏r en rett linje i koordinatsystemet. Vi ser ogs√• p√• en annen klassifiseringsregel: kNN (k nearest neighbours), som ikke bruker sannsynlighetsmodeller eller regresjonsparametre til √• klassifisere, men heller er en enkel regel basert p√• f√∏lgende prinsipp: Hvis et flertall av kundene som er mest lik meg har sagt opp, er det mer enn 50% sannsynlig at ogs√• jeg vil si opp. Her bruker vi litt tid p√• detaljer, men det handler i grunn bare om √• lage en presis definisjom om hvem vi definerer som de kundene som ligner mest p√• meg, og svaret er de \\(k\\) kundene som ligger n√¶rmest meg i koordinatsystemet. P√• samme m√•te som for logistisk regresjon kan vi lese mer om kNN i ISLR. P√• s. 39‚Äì42 st√•r det hvordan teknikken fungerer, og i forelesningsnotatene og det medf√∏lgende scriptet ser vi hvordan det kan gj√∏res i praksis. N√•r vi forst√•r hvordan kNN fungerer, er neste steg √• reflektere litt over hvordan vi har tenkt √• velge parameteren \\(k\\) i praksis. Vi s√• i forelesningen at: Vi kan ikke velge \\(k\\) for liten. Da ser vi for mye p√• st√∏y og tilfeldigheter. Vi kan enkelt tenke oss at jeg er en lavrisikokunde, selv om de to kundene som er n√¶rmest meg i koordinatsystemet sa opp av en eller annen grunn. Hvis vi velger \\(k = 3\\), vil jeg likevel bli klassifisert som h√∏yrisiko og bli bombardert med un√∏dvendig reklame (som i seg selv kan gj√∏re stor skade!) Hadde vi heller valgt \\(k = 50\\) eller \\(k=500\\) ville disse to raringene ikke bli tatt hensyn til, men blitt dominert av alle andre i omr√•det som faktisk ikke har sagt opp. Alts√•: vi kan ikke henge oss for mye opp i detaljene og den tilfeldige variasjonen! Vi kan heller ikke velge \\(k\\) for stor, for det vil til slutt n√¶rme seg en situasjon det det bare blir en avstemning mellom alle kundene i datasettet. Det er flest kunder som ikke sier opp avtalen, s√• da blir alle kunder klassifisert som lavrisiko. Alts√•: vi vil heller ikke ignorere variasjonen i datamaterialet! Hele poenget er jo √• l√¶re noe nyttig fra hvordan prikkene fordeler seg i koordinatsystemet. I Figur 6.1 kan du pr√∏ve f√∏lgende: En liten \\(k\\) svarer til √• se n√∏ye p√• figuren (putt hodet ditt helt inntil skjermen!), og virkelig legge merke til hvor hver eneste en av de r√∏de prikkene befinner seg. √Ö velge en st√∏rre \\(k\\) svarer til √• trekke lenger bort, og kanskje begynne √• myse litt, slik at du f√•r √∏ye p√• systematikken, nemlig at det r√∏de dominerer nede til h√∏yre i figuren. Til slutt st√•r du i rommet ved siden av med lukkede √∏yne, og da ser du plutselig ingenting! Et eller annet sted i mellom der √∏nsker vi √• v√¶re. Kryssvalidering er en systematisk og generell m√•te √• velge k for KNN (og tilsvarende parametre i andre maskinl√¶ringsmetoder), som litt lenger enn √• bare dele datasettet inn i trenings- og testdata ISLR behandler temaet p√• s. 181‚Äì186, men det er forholdsvis teknisk og skrevet i lys av noen metoder som vi ikke har sett p√• i MET4. "],["paneldata.html", "6.3 Paneldata", " 6.3 Paneldata 6.3.1 Videoforelesninger 6.3.2 Kontrollsp√∏rsm√•l Hva er paneldata? Hva m√• vi ta hensyn til n√•r vi analyserer paneldata? Hvordan ser en generell modell for paneldata ut? Hva er den konseptuelle forskjellen mellom faste og tilfeldige effekter? N√•r kan vi bruke faste effekter? N√•r kan vi bruke tilfeldige effekter? Finnes det en m√•te √• formelt teste om man skal bruke faste eller tilfeldige effekter? (obs: se helt nederst p√• denne siden for svaret p√• denne.) 6.3.3 Teori og R I denne forelesningen introduserer vi en ny datastruktur. Vi observerer flere individer (tversnittsdimensjonen) gjentatte ganger (tidsdimensjonen), og et slikt datasett kaller vi et panel, eller paneldata. Fordelen ved √• jobbe med slike data er √•penbar: vi har mer informasjon og kan gjennomf√∏re mer presise statistiske analyser. P√• den annen side m√• vi akseptere at en mer kompleks datastruktur gj√∏r det n√∏dvendig √• innf√∏re mer kompleks metodikk. I gjennomgangen under bruker vi et liten del av dataene fra eksempelet som er beskrevet i videoene. √ònsker du √• f√∏lge R-gjennomgangen laster du ned f√∏lgende datasett: panel_liten.csv 6.3.3.1 Struktur p√• Paneldata Til n√• har vi typisk observert \\(n\\) individer en gang. Hvis vi holder oss til eksempelet fra videoforelesningen, kan vi tenke oss at vi har spurt \\(n\\) arbeidstakere om hvor mange timer de jobbet forrige √•r (\\(X\\)), og hvor mye de hadde i timel√∏nn (\\(Y\\)). Da ville datasettet sett omtrent slik ut: Her er \\(y_i\\) timel√∏nn til arbeidstaker nummer \\(i\\), og \\(x_i\\) er antall timer jobbet for arbeidstaker nummer \\(i\\). Hvis vi s√• √∏nsker √• se om det er en sammenheng mellom disse to variablene, kan vi sette opp en enkel regresjonsmodell som vi har gjort f√∏r: \\[\\begin{equation} y_i = \\alpha + \\beta x_i + \\epsilon_i, \\label{p-ols} \\end{equation}\\] der vi gj√∏r de vanlige antakelsene om homoskedastisitet, uavhengige feilledd, og selvsagt at forklaringsvariabelen er eksogen, dvs at de stokastiske variablene \\(X\\) og \\(\\epsilon\\) er uavhengige fra hverandre. Hvis vi aksepterer det, s√• kan vi estimere \\(\\beta\\) ved hjelp av minste kvadreters metode (OLS - orinary least squares), som vi kan tolke som forventet √∏kning i timel√∏nn ved √• jobbe en time ekstra. For paneldata har vi ikke lenger kun observert \\(n\\) arbeidstakere 1 gang, men spurt \\(N\\) arbeidstakere \\(T\\) ganger, slik at vi trenger to indekser til √• identifisere hver enkelt observasjon: \\(y_{i,t}\\) er timel√∏nn til arbeidstaker nummer \\(i\\) ved tidspunkt \\(t\\). V√•re observerte \\(X\\)er og \\(Y\\)er kan vi samle i en tabell som f√∏r, se illustrasjonen under. Legg merke til at det bare er de to f√∏rste kolonnene for \\(X\\) og \\(Y\\) som utgj√∏r de faktiske observasjonene, mens de to neste kolonnene sier hvilket individ som er observert, og ved hvilket tidspunkt observasjonen er utf√∏rt, og viser bare indeksene til \\(X\\)- og \\(Y\\)-observasjonene. Kall det gjerne metadata, og vi trenger den informasjonen n√•r vi skal utf√∏re paneldatateknikker. Formatet i tabellen over kalles gjerne et langt format, og omtrent samtlige R-pakker og funksjoner som brukes til √• analysere panel data forventer at dataene er organisert p√• denne m√•ten. Vi kan ta en titt p√• hvordan dette ser ut i R for eksempelet v√•rt: df &lt;- read.csv(&quot;panel_liten.csv&quot;) # Leser inn datasettet head(df) # Ser p√• datasettet ## X lnhr lnwg kids age disab id year mlhr mlwg dlhr dwg ## 1 5241 7.71 3.19 0 30 0 1 1979 7.742 3.218 -0.032 -0.028 ## 2 5242 7.64 3.14 0 32 0 1 1980 7.742 3.218 -0.102 -0.078 ## 3 5243 7.71 3.11 0 33 0 1 1981 7.742 3.218 -0.032 -0.108 ## 4 5244 7.72 3.00 0 34 0 1 1982 7.742 3.218 -0.022 -0.218 ## 5 5245 7.72 2.94 0 35 0 1 1983 7.742 3.218 -0.022 -0.278 ## 6 5246 7.73 3.12 1 35 0 1 1984 7.742 3.218 -0.012 -0.098 Her svarer lnwgtil responsvariabelen (log) l√∏nn og lnhr til forklaringsvariabelen (log) antall timer jobbet. Legg merke til at det er en egen kolonne med navn id som forteller oss hvilket individ observasjonene gjelder for. Dette svarer til \\(i\\)-indeksen i notasjonen over. Det er ogs√• en egen kolonne kalt year som forteller oss hvilket √•r observasjonen er fra, og dette svarer til \\(t\\)-indeksen. F.eks er f√∏rste rad observasjoner gjort for individ nr. 1 i √•r 1979. 6.3.3.2 Hva m√• vi ta hensyn til? Hovedmotivasjonen for √• analysere paneldata er enn√• √• unders√∏ke sammenhengen mellom respons og forklaringsvariabelen. En slik m√•te √• samle inn data p√• gir f.eks mer innformasjon om sammenhengen mellom timel√∏nn og antall arbeidstimer fordi vi har flere observasjoner enn om vi bare betraktet en observasjon per individ. Men siden vi har gjentatte observasjoner over tid kan responsvariablene v√¶re avhengige. Vi kan se for oss to grunner til dette: En utvikling i tid som er felles for alle individene; Det er f.eks tenkelig at det er en generell utvikling i l√∏nnsniv√•et over tid, eller at det f.eks finnes gode √•r hvor alle tjener spesielt godt. De gjentatte observasjonene for ett gitt individ vil typisk v√¶re avhengige; Har et individ h√∏y inntekt det ene √•ret er det tenkelig at det ogs√• har h√∏y inntekt det neste √•ret. Denne effekten kan misforst√•s som en effekt av forklaringsvariabelen. Alts√• m√• vi b√•de ta hensyn til at det kan v√¶re en generell utvikling i tid og at det kan v√¶re individuelt forskjellige l√∏nnsniv√•. Disse aspektene kan nemlig p√•virke v√•rt estimat av effekten av √• jobbe mer dersom vi bruker den tradisjonelle regresjonsmodellen og OLS. La oss inspisere de \\(3\\) individene vi har data for i v√•rt lille datasett ved √• lage et figur med l√∏nnsutvikling (lnwg) langs y-aksen og √•r (year) langs x-aksen for √• se om det finnes et slags felles m√∏nster i l√∏nnsutviklingen (ref. punkt 1. over): library(ggplot2) ggplot(df) + geom_point(aes(x = year, y = lnwg, color = factor(id))) her ser vi f.eks at alle individene har et d√•rlig √•r i 1983, mens 1985 virker √• v√¶re et godt √•r. Det ogs√• tydelig at l√∏nnen holder seg relavivt lik l√∏nnen det foreg√•ende √•ret. Det er alts√• rimelig √• tro at det er fellestrekk i l√∏nnen til individene for gitte √•r. La oss s√• lage et spredningsplott mellom lnhr og lnwg hvor vi fargelegger hvilket individ observasjonene kommer fra: library(ggplot2) ggplot(df) + geom_point(aes(x = lnhr, y = lnwg, color = factor(id))) Ser vi p√• disse dataene samlet sett ser du til √• v√¶re en klart positiv korrelasjon mellom l√∏nn og antall timer jobbet. Men legg merke til at individ nr. 1 ligger p√• et h√∏yere l√∏nnsniv√• og jobber mer enn de to andre individene. Det er dette som i stor grad skaper et bilde av en sterk positiv sammenheng mellom variablene. Hvis vi ser p√• de individuelle observasjonene (hver fargesky) hver for seg, virker ikke sammenhengen √• v√¶re like sterk, og det har kanskje ikke like mye √• si for l√∏nnen om du individuelt velger √• jobber mer. Dette svarer til fenomenet beskrevet i punkt 2. over. 6.3.3.3 Generelt oppsett av modell Effektene av de fenomene vi beskrev over kan vi ta hensyn til ved √• inkludere dem i regresjonsmodellen p√• f√∏lgende m√•te: \\[y_{it} = \\beta_0 + \\beta_1 x_{it} + v_t + \\alpha_i + \\epsilon_{it} \\] hvor vi n√• har lagt til to nye ledd, \\(v_t\\) og \\(\\alpha_i\\), i modellen: Her representerer \\(v_t\\) den generelle utviklingen i tid som er felles for alle individene (det er ingen ‚Äúi‚Äù-indeks i denne). Det kan f.eks v√¶re en line√¶r trend (\\(v_t = \\delta t\\)) eller helt unike √•rlige effekter \\(v_t\\), som fanger opp gode og d√•rlige √•r. Leddene \\(\\alpha_i\\) representerer s√• de individuelle l√∏nnsniv√•ene (disse er ‚Äúi‚Äù indeksert). Har individ \\(1\\) h√∏yere l√∏nn enn individ \\(2\\) s√• vil \\(\\alpha_1\\) blir estimert til √• v√¶re st√∏rre enn \\(\\alpha_2\\). Vi justerer alts√• for at individer kan ligge p√• et forskjellig l√∏nnsniv√•, og at det er en felles √•rlige variasjoner i l√∏nn. I praksis betyr dette at vi justerer regresjonslinjen vertikalt slik at den tilpasser seg l√∏nnsniv√•et til hvert individ. Effekten \\(\\beta_1\\) av √• jobbe mer er derimot antatt lik for hvert individ og den estimerte effekten vil da bli et slags gjennomsnitt av hvor mye det individuelt l√∏nner seg √• jobbe mer. I utgangspunktet kan vi betrakte \\(v_t\\) og \\(\\alpha_i\\) som kategoriske variabler som kan estimeres ved hjelp av dummyvariabler slik vi har l√¶rt f√∏r. Problemet er at i et tradisjonelt paneldatasett s√• er \\(N\\) (antall individer) et stort tall, mens \\(T\\) (antall observasjoner per individ) et relativt lite tall. Dette f√∏rer til sv√¶rt mange kategoriske variabler \\(\\alpha_i\\) √• estimere, og i praksis m√• vi derfor betrakte andre metoder. Vi noterer oss f√∏lgende: Egenskapene til \\(\\alpha_i\\) bestemmer typen paneldatamodell og vi deler disse modellene grovt sett inn i modeller med faste effekter og tilfeldige effekter. Selve ligningene vil alts√• se like ut, men tolkning og estimering er forskjellig. Leddene \\(v_t\\) vil vi i de fleste tilfeller klare √• estimere som kategoriske variabler og i fortsettelsen ser vi bort fra dette leddet For enkelthets skyld betrakter vi bare √®n forklaringsvariabel, men det kan selvsagt v√¶re flere forklaringsvariabler i en regresjonsmodell for panel data ogs√•. 6.3.3.4 Forskjellige parameteriseringer Merk at det b√•de i l√¶reb√∏ker og i forskjellige R-pakker veksles mellom √• to typer formuleringer av den generelle modellen over. Hvis vi ser bort fra \\(v_t\\) leddet, er modellen vi til n√• har betraktet formulert som: \\[\\begin{align} y_{it} = \\beta_0 + \\beta_1 x_{it} + \\alpha_i + \\epsilon_{it} \\tag{6.1} \\end{align}\\] hvor \\(\\beta_0\\) er inkludert. Her kan \\(\\beta_0\\) tolkes som det gjennomsnittlige skj√¶ringspunktet med y-aksen blant de individuelle regresjonslinjene, mens \\(\\beta_0 + \\alpha_i\\) vil v√¶re skj√¶ringspunktet med y-aksen for individ nr. \\(i\\). Men det er ogs√• sv√¶rt vanlig (og kanskje litt lettere) √• formulere modellen uten \\(\\beta_0\\): \\[\\begin{align} y_{it} = \\beta_1 x_{it} + \\alpha_i + \\epsilon_{it} \\tag{6.2} \\end{align}\\] og da vil \\(\\alpha_i\\) v√¶re det individuelle skj√¶ringspunktet med y-aksen for individ nr. \\(i\\). Forskjellen er rett og slett tolkningsmessig. I videoen for faste effekter g√•r vi igjennom estimeringen av begge modellene, men under betrakter vi bare estimering av sistnevnte modell n√•r vi bruker faste effekter. Dette gj√∏r vi siden modellen i R er definert p√• denne m√•ten. N√•r vi s√• ser p√• tilfeldige effekter vil vi av samme grunn betrakte modell (6.1). 6.3.3.5 Faste effekter I en modell med faste effekter betrakter vi \\(\\alpha_i\\) leddene som faste st√∏rrelser som m√• estimeres. Denne modellen er omtrent alltid gyldig og kan brukes selv om vi tror de individuelle forskjellene \\(\\alpha_i\\) er relativt store og at det er avhengighet mellom forklaringsvariabelen(e) og \\(\\alpha_i\\). I modellen v√•r som er formulert som \\[y_{it} = \\beta_1 x_{it} + \\alpha_i + \\epsilon_{it} \\] skal vi alts√• estimere \\(\\alpha_1, \\alpha_2, ..., \\alpha_N\\) samt effekten av det √• jobbe mer \\(\\beta_1\\). Det finnes en rekke estimeringsteknikker og vi vil her (og i videoen) bare beskrive en metode. Vi begynner med √• ta tidsgjennomsnittet av ligningen over for hvert individ: \\[1/T \\sum_{t = 1}^T y_{it} = 1/T \\sum_{t = 1}^T \\beta_1 x_{it} + 1/T \\sum_{t = 1}^T \\alpha_i + 1/T \\sum_{t = 1}^T \\epsilon_{it}\\] Her vil tidsgjennomsnittet av \\(\\alpha_i\\) bare v√¶re \\(\\alpha_i\\) siden dette leddet ikke varierer med tiden. Alts√• kan vi skrive ligningen over som: \\[\\begin{align} \\overline{y}_{i} = \\beta_1\\overline{x}_i + \\alpha_i + \\overline{\\epsilon}_i \\tag{6.3} \\end{align}\\] Her er henholdsvis \\(\\overline{y}_i\\) og \\(\\overline{x}_i\\) den gjennomsnittlige l√∏nnen og antall timer jobbet for individ nr. i, og dette er st√∏rrelser vi kan regne ut. Vi tar s√• v√•r originale modell √• trekker fra denne ligningen: \\[y_{it} - \\overline{y}_{i} = \\beta_1(x_{it} - \\overline{x}_i) + \\alpha_i - \\alpha_i + \\epsilon_{it} - \\overline{\\epsilon}_i\\] N√∏kkelen her er at \\(\\alpha_i\\)-leddene kansellerer hverandre og vi kan formulere en ligning helt uten disse leddene: \\[\\tilde{y}_{it} = \\beta_1\\tilde{x}_{it} + \\tilde{\\epsilon}_{it},\\] hvor \\(\\tilde{y}_{it} = y_{it} - \\overline{y}_{i}\\), \\(\\tilde{x}_{it} = x_{it} - \\overline{x}_{i}\\) og \\(\\tilde{\\epsilon}_{it} = \\epsilon_{it} - \\overline{\\epsilon}_{i}\\). Siden vi n√• ikke lenger har \\(\\alpha_i\\) i ligningen, og siden \\(\\tilde{\\epsilon}_{it}\\) bare er et nytt feilledd sentrert rundt null, kan vi estimere \\(\\beta_1\\) ved vanlig OLS, alts√• velge den verdien \\(\\hat{\\beta}_1\\) som minimerer: \\[\\sum_{i=1}^N\\sum_{t=1}^T(\\tilde{y}_{it} - \\beta_1\\tilde{x}_{it})^2\\] Gitt et estimat av \\(\\beta_1\\) kan vi f√• estimater av \\(\\alpha_1, \\dots, \\alpha_N\\) ved √• og ta forventning av den tidsgjennomsnittlige modellen (6.3) (da forsvinner \\(\\overline{\\epsilon}_{it}\\) leddet), erstatte \\(\\beta_1\\) med estimatet \\(\\hat{\\beta}_1\\) og l√∏se ligningen m.h.p \\(\\alpha_i\\). \\[\\begin{align} \\hat{\\alpha}_1 &amp;= \\overline{y}_{1} - \\hat{\\beta}_1\\overline{x}_1\\\\ \\hat{\\alpha}_2 &amp;= \\overline{y}_{2} - \\hat{\\beta}_1\\overline{x}_2\\\\ &amp;\\vdots\\\\ \\hat{\\alpha}_N &amp;= \\overline{y}_{N} - \\hat{\\beta}_1\\overline{x}_N\\\\ \\end{align}\\] Sluttproduktet er derfor \\(N\\) individuelle regresjonslinjer: \\[\\begin{align} y_{1t} &amp;= \\hat{\\alpha}_1 + \\hat{\\beta}_1 x_{1t} \\\\ y_{2t} &amp;= \\hat{\\alpha}_2 + \\hat{\\beta}_1 x_{2t} \\\\ &amp;\\vdots\\\\ y_{Nt} &amp;= \\hat{\\alpha}_N + \\hat{\\beta}_1 x_{Nt} \\\\ \\end{align}\\] som har individuelle skj√¶ringspunkt med \\(y\\)-aksen (\\(\\hat{\\alpha}_i\\)) for √• justere for forskjellig l√∏nnsniv√•, men hvor alle observasjonene har blitt brukt til √• estimere det felles stigningstallet \\(\\hat{\\beta}_1\\). Det er verdt √• merke seg at denne metoden ikke kan brukes dersom forklaringsvariabelen ikke varierer med tid (eksempelvis kj√∏nn). Da vil nemlig \\(x_{it} - \\overline{x}_i = x_{it} - x_{it} = 0\\), og vi har derfor ingen mulighet til √• estimere \\(\\beta_1\\) med OLS. Det finnes flere pakker som kan estimere slike modeller i R, men en veldig enkel pakke √• bruke heter plm. Det f√∏rste vi gj√∏r er √• laste pakken fors√• √• ‚Äúoversette‚Äù dataene v√•re til paneldata. P√• denne m√•ten forst√•r plm funksjonen hva som er individ indeksen og hva som er tidsinndeksen: library(plm) # Pakke for √• estimere faste effekter # Oversetter til panel data frame p.df &lt;- pdata.frame(df, index = c(&quot;id&quot; ,&quot;year&quot;)) Syntaksen for √• bruke plm funksjonen er sv√¶rt lik den for lm og glm. For √• bruke en modell med faste effekter m√• man huske √• spesifiserer argumentet model = \"within\": reg.fe &lt;- plm(lnwg ~ lnhr, data = p.df, model = &quot;within&quot;) summary(reg.fe) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = lnwg ~ lnhr, data = p.df, model = &quot;within&quot;) ## ## Balanced Panel: n = 3, T = 10, N = 30 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.270016 -0.042538 -0.011427 0.051738 0.336355 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## lnhr 0.36293 0.26210 1.3847 0.1779 ## ## Total Sum of Squares: 0.37546 ## Residual Sum of Squares: 0.34967 ## R-Squared: 0.068678 ## Adj. R-Squared: -0.038782 ## F-statistic: 1.91731 on 1 and 26 DF, p-value: 0.17792 Vi ser at den estimerte \\(\\beta_1\\) effekten av √• jobbe mer estimeres til \\(0.36\\). Vi kan ogs√• f√• ut estimatene for de faste effektene \\(\\alpha_1\\), \\(\\alpha_2\\) og \\(\\alpha_3\\): fixef(reg.fe) ## 1 2 3 ## 0.408228 -0.062905 -0.279994 Det kan v√¶re nyttig √• ta en visuell innspeksjon p√• hvordan de individuelle regresjonskurvene passer til dataene: plot(reg.fe) Denne figuren viser ogs√• hvordan regresjonskurven ville sett ut dersom vi hadde sett bort fra paneldatastrukturen og brukt en helt vanlig (pooled) regresjonsmodell. Sammenlignet med modellen med faste faste effekter (within) s√• ville vi da estimert effekten av jobbe mer til √• v√¶re st√∏rre. Selv om produktet her er \\(3\\) individuelle regresjonsmodeller, presiserer vi at dette ikke er \\(3\\) uavhengige analyser; alle observasjonene er brukt til √• finne et estimat p√• \\(\\beta_1\\). Vi husker at det ogs√• kunne v√¶re en felles tidskomponent \\(v_t\\) i en slik modell og at denne kunne betraktes som en kategorisk variabel siden det typisk ikke er s√• mange (\\(T\\)) av disse. Vi kan derfor bare legge til year som en ekstra (kategorisk) forklaringsvariabel forutsatt at den er koded som en factor: is.factor(p.df$year) ## [1] TRUE reg.fe &lt;- plm(lnwg ~ lnhr + year, data = p.df, model = &quot;within&quot;) summary(reg.fe) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = lnwg ~ lnhr + year, data = p.df, model = &quot;within&quot;) ## ## Balanced Panel: n = 3, T = 10, N = 30 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.1740253 -0.0689048 0.0054976 0.0668643 0.2081334 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## lnhr 0.182181 0.317431 0.5739 0.5735 ## year1980 0.030310 0.095869 0.3162 0.7557 ## year1981 0.015762 0.095752 0.1646 0.8712 ## year1982 -0.050297 0.095805 -0.5250 0.6064 ## year1983 -0.063590 0.103765 -0.6128 0.5481 ## year1984 0.031862 0.102964 0.3094 0.7607 ## year1985 0.162429 0.095752 1.6964 0.1081 ## year1986 0.066977 0.095869 0.6986 0.4942 ## year1987 0.082429 0.095752 0.8609 0.4013 ## year1988 0.087881 0.095682 0.9185 0.3712 ## ## Total Sum of Squares: 0.37546 ## Residual Sum of Squares: 0.23334 ## R-Squared: 0.37853 ## Adj. R-Squared: -0.060163 ## F-statistic: 1.03543 on 10 and 17 DF, p-value: 0.45624 For dette lekedatasettet kunne vi strengt tatt ogs√• betraktet \\(\\alpha_i\\)-leddene som kategoriske variabler, men som sagt er som regel \\(N\\) for stor til at dette lar seg gj√∏re. 6.3.3.6 Tilfeldige effekter Hovedmotivasjonen for analysen av paneldataene er √• finne ut hva effekten av √• jobbe mer er (\\(\\beta_1\\)). Vi vet at det eksisterer individuelle effekter \\(\\alpha_i\\) som en konsekvens av datastrukturen, men vi er ikke n√∏dvendigvis interessert i disse verdiene i seg selv. I motsetning til en modell med faste effekter hvor vi betraktet \\(\\alpha_i\\) som faste st√∏rrelser, vil vi i en modell med tilfeldige effekter betrakte disse som tilfeldige variabler. I en slik modell estimerer vi derfor heller fordelingen til disse effektene. En vanlig antagelse er da at \\(\\alpha_i\\sim N(0, \\sigma_{\\alpha}^2)\\) dersom vi bruker parameteriseringen (6.1) med \\(\\beta_0\\) inkludert. \\(\\alpha_i\\sim N(\\beta_0, \\sigma_{\\alpha}^2)\\) dersom vi bruker parameteriseringen (6.2) uten \\(\\beta_0\\). Variansen \\(\\sigma_{\\alpha}^2\\) er da et m√•l p√• uobservert heterogenitet; i dette tilfellet hvor stor variasjon det i l√∏nnsniv√•et mellom individene. Det ogs√• vanlig √• anta at \\(\\epsilon_{it}\\sim N(0, \\sigma_{\\epsilon}^2)\\), s√• i en slik modell skal vi alts√• estimere \\(\\beta_1\\) (og \\(\\beta_0\\)), \\(\\sigma_{\\alpha}^2\\) og \\(\\sigma_{\\epsilon}^2\\). Vi bruker alts√• bare √®n ekstra parameter (\\(\\sigma_{\\alpha}^2\\)) for √• justere for forskjellen i l√∏nnsniv√•ene. Sammenligner vi dette med modellen med faste effekter der vi trengte \\(N\\) (\\(\\alpha_1, \\alpha_2,\\dots,\\alpha_N\\)) ekstra parametre er dette en mye enklere modell. En modell med tilfeldige effekter brukes dersom det er rimelig √• anta at de individuelle effektene \\(\\alpha_i\\) er sm√• og uavhengig av forklaringsvariabelen(e). Dersom dette er oppfylt viser det seg at en kan f√• mer presise estimat av effekten vi egentlig er interessert i , \\(\\beta_1\\). Det finnes en rekke estimeringsmetoder og vi skal ikke g√• detaljer p√• noen her, men nevner: Varianter av minstekvadraters metode som kan minne om det vi gjorde for faste effekter. Sannsynlighetsmaksimeringsestimering. Bayesiansk estimering. De to siste metodene er mye brukt for √• estimere tilfeldige effekter. I R kan vi fortsatt bruke plm, men m√• endre model argumentet til \"random\": # tilfeldig effekt modell reg.re &lt;- plm(lnwg ~ lnhr, data = p.df, model = &quot;random&quot;) summary(reg.re) ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = lnwg ~ lnhr, data = p.df, model = &quot;random&quot;) ## ## Balanced Panel: n = 3, T = 10, N = 30 ## ## Effects: ## var std.dev share ## idiosyncratic 0.01345 0.11597 0.356 ## individual 0.02429 0.15586 0.644 ## theta: 0.771 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.182643 -0.082132 -0.017109 0.046306 0.421926 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) -1.35059 2.17414 -0.6212 0.53446 ## lnhr 0.54307 0.28506 1.9051 0.05677 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 0.53409 ## Residual Sum of Squares: 0.47281 ## R-Squared: 0.11475 ## Adj. R-Squared: 0.083133 ## Chisq: 3.62944 on 1 DF, p-value: 0.056766 I motsetningen til modellen vi estimerte med faste effekter er n√• parameteriseringen gjort med \\(\\beta_0\\) leddet inkludert (modell (6.1)) og vi ser at dette blir estimert til √• v√¶re \\(-1.35\\). Videre estimeres effekten av √• jobbe mer til \\(\\hat{\\beta}_1 = 0.54\\). Litt lenger oppe i utskriften ser vi at \\(\\hat{\\sigma}^2_{\\alpha}= 0.0242\\) (‚Äúindividual‚Äù), mens \\(\\hat{\\sigma}^2_{\\epsilon}= 0.0134\\) (‚Äúidiosyncratic‚Äù). 6.3.3.7 Hausman test En modell med faste effekter vil v√¶re mulig √• bruke i alle tilfeller, mens en modell med tilfeldige effekter har strengere krav til hvordan disse individuelle effektene oppf√∏rer seg. Dersom disse er oppfylt er det en fordel √• bruke en modell med tilfeldige effekter. En strategi for √• finne riktig modell er √• estimere begge modellene fors√• √• utf√∏re en s√•kalt Hausman test. Nullhypotesen er da at den riktige modellen er den med tilfeldige effekter. Forkaster vi bruker vi modellen med faste effekter, forkaster vi ikke bruker vi modellen med tilfeldige effekter. I R utf√∏rer vi testen slik: # Hausman test phtest(reg.fe, reg.re) ## ## Hausman Test ## ## data: lnwg ~ lnhr + year ## chisq = 6.6775, df = 1, p-value = 0.009764 ## alternative hypothesis: one model is inconsistent Siden vi f√•r forkastning vil den beste modellen for dette (leke-) datasettet v√¶re modellen med faste effekter. "],["oppgaver-3.html", "6.4 Oppgaver", " 6.4 Oppgaver 6.4.1 Oppgaver om logistisk regresjon Kommentar: Oppgave 1 a) og oppgave 2) er sv√¶rt like i hva du skal gj√∏re, bare at den siste er mer realistisk. Oppgave 1 Du har estimert en logistisk regresjonsmodell med to forklaringsvariabler \\(x_1\\) og \\(x_2\\). Koeffisientene i modellen er estimert til \\(\\hat{\\beta}_0 = 0.4\\), \\(\\hat{\\beta}_1 = -0.1\\) og \\(\\hat{\\beta}_2 = 0.3\\). Du observerer s√• et nytt individ med forklaringsvariablene \\(x_1 = 1\\) og \\(x_2 = 2\\). Prediker sannsynlighet for at \\(Y=1\\) for dette individet. L√∏sning \\[z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 = 0.4 -0.1\\times1 + 0.3\\times2 = 0.9\\] Den predikerte sannsynligheten er gitt ved f√∏lgende sammenheng: \\[P(Y=1|Z=z) = \\frac{e^z}{1+e^z} = \\frac{e^{0.9}}{1 + e^{0.9}} \\approx 0.71.\\] Klassifiser det nye individet. L√∏sning Siden vi estimerer \\(P(Y=1)\\) til √• v√¶re \\(0.71\\) som er st√∏rre enn \\(0.5\\) klassifiserer vi dette individet til \\(\\hat{y}=1\\). Avhengig av kontekst, kan det v√¶re relevant √• bruke enn h√∏yere eller lavere terskel enn \\(0.5\\), men dette er alts√• standardverdien. Oppgave 2 (Individuell Eksamen V2020 1 i)) Denne eksamensoppgaven handlet om luftforurensning der myndighetene bruker en m√•lestasjon for √• advare innbyggerne dersom konsentrasjonen av nitrogendioksid (NO\\(_2\\)) overstiger 100 \\(\\mu\\textrm{g}/\\textrm{m}^3\\). I en av deloppgavene tilpasses det en logistisk regresjonsmodell der responsvariabelen er en dummyvariabelen danger_warning, som indikerer om gjenomsnittskonsentrasjonen av NO\\(_2\\) den aktuelle dagen oversteg 100 \\(\\mu\\textrm{g}/\\textrm{m}^3\\). Dersom det skjer m√• myndighetene utstede et s√•kalt gult farevarsel. Den estimerte modellen er gitt i kolonne (2) i tabellen under. ‚Ä¶.. I morgen er det l√∏rdag 16. mai, og i den aktuelle byen er det meldt en gjennomsnittlig temperatur p√• 19 \\(^\\circ\\)C og en gjennomsnittlig relativ luftfuktighet p√• 47%. Bruk den logistiske regresjonsmodellen til √• predikere sannsynligheten for at gjennomsnittlig NO\\(\\mathbf{_2}\\)-konsentrasjon overstiger 100 \\(\\mu\\textrm{g}/\\textrm{m}^3\\). Gi en kort vurdering om myndighetene b√∏r utstede gult farevarsel. (Husk at luftfuktigheten er gitt p√• skala 0‚Äì100, og ikke 0‚Äì1). L√∏sning Den predikerte log-oddsen f√•r vi ved √• sette inn for variablene (l√∏rdag, temperatur, fuktighet, vinterdummyen er null): \\[z = 5.052 + -2.292 - 0.086*19 - 0.044*47 = -0.942.\\] Den predikerte sannsynligheten er gitt ved f√∏lgende sammenheng: \\[P(Y=1|Z=z) = \\frac{e^z}{1+e^z} = \\frac{e^{-0.942}}{1 + e^{-0.942}} \\approx 0.28.\\] Den predikerte sannsynligheten er klart under 50%, som passer godt med den tidlighere analysen v√•r. Det er snakk om en forholdsvis varm l√∏rdag i sommerhalv√•ret, og vi vil nok ikke utstede farevarsel. Det kan ogs√• v√¶re gode argumenter for at vi ikke n√∏dvendigvis bruker 50% som terskel for farevarsel. Kanskje er det mer alvorlig √• ikke utstede et farevarsel som burde v√¶rt sendt ut fordi det kan v√¶re farlig for folk, enn √• utstede et un√∏dvendig farevarsel. F√∏re var osv., og det kan tilsi at vi f.eks. bruker 40% eller 30% sannsynlighet som grense. Det kommer litt an p√• situasjonen, som vi ikke har full oversikt over her. 6.4.2 Oppgaver om KNN Oppgave 1 (Individuell hjemmeeksamen H2020, oppgave 3) Vi har f√∏lgende datasett med seks observasjoner best√•ende av en bin√¶r responsvariabel \\(y\\) og to forklaringsvariabler \\(x_1\\) og \\(x_2\\): Tabell 6.1: Datasett y x1 x2 0 3 4 0 4 5 1 5 3 0 3 6 1 4 3 1 6 2 Du observerer s√• forklaringsvariablene \\((x_1, x_2) = (3, 3)\\) for et nytt individ. Regn ut hva klassifiseringen av \\(y\\) blir for det nye individet ved √• bruke k-nearest neighbor (KNN), med \\(k=3\\). L√∏sning Vi begynner med √• regne ut den euklidske avstanden mellom \\((3,3)\\) og alle punktene \\((x_1, x_2)\\) i datasettet v√•rt. F.eks er avstanden mellom \\((3,3)\\) og \\((3,4)\\) \\[\\begin{equation*} d((3,3), (3,4)) = \\sqrt{(3 - 3)^2 + (3 - 4)^2} = 1 \\end{equation*}\\] Vi kan s√• legge disse avstandene inn i en egen kolonne i tabellen: Tabell 6.2: Utregnede avstander y x1 x2 avstand 0 3 4 1.000 0 4 5 2.236 1 5 3 2.000 0 3 6 3.000 1 4 3 1.000 1 6 2 3.162 Vi ser da at observasjon \\(1\\),\\(3\\) og \\(5\\) med avstander p√• h.h.v. \\(1\\), \\(2\\) og \\(1\\) er de tre n√¶rmeste naboene, og blant dem er det 2 mot 1 i flertall for √• klassifisere \\(y\\) som en 1‚Äôer. Alts√• er \\(\\hat{y}=1\\). Det g√•r selvsagt an √• l√∏se oppgaven visuelt ogs√•. Hvordan fungerer KNN n√•r \\(k = n\\), hvor \\(n\\) er antall observajoner i datasettet? Hva vil skje dersom \\(k = 6\\) for dette datasettet? L√∏sning Siden vi bare har seks observasjoner vil alle verdier av \\(k\\geq 6\\) fullstendig ignorere informasjonen som ligger i forklaringsvariablene. Klassifiseringen vil da bare v√¶re basert p√• om det totalt sett er mest 1‚Äôere eller 0‚Äôere. I dette spesifikke datasettet har vi totalt tre 1‚Äôere og tre 0‚Äôere, s√• enhver majortetsavstemning med \\(k\\geq 6\\) blir uavgjort. Alts√• vil det her ikke v√¶re mulig √• oppn√• flertall for verken 0‚Äôer eller 1‚Äôer for store verdier av \\(k\\). 6.4.3 Oppgaver om paneldata Oppgave 1 For et paneldata best√•ende av en responsvariabel \\(Y\\) og en forklaringsvariabel \\(X\\) har du estimert modellen \\[y_{it} = \\beta_1 x_{it} + v_t + \\alpha_i + \\epsilon_{it} \\] der du har betraktet \\(\\alpha_i\\) som faste effekter og \\(v_t\\) som kategoriske variabler. Estimatet av \\(\\beta_1\\) er \\(\\hat{\\beta}_1 = 1.5\\). For individ \\(4\\) i datasettet har du estimert \\(\\alpha_4\\) til √• v√¶re \\(0.2\\). Videre er √•rseffekten for 2012, \\(v_{2012}\\), estimert til √• v√¶re \\(-0.5\\). Prediker responsvariabelen til dette individet for 2012 dersom \\(x_{4,2012} = 2\\). L√∏sning \\[\\hat{y}_{4,2012}=\\hat{\\beta}_1 x_{4,2012} + \\hat{v}_{2012} + \\hat{\\alpha}_4 = 1.5\\times2 -0.5 + 0.2 = 2.7\\] Du tilpasser ogs√• en tilsvarende modell med tilfeldige effekter. En Hausman test gir en p-verdi p√• \\(0.23\\). Hvilken modell skal du da bruke? L√∏sning Forenklet sett har denne testen som nullhypotese at modellen med tilfeldige effekter er gyldig. Her er p-verdien veldig stor og vi har lite bevis for at denne nullhypotesen er feil. Vi kan alts√• bruke modellen med tilfeldige effekter. Dersom vi hadde f√•tt forkastning ville det v√¶rt lurt √• bruke modellen med faste effekter. Oppgave 2 Pr√∏v deg p√• Oppgave 2 i den individuelle hjemmeeksamen H2020 som du finner i kapittel 9.1. Det er spesielt oppgave e) og f) som er relatert til paneldata, men vi bemerker at oppgave f) var ‚Äún√∏tten‚Äù i det oppgavesettet. "],["relevante-r-avansert-regresjon.html", "6.5 Relevante R-kommandoer", " 6.5 Relevante R-kommandoer Under f√∏lger en liste over hvilke oppgaver du skal klare i R fra denne modulen. V√•r policy fra og med v√•rsemesteret 2022 er at R-kommandoene under er tilstrekkelige for √• l√∏se oppgavene i datalabber og hjemmeeksamen i MET4. Det er med andre ord ikke n√∏dvendig √• l√¶re seg teknikker utover det som er listet opp eksplisitt i listen under. Eventuelle nye teknikker som trengs for √• l√∏se en bestemt oppgave vil bli oppgitt og forklart dersom det er n√∏dvendig. Det antas i tillegg at du kan den grunnleggende R-syntaksen som er dekket under Introduksjon til R. Antakelser om datasett Du kan gj√∏re de samme antakelsene om datasettet som i den tilsvarende oversikten i modulen om hypotesetesting: Datasettene er inneholdt i Excel-filer (.xls eller xslx) eller .csv-filer, som kolonner av variabler, med variabelnavn i f√∏rste rad. Tilpasse en logistisk regresjonsmodell Dersom vi √∏nsker √• foklare variasjon i en bin√¶r variabel ved hjelp av en eller flere forklaringsvariabler. Vi kan bruke det samme datasettet som tilvarende seksjon i forrige modul: data-reg.xsls. I dette datasettet har vi en bin√¶r variabel i x3, samt to kontinuerlige variabler x1 og x2. Du m√• kunne lese inn datasettet, estimere en logistisk regresjonsmodell, og skrive ut resultatet p√• f√∏lgende m√•te: df &lt;- readxl::read_excel(&quot;datasett/data-reg.xlsx&quot;) model1 &lt;- glm(x3 ~ x1 + x2, data = df, family = &quot;binomial&quot;) summary(model1) Dersom du skal bruke logistisk regresjon til √• predikere verdien av den bin√¶re responsvariabelen for nye ‚Äúindivider‚Äù m√• du f√∏rst v√¶re i stand til √• dele opp datasettet i et testsett og et treningssett. Det holder √• kunne gj√∏re en enkel splitt basert p√• rekkenummer. Her utgj√∏r treningsdatasettet de f√∏rste 70 observasjonene og testdatasettet resten: treningssett &lt;- df[1:70, ] testsett &lt;- df[71:nrow(df), ] Du vil da estimere modellen ved √• bruke treningsdatasettet, og du kan teste prediksjonsevnen ved √• predikere utfallet i observasjonene i testdatasettet ved p bruke predict(): predikert &lt;- predict(model1, newdata = testsett, type = &quot;response&quot;) Resultatet blir en data frame med predikerte sannsynligheter for at verdien av x3 for den aktuelle observasjonen er lik 1. Du kan oversette sannsynlighetene til 0 eller 1 ved √• velge en terskelverdi. Vi kan for eksempel velge at vi predikerer at x3 tar verdien 1 dersom den predikerte sannsynligheten for 1 er st√∏rre enn 0.5 p√• f√∏lgende m√•te: sann &lt;- df$x3 # Den sanne verdien i testdataene pred_test &lt;- predict(model1, newdata = testsett, type = &quot;response&quot;) # Predikert sannsynlighet klassifisering &lt;- ifelse(pred_test &gt; 0.5, 1, 0) # Klassifisering av kundene table(sann, klassifisering) # Kontigenstabell Et par ekstra bemerkninger: - Du kan predikere responsvariabel for nye kombinasjoner av forklaringsvariablene ved √• lage en data frame som du sender inn i newdata-argumentet til predict()-funksjonen p√• akkurat samme m√•te som for vanlig regresjon. Trene en kNN-modell Logistisk regresjon kan brukes b√•de til statistisk inferens (vi bruker modellen til √• forst√• sammenhenger mellom respons- og forklaringsvariablene) og til prediksjon. Dersom vi f√∏rst og fremst er interessert i prediksjon kan vi ogs√• bruke kNN, som kan gi bedre resultater. Vi antar at vi har med oss datasettet og oppsplittingen i treningssett og testsett fra seksjonen over. Du m√• kunne trene en kNN-modell, evaluere den p√• testsettet, og predikere status p√• nye individer. # Pass p√• at caret-pakken er installert library(caret) # Hvis vi vil sette k selv model2 &lt;- train(x3 ~ x1 + x2, data = treningssett, method = &quot;knn&quot;, tuneGrid = data.frame(k = 50)) # R-kode dersom vi vil velge k automatisk med kryssvalidering trControl &lt;- trainControl(method = &quot;cv&quot;, # 5-fold kryssvalidering number = 5) # Tilpasser modellen model3 &lt;- train(x3 ~ x1 + x2, data = treningssett, method = &quot;knn&quot;, trControl = trControl, metric = &quot;Accuracy&quot;) # Hvilken k valgte kryssvalideringen? k &lt;- model3$finalModel$k k predict()-funksjonen fungerer p√• samme m√•te som for line√¶r og logistisk regresjon. Paneldata Skriptfilen som f√∏lger denne modulen gir et greit sammendrag for hvilke R-kommandoer som er relevanter for √• estimere paneldatamodeller. Datasettet som brukes her er panel_liten.csv. library(readr) # Lese inn csv-filer library(plm) # Paneldata # Innlesning av data: OBS! Linken i videoen fungerer ikke s√• du m√• laste ned # panel_liten.csv fra modulen selv og s√• lese inn p√• vanlig m√•te: df &lt;- read_csv(&quot;panel_liten.csv&quot;) # Oversetter til panel data frame med metadata for kolonner som skal brukes som # faste effekter. p.df &lt;- pdata.frame(df, index = c(&quot;id&quot; ,&quot;year&quot;)) # Faste effekter med utskrift av sammendrag reg.fe &lt;- plm(lnwg ~ lnhr, data = p.df, model = &quot;within&quot;) summary(reg.fe) fixef(reg.fe) # Tilfeldige effekter med utskrift av sammendrag reg.re &lt;- plm(lnwg ~ lnhr, data = p.df, model = &quot;random&quot;) summary(reg.re) # Hausmann-test phtest(reg.fe, reg.re) "],["data√∏vinger.html", " 7 Data√∏vinger", " 7 Data√∏vinger Her finner du data√∏vingene som skal gjennomf√∏res i MET4. Se tidsplanen til kurset for en oversikt over n√•r de ulike √∏vingene skal gj√∏res og hvilke uker studentassistentene gjennomf√∏rer √∏vingene p√• datasal. "],["data√∏ving-1.html", "7.1 Data√∏ving 1", " 7.1 Data√∏ving 1 7.1.1 Innledning Velkommen til den f√∏rste data√∏velsen i MET4. I denne √∏velsen skal vi bli litt kjent med verkt√∏yene R og Rstudio som brukes i datalabbene. Disse verkt√∏yene er ogs√• essensielle for gjennomf√∏ringen av den obligatoriske innleveringen og p√• hjemmeksamen. Den f√∏rste delen av √∏vingen inneholder praktisk informasjon om bruk av R og Rstudio etterfulgt av oppgaver. 7.1.2 Om R og Rstudio R er et program/programmeringsspr√•k som er spesialdesignet til √• utf√∏re statistiske analyser. R er basert p√• at du m√• skrive forskjellige kommandoer for √• utf√∏re utregninger og analyser. Gjennomsnittet av 3, 2 og 5 finner man for eksempel ved √• skrive: mean(c(3,2,5)) Dette kan for mange v√¶re litt uvant i starten, men datalabbene vil gi deg god trening p√• denne type tankegang. Rstudio er et program som gj√∏r det enklere √• bruke R. P√• samme m√•te som Word kan hjelpe deg til √• lage fine og oversiktlige tekster, kan Rstudio hjelpe deg til √• utf√∏re fine og oversiktlige statistiske analyser. Rstudio er et redigeringsprogram som vi i dette kurset skal bruke til √• redigere og utf√∏re R-kommandoer. 7.1.2.1 Installere R og Rstudio Bruker du din egen datamaskin kan du enkelt laste ned og installere R og Rstudio. Begge programvarene er gratis og kan installeres med √• f√∏lge instruksene under. F√•r du problemer kan du f√• en av studentassistentene til √• hjelpe deg. Start med √• installere R: G√• til r-project.org Last ned versjonen som passer ditt operativsystem (Windows/Mac/Linux) Kj√∏r installasjonsfilen og f√∏lg instruksene. Standard innstillingene skal v√¶re greie √• bruke, s√• du kan trykke neste/ok til installasjonen er ferdig. Installer s√• RStudio: rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (‚ÄúOpen source edition‚Äù) for ditt operativsystem og installere p√• vanlig m√•te. Kj√∏r installasjonsfilen som lastes ned og f√∏lg instruksene 7.1.2.2 Vinduene i Rstudio og det √• jobbe med R F√∏rste gang du √•pner Rstudio vil du se tre vinduer. Et fjerde vindu √•pner du med √• klikke p√• File i menyen, s√• New File, og s√• R Script. Figur 7.1 viser en oversikt over de fire vinduene. Det er viktig at du forst√•r forskjellen p√• de to vinduene til venstre. Figur 7.1: Oversikt over vinduene i RStudio. Nederste vindu til venstre (b) viser R-konsollen og det er her alle utregninger blir gjennomf√∏rt. I dette vinduet kan du for eksempel skrive (3*5 - 3/4)*(2 + 2) ## [1] 57 Her er (3*5 - 3/4)*(2 + 2) en s√•kalt kommando og det er programmet R som finner ut hva du mener med kommandoen og gir deg svaret 57 i retur. Du kan se at R tillater standard matteoperasjoner som gange, deling, pluss og minus (*, /, +, -). R er det vi kaller ‚Äòobjektbasert‚Äô, som betyr at du kan definere ‚Äòobjekter‚Äô (ofte kalt variabler). Utregningen over kan for eksempel ogs√• regnes ut ved √• skrive: a &lt;- 3*5 - 3/4 b &lt;- 2 + 2 a*b ## [1] 57 Her er a og b objekter/variabler som vi definerer ved bruk av ‚Äòtildelingspilen‚Äô &lt;- (du kan ogs√• bruke =). Det g√•r an √• lagre objekter i egne filer, men vi skal se at det stort sett er smartere √• lagre ‚Äòoppskriften‚Äô (selve koden) p√• hvordan de lages i en egen .R-fil. Det √∏verste vinduet til venstre (a) viser en .R-fil (et skript). En .R-fil fungerer som et manuskript med R-kommandoer (kode) og kan lagres slik at du kan senere kan se hvilke kommandoer du har brukt i analysen og eventuelt fortsette der du slapp. I Del 2 av denne data√∏vingen skal du selv lage en .R-fil som inneholder alle kommandoer som brukes i en enkel analyse. N√•r du vil at R skal utf√∏re noen av kommandoene du har skrevet i .R-filen markerer du bare disse (eller lar pekeren st√• i linjen du vil kj√∏re) og trykker Ctrl + Enter (Cmd + Enter p√• Mac): Figur 7.2: Utf√∏relse av kommandoer du har skrevet i R filen. Marker eller la pekeren st√• i linjen du vil kj√∏re og trykk ctrl + Enter (Cmd + Enter p√• Mac) Vinduet nederst til h√∏yre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet √∏verst til h√∏yre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en n√¶rmere titt p√• et datasett du har lest inn. Det er viktig at du forst√•r forskjellen p√• de to vinduene til venstre, alts√• .R-filen og konsollen. R-kode du √∏nsker √• ta vare p√• og som er en essensiell del av analysen skriver og lagrer du i .R-filen, mens sm√• eksperimenter og unders√∏kelser som du ikke trenger senere kan du gjerne gj√∏re direkte i konsollen. For de av dere som er glad i hurtigtaster finnes det en oversikt i Rstudio som kommer opp dersom du trykker Alt + Shift + K (Option + Shift + K p√• Mac). Ofte vil man f.eks m√•tte skifte musepeker fra .R-filen til konsoll og motsatt, og hurtigtaster for √• veksle mellom disse er Ctrl + 1 (R-fil) og Ctrl + 2 (konsoll). Hurtigtasten du kommer til √• bruke desidert mest er Ctrl + Enter for √• kj√∏re kode fra R-skriptet ditt i konsollen (P√• Mac erstatter du Ctrl med Cmd over alt). 7.1.2.3 Funksjoner, dokumentasjon og R-pakker R kommer med en rekke ‚Äúinnebygde‚Äù funksjoner som kan utf√∏re ulike statistiske analyser. For eksempel kan en t-test utf√∏res med √• bruke en funksjon som heter nettopp t.test(). Alle slike funksjoner kommer med en dokumentasjon som viser hva funksjonen gj√∏r og hvordan den skal brukes. For √• tilgang til denne dokumentasjonen skriver man ? foran funksjonen i konsollen. Skriver du f.eks ?t.test ser du at det dukker opp en side i vinduet nede til h√∏yre: Figur 7.3: Dokumentasjon av funksjoner dukker opp i et vindu nede til h√∏yre. Dette vinduet kan √•pnes til et st√∏rre vindu som vist over Dokumentasjonen vil som hovedregel inneholder en kort beskrivelse av hva funksjonen gj√∏r, hvilke argumenter funksjonen tar og hva den gir ut. Helt i slutten av dokumentasjonen er det ofte et eksempel p√• hvordan funksjonen kan brukes og er ofte sv√¶rt nyttig √• se p√•. Selv om det finnes mange funksjoner som allerede er innebygget i R, m√• man noen ganger installere ekstra ‚Äòpakker‚Äô for √• f√• tilgang til spesielle funksjoner. I oppgave 2.2 i denne √∏velsen vil vi g√• gjennom hvordan dette gj√∏res for en bestemt pakke. 7.1.2.4 Skriv pen R-kode! Det er viktig at R-koden du skriver er veldokumentert og skrevet p√• en oversiktlig og pen m√•te. Hvis vi √∏nsker √• skrive kommentarer til koder som st√•r i .R-filen bruker vi tegnet # foran kommentaren. Dette gj√∏r at R ikke pr√∏ver √• evaluere kommentaren som en R-kode. Det finnes en rekke konvensjoner n√•r det kommer til mellomrom, linjeskift, navngivning av objekter og lignende. Vi anbefaler tipsene som er oppsummert p√• (http://adv-r.had.co.nz/Style.html)[http://adv-r.had.co.nz/Style.html], men det er selvsagt lov √• ha sine egne preferanser. Under ser du et eksempel p√• d√•rlig praksis ved R-koding. Her er det manglende dokumentasjon, d√•rlig navngivning og ingen ‚Äòluft‚Äô i form av mellomrom og linjeskift. Dette gj√∏r at du eller andre vil m√•tte bruke un√∏dvendig mye tid p√• √• finne ut hva koden faktisk gj√∏r p√• et senere tidspunkt. # D√•rlig praksis: library(readxl) d&lt;-readxl(file=&quot;financedata.xlsx&quot;,sheetIndex = 1) %&gt;% na.omit() √ò95&lt;-mean(d$value)-qt(0.975,df=length(d$value)-1)*sd(d$value) N95&lt;-mean(d$value)+qt(0.975,df=length(d$value)-1)*sd(d$value) F√∏lgende R kode gir det samme resultatet men er mye mer oversiktlig siden den er mer luftig, er brutt ned i biter, er godt dokumentert og har fornuftige objektnavn: # God praksis: # ---------- Analyse av data # N√∏dvendige pakker i analysen library(readxl) # Les data, fjern NA-verdier og hent ut gjeld my_data &lt;- readxl(file = &quot;financedata.xlsx&quot;, sheetIndex = 1) %&gt;% na.omit() debt &lt;- my_data$debt # Konfidensintervall n_obs &lt;- length(debt) # antall observasjoner alpha &lt;- 0.05 # signifikansniv√• average &lt;- mean(debt) # gjennomsnitt st_dev &lt;- sd(debt) # standardavvik lower &lt;- average - qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # nedre grense upper &lt;- average + qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # √∏vre grense Vi oppfordrer deg til √• pr√∏ve √• skrive R-kode som er pen og oversiktlig i datalabbene fremover. D√•rlige vaner kan v√¶re vonde √• vende! 7.1.3 Oppgave 1: Interaktiv √∏velse Her skal du bruke et l√¶ringsverkt√∏y kalt swirl som vil ta deg gjennom en interaktive √∏velse hvor du m√• utf√∏re forskjellige oppgaver i konsollen. I flere av data√∏vingene vil det v√¶re en slik interaktiv del. Her er tanken at du skal leke deg litt med R. F√∏r du kan begynne m√• du installere swirl. Kopier derfor f√∏lgende tre linjer og lim dem inn i R-konsollen: install.packages(&quot;swirl&quot;) library(swirl) install_course(&quot;R Programming&quot;) For √• starte swirl skriver du s√• f√∏lgende i konsollen: swirl() Du vil i starten bli bedt om √• skrive inn ditt navn og s√• f√∏lger litt info om hvordan swirl fungerer. Du blir s√• bedt om √• velge kurs. Her skal du velge alternativet ‚ÄòR Programming‚Äô (1 og s√• enter). Du f√•r s√• se alle modulene dette kurset inneholder: I denne √∏vingen skal du pr√∏ve deg p√• modul 1 ‚ÄòBasic Building Blocks‚Äô, modul 4 ‚ÄòVectors‚Äô (kun f√∏rste halvdel), og modul 12 ‚ÄòLooking at Data‚Äô. I modul 1 vil du l√¶re litt om de mest grunnleggende operasjonene som kan gj√∏res i R. Modul 4 ser n√¶rmere p√• vektorer og her er f√∏rste halvdel av modulen mest relevant. Modul 12 tar for seg det √• utforske strukturen p√• et datasett. Start med modul 1 (1 og s√• Enter). Du vil bli bedt om √• gj√∏re enkle operasjoner i R og av og til m√• du svare p√• multiple choice sp√∏rsm√•l: Merk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (Esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.1.4 Oppgave 2: Innlesning av data og deskriptiv statistikk i R I denne oppgaven skal vi lese inn noen data og produsere enkel deskriptiv statistikk av disse dataene. Dataene kommer fra et amerikansk fors√∏k hvor man ville unders√∏ke p√•standen om at voldelige dataspill f√∏rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det ‚Äúvoldelige‚Äù dataspillet var oppdraget √• skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille√∏kt ble deltakernes aggresjonsniv√• m√•lt p√• en skala fra 1 til 9 ved hjelp av en standard psykologisk test. Dette datasettet ble brukt i eksamensoppgaven v√•rsemesteret 2019. Oppgave 2.1. Last ned filen violence.xslx. Denne filen lagrer du fortrinnsvis i en egen mappe der du √∏nsker at filer fra denne √∏vingen skal ligge. √Öpne s√• RStudio, velg File -&gt; New File -&gt; R Script for √• √•pne et nytt Rscript. Lagre s√• scriptet ditt i samme mappen som du har lagt datasettet, slik at du n√• har en mappe som ser ut som figuren under: N√•r vi skal lese inn data, lagre figurer og andre ting har R en standard ‚Äòmappesti‚Äô (working directory) den leter/lagrer i. Du kan se hva denne stien peker p√• ved √• skrive getwd() i konsollen. Du skal n√• spesifisere denne mappestien til mappen du har opprettet. Dette gj√∏r du raskest ved √• velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du √•pne RStudio ved √• dobbeltklikke p√• data√∏ving1.R, og mappestien skal da settes automatisk til riktig mappe. Lag gjerne en liten overskrift ved hjelp av kommentartegnet # slik at .R filen din ser omtrent slik ut: Oppgave 2.2. Du skal n√• lese inn excel filen du lagret i over i R. Selv om det finnes mange funksjoner som allerede er innebygget i R, m√• man noen ganger installere ekstra ‚Äòpakker‚Äô for √• f√• tilgang til spesielle funksjoner. For √• lese inn en excel fil trenger du nettopp en slik ikke standard funksjon. Denne finnes i pakken readxl. Selve installeringen kan du gj√∏re direkte i konsollen med √• skrive (hvis du ikke har gjort det allerede, for eksempel da du gikk gjennom forelesningsvideoen om R-pakker): install.packages(&quot;readxl&quot;) Pakken legger seg da i en bibliotekmappe der R er installert. For √• gi R beskjed om √• laste inn funksjonene til pakken du nettopp installerte bruker du funksjonen library(). Du har n√• tilgang til en funksjon kalt read_excel() som du kan bruke til √• lese inn excel filen: # MET4 - Data√∏ving 1 # ------------------ # les inn data library(readxl) violence &lt;- read_excel(&quot;violence.xlsx&quot;) Marker linjene du nettopp skrev i R-skriptet ditt og trykk Ctrl + Enter (Cmd + Enter), for √• opprette objektet violence som inneholder datasettet. Funksjonen ls() lister opp alle objekter som har blitt definert. Du kan pr√∏ve selv √• skrive f√∏lgende i konsollen: ls() ## [1] &quot;violence&quot; Du ser at det har kommet et nytt objekt som heter violence. En tilsvarende oversikt finner du i vinduet √∏verst til h√∏yre i Rstudio (se Figur 7.1) hvor du ogs√• kan klikke p√• objektet for √• se n√¶rmere p√• det. Oppgave 2.3. Ta en titt p√• strukturen til datasettet du nettopp leste inn. Husker du kanskje noe fra den interaktive √∏velsen ‚ÄòLooking at Data‚Äô? N√•r du gj√∏r slike sm√• utforskninger kan du gjerne jobbe direkte i konsollen, og det du gj√∏r i dette punktet trenger n√∏dvendigvis ikke v√¶re med i .R-filen din. G√• til konsollen og bruk funksjoner som class, dim, names, head og str for √• utforske strukturen p√• dataene. Vi ser at det er 5 variabler: id er bare et tall som identifiserer fors√∏kspersonen. aggression_level er aggresjonsniv√•et som ble m√•lt rett etter at fors√∏kspersonen hadde spilt en viss tid. violent_treatment er varianten av dataspillet som fors√∏kspersonen ble utsatt for; enten Violent eller Less Violent. difficulty_treatment er vanskelighetsgraden av spillet, som enten var Easy eller Hard. En mulig forklaring p√• aggressiv adferd er at vanskelige spill f√∏rer til h√∏yere stressniv√•, som igjen kan f√∏re til aggressivitet. experienced_violence er svaret til fors√∏kspersonen p√• sp√∏rsm√•let om vedkommende oppfattet spillet som Violent eller Less Violent. Fors√∏kspersonene visste ikke selv hva forss√∏ket gikk ut p√•, eller at det var flere varianter av det samme spillet. Oppgave 2.4 Vi skal se n√¶rmere p√• om aggresjonsniv√•et er forskjellig i de to gruppene. Da m√• vi trekke ut de aktuelle tallene fra datasettet. Vi √∏nsker √• velge ut to vektorer for √• gj√∏re denne sammenligningen: en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene f√• navn voldelig og ikke_voldelig, og lag dem ved √• skrive f√∏lgende kodelinjer (se video om pipe-operatoren og enkel datavask for en forklaring av disse funksjonene. Den siste linjen, pull, gj√∏r en dataframe med √©n kolonne om til en vektor) : # Laster inn dplyr-pakken for library(dplyr) # Vektorer med aggresjonsniv√• til gruppen som har spilt voldelig/ikke-voldelig spill voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull ikke_voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Less Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull Sjekk n√• at dette har fungert ved √• skrive voldelig og ikke_voldelig inn i konsollen for √• se at det faktisk er vektorer som inneholder tallene 1 ‚Äì 9. Bruk ogs√• noen minutter til √• pr√∏ve √• forst√• hva kodelinjene over faktisk gj√∏r. (NB! Pass p√• at du skriver Violent og Less Violent helt riktig med store og sm√• bokstaver, ellers vil det ikke fungere!) Oppgave 2.5. I eksamensoppgaven fra 2019 f√•r vi oppgitt deskriptiv statistikk over aggresjonsniv√•et for de to gruppene i f√∏lgende tabell: Bruk funksjoner som min(), max(), median(), mean(), length() og summary() til √• finne ut om tallene stemmer (Du vil se at datasettet ditt inneholder noen f√¶rre observasjoner enn det som er oppgitt i tabellen, som gj√∏r at tallene er litt forskjellige). Oppgave 2.6. Vi skal n√• lage et histogram av hver av gruppene du lagret som vektorer i tidligere. Vi kan f√∏rst kikke p√• Figur 2.1 og koden som lagde disse figurene for √• f√• en id√© om hva vi m√• gj√∏re. Et sv√¶rt viktig punkt er f√∏gende: ggplot-funksjonen skal alltid ha hele datasettet (en data frame) som argument!! Det betyr at vi ikke skal bruke de to vektorene voldelig og ikke_voldelig, slik som i hist()-funksjonen, men bruke hele datasettet violence. Vi ser av oversikten over at variabelen som inneholder aggresjonsniv√•et er aggression_level, s√• det er den vi skal bruke som \\(x\\)-argument. Ved √• ta utgangspunkt i koden som lagde Figur 2.1, kan vi gj√∏re et f√∏rste fors√∏k (der vi husker √• laste inn ggplot2-pakken f√∏rst): library(ggplot2) ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) Nesten! Det eneste problemet er at vi har ett histogram for alle observasjonene, mens det vi egentlig √∏nsket var √• lage et histogram for hver av gruppene. Dette er s√•re enkelt i ggplot2. Det eneste vi trenger √• gj√∏re er √• identifisere den variabelen i datasettet som angir gruppetilh√∏righet (sjekk variabeloversikten over, svaret er violent_treatment), og s√• plusse p√• en funksjon som heter facet_wrap() som vist under. ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) + facet_wrap(~ violent_treatment) Dersom vi i stedet √∏nsker et skalert histogram kan vi spesifisere y-argumentet p√• f√∏lgende vis: ggplot(violence, aes(x = aggression_level, y = ..density.. )) + geom_histogram(bins = 9) + facet_wrap(~ violent_treatment) Oppgave 2.7. N√•r man skal sammenligne sentrum og spredning i to grupper er et boxplott et ypperlig alternativ og vi kan da bruke funksjonen boxplot() i ‚Äúbase R‚Äù, eller funksjonen geom_boxplot() hvis vi heller √∏nsker √• benytte ggplot2. Vi holder oss til det siste alternativet her, og ser at kodelinjene ligner p√• det vi laget over. Dersom vi √∏nsker √• lage et enkelt boxplot av en variabel for √• sammenligne spredingen i to eller flere grupper kan vi skrive ggplot(a, aes(x = b, y = c)) + geom_boxplot() Her m√• du selv erstatte bokstavene a, b og c i henhold til f√∏lgende regel: a er navnet p√• datasettet. b er variabelen som inneholder gruppeinndelingen. c er variabelen som inneholder m√•lingene. De ferdige kodelinjene skal v√¶re med i .R-skriptet ditt. For √• se boxplottet kan du som vanlig kj√∏re kommandoene med √• trykke Ctrl + Enter. Ser det ut til √• v√¶re noe forskjell p√• sentrum og spredning i de to gruppene? Bonusoppgave. Bytt ut geom_boxplot() over med geom_jitter() og geom_violin(). Hva viser disse plottene? "],["data√∏ving-2.html", "7.2 Data√∏ving 2", " 7.2 Data√∏ving 2 7.2.1 Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysen begynner vi med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(\"swirl\") i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) swirl() Du vil i starten bli bedt om √• skrive inn ditt navn. Hvis du bruker samme navn som tidligere f√•r du kanskje tilbud om √• starte opp igjen der du slapp, men da kan du bare velge det nederste valget ‚ÄòNo.¬†Let me start something new‚Äô. Du velger s√• alternativet ‚ÄòR Programming‚Äô hvor du f√•r se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul 6 ‚ÄòSubsetting Vectors‚Äô og modul 8 ‚ÄòLogic‚Äô. Husk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl () f√∏r du begynner p√• neste del av datalabben. Lykke til! 7.2.2 Data til data√∏velsen I denne data√∏velsen skal vi ved hjelp av R gjennomf√∏re en del av testene som vi har l√¶rt i praksis. Vi skal gj√∏re b√•de ett- og to-utvalgs tester, og vi skal bruke \\(\\chi^2\\)-testen Vi skal jobbe med tre ulike datasett i denne √∏vingen, og alle sammen kan lastes ned ved √• klikke p√• lenkene under: testdata.xls violence.xlsx roubik_2002_coffee_yield.xlsx Last ned disse filene og legg dem i en mappe p√• datamaskinen din. √Öpne s√• RStudio, velg File -&gt; New File -&gt; R Script for √• √•pne et nytt Rscript, og lag gjerne en liten overskrift ved hjelp av kommentartegnet #. Lagre s√• scriptet ditt i samme mappen som du har lagt datasettene, slik at du n√• har en mappe som ser ut som figuren under: Det neste du m√• gj√∏re er √• s√∏rge for at du har satt opp riktig mappesti (working directory) i RStudio, og det gj√∏r du raskest ved √• velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du √•pne RStudio ved √• dobbeltklikke p√• data√∏ving2.R, og mappestien skal da settes automatisk til riktig mappe. I alle tilfeller skal vinduet ditt se omtrent slik ut: 7.2.3 Oppgaver til √∏vingen: 7.2.3.1 Oppgave 1 Costa Rica er en stor kaffeprodusent med moderne produksjon. Kaffeprodusentene har over lengre tid benyttet en standardisert miks av spr√∏ytemidler som skal ta knekken p√• ugress og skadelige insekter, men uten √• skade avlingen eller milj√∏et ellers. En liten kaffeplantasje i Costa Rica har begynt √• eksperimentere med en ny kombinasjon av spr√∏ytemidler som skal v√¶re like effektiv mot ugress, men samtidig enda mer sk√•nsom mot kaffeplantene, slik at avlingen blir st√∏rre. Innehaveren av plantasjen √∏nsker √• sette opp et eksperiment for √• unders√∏ke denne p√•standen. Han velger ut 25 tilfeldige jordlapper fordelt p√• hele eiendommen der han bruker de nye spr√∏ytemidlene gjennom en hel sesong. Lang erfaring har vist at avlingen ved bruk av gammel metode er normalfordelt med forventning \\(\\mu = 100\\) og standardavvik \\(\\sigma = 10\\), der vi har brukt en standardisert enhet for mengde avling per arealenhet. Hjelp bonden, ved √• l√∏se f√∏lgende oppgaver: Oppgave 1.1: Les inn datasettet testdatasdata.xsl i RStudio og se p√• de f√∏rste par radene. Det kan du gj√∏re ved √• kj√∏re f√∏lgende kodelinjer: library(readxl) # Pakke for √• lese excel-filer data &lt;- read_excel(&quot;testdata.xls&quot;) # Leser inn datasettet data # Ser p√• datasettet ## # A tibble: 25 √ó 4 ## X1 X2 A1 A2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 122. 121. 1 1 ## 2 101. 105 1 1 ## 3 114. 108 1 1 ## 4 103 99.1 1 0 ## 5 97.6 96.2 0 0 ## 6 85.9 95.4 0 0 ## 7 93.5 101. 0 1 ## 8 92 97 0 0 ## 9 98.8 106. 0 1 ## 10 99.9 100. 0 1 ## # ‚Ä¶ with 15 more rows ## # ‚Ñπ Use `print(n = ...)` to see more rows Det er kolonnen X2 som inneholder de observerte avlingene p√• de 25 fors√∏ksseksjonene. Oppgave 1.2: Er forventet avling ved bruk av den nye metoden st√∏rre enn forventet avling ved bruk av den gamle metoden? Hint: Forelesningsnotatene/scriptet inneholder koden du trenger for √• l√∏se denne og neste oppgave. Du kan ogs√• se p√• oversikten over relevante R-kommandoer for det du trenger. Oppgave 1.3: Det er viktig for kaffebonden at avlingen ikke varierer for mye mellom de ulike delene av farmen. En viktig m√•leparameter for denne type produksjon er derfor variansen. Kan vi sl√• fast at variansen til avlingen har forandret seg etter omlegging til ny metode? Oppgave 1.4: Kaffebonden er skeptisk til p√•standen om at forventet avling med den gamle metoden er \\(\\mu = 100\\), og mener at det vil variere med for eksempel jordsmonn. For √• ta h√∏yde for dette gjennomf√∏rte han √•ret i forveien tilsvarende m√•linger p√• de samme jordlappene, med med gammel spr√∏ytemetode. Disse m√•lingene finner du i kolonne X1 i datasettet. Test om avlingene er forskjellige, b√•de med og uten paring av observasjonene. Kommenter resultatet. 7.2.3.2 Oppgave 2 Vi skal i denne oppgaven se p√• oppgave 1a og 1b som ble gitt p√• skoleeksamen i MET4 v√•rsemesteret 2019. Dette er det samme datasettet som vi s√• p√• i forrige data√∏ving. I et amerikansk fors√∏k ville man unders√∏ke p√•standen om at voldelige dataspill f√∏rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det ‚Äúvoldelige‚Äù dataspillet var oppdraget √• skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille√∏kt ble deltakernes aggresjonsniv√• m√•lt p√• en skala fra 1 til 9 ved hjelp av en standard psykologisk test. I denne oppgaven skal vi i hovedsak finne ut om gruppen som spilte de voldelige dataspillet hadde signifikant h√∏yere aggresjonsniv√• enn kontrollgruppen. Oppgave 2.1: Les inn datasettet violence.xslx p√• samme m√•te som i forrige data√∏ving. Hvis du allerede har kj√∏rt library(readxl) trenger du ikke gj√∏re det igjen med mindre du har startet RStudio p√• nytt. Gi datasettet et passende navn, f.eks violence &lt;- read_excel(&quot;violence.xlsx&quot;) Vi skal alts√• teste om aggresjonsniv√•et er forskjellig i de to gruppene. Da m√• vi trekke ut de aktuelle tallene fra datasettet. Som vi husker fra forelesningsnotatene trenger vi to vektorer for √• gj√∏re en to-utvags \\(t\\)-test: en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene f√• navn voldelig og ikke_voldelig, og lag dem ved √• skrive f√∏lgende kodelinjer (samme som forrige data√∏ving): voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull ikke_voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Less Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull Oppgave 2.2: Vi er n√• klare til √• gj√∏re en to-utvalgs \\(t\\)-test for om aggresjonsniv√•et er det samme i de to gruppene. Pr√∏v √• gj√∏re det n√•, men v√¶r bevisst p√• hvilke valg du gj√∏r underveis, og som du mater inn i t.test()-funksjonen, f.eks: Antar du lik varians i de to gruppene? Hvorfor/Hvorfor ikke? Bruker du ensidig eller tosidig test? Hvorfor? Oppgave 2.3: En avgj√∏rende detalj i studien som vi ser p√• i denne oppgaven er at forskerne ogs√• spurte fors√∏kspersonene hvorvidt de selv syntes spillet de spilte var voldelig. For √• kunne trekke noen som helst l√¶rdom fra et slikt fors√∏k er det viktig at den voldelige spillvarianten faktisk blir oppfattet som voldelig og vice versa. Vi √∏nsker dermed √• unders√∏ke nullhypotesen om at variablene violence_tratment og experienced_violence er uavhengige av hverandre. Den hypotesen er vi n√∏dt til √• forkaste for at fors√∏ket skal v√¶re gyldig: hvis det ikke er noen sammenheng mellom opplevd og faktisk voldelighet er fors√∏ket helt klart ugyldig. F√∏rste steg er √• lage et nytt datasett der vi bare ta med oss de to kolonnene vi er interessert i. Kall det hva du vil, f.eks. violence_redusert. Vi bruker select()-funksjonen til √• velge ut variablene vi trenger, se video om datavask dersom du trenger √• repetere denne funksjonen. violence_redusert &lt;- violence %&gt;% select(violent_treatment, experienced_violence) Skriv violence_redusert i konsollen for √• bekrefte at du har valgt ut de korrekte kolonnene. Vi fortsetter som i videoforelesningen og lager en krysstabell for disse variablene krysstabell &lt;- table(violence_redusert) krysstabell ## experienced_violence ## violent_treatment Less Violent Violent ## Less Violent 114 9 ## Violent 33 93 Oppgave 2.4: Heldigvis ser det ut til at det er en klar sammenheng mellom faktisk og opplevd voldelighet ved at de fleste fors√∏kspersonene havner p√• diagonalen i krysstabellen. Bruk funksjonen chisq.test() p√• samme m√•te som i forelesningen til √• formelt teste nullhypotesen om uavhengighet. 7.2.3.3 Oppgave 3 Vi skal i denne oppgaven returnere til kaffeproduksjon. Vi skal gj√∏re statistiske tester i R som i de tidligere oppgavene i denne √∏vingen, men vanskelighetsgraden g√•r opp fordi vi ogs√• m√• tenke n√∏ye over hvordan vi anvender metodene korrekt i en gitt kontekst. I 2002 publiserte det prestisjetunge tidsskriftet Nature en kort artikkel skrevet av David W. Roubik1, som handler om den kjente kaffeb√∏nnen Arabica. Arabicab√∏nnen kommer opprinnelig fra Afrika, og er en selvpollinerende plante. Det vil si at den ikke er avhengig av insekter for √• formere seg, og man trodde lenge at den heller ikke hadde noen fordeler av insektspollinering. For √• unders√∏ke denne p√•standen samlet Roubik inn historiske data over arabicaavlinger fra hele verden. Han delte verdens kaffeproduserende land inn i to kategorier: Old world som omfatter afrikanske og asiatiske land, og New world som omfatter land i Latin-Amerika. Han registrerte videre gjennomsnittlig √•rlig avling (m√•lt i kg/hektar) i to perioder: 1961‚Äì80 og 1981‚Äì2001. N√∏kkelen til analysen er at den afrikanske honningbien var en viktig pollinator i Afrika og Asia b√•de i den f√∏rste og andre perioden, men knapt eksisterte i Amerika f√∏r 1980. Etter 1980, derimot, √∏kte utbredelsen av denne bien i Amerika, og ble fort naturalisert. Kan vi sette denne utviklingen i sammenheng med √∏kt kaffeavling i Latin-Amerika etter 1980, og dermed skrote teorien om at kaffeplanter ikke drar nytte av insektspollinering? Oppgave 3.1: For √• unders√∏ke dette kan vi bruke datasettet som Roubik brukte, som finnes i filen roubik_2002_coffe_yield.xlsx. Last datasettet inn i R p√• vanlig m√•te, og se p√• det: yield &lt;- read_excel(&quot;roubik_2002_coffe_yield.xlsx&quot;) yield ## # A tibble: 28 √ó 4 ## world country yield_61_to_80 yield_81_to_01 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 new Costa_Rica 9139 14620 ## 2 new Bolivia 7686 8767 ## 3 new El_Salvador 9996 8729 ## 4 new Guatemala 5488 8231 ## 5 new Colombia 5920 7740 ## 6 new Honduras 4096 7264 ## 7 new Nicaragua 4566 6408 ## 8 new Brazil 4965 6283 ## 9 new Peru 5487 5740 ## 10 new Mexico 5227 5116 ## # ‚Ä¶ with 18 more rows ## # ‚Ñπ Use `print(n = ...)` to see more rows Vi ser at det er fire kolonner i datasettet: world angir om det er snakk om New world (new) eller Old world (old). country angir navnet p√• landet. yield_61_to_80 angir avlingen i perioden 1961‚Äì80. yield_81_to_01 angir avlingen i perioden 1981‚Äì2001. Oppgave 3.2: Kall den f√∏rste tidsperioden p1 og den andre tidsperioden p2. Lag s√• fire vektorer, en for hver kombinasjon av world og tidsperiode ved √• bruke samme teknikk som i oppgave 2.2 over. N√•r du er ferdig, skal du ha laget f√∏lgende vektorer: new_p1: inneholder avling for alle land med world == new i f√∏rste periode. new_p2: inneholder avling for alle land med world == new i andre periode. old_p1: inneholder avling for alle land med world == old i f√∏rste periode. old_p2: inneholder avling for alle land med world == old i andre periode. Her m√• du bruke b√•de filter() og select(), og du m√• avslutte med en pull for √• oversette en en-kolonnes dataframe til en vektor. Dersom du har gjort det riktig, ser vektorene slik ut n√•r du er ferdig: new_p1 ## [1] 9139 7686 9996 5488 5920 4096 4566 4965 5487 5227 2347 3089 1938 new_p2 ## [1] 14620 8767 8729 8231 7740 7264 6408 6283 5740 5116 4124 3240 ## [13] 2789 old_p1 ## [1] 4251 10522 3509 10028 5667 17064 5904 4001 6604 4738 5716 3824 ## [13] 3525 3393 3213 old_p2 ## [1] 13380 11561 9652 9593 8797 7869 7354 7288 6055 5432 5394 3576 ## [13] 3141 2391 2136 Oppgave 3.3: Bruk en paret \\(t\\)-test til √• finne ut om kaffeavlingen i den gamle verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.4: Bruk en paret \\(t\\)-test til √• finne ut om kaffeavlingen i den nye verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.5 (Diskusjonsopgave): Dersom du har gjort de to foreg√•ende oppgavene riktig vil du se at den gjennomsnittlige kaffeavlingen ikke har endret seg signifikant i den gamle verden, mens √∏kningen i den nye verden er klart statistisk signifikant. Vi har brukt parrede \\(t\\)-tester, slik at vi ‚Äúkontrollerer for‚Äù eventuelle landeffekter (denne terminologien blir skal vi bruke mer n√•r vi skal jobbe med regresjon). Roubik omtaler funnet som f√∏lger: A substantial increase in Latin American coffee yield partly coincided with the establishment of African honeybees in those countries, although there was no such change in the Old World, where honeybees originated [‚Ä¶]. This comparison underlines a possible cause-and-effect relationship between the presence of social bees and cofee yield. Dette er intet mindre enn en kortslutning, p√• minst to forskjellige m√•ter. Hvorfor? Diskuter med dine medstudenter. Kan det gjennomf√∏res en enkel test som gir et bedre bilde av situasjonen? David W. Roubik: The value of bees to the coffee harvest. Nature (2002)‚Ü©Ô∏é "],["data√∏ving-3.html", "7.3 Data√∏ving 3", " 7.3 Data√∏ving 3 7.3.1 Oppgave 1: Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysen begynner vi som vanlig med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(\"swirl\") i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) install_course(&quot;Regression_Models&quot;) # legger til nytt kursmateriale om regresjon swirl() Du vil i starten bli bedt om √• skrive inn ditt navn. Hvis du bruker samme navn som tidligere f√•r du kanskje tilbud om √• starte opp igjen der du slapp, men da kan du bare velge det nederste valget ‚ÄòNo.¬†Let me start something new‚Äô. Du velger s√• alternativet ‚ÄòRegression Models‚Äô hvor du f√•r se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul modul 1 ‚ÄòIntroduction‚Äô. Her vil du l√¶re litt om hvordan du kan bruke R til √• gj√∏re en regresjonsanalyse ved hjelp av et treningsdatasett. Noen av kommandoene som gjennomg√•s i denne modulen vil komme til nytte senere i datalabben. Husk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.3.2 Oppgave 2: Regresjonsanalyse Et rock-and-roll museum √•pnet i Atlanta i 1990. Museet l√• i en sentral del av byen i n√¶rheten av mange ulike butikker. Mot slutten av juli m√•ned i 1992 startet en stor brann i en av disse butikkene som √∏dela hele kvartalet, inkludert museet. Heldigvis var museet forsikret, b√•de mot selve brannskadene, og mot tapte billettinntekter i gjennoppbyggingsperioden. Vanligvis vil et forsikringsselskap beregne erstatningsbel√∏pet under antakelsen om at bes√∏kstallene i gjenoppbyggingsperioden ville v√¶rt p√• samme niv√• som bes√∏kstallene i tiden f√∏r brannen. I dette tilfellet mente derimot eierne av museet at bes√∏kstallene var √∏kende, slik at de reelt sett hadde krav p√• et st√∏rre erstatningsbel√∏p. Argumentet var basert p√• bes√∏kstallene til en forn√∏yelsespark like ved. Forn√∏yelsesparken √•pnet i desember 1991, slik at museet og parken opererte sammen i de siste fire ukene av 1991, og de f√∏rste 28 ukene i 1992 f√∏r brannen √∏dela museet. Museet √•pnet igjen i april 1995, men var da betydelig st√∏rre enn det var opprinnelig. Data for bes√∏kstall for museet og forn√∏yelsesparken finner vi i regnearket C16-01.xlsx. Som i de to foreg√•ende data√∏vingene legger du denne filen i en mappe p√• maskinen din, og oppretter et tomt R-script der du lagrer koden for denne oppgaven. Oppgave 2.1: Kikk raskt p√• datasettet i Excel eller tilsvarende. Du ser at det er tre kolonner, en som angir ukenummer (Week, teller fra 1 til 205), en som angir ukentlig bes√∏kstall p√• museet (Museum) og en som angir ukentlig bes√∏kstall i forn√∏yelsesparken (A-Park). Legg merke til at bes√∏kstallet i museet er null fra og med uke 33, til og med uke 179, som er perioden fra brannen til ny√•pning. Oppgave 2.2: Last s√• datasettet inn i R som f√∏r ved hjelp av read_excel()-funksjonen. Gi det et passelig navn (f.eks visits), og sjekk raskt at det har g√•tt bra ved √• taste inn datanavnet i konsollen. Da skal det se omtrent slik ut: visits ## # A tibble: 205 √ó 3 ## Week Museum `A-Park` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 787 1379 ## 2 2 1179 1396 ## 3 3 4225 5332 ## 4 4 1336 1477 ## 5 5 2122 3717 ## 6 6 1136 1663 ## 7 7 2413 3573 ## 8 8 1399 2086 ## 9 9 1528 2503 ## 10 10 1788 2553 ## # ‚Ä¶ with 195 more rows ## # ‚Ñπ Use `print(n = ...)` to see more rows Legg merke til f√∏lgende: Observasjonene ser ut til √• v√¶re de samme som vi s√• da vi kikket p√• selve regnearket. Det er alltid en god vane √• forsikre seg om at R har lest inn datasettet p√• riktig m√•te. Et av variabelnavnene har f√•tt noen rare t√∏dler rundt seg. Grunnen til det er at A-park inneholder en bindestrek, s√• for at R ikke skal tolke det tegnet som et minustegn (og dermed gi oss et mareritt med feilmeldinger), m√• vi alltid bruke disse t√∏dlene n√•r vi refererer til denne variabelen. (P√• tastaturet som forfatteren av disse ord skriver p√•, er det Shift + tasten til venstre for Backspace. Oppgave 2.3: F√∏r vi g√•r videre, m√• vi f√• et bedre begrep om problemet ved √• kikke grafisk p√• observasjonene. La oss plotte observasjonene i et linjeplott for √• se hvordan de utvikler seg over tid, ved √• ha ukenummer p√• \\(x\\)-aksen og bes√∏kstall p√• \\(y\\)-aksen. Vi kan lage et enkelt plott for bes√∏kstall for museet ved √• skrive # Laster f√∏rst ggplot-pakken (det trenger vi bare gj√∏re en gang i skriptet) library(ggplot2) # Lager et enkelt linjeplott: ggplot(visits, aes(x = Week, y = Museum)) + geom_line() Du kan legge til bes√∏kstall for forn√∏yelsesparken ved √• plusse p√• en ny linje med geom_line(), men da m√• du spesifisere y-variabelen p√• nytt. Hele plottekommandoen blir da: ggplot(visits, aes(x = Week, y = Museum)) + geom_line() + geom_line(aes(y = `A-Park`)) Vi ser at det er en sterk sammenheng mellom bes√∏kstallene til museet og parken, spesielt etter gjen√•pningen i 1995, og det skal vi utnytte n√•r vi senere skal beregne erstatningssummen. Oppgave 2.4: Juster p√• argumentene i geom_line()-funskjonene, og legg til flere ‚Äúlag‚Äù p√• samme m√•te som vi gjorde for √• pynte p√• figuren i oppgave 3 i kapittel 1.11 (det er 100% lov √• Google). Dette ser bedre ut: Oppgave 2.5: La oss n√• ta utgangspunkt i forsikringsselskapets p√•stand: bes√∏kstallet i perioden der museet er stengt skal beregnes ved hjelp av observasjonene f√∏r brannen. Vi estimerer parametrene i en enkel regresjonsmodell \\[y_i = \\beta_0 + \\beta_1x_i + \\epsilon,\\] der responsvariabelen \\(y_i\\) er bes√∏kstallet p√• museet p√• dag nr. i, og \\(x_i\\) er bes√∏kstallet i forn√∏yelsesparken samme dag. Datasettet vi skal bruke er alts√• de 32 f√∏rste radene i datasettet visits. Da kan vi enten lage en ny tabell som best√•r av de 32 f√∏rste radene (for eksempel ved hjelp av filter(Week &lt;= 32)), eller s√• kan vi bruket argumentet subset i lm()-funkesjonen til √• spesifisere hvilke observasjoner som skal brukes for √• estimere modellen: reg1 &lt;- lm(Museum ~ `A-Park`, data = visits, subset = 1:32) Oppgave 2.6: Pakken stargazer inneholder funksjoner for √• lage pene regesjonstabeller automatisk fra regresjonsobjekter i R. Pakken m√• installeres og lastes p√• vanlig m√•te: install.packages(&quot;stargazer&quot;) library(stargazer) Inne i stargazer-pakken er det en funksjon som ogs√• heter stargazer(). Hvis du ikke har sett den brukt f√∏r (f.eks i forelesning), kan du lese mer om den ved hjelp av hjelpefunksjonen: ?stargazer. Bruk s√• stargazer() til √• lage f√∏lgende regresjonsutskrift (hint: bruk argumentet type = \"text\"): =============================================== Dependent variable: --------------------------- Museum ----------------------------------------------- `A-Park` 0.693*** (0.018) Constant 16.229 (114.695) ----------------------------------------------- Observations 32 R2 0.979 Adjusted R2 0.979 Residual Std. Error 355.588 (df = 30) F Statistic 1,424.094*** (df = 1; 30) =============================================== Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Oppgave 2.7: Lag tre diagnoseplott etter mal som er gitt i forelesningsnotatene: Et som viser residualene i regresjonsmodellen i et spredningsdiagram, et QQ-plott, og et histogram. Kan du gj√∏re en grov vurdering om hvorvidt forutsetningene for line√¶r regresjon er oppfylt? Oppgave 2.8: Bruk denne regresjonsmodellen til √• beregne hva bes√∏kstallet hadde v√¶rt dersom museet hadde v√¶rt √•pent som vanlig. Dette kan vi gj√∏re ved √• bruke predict()-funksjonen. F√∏lg oppskriften under n√•, s√• skal du pr√∏ve √• gj√∏re det selv etterp√•. # Vi lager et nytt datasett best√•ende av de ukene der museet var stengt: visits_pred &lt;- visits %&gt;% filter(Museum == 0) %&gt;% select(&quot;Week&quot;, &quot;A-Park&quot;) # Bruker predict()-funksjonen til √• predikere tilh√∏rende y&#39;er: predicted_visits1 &lt;- predict(reg1, newdata = visits_pred) # Til slutt legger vi til de predikerte verdiene som en ny kolonne i visits_pred: visits_pred$predikert1 &lt;- predicted_visits1 De predikerte bes√∏kstallene er n√• lagret som kolonne predicted1 i datasettet visits_pred. Oppgave 2.9 For √• f√• bedre greie p√• hvordan prediksjonene egentlig ser ut kan vi legge dem til figuren v√•r fra over. La oss lage en bl√• stiplet linje, og det kan vi gj√∏re med √• legge til enda et kall til geom_lines(). Denne gangen m√• vi bruke flere argumenter: Vi m√• bruke argumentet data til √• si at tallene vi skal plotte for den nye linjen n√• ligger i datasettet visits_pred, og ikke visits. Vi m√• bruke argumentet colour til √• fortelle hvilken farge vi skal ha p√• linjen. Vi m√• bruke argumentet linetype til √• fortelle at vi vil ha en stiplet linje. Ta for deg figuren du lagde i oppgave 2.4, og legg til f√∏lgende linjer (husk √• f√• med en + mellom hvert lag): geom_line(aes(x = Week, y = predikert1), data = visits_pred, colour = &quot;blue&quot;, linetype = &quot;dashed&quot;) Da blir figuren min seende slik ut: Oppgave 2.10: Kommenter kort regresjonsutskriften fra oppgave 2.6 og figuren fra oppgave 2.9. Ser det fornuftig ut? Oppgave 2.11: Se p√• saken heller fra museets side. De mener at det er bes√∏kstallene fra etter √•pningen i 2005 som skal brukes til √• estimere regresjonsmodellen. Det er lett √• forst√• hvorfor de √∏nsker det, for da ser det ut som at det er omtrent like mange bes√∏kende p√• museet som i forn√∏yelsesparken. Repeter oppgave 2.5, men n√• bruker du alts√• bes√∏kstallene fra etter √•pningen til √• estimere regresjonskoeffisientene. Hint 1: Det eneste du m√• endre er hva som skal inn i subset-argumentet. Hint 2: Stigningstallet i den nye modellen skal v√¶re 0.97. Oppgave 2.12: Beregn hvilke bes√∏kstall museet hadde hatt i perioden det var stengt ved √• legge til grunn den nye regresjonsmodellen etter m√∏nster fra oppgave 2.8, og legg dem inn i figuren etter m√∏nster fra oppgave 2.9. Figuren blir skal da se omtrent slik ut hvis vi bruker en finn gr√∏nnfarge (forestgreen) til den siste linjen: Oppgave 2.13: N√•r vi ser hvor tett de to bes√∏kstallene beveger seg etter ny√•pningen er det ikke rart at de beregnede bes√∏kstallene basert p√• den nye modellen (markert i gr√∏nt over) f√∏lger observasjoenen fra forn√∏yelsesparken. Anta at hver billett til museet koster $6.99. Hvor stor er differansen mellom erstatningskravet til museet og tilbudet til forsikringsselskapet? Oppgave 2.14 (Diskusjon): Det er ganske stor forskjell mellom tilbud og krav, men hvis vi tenker oss om skj√∏nner vi fort at begger parter befinner seg i en klassisk catch-22. Hvis den ene partens argument f√∏rer til en utbetaling som er for stor eller for liten fordi de tar utgangspunkt i slutten eller starten p√• en stigende utvikling, m√• n√∏dvendigvis det motsatte standpunkt ogs√• v√¶re galt av n√∏yaktig samme grunn. Kan du foresl√• et kompromiss? "],["data√∏ving-4.html", "7.4 Data√∏ving 4", " 7.4 Data√∏ving 4 En produsent som vil selge kraft til Nord Pool leverer salgsbud til kraftb√∏rsen som spesifiserer, for hver time neste dag, hvor mange megawatt (MW) man er villig til √• produsere til ulike priser. Fristen for √• levere salgsbud er kl 12:00 dagen f√∏r produksjonen skal finne sted. For en vindkraftprodusent er det flere usikre faktorer man m√• ta stilling til n√•r man skal levere salgsbud for neste dag: Timeprisene i spotmarkedet (Euro/MW) er ukjente (blir ikke offentliggjort f√∏r kl 12:45). For √• vite hvor mange megawatt (MW) man kan produsere i en gitt time trenger man √• vite vindstyrken. Selv med gode v√¶rprognoser vil det fremdeles v√¶re betydelig usikkerhet knyttet til vindstyrken i de ulike timene neste dag. Dersom den faktiske produksjonen avviker fra det man har meldt inn vil det p√•l√∏pe en straffekostnad. I timer med mye vind vil man m√•tte selge den overskytende produksjonen til en lavere pris enn spotprisen, og i timer med lite vind vil man m√•tte kompensere fleksible produsenter for √• dekke opp for den manglende produksjonen. Straffekostnaden (Euro/MW) for over- eller underproduksjon er en ukjent st√∏rrelse p√• budgivningstidspunktet. I denne data√∏vingen skal vi konsentrere oss om √• lage prognoser for spotprisen. I case 3 i BED4 kommer dere ogs√• til √• f√• bruk for vindstyrken og straffekostnadene, men √• lage prognoser for disse vil kreve ferdigheter utover det som gjennomg√•s i MET4. Hvis du ikke tar BED4 dette semesteret, s√• g√•r det helt fint ogs√•. Data√∏vingen st√•r fint p√• egne bein, og du kan uansett komme tilbake til disse resultatene hvis du for eksempel skal ta BED4 p√• et senere tidspunkt. Du har kanskje lagt merke til at R-kodingen i tidsrekkemodulen har en litt forskjellig stil fra det vi har gjort tidligere i kurset. I denne √∏vingen vil derfor st√∏rsteparten av koden blir oppgitt i oppgaveteksten. Din oppgave blir √• kj√∏re koden, f√• ut figurer og resultater, samt √• kommentere og tolke resultatene. Vi starter med √• laste inn noen pakker som vi kommer til √• trenge. Som vanlig m√• du installere pakkene f√∏rst dersom du ikke har gjort det allerede: library(forecast) library(ggplot2) 7.4.1 Oppgave 1: Last inn og se p√• datasettet Denne gang er datasettet pakket inn i en s√•kalt .Rdata-fil. Det er et enkelt filformat for √• lagre R-objekter. Last ned p_da.Rdata, og last datasettet inn i R ved √• kj√∏re f√∏lgende kommando (der du selvsagt har satt arbeidsmappen til der du har lagt datafilen): load(&quot;p_DA.Rdata&quot;) Du skal n√• f√• to tidsrekker i minnet: n03 og no5, som i figuren under: Disse to tidsrekkene inneholder str√∏mprisen i to prisomr√•der i Norge hver time fra 1. januar 2022 til og med 21. september 2022. Tidsrekken no3 inneholder prisen for Midt-Norge (NO3) og no5 inneholder prisen for Vest-Norge (NO5). Vi konsentrerer oss om NO3 i f√∏rste omgang, og kikker raskt p√• datasettet ved √• plotte tidsrekken direkte med autoplot()-funksjonen som vi finner i forecast-pakken: autoplot(no3) P√• \\(x\\)-aksen har vi antall dager siden 1. januar 2022. Skriv en kort kommentar der du peker p√• noen viktige karakteristikker ved denne tidsrekken. Du m√• gjerne bruke xlim-argumentet i plot()-funksjonen for √• zoome inn og se p√• mindre tidsperioder. Ser tidsrekken ut til √• v√¶re stasjon√¶r? 7.4.2 Oppgave 2: Gjem bort den siste dagen slik at vi kan sjekke prediksjonene v√•re For √• kunne gj√∏re en vurdering av hvor gode prediksjonene v√•re er, deler vi n√• datasettet v√•rt i to, der vi tar ut de siste 24 timene som vi kan bruke til √• evaluere prediksjonene. Vi kaller disse to delene no3_train, som er den lange delen som vi skal bruke til √• estimere en modell (trene en modell), og no3_test som er de siste 24 timene som vi skal bruke til √• teste etterp√• om modellen duger. Vi bruker funksjonen window() til √• hente ut deler av tidsrekken, der vi m√• spesifisere start- og sluttverdier som vektorer med to elementer; en for dag og en for time. Det er 264 dager i datasettet v√•rt, s√• da f√•r vi: no3_train &lt;- window(no3, start = c(1, 0), end = c(263, 23)) no3_test &lt;- window(no3, start = c(264, 0), end = c(264, 23)) Du kan n√• dobbelsjekke at du har f√•tt ut en enkelt dag i no3_test ved √• kj√∏re autoplot(no3_test). 7.4.3 Oppgave 3: Hent ut sesong og trend Vi har l√¶rt at et f√∏rste steg i tidsrekkeanalyse er √• hente ut eventuelle sesong og trendkomponenter. Vi har ogs√• sett at det er en enkel funksjon i R som kan gj√∏re dette for oss, nemlig stl(), slik vi s√• i seksjonen om trend og sesong. dekomponert &lt;- stl(no3_train, s.window = &quot;periodic&quot;) autoplot(dekomponert) Det var ikke s√• lett √• se detaljer i sesongkomponenten i dette plottet, s√• vi zoomer inn p√• en mindre del av x-aksen: autoplot(dekomponert) + xlim(245, 260) Gi en kort beskrivelse av de ulike komponentene i tidsrekken. 7.4.4 Oppgave 4: Prediker treningstidsrekken 24 steg frem og visualiser resultatene. Vi skal n√• slippe veldig billig unna! Denne oppgaven best√•r egentlig av flere steg: Finn en statistisk modell for residualtidsrekken. Bruk for eksempel auto.arima() for √• finne den ARIMA-modellen som passer best til treningsdatasettet. Bruk denne modellen til √• predikere residualtidsrekken 24 steg frem. Skriv trendserien 24 steg frem. Her m√• vi ha en fornuftig m√•te √• ekstrapolere som vi ikke har dekket eksplisitt i materialet v√•rt. Hekt p√• en ny dag med den daglige sesongvariasjonen. Legg sammen prediksjonene av residualene, trend- og sesongkomponenten for √• lage en prediksjon av prisserien. Vi kunne godt satt oss ned for √• programmere disse stegene hver for seg. Heldigvis har noen gjort dette f√∏r oss, gjennom funksjonen forecast() i forecast-pakken. For √• lage en prognose m√• vi sende inn den dekomponerte tidsrekken, sammen med en spesifikasjon av hvilken type statistisk tidsrekkemodell vi √∏nsker √• tilpasse til residualtidsrekken (vi velger ARIMA, for det er den modellen vi har l√¶rt om), og hvor mange steg frem vi √∏nsker √• predikere. Vi kan ogs√• legge til signifikansniv√•et for et prediksjonsintervall som vi vil ha p√• 95%: prognose &lt;- forecast(dekomponert, method = &quot;arima&quot;, h = 24, level = 95) Vi kan visualisere resultatet ved hjelp av autoplot(). For √• kunne se noe fornuftig i plottet s√• tar vi bare med de 100 siste observerte tidsstegene i tillegg til de 24 prediksjonene: autoplot(prognose, include = 100) Gi en kommentar til dette plottet. 7.4.5 Oppgave 5: Sammenlign prediksjonene med de faktiske observasjonene Vi kan n√• finne frem igjen no3_test, som er en tidsrekke som inneholder de faktiske observasjonene for dagen der vi har gjort prediksjoner. La oss sammenligne. En m√•te √• visualisere dette p√• er √• hente ut prediksjonene fra prognose-objektet (de ligger under $mean), og sette det sammen med de faktiske observasjonene (som vi har lagret i no3_test). Vi kan ogs√• hente ut prediksjonsintervallene, og sette alt inn i en data frame: # Setter prediksjoner, intervaller og observasjoner inn i samme data frame. prediksjoner &lt;- data.frame( x = 1:24, # Timer i d√∏gnet for x-aksen prediksjon = prognose$mean, # Predikerte priser nedre = prognose$lower[,1], # Nedre og √∏vre prediksjonsintervaller ovre = prognose$upper[,1], observert = no3_test # De faktiske observasjonene ) # Lager plott ggplot(prediksjoner) + geom_line(aes(x = x, y = prediksjon), linetype = &quot;dashed&quot;) + # Prediksjoner geom_line(aes(x = x, y = nedre), colour = &quot;darkred&quot;) + # Nedre grense geom_line(aes(x = x, y = ovre), colour = &quot;darkred&quot;) + # √òvre grense geom_line(aes(x = x, y = observert), size = 1.5) + # Observert xlab(&quot;&quot;) + ylab(&quot;&quot;) + ggtitle(&quot;24 timers prognose av str√∏mpris&quot;) + theme_minimal() I dette plottet er prediksjonene av str√∏mprisen vist som en stiplet linje, mens de prisene som faktisk ble observert er vist som en tykk heltrukken linje. Kommenter plottet. 7.4.6 Oppgave 6: Lag prediksjoner for neste dag S√• langt har vi brukt alle dagene i datasettet v√•rt bortsett fra den siste til √• predikere str√∏mprisen p√• den siste dagen. Resultatene ser ut til √• v√¶re gode. Du kan n√• gjenta denne prosedyren, men i stedet for tidsrekken no3_train skal du n√• bruke hele tidsrekken no3 til √• predikere prisen for dagen etter det ‚Äì den 22. september 2022 ‚Äì en dag der vi ikke har de faktisk realiserte prisene i datasettet v√•rt. Du skal f√• et prediksjonsplott som ser slik ut: Du kan s√• samle prediksjonene i en data frame som i forrige oppgave, men der vi selvsagt ikke kan ha med en kolonne med observerte priser, siden vi ikke har dem tilgjengelige. Den endelige tabellen med observasjoner skal se slik ut: ## x prediksjon nedre ovre ## 1 1 36.02709 12.1495723 59.90460 ## 2 2 36.45012 3.3208432 69.57940 ## 3 3 37.28821 -3.5736943 78.15012 ## 4 4 38.53910 -7.6663095 84.74451 ## 5 5 39.89017 -9.5638644 89.34420 ## 6 6 42.27134 -9.0837471 93.62643 ## 7 7 43.55218 -8.9521015 96.05647 ## 8 8 49.43543 -3.8202856 102.69114 ## 9 9 54.36794 0.5712673 108.16460 ## 10 10 56.23131 2.0083818 110.45425 ## 11 11 54.74981 0.1657312 109.33389 ## 12 12 51.32547 -3.5811987 106.23213 ## 13 13 49.64904 -5.5564816 104.85456 ## 14 14 47.41288 -8.0764075 102.90216 ## 15 15 46.22697 -9.5361822 101.99013 ## 16 16 46.70673 -9.3236145 102.73708 ## 17 17 46.61878 -9.6740934 102.91166 ## 18 18 48.72382 -7.8282025 105.27583 ## 19 19 50.11119 -6.6974082 106.91979 ## 20 20 50.21319 -6.8499490 107.27634 ## 21 21 50.04209 -7.2739046 107.35808 ## 22 22 48.34032 -9.2270566 105.90769 ## 23 23 45.94396 -11.8734681 103.76139 ## 24 24 42.20995 -15.8563146 100.27621 Kommenter. 7.4.7 Oppgave 7: Lagre prediksjonene i en excel-fil. Hvis du tar BED4 dette semesteret (eller skal ta BED4 p√• et senere tidspunkt) s√• trenger du n√• √• eksportere disse prediksjonene til en Excel-fil. En pakke som kan gj√∏re dette er writexl (som du, igjen, er n√∏dt til √• installere f√∏r bruk: install.packages(\"writexl\")). Hvis du har lagret prediksjonene i en data frame som heter prediksjoner2, s√• kan du skrive den ut i en Excel-fil p√• f√∏lgende m√•te: library(writexl) write_xlsx(prediksjoner2, &quot;no3_prediksjoner.xlsx&quot;) Du skal n√• ha en Excel-fil med prediksjonene dine i filen no3_prediksjoner.xlsx i arbeidsmappen din. 7.4.8 Oppgave 8: Gj√∏r det samme for no5 Du kan n√• gjenta √∏velsen over for √• f√• ut samme type prediksjoner for det andre prisomr√•det. Tidsrekken finner du i no5 og prediksjonsplottet ser slik ut: Data framen med prediksjonene skal se slik ut: prediksjoner3 &lt;- data.frame( x = 1:24, # Timer i d√∏gnet for x-aksen prediksjon = prognose3$mean, # Predikerte priser nedre = prognose3$lower[,1], # Nedre og √∏vre prediksjonsintervaller ovre = prognose3$upper[,1] ) prediksjoner3 ## x prediksjon nedre ovre ## 1 1 346.3622 310.5934 382.1310 ## 2 2 338.6796 286.6895 390.6698 ## 3 3 344.5907 281.3350 407.8464 ## 4 4 358.3632 286.3178 430.4086 ## 5 5 378.5406 300.1708 456.9105 ## 6 6 402.4033 319.0857 485.7209 ## 7 7 424.7142 337.5252 511.9031 ## 8 8 441.2872 350.5347 532.0397 ## 9 9 441.0059 346.6958 535.3159 ## 10 10 417.9910 319.6357 516.3462 ## 11 11 393.0380 290.0513 496.0247 ## 12 12 369.8592 261.5774 478.1409 ## 13 13 352.9104 239.0015 466.8192 ## 14 14 346.8510 227.3225 466.3794 ## 15 15 350.4399 225.7535 475.1262 ## 16 16 367.2739 238.1157 496.4321 ## 17 17 390.4917 257.6416 523.3417 ## 18 18 415.6232 279.7278 551.5187 ## 19 19 433.2506 294.7538 571.7474 ## 20 20 437.4176 296.4963 578.3390 ## 21 21 429.5152 286.1074 572.9229 ## 22 22 412.5279 266.3558 558.7000 ## 23 23 390.6720 241.3325 540.0115 ## 24 24 368.3594 215.4343 521.2845 Du lagrer den som en Excel-fil slik: write_xlsx(prediksjoner3, &quot;no5_prediksjoner.xlsx&quot;) Du kan laste ned de ferdige Excel-filene her for √• kontrollere at du har f√•tt det til: no3_prediksjoner.xlsx og no5_prediksjoner.xlsx. "],["data√∏ving-5.html", "7.5 Data√∏ving 5", " 7.5 Data√∏ving 5 7.5.1 Oppgave 1: Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysens begynner vi som vanlig med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(\"swirl\") i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) swirl() Du vil i starten bli bedt om √• skrive inn ditt navn og s√• f√∏lger litt info om hvordan swirl fungerer. Du blir s√• bedt om √• velge kurs. Her skal du f√∏rst velge alternativet ‚ÄòR Programming‚Äô. Merk at du kanskje m√• trykke alternativet ‚ÄòNo.¬†Let me start something new‚Äô for √• komme tilbake til hovedmenyen etter √• ha brukt swirl tidligere. Du f√•r s√• se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul 9 ‚ÄòFunctions‚Äô. I denne modulen vil du l√¶re litt om funksjoner i R. Merk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.5.2 Oppgave 2 - Maskinl√¶ring: Logistisk regresjon og k n√¶rmeste naboer I denne oppgaven skal vi se p√• de samme dataene som ble brukt i forelesningen om logistisk regresjon. Vi har data p√• 10000 kredittkortkunder og vi √∏nsker √• kunne bygge og trene en best mulig modell til √• predikere hvilke kunder som vil misligholde sin gjeld. Oppgave 2.1: Vi starter med √• f√• tak i dataene. Disse er integrert i pakken ISLR. Last inn pakken og ta en titt p√• dataene ved bruk av f√∏lgende linjer (hvordan du kommenterer er opp til deg): library(ISLR) # Pakke som inneholder dataene head(Default) # Viser starten p√• dataframen str(Default) # Viser hvilke typer variabler dataframen inneholder Responsvariabelen er : Dette er en kategorisk variabel. Misligholdt kunden gjelden? Forklaringsvariabler: : Kategorisk : Kontinuerlig, st√∏rrelsen p√• gjelden ($) : Kontinuerlig, kundens √•rlige inntekt ($) Oppgave 2.2: Det neste vi gj√∏r er √• visuelt unders√∏ke avhengigheten mellom det √• misligholde (default) og hvor stor gjeld (balance) kunden har . Vanligvis n√•r vi visuelt skal inspisere sammenhengen mellom to variabler lager vi et spredningsplott. Men n√•r den ene variabelen er kategorisk er det mer informativt √• sammenligne to boksplott av den kontinuerlige variabelen for hver av gruppene den kategoriske variabelen representer. Dette kan gj√∏res p√• f√∏lgende m√•te: boxplot(balance ~ default, data = Default, ylab = &quot;balance&quot;, xlab = &quot;default&quot;) Her er det formelen balance ~ default som gj√∏r at boxplot() funksjonen lager to boksplott av balance; et for gruppen som misligholdt (‚ÄúYes‚Äù) og et for gruppen som ikke misligholdt (‚ÄúNo‚Äù). Reflekter over figuren og gj√∏r deg opp en mening om sammenhengen mellom default og balance. Oppgave 2.3: Det er lurt √• dele inn dataene i et treningssett og et testsett n√•r vi driver med maskinl√¶ring. Treningsettet bruker vi til √• tilpasse (trene/l√¶re) modellen, mens testsettet bruker vi til √• se hvor godt forskjellige modeller presterer. Dette kan gj√∏res p√• flere m√•ter, men vi velger her √• bruke pakken dplyr som ble beskrevet i siste del av datalabb 2. F√∏rst legger vi til en unik id til hver kunde. Vi lar id-nummeret v√¶re lik radnummeret til kunden og til dette bruker vi funksjonen mutate: library(dplyr) my_data &lt;- Default %&gt;% mutate(id = row_number()) Siden vi n√• skal trekke et utvalg av dataene v√•re kan det v√¶re lurt √• sikre at resultatet er reprodusibelt ved √• sette set.seed(123) foran koden som f√∏lger. Du kan gjerne velge et annet tall enn 123, men n√•r en gj√∏r dette i forkant av en tilfeldig trekning i R er trekningen bestemt. S√• trekker vi et treningssett best√•ende av 70 % av dataene ved bruk av funksjonen sample_frac: train &lt;- my_data %&gt;% sample_frac(.70) De resterende kundene bruker vi som testsett ved bruk av funksjonen anti_join: test &lt;- my_data %&gt;% # Treningssettet er da de resterende 30 % av dataene anti_join(train, by = &#39;id&#39;) Koden over trekker ut alle kunder som ikke har lik id som i treningssettet som derfor svarer til de resterende 30 % av dataene. Oppgave 2.4: Vi forklarer i denne oppgaven hvordan en logistisk regresjonsmodell kan estimeres, tolkes og brukes. Du vil m√•tte lage nye modeller med tilsvarende koder i oppgavene som f√∏lger. Vi lager en modell hvor vi bruker variabelen balance (gjeld) som forklaringsvariabel. Vi bruker da funksjonen glm: model1 &lt;- glm(default ~ balance, data = train, family = &quot;binomial&quot;) Syntaksen til glm-funksjonen er veldig lik den vi bruker i regresjon (lm-funksjonen) bortsett fra at vi p√• spesifisere argumentet family = \"binomial\" for at √• fortelle R at vi √∏nsker √• gj√∏re en logistisk regresjon. Merk at vi bruker treningssettet til √• estimere (trene) modellen ved √• spesifisere argumentet data = train. Det kan v√¶re lurt √• se om forklaringsvariabelen balance har en signifikant effekt p√• default ved √• bruke summary funksjonen: summary(model1) For √• tolke hvilken effekt balance (gjeld) har p√• default (mislighold) er det lurt √• regne ut hva effekt en √∏kning p√• 1 $ i balance har p√• oddsen for default (Se forelesning): exp(coef(model1)) ## (Intercept) balance ## 2.205746e-05 1.005567e+00 Vi ser at oddsen for default √∏ker med en faktor 1.0056 (en 0.56 % √∏kning) dersom balance √∏ker med 1 $. Si at du √∏nsker √• predikere sannsynligheten for hvorvidt to kunder med henholdsvis 1000 $ og 2000 $ i balance vil misligholde sitt l√•n. Da kan vi bruke predict2 p√• f√∏lgende m√•te: to_personer &lt;- data.frame(balance = c(1000, 2000)) pred &lt;- predict(model1, newdata = to_personer, type = &quot;response&quot;) pred ## 1 2 ## 0.005648303 0.593966756 Det f√∏rste argumentet i funksjonen predict er hvilken modell vi skal bruke i prediksjonen (model1). Det andre argumentet newdata er hvilke kunder vi √∏nsker √• predikere misligholdsannsynligheter for. Vi setter dette argumentet til data.frame‚Äôn vi har kalt to_personer hvor hver rad svarer til en kunde med et sett forklaringsvariabler (i dette tilfellet to kunder og derfor to rader). Det er viktig at den inneholder en (eller flere) kolonne(r) med kolonnenavn som svarer til navnet til forklaringsvariabelen(e) vi har brukt i modellen. Argumentet type = \"response\" gj√∏r at vi f√•r returnert sannsynligheten for mislighold og ikke bare verdien av det line√¶re leddet i modellen. Hvis vi ut fra disse sannsynlighetene √∏nsker en klassifiseringsregel som klassifiserer om kunden vil misliholde eller ikke (‚ÄúYes/No‚Äù) er det naturlig √• tildele kunden ‚ÄúYes‚Äù hvis misligholdsannsynligheten overstiger en hvis grense og ‚ÄúNo‚Äù hvis ikke. Det kan det tenkes at kredittgiver vil v√¶re enten konservativ (sette grensen lavt, si 0.3) eller liberal (sette grensen h√∏yt, si 0.7), men i eksempelet under bruker vi en ‚Äún√∏ytral‚Äù grense p√• 0.5: ifelse(pred &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;) ## 1 2 ## &quot;No&quot; &quot;Yes&quot; Som navnet tilsier, vurderer ifelse funksjonen en logisk test i f√∏rste argumentet (pred &gt; 0.5 hvor pred er misligholdsannsynlighetene vi predikerte) og hvis testen har verdi TRUE gir den ut det du skriver i det andre argumentet (\"Yes\"), og det tredje argumentet (\"No\") ellers. Vi ser at individet med 1000 $ i gjeld blir klassifisert som ‚ÄúNo‚Äù, mens individet med 2000 $ i gjeld blir klassifisert som ‚ÄúYes‚Äù. Oppgave 2.4: Lag en ny modell ved navn model2 hvor du bruker den kategoriske variabelen student som forklaringsvariabel. Hvilken effekt har det √• v√¶re student p√• for oddsen for mislighold? Prediker sannsynligheten for at en student og en ikke-student misligholder gjelden sin. Oppgave 2.5: Lag en tredje model ved navn model3 hvor du bruker alle forklaringsvariablene. Hvilken effekt har det √• v√¶re student p√• for oddsen for mislighold n√•? Sammenlign med forrige oppgave. Unders√∏k visuelt om det er en sammenheng mellom student og balance med √• lage et boxplot over balance for studenter og et for ikke-studenter (hint: se Oppgave 2.2). Prediker sannsynligheten for mislighold for en ikke-student og en student med lik balance og income p√• henholdsvis 1500 $ og 10000 $. Sammenlign med prediksjonen du gjorde i Oppgav 2.4. Basert p√• model2 og model3, hvordan skal kredittgiver forholde seg til en student versus en ikke-student dersom a) Ingen informasjon om balance eller income er oppgitt og b) dersom en vet balance og income? Oppgave 2.6: I denne oppgaven skal vi trene opp en knn (k-n√¶rmeste-naboer) modell til √• gj√∏re en tilsvarende klassifisering som den logistiske regresjonsmodellen gjorde over. Funksjonen train som vi trenger er inneholdt i pakken caret (som m√• installeres ved hjelp av install.packages(\"caret\")). Vi velger √• tilpasse en modell hvor antall naboer ‚Äúk‚Äù velges automatisk med kryssvalidering vi argumentet ‚Äú`trControl‚Äù: library(caret) # R-kode dersom vi vil velge k automatisk set.seed(200) trControl &lt;- trainControl(method = &quot;cv&quot;, # 5-fold kryssvalidering number = 5) # Tilpasser modellen model4 &lt;- train(default ~ balance + income + student, data = train, method = &quot;knn&quot;, trControl = trControl, metric = &quot;Accuracy&quot;) Vi kan sjekke hvilken k som ble valgt p√• f√∏lgende m√•te (siden kryssvalidering bruker tilfeldige trekninger kan resultatet bli noe foreskjellig fra gang til gang, selv om datasettet er det samme): # Hvilken k valgte kryssvalideringen? k &lt;- model4$finalModel$k k ## [1] 5 Som for de andre modellene bruker vi funksjonen predict n√•r vi skal predikere og syntaksen er helt lik: to_kunder &lt;- data.frame(balance = c(1000, 2000), income = 10000, student = c(&quot;Yes&quot;, &quot;Yes&quot;)) predict(model4, newdata = to_kunder) ## [1] No Yes ## Levels: No Yes Merk at i motsetning til de logistiske regresjonsmodellene som predikerte sannsynligheter klassifiserer knn modellen kundene direkte som ‚ÄúYes‚Äù/‚ÄúNo‚Äù. Oppgave 2.7: Vi √∏nsker √• vurdere hvilken av model3 (logistisk regresjon) og model4 (knn) som er best. Vi kan da sjekke hvor godt de klarer √• klassifisere testsettet v√•rt hvor vi vet hvem som har misligholdt l√•nene sine. Vi starter med √• hente ut de sanne verdiene av default i treningssettet: sann &lt;- test$default # Den sanne verdien av default i testdataene Disse skal vi s√• sammenligne med hvordan modellene klassifiserer de samme kundene basert p√• de andre variablene. Vi gj√∏r f√∏rst klassifiseringen med den logistiske regresjonsmodellen: pred_logreg &lt;- predict(model3, newdata = test, type = &quot;response&quot;) # Predikert sannsynlighet klass_logreg &lt;- ifelse(pred_logreg &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;) # Klassifisering av kundene En oversikt over hvor mange riktige/feil klassifiseringer modellen gj√∏r kan lett oppsummeres med en kontigenstabell. For √• lage en kontigenstabell i R bruker vi funksjonen table: logreg_tab &lt;- table(sann, klass_logreg) # Kontigenstabell logreg_tab ## klass_logreg ## sann No Yes ## No 2889 11 ## Yes 70 30 Her kan vi f.eks se at 2889 kunder blir riktig klassifisert som ‚ÄúNo‚Äù, dvs at de ikke misligholdt l√•net og modellen sp√•r at de ikke vil misligholde l√•net. Merk at diagonalen (2889 og 30) representerer korrekte klassifiseringer, mens av-diagonal (11 og 70) representer feil klassifiseringer. Det kan v√¶re en fordel √• dele kontigenstabellen over med totalt antall kunder for √• f√• andelel i stedet. Funksjonen prop.table gj√∏r nettopp dette: logreg_tab_norm &lt;- logreg_tab %&gt;% prop.table %&gt;% # normaliser round(3) # rund av til 3 desimaler logreg_tab_norm ## klass_logreg ## sann No Yes ## No 0.963 0.004 ## Yes 0.023 0.010 Summen av diagonalen p√• denne tabellen (0.963 og 0.01) gir da totalt andel korrekt klassifiseringer: logreg_tot &lt;- sum(diag(logreg_tab_norm)) # Total andel korrekt klassfisering logreg_tot ## [1] 0.973 Oppgave 2.8: Gj√∏r en tilsvarende klassifisering av kundene i testsettet med knn modellen model4 og sammenlign med resultatet over. Hvilken modell foretrekker du? Hvilke egenskaper ved klassifisering tror du kredittgiver vektlegger? Funksjonen predict er satt opp med litt forskjellige argumenter alt ettersom hvilken type modell vi bruker. Du kan lese dokumentasjonen ?predict.glm for √• se hvordan den er satt opp for glm objekter‚Ü©Ô∏é "],["seminar.html", " 8 Seminaroppgaver", " 8 Seminaroppgaver Her finner dere oppgavesettene som vi skal regne p√• oppgaveseminarene som vi i all hovedsak skal bruke torsdagstimene p√•. "],["seminar-1---grunnleggende-statistikk.html", "8.1 Seminar 1 - Grunnleggende statistikk", " 8.1 Seminar 1 - Grunnleggende statistikk (V20, OPPG 1) Grafen ble publisert av klima- og milj√∏minister Ola Elvestuen fra Venstre p√• Twitter 1. november 2019 (men senere tatt bort), og viser norske CO\\(_2\\)-utslipp (i 1000 tonn CO\\(_2\\)-ekvivalenter) som funksjon av tid. Venstre gikk inn i regjering sammen med H√∏yre og Fremskrittspartiet i januar 2018. Denne figuren ble kritisert for √• v√¶re misvisende. P√• hvilken m√•te er den det, og hvordan ville du forandret den for at den skulle v√¶re mindre misvisende? (V20, OPPG 1) Figuren under ble publisert av H√∏yre p√• Facebook 1. november 2019, og viser norske CO\\(_2\\)-utslipp (i 1000 tonn CO\\(_2\\)-ekvivalenter) som funksjon av tid. Denne figuren ble ogs√• kritisert for √• v√¶re misvisende. P√• hvilken m√•te er den det, og hvordan ville du forandret den for at den skulle blitt mindre misvisende? (V19, OPPG 3) I figuren under ser vi en graf over den norske styringsrenten siden 2013 og anslag over hvilken bane renten skal f√∏lge de neste tre √•rene med fire usikkerhetsintervaller. Bruk figuren til √• ansl√• sannsynligheten for negativ styringsrente ved utgangen av 2022. Florida innf√∏rte i 2005 en s√•kalt ‚ÄúStand Your Ground‚Äù-lov, som i st√∏rre grad tillater folk √• bruke d√∏delig makt i selvforsvar. Grafen under, som viser utviklingen av d√∏dsoffer i skyteepisoder i Florida, illustrerte mange nyhetsreportasjer etter et drap i 2012, men fikk skarp kritikk i ettertid. Hvorfor det tror du? La oss anta at 50 avgangsstudenter som gikk ut av NHHs masterprogram i fjor svarte p√• et sp√∏rreskjema hvor mye de har i startl√∏nn i sin f√∏rste jobb. Gjennomsnittsl√∏nnen var 450.000, med et standardavvik p√• 120.000. Anta videre at l√∏nnsfordeningen for √•rets studenter er den samme (og se bort fra inflasjon). Estimer sannsynligheten for at gjennomsnittlig startl√∏nn for 50 responenter i √•r vil v√¶re st√∏rre enn 450.000. Estimer sannsynligheten for at gjennomsnittlig startl√∏nn for 50 responenter i √•r vil v√¶re st√∏rre enn 500.000. La \\(X\\) v√¶re en stokastisk variabel med forventningsverdi lik 5 og varians lik 2. Definer to nye stokastiske variabler \\(Y = 2X-1\\) og \\(Z = X^2 + Y\\). Regn ut: E\\((Y)\\) og Var\\((Y)\\). E\\((Z)\\) og Var\\((Z)\\). La \\(X\\) v√¶re en standard normalfordelt variabel. Du f√•r oppgitt at det medf√∏rer at E\\((X^3) = 0\\). La \\(Y = X^2\\). Vis at korrelasjonen mellom \\(X\\) og \\(Y\\) er lik null. Er \\(X\\) og \\(Y\\) uavhengige? "],["seminar-2---hypotesetesting.html", "8.2 Seminar 2 - Hypotesetesting", " 8.2 Seminar 2 - Hypotesetesting Sett opp en generell regel/oppskrift som du kan f√∏lge alle gangene du skal gjennomf√∏re en hypotesetest. Tegn opp en figur som viser hvordan de samme verdiene av \\(\\overline{X}\\) og \\(\\mu\\) i to ett-utvalgs \\(t\\)-tester likevel kan f√∏re til motsatt konklusjon av testen. Det er desverre et stort problem at folk som bruker begrepet p-verdi i ulike sammenhenfer ofte ikke forst√•r hva begrepet betyr. I den sammenheng publiserte The American Statistical Association i 2016 et skriv som i klare ordelag beskriver problemet. Les gjennom dette skrivet, og spesiel avsnitt 3 ‚ÄúPrinciples‚Äù. Oversett hver av disse seks overskriftene (prinsippene) til norsk med dine egne ord, og skriv s√• en setning, igjen med egne ord, om hvordan du forst√•r hvert av punktene. Pr√∏v √• definer begrepet p-verdi med s√• enkle ord som du klarer. Gj√∏r oppgave 11.38 i l√¶reboken: The club professional at a difficult public course boasts that his course is so tough that the average golfer loses a dozen or more golf balls during a round of golf. A dubious golfer sets out to show that the pro is fibbing. He asks a random sample of 15 golfers who just completed their rounds to report the number of golf balls they lost. Assuming that the number of golf balls lost is normally distributed with a standard deviation of 3, can we infer at the 10% significance level that the average (rett ord her er vel egentlig ‚Äúexpected‚Äù) number of golf balls lost is less than 12? Observasjonene er: 1, 14, 8, 15, 17, 10, 12, 6, 14, 21, 15, 9, 11, 4, 8 Anta at det sanne forventede antall golfballer som forsvinner i forrige oppgave er 10, hva er da styrken (power) til testen som du gjorde der? Hva er tolkningen til dette tallet? Gj√∏r skoleeksamen V17, oppgave 1a og 1b. Gj√∏r skoleeksamen V19, oppgave 1b. "],["seminar-3---regresjon-i.html", "8.3 Seminar 3 - Regresjon I", " 8.3 Seminar 3 - Regresjon I Se p√• den estimerte regresjonskurven under: Bestem hvilke av de f√∏lgende parameterestimatene som kan v√¶re riktig: \\(\\hat{\\beta}_0 = 5\\), \\(\\hat{\\beta}_1 = -3\\) \\(\\hat{\\beta}_0 = 10\\), \\(\\hat{\\beta}_1 = 4\\) \\(\\hat{\\beta}_0 = -4\\), \\(\\hat{\\beta}_1 = 2\\) \\(\\hat{\\beta}_0 = 10\\), \\(\\hat{\\beta}_1 = -2\\) Bestem hvilke av de f√∏lgende utsagn om den estimerte korrelasjonen mellom \\(X\\) og \\(Y\\) og andel forklart variasjon (\\(R^2\\)) som er riktig: Korrelasjonen er \\(-0.94\\) andel forklart variasjon er \\(-0.88\\). Korrelasjonen er \\(0.94\\) andel forklart variasjon er \\(0.88\\). Korrelasjonen er \\(-0.94\\) andel forklart variasjon er \\(0.88\\). Korrelasjonen er \\(1\\) andel forklart variasjon er \\(0.88\\). Under ser du et residualplott og et QQ-plot for en regresjonsanalyse. Hvilke brudd p√• antagelsene for line√¶r regresjon ser du? Dersom alle andre kriterier er oppfylt, hvilke konsekvenser har disse bruddene? En student √∏nsker √• unders√∏ke sammenhengen mellom pris og st√∏rrelsen p√• leiligheter (m^2). Han bestemmer seg for √• samle inn data p√• solgte leiligheter ukentlig over et helt √•r. Hva kan v√¶re problematisk for en slik strategi? Anta \\(Y_i\\) er forandring i BNP fra kvartal \\(i-1\\) til kvartal \\(i\\), mens \\(x_i\\) er forandringen i arbeidsledighet fra kvartal \\(i\\) til kvartal \\(i-1\\). Du tilpasser s√• regresjonsmodellen \\[\\begin{equation} Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\end{equation}\\] Forklar hva forskjellen p√• et prediksjonsintervall og konfidensintervall er i denne sammenhengen dersom \\(x=0\\), og hvorfor begge typer intervall er interessante. Eksamen V√•r 2019, Oppgave 2d) og e). "],["seminar-4---regresjon-ii.html", "8.4 Seminar 4 - Regresjon II", " 8.4 Seminar 4 - Regresjon II Vi har lyst til √• forst√• forskjellen p√• den statistiske modellen \\(Y = \\beta_0 + \\beta_1X + \\epsilon\\) der \\(\\epsilon\\) er normalfordelt med forventningsverdi 0 og varians \\(\\sigma^2\\), og det vi faktisk observerer, som er par av observasjoner \\((X_1, Y_1), \\ldots, (X_n, Y_n)\\). Klarer du √• illustrere denne forskjellen ved √• fortsette p√• tegningen under? Her har vi satt \\(n=4\\). Et lite firma som selger babyutstyr ser god effekt av √• markedsf√∏re produktene sine p√• Youtube. For √• analysere denne sammenhengen n√∏yere samler de inn historiske data p√• hvor mye de har brukt p√• Youtube-reklame (youtube) i l√∏pet av en m√•ned, og omsetningen den m√•neden (sales), og gjennomf√∏rer s√• en enkel line√¶r regresjon med youtube som forklaringsvariabel og sales som responsvariabel. Gi en kort fortolkning av regresjonsutskriften under: ## ## =============================================== ## Dependent variable: ## --------------------------- ## sales ## ----------------------------------------------- ## youtube 0.048*** ## (0.003) ## ## Constant 8.439*** ## (0.549) ## ## ----------------------------------------------- ## Observations 200 ## R2 0.612 ## Adjusted R2 0.610 ## Residual Std. Error 3.910 (df = 198) ## F Statistic 312.145*** (df = 1; 198) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 I figuren under har vi plottet inn datasettet, den estimerte regresjonslinjen (r√∏d heltrukken strek), samt linjen \\(y = x\\) (sort stiplet linje). Hvordan skal babyutstyrforhandleren tolke denne figuren? Ved hjelp av den estimerte regresjonsmodellen lager babyutstyrforhandleren f√∏lgende plott av residualene mot de predikerte verdiene for hver observasjon i datasettet. Hva sier denne figuren oss om line√¶r regresjon som modell for sammenhengen mellom penger brukt p√• markedsf√∏ring og omsetning? Det er gjort mange fors√∏k p√• √• forklare hvorfor noen land er rike, mens andre land er fattige, se f.eks hjemmeeksamen i MET4, V17. En mulig forklaring kan ligge in landenes fysiske og geografiske egenskaper. For eksempel, kan det hende at land som har ulendt terreng kan ha st√∏rre vanskeligheter med √• bygge infrastruktur og frakte varer enn land som er helt flate, og dermed ende opp som fattigere av den grunn? Vi ser p√• et lite datasett (l√•nt fra boken Statistical Rethinking) der vi har et m√•l p√• landenes rikdom (logaritmen av BNP, log_gdp), samt et m√•l p√• hvor ulendt terrenget er i det landet (rugged). Vi har ogs√• mer informasjon om landene, for eksempel om det ligger i Afrika eller ikke (cont_africa). Vi har gjort tre regresjonsanalyser i R, med f√∏lgende utskrifter: ## ## ======================================================================================= ## Dependent variable: ## ------------------------------------------------------------------- ## log_gdp ## (1) (2) (3) ## --------------------------------------------------------------------------------------- ## rugged 0.003 -0.067 -0.203*** ## (0.077) (0.064) (0.077) ## ## cont_africa -1.469*** -1.948*** ## (0.165) (0.227) ## ## rugged:cont_africa 0.393*** ## (0.132) ## ## Constant 8.513*** 9.030*** 9.223*** ## (0.136) (0.127) (0.140) ## ## --------------------------------------------------------------------------------------- ## Observations 170 170 170 ## R2 0.00001 0.322 0.357 ## Adjusted R2 -0.006 0.314 0.345 ## Residual Std. Error 1.170 (df = 168) 0.966 (df = 167) 0.944 (df = 166) ## F Statistic 0.001 (df = 1; 168) 39.715*** (df = 2; 167) 30.712*** (df = 3; 166) ## ======================================================================================= ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Skriv opp de tre estimerte regresjonsmodellene. Gi en kort fortolkning av modell (2). Gi en forklaring p√• hva vi l√¶rer ved √• g√• fra modell (2) til modell (3). Fokuser spesielt p√• rollen til interaksjonsleddet (rugged:cont_africa). Hvordan kan det ha seg at rugged-variabelen n√• plutselig er statistisk signifikant forskjelig fra null? Kan du tenke deg en praktisk fortolkning av disse resultatene? "],["seminar-5---tidsrekker.html", "8.5 Seminar 5 - Tidsrekker", " 8.5 Seminar 5 - Tidsrekker Vi skal jobbe oss gjennom en serie tidligere eksamensoppgaver om tidsrekker: V17, oppgave 1g V18, oppgave 2a‚Äì2b H19, opppgave m‚Äìn V20, oppgave 3 Oppgaveformuleringene finner du i seksjon 9.1. "],["seminar-6---avansert-regresjon-og-maskinl√¶ring.html", "8.6 Seminar 6 - Avansert regresjon og maskinl√¶ring", " 8.6 Seminar 6 - Avansert regresjon og maskinl√¶ring Nevn minst to grunner til at en √∏nsker √• utf√∏re en vanlig regresjonsanalyse. Reflekter s√• over hva hovedgrunnen er med √• lage henholdsvis en KNN-modell og en regresjonsmodell. Diskuter i hvilken grad det er rimelig med komponenten \\(v_t\\) i en paneldatamodell \\[y_{it} = \\beta_0 + \\beta_1 x_{it} + ... + v_t + \\alpha_i + \\epsilon_{it} \\] dersom en skal analysere paneldata av f√∏lgende responsvariabler \\(y_{it}\\): Antall konkurser hver m√•ned i ulike land. Timentlig energi-ettersp√∏rsel i norske kommuner. L√∏nn per √•r for forskjellige individer i et land. Kan du komme p√• en tidsinvariant forklaringsvariabel som er relevant for responsvariablene over? Gj√∏r det noe om vi ‚Äúglemmer‚Äù disse? Tegn et sett med observasjoner best√•ende av en dummy-variabel \\(Y\\) og en kontinuerlig variabel \\(X\\) i et xy-koordinatsystemet hvor en ville f√•tt bedre prediksjoner av \\(Y\\) med KNN-metoden enn med logistisk-regresjon. Pr√∏v deg p√• eksamen H21 oppgave 3 Oppgaveformuleringene finner du i seksjon 9.1. "],["eksamensoppgaver.html", " 9 Eksamensoppgaver", " 9 Eksamensoppgaver Her finner du tidligere eksamensoppgaver samt diverse (og lett redigert) korrespondanse mellom studenter og studentassistenter som kan v√¶re nyttig for senere √•rganger av studenter. "],["skoleeksamen.html", "9.1 Tidligere eksamensoppgaver (skoleeksamen)", " 9.1 Tidligere eksamensoppgaver (skoleeksamen) I tabellen under finner du en lang rekke eksamenssett som er gitt tidligere i MET4. Vi har lagt til en kolonne med oppgaver som √•penbart ligger utenfor pensum i dag. Utover det er selvsagt oppgavene relevante i st√∏rre eller mindre grad for kurset i dag, uten at vi har mulighet til √• g√• n√¶rmere inn p√• en slik detaljert rangering. Lenger nede p√• siden finner du noen kommentarer og rettelser til oppgavesett og l√∏sningsforslag som har dukket opp i ettertid. Semester Oppgaver L√∏sningsforslag Ikke lenger pensum per 2023 2017 - V√•r Oppgaveformulering L√∏sningsforslag 1c 2017 - H√∏st Oppgaveformulering L√∏sningsforslag 1f-1h 2018 - V√•r Oppgaveformulering L√∏sningsforslag 2018 - H√∏st Oppgaveformulering L√∏sningsforslag 1d, 1g 2019 - V√•r Oppgaveformulering L√∏sningsforslag 1c 2019 - H√∏st Oppgaveformulering L√∏sningsforslag 2020 - V√•r Oppgaveformulering L√∏sningsforslag 2020 - H√∏st Oppgaveformulering L√∏sningsforslag 2021 - V√•r Oppgaveformulering L√∏sningsforslag 2021 - H√∏st Oppgaveformulering L√∏sningsforslag 2022 - V√•r Oppgaveformulering L√∏sningsforslag 2022 - H√∏st Oppgaveformulering L√∏sningsforslag Rettelser og kommentarer til oppgaver og l√∏sningsforslag Her vil du finne en del kommentarer og rettelser som er spesifikke for de enkelte oppgavesettene. Dette er basert p√• et dokument som Jarle M√∏en startet p√• i sin tid, og som senere er oppdatert av Benjamin Narum. Curipod tok over for denne oversikten, s√• man finner andre sp√∏rsm√•l og svar der som ogs√• er mer nylig. S√∏k eller bruk ‚Äútags‚Äù for √•rgangene av oppgaver. Vi lar sp√∏rsm√•lene under st√• i tilfelle de ogs√• er av nytte. Overskriftene under kan trykkes p√•, s√• ekspanderes innholdet for hver eksamen. V√•r 2017 Oppgave 2c: Eksamen V17, oppgave 2c): Man blir bedt om √• regne ut om koeffisienten er signifikant, hvorfor er frihetsgraden 282 (\\(v = n - k - 1\\)) og ikke 286 (\\(n-2\\))? Den generelle regelen for line√¶r regresjon er at man trekker fra antall frihetsgrader som svarer til antall parametre man har estimert f√∏rst, som s√• brukes i beregningen av standardavviket. I oppgave 2c p√• analyse (1) er det brukt 6 estimerte parametre (5 koeffisienter og ett konstantledd) dermed blir det \\(n - 5 - 1\\). I sliden du viser er det en koeffisient og ett konstantledd, dermed \\(n - 2\\). H√∏st 2017 Oppgave 1b: ‚ÄúViser resultatet av testen at studentene i gruppe A kanskje har plagiert?‚Äù. F-testen vil jo kun teste om variansene er den samme for gruppe A og gruppe B, eller ulik? Hvordan kan vi svare p√• dette sp√∏rsm√•let ved hjelp av en F-test? I fasiten st√•r det at studentene i gruppe A har kanskje plagiert. Er dette fordi variansen i gruppe A er minst, dermed har de mer like respons, noe som kan indikere plagiat? Ja, oppgave a og b henger tett sammen. Det stemmer at F-testen bare kan si om de er ulik. Man m√• tolke hva ulike standardavvik m√• bety utfra konteksten av ‚Äúeksperimentet‚Äù for √• komme frem til at det er juks p√• gang. Det stemmer som du sier at lavt standardavvik betyr plagiat. Poenget her er at gruppe B skal v√¶re representativt for studenter generelt, s√• ettersom standardavviket er signifikant forskjellig fra det det skulle v√¶rt (statistisk lik gruppe B) er det noe som foreg√•r. V√•r 2018 Oppgave 1b: I fasiten st√•r det at man ogs√• kan bruke T-test for √• sammenligne forventningsverdiene i de to datasettene, er det fordi n er stor og dermed vil normal og t-fordeling v√¶re omtrent det lik? Vi kan gj√∏re to forskjellige argumenter n√•r \\(n\\) er stor i dette tilfellet: N√•r \\(n\\) er stor er det ikke s√• farlig med normalitetsantakelsen for observasjonene, siden sentralgrenseteoremet s√∏rger for at testobservatoren er tiln√¶rmet normalfordelt uansett, og da kan vi bruke Z-test eller t-test avhengig av om vi kjenner det/de sanne standardavviket/standardavvikene eller ikke. I tillegg ser vi at n√•r \\(n\\) blir stor s√• er de kritiske verdiene for hypotesetesten nesten like. Det f√∏lger av at vi da kan estimere standardavviket mer presist, s√• de empiriske standandardavvikene \\(s\\) (eventuelt (\\(s_1\\) og \\(s_2\\)) er n√¶rme de sanne verdiene \\(\\sigma\\) (eventuelt \\(\\sigma_1\\) og \\(\\sigma_2\\)). H√∏st 2018 Oppgave 1c: I oppgaven skal man se hvorvidt ‚Äú‚Ä¶ the trimmed mean of the offers is smaller in 2008 than in 2006.‚Äù De setter opp H0 = Mean(Libor2006) = Mean(Libor2008), men s√• setter de opp H1 : Mean(Libor2006) &lt; Mean(Libor2008). Burde det ikke v√¶re omvendt her ettersom vi skal se om gjennomsnittet er lavere i 2008 enn i 2006? alts√• at H1: Mean(Libor2006) &gt; Mean(Libor2008). Videre konkluderer man med at ‚ÄúThe test indicates that the Libor in 2006 is lower than the Libor in 2008‚Äù. Men i summary tabellen f√•r man oppgitt at gjennomsnittlig libor i 2006 = 3.09 og 2.00 i 2008. Hvordan kan det ha seg da at man konkluderer med at libor er lavere i 2006 enn i 2008? De har snudd ulikheten. Det er feil i fasiten og det skal egentlig v√¶re Mean(Libor2006) &gt; Mean(Libor2008). I konklusjonen skal det f√∏lgelig konkluderes med at Libor i 2006 er st√∏rre enn i 2018. H√∏st 2019 Oppgave 1a: Oppgaven sp√∏r om hvilke tester man kan utf√∏re for √• finne ut hvilket land som har den signifikant st√∏rste andelen kjempelykkelige land. Er det ikke z-test man da bruker? Videre blir vi bedt om √• gi et datatransformasjon for Norge, hva mener de med dette? Hvorfor har fasiten kun brukt det som st√•r under br√∏kstreken i testobservatoren? Det stemmer at de bruker en z-test i fasit, men det er ogs√• mulig √• bruke en chi-squared goodness-of-fit test. Poenget her er at man skal finne ut hvem som er mest lykkelig i forhold til hverandre og dermed m√• man teste to og to land mot hverandre ved bruk av flere z-tester. Tanken med ‚Äútransformasjonen‚Äù er at man tar tallene fra tabellen og beregner noe man enkelt kan sammenligne to og to land basert p√•, det blir da estimatet av ‚Äúsannsynlighet for kjempelykkelig‚Äù med et empiriske standardavvik. Det empiriske standardavviket er da det som st√•r i nevneren for testobservatoren (se kap 12-3c i boken). Siden testen i teorien m√• gjennomf√∏res 3 ganger er det bedre √• regne p og empirisk standardavvik for s√• √• sette disse tallene inn i uttrykket for testobservatoren etterp√•. Oppgave 1b: Etter at \\(z = 5.33\\) er regnet ut dukker det opp en \\(z = 0.11\\) under. Hvor kommer denne fra og hva forklarer den? Den blir ikke kommentert videre. I oppgave B har de f√∏rst regnet ut z dersom man antar pooled standardavvik, deretter har de beregnet z med hvert sitt standardavvik og testet om disse to z-verdiene er ulike. Det er en litt knotete m√•te √• gj√∏re det p√•. De kunne bare brukt den sistnevnte z og testet den ulik null heller enn lik f√∏rstnevnte z. Konklusjonen blir den samme. Se side 482, Case 2. I eksemplene i boken beregner de ikke D f√∏rst slik de har gjort i fasit, men sier at den er kjent. Oppgave 1j: Vi blir bedt om √• skissere regresjonslinjen for r√•alders samlede p√•virkning p√• lykkeniv√•et. Jeg forstod fasiten, men dersom oppgaven hadde bedt om √• skissere regresjonslijen for rettferdighet samlede p√•virkning p√• rettferdighet, hadde linjen bare v√¶rt line√¶r med en stigningstall p√• 0.03? M√•tte vi gj√∏re alle de beregningene igjen siden variabelen var logaritmen til alder? Det stemmer. Rettferdighet-til-lykke-forholdet er lin√¶rt, s√• det hadde bare blitt en linje. Her sp√∏rres det om en skisse nettopp fordi forholdet skal v√¶re ikke-line√¶rt, s√• du ville nok ikke f√•tt samme sp√∏rsm√•l for ‚Äúrettferdighet‚Äù med mindre begge skulle inn i figuren samtidig som sammenligning. Beregningene var for √• st√∏tte at plottet ble riktig. I det line√¶re tilfellet kunne du jo bare ha funnet to punkter og dratt en linje imellom, det g√•r jo ikke i det ikke-line√¶re tilfellet. V√•r 2020 Oppgave 3c: Jeg er litt usikker ifm oppgave c) hvor vi blir spurt om redisualserien er stasjon√¶r. Jeg forst√•r resonnementet i fasiten, men er litt usikker n√•r det kommer til denne figuren. Her ser det jo ut til at variansen √∏ker med tiden? Et av forutsetningene for stasjon√¶r tidsrekke er jo at variansen skal v√¶re konstant og uavhengig av t? Hvordan ser vi forresten om forventningen er konstant eller ikke? Visuell inspeksjon kan gi deg en del innsikt, men noen ganger kan det v√¶re vanskelig √• konkludere eksakt kun fra figuren. Om det er tvil m√• man st√∏tte seg videre p√• beregninger. For residualserien er den litt kort til √• konkludere bare fra plottet om variansen √∏ker eller ikke. De laveste residualverdiene (p√• bunnen av plottet) ser ikke ut til √• endre seg slik som det kanskje kan se ut for de h√∏yeste (p√• toppen av plottet). Om du hadde plottet denne over lenger tid ville du kanskje ikke lenger tenkt at variansen endrer seg. Forventningen er konstant, og lik 0, om det er ca like mange punkter over som under 0-linjen over tid. Det ser ut til √• v√¶re tilfelle her. "],["tidligere-eksamensoppgaver-hjemmeeksamen.html", "9.2 Tidligere eksamensoppgaver (hjemmeeksamen)", " 9.2 Tidligere eksamensoppgaver (hjemmeeksamen) Her finner du oppgavene som er gitt ved hjemmeeksamen etter at eksamensformen ble lagt om i 2017. Merk at besvarelsen skal leveres som en sammenhengende rapport, og at l√∏sningsforslagene under ikke oppfyller det kravet, men heller er en skisse av kodesnutter som kan brukes til √• besvare sp√∏rsm√•lene. For v√•r 2018 har vi et sett med eksempelbesvarelser p√• ulike karakterniv√•er, med sensors kommentarer. Semester Oppgaver L√∏sningsforslag Data, relevante artikler, etc. 2017 - V√•r Oppgaveformulering Ikke tilgjengelig Materiale 2017 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale 2018 - V√•r Oppgaveformulering L√∏sningsforslag Materiale, Eksempelbesvarelser 2018 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale 2019 - V√•r Oppgaveformulering L√∏sningsforslag Materiale 2019 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale 2020 - V√•r Oppgaveformulering L√∏sningsforslag Materiale 2020 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale 2021 - V√•r Oppgaveformulering L√∏sningsforslag Data ikke lenger tilgjengelig. 2021 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale 2022 - V√•r Oppgaveformulering L√∏sningsforslag Materiale 2022 - H√∏st Oppgaveformulering L√∏sningsforslag Materiale "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
