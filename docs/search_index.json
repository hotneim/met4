[["index.html", "MET4 - Empiriske Metoder Innledning", " MET4 - Empiriske Metoder H√•kon Otneim og Geir Drage Berentsen Innledning Velkommen til hjemmesiden for kurset MET4 - Empiriske metoder, som er et obligatorisk kurs p√• Bachelorprogrammet i √òkonomi og Administrasjon ved Norges Handelsh√∏yskole. Her vil du finne undervisningsmaterialet ‚Ä¶ Videobasert. Innledning til kurset, detaljer om datoer, hvordan jobbe, hvor finne informasjon, f√∏lge med p√• Canvas osv. "],["introduksjon-til-r.html", " 1 Introduksjon til R", " 1 Introduksjon til R Vi skal i dette kurset bruke programmeringsspr√•ket R til √• gj√∏re beregninger og gjennomf√∏re de ulike statistiske analysene som vi skal l√¶re etter hvert. Dette vil v√¶re nytt for mange. Vi skal f√∏rst og fremst skal skrive kode og kommandolinjer for √• f√• ut resultater i R, noe som kan oppleves uvant siden vi ellers er vant med √• klikke oss frem i et menysystem n√•r vi jobber med ulike programmer. Tr√∏sten kan v√¶re at ferdigheter i programmering blir stadig viktigere i mange yrker, spesielt innen √∏konomifaget. Vi m√• installere to ting p√• maskinen v√•r f√∏r vi g√•r videre; selve programeringsspr√•ket R, samt programmet RStudio som vi skal bruke til √• skrive og kj√∏re koden. Begge deler er gratis, og begge deler fungerer fint p√• b√•de Windows og Mac (og Linux!). Det er greiest √• gj√∏re dette i riktig rekkef√∏lge: G√• til r-project.org for √• laste ned R til ditt operativsystem, og installer p√• vanlig m√•te uten √• forandre p√• foresl√•tte innstillinger. G√• til rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (‚ÄúOpen source edition‚Äù) for ditt operativsystem og installere p√• vanlig m√•te. Det er heller ikke her n√∏dvendig √• forandre p√• de foresl√•tte innstillingene. Du kan s√• √•pne RStudio, og f√∏lge sekvensen av videoforelesniger som f√∏lger under. Merk at disse videoene er l√•nt fra seminaret BAN420 - Introduction to R som gis p√• masterprogrammet ved NHH. De er derfor spilt inn p√• engelsk. Det resterende videomaterialet i kurset gis p√• norsk. "],["en-gjennomgang-av-rstudio.html", "1.1 En gjennomgang av RStudio", " 1.1 En gjennomgang av RStudio I denne videoen √•pner vi opp Rstudio og rusler gjennom det grafiske grensesnittet. "],["enkle-beregninger-og-variabler.html", "1.2 Enkle beregninger og variabler", " 1.2 Enkle beregninger og variabler Vi g√•r videre og skriver v√•re f√∏rste kommandoer i R. Det er kritisk at vi allerede n√• setter i gang med √• f√• programmeringen inn i fingrene, og det gj√∏res best ved √• skrive inn kodelinjene slik det gj√∏res i videoen, og passe p√• at du f√•r ut de samme resultatene. N√•r du er ferdig med det kan du pr√∏ve deg p√• f√∏lgende lille oppgave: Oppgave: Velg dine tre favorittall og lagre dem i tre forskjellige variabler. Beregn s√• ditt magiske tall, som er summen av favorittallene dine. Lagre ditt magiske tall i en ny variabel, og gi denne variabelen et informativt navn som identifiserer hva det er. Fikk du det til? Kikk p√• l√∏sningen under for √• sjekke. L√∏sning tall1 &lt;- 1 tall2 &lt;- 87 tall3 &lt;- 101 magisk_tall &lt;- tall1 + tall2 + tall3 "],["vektorer.html", "1.3 Vektorer", " 1.3 Vektorer Vi introduserer begrepet vektorer som er sv√¶rt viktig i statistikk generel og R spesielt. En vektor er ganske enkelt en samling med tall, og n√•r vi senere begynner √• jobbe med data kommer vi til √• lagre observasjoner av ulikt slag i vektorer. Vi ser ogs√• at vi kan gj√∏re operasjoner p√• vektorer ved √• bruke funksjoner. For eksempel bruker vi sum()-funksjonen til √• regne ut summen av alle tallene som er lagret i en vektor. Oppgave: Beregn maksimum- og minimumsverdien av vector1, samt medianen, ved √• bruke funksjoner i R. (Hint: en d√•rlig skjult hemmelighet i anvendt programmering er at dersom vi ikke vet navnet p√• funksjonen vi skal bruke, s√• er Google v√•r‚Äô beste venn!) L√∏sning # Relevante Google-s√∏k: &quot;minimum value r&quot;, &quot;maximum r&quot;, &quot;median r&quot; min(vector1) max(vector1) median(vector1) "],["pakker.html", "1.4 Pakker", " 1.4 Pakker Vi l√¶rer at n√•r vi laster ned R s√• f√∏lger det med et grunnleggende sett av funksjoner (‚Äúbase R‚Äù), men at det finnes et stort antall tilleggspakker. Vi kan enkelt laste ned og installere disse pakkene ved √• skrive kommandoen install.packages(&quot;pakkenavn&quot;). Det trenger vi bare gj√∏re en gang p√• datamaskinen v√•r. For √• bruke pakken m√• vi skrive kommandoen library(pakkenavn), og det m√• vi gj√∏re hver gang i restarter R. Oppgave: Installer f√∏lgende pakker, som vi kommer til √• bruke senere i kurset: ggplot2 dplyr stargazer L√∏sning install.packages(&quot;ggplot2&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;stargazer&quot;) "],["mappesti.html", "1.5 Mappesti", " 1.5 Mappesti Vi kommer til √• forholde oss til filer p√• flere m√•ter. Vi skal lese inn datafiler, og vi kommer til √• produsere ulike former for output, slik som figurer og tabeller. Vi m√• da ha kontroll p√• hva R bruker som gjeldende mappesti (‚Äúworking directory‚Äù) der filer som skal leses inn ligger, og der ulike output-filer havner. Vi kan bruke funksjonen getwd() til √• sjekke hva som er gjeldende mappesti. For √• forandre mappestien kan vi bruke menysystemet (Session -&gt; Set Working Directory -&gt; Choose Directory), eventuelt funksjonen setwd() med √∏nsket mappesti som argument. Oppgave: Pass p√• at du har gjort f√∏lgende f√∏r du g√•r videre til neste leksjon: Du har laget en dedikert mappe p√• datamaskinen din der du skal samle alt materiale som vi bruker i dette kapitlet. Du har lastet ned filen testdata.xls og lagt den i den nye mappen din. Du har endret gjeldende mappesti til denne mappen. Du har bekreftet at gjeldende mappesti n√• er korrekt. "],["innlesing-av-data.html", "1.6 Innlesing av data", " 1.6 Innlesing av data Vi leser inn tabellen i excelfilen som en tabell (‚Äúdata frame‚Äù) i R ved hjelp av funksjonen read_xls() i readxl-pakken og ser p√• noen enkle kommandoer for √• jobbe med en slik tabell. Oppgave: Hvor mange kolonner har datasettet v√•rt? Kan du finne en m√•te √• skrive ut en vektor som inneholder summen av X1- og X2-kolonnene i datasettet? (Alts√•, vi vil vite summen av de to f√∏rste elementene i X1 og X2, summen av de to andre elementene, osv.) Hva er summen av alle tallene i X1- og X2-kolonnene itestdata? L√∏sning # 1 ncol(testdata) # 2 testdata$X1 + testdata$X2 # 3 sum(testdata$X1 + testdata$X2) "],["statistiske-analyser.html", "1.7 Statistiske analyser", " 1.7 Statistiske analyser Den f√∏rste kommentaren i denne videoen er selvsagt ikke sann for MET4. For oss er det motsatt: Det er ikke R som er poenget med kurset, men de statistiske metodene som vi skal l√¶re. R er bare verkt√∏yet vi skal bruke. Vi ser p√• et eksempel der vi kj√∏rer en enkel statistisk analyse (en \\(t\\)-test) p√• datasettet v√•rt, og hvordan vi kan gj√∏re ulike valg ved √• endre argumenter i funksjonskallet. Vi bruker ogs√• hjelpefilene til √• lese mer om funksjonen vi bruker. Oppgave: Hva er verdien av testobservatoren i testen som vi gjorde i denne videoen? Hint: Bruk hjelpefilene til t.test()-funksjonen. L√∏sning test_result$statistic "],["plotting.html", "1.8 Plotting", " 1.8 Plotting Vi lager v√•r f√∏rste figur i R ved √• bruke den innebygde plot()-funksjonen. Vi g√•r s√• over til √• se hvordan vi kan lage det samme plottet ved √• bruke ggplot-pakken, som er det vi kommer til √• bruke til √• lage figurer i dette kurset. Vi ser ogs√• hvordan vi kan g√• frem for √• lagre plottet som en pdf-fil i arbeidsmappen v√•r. Oppgave: Klarer du, for eksempel ved √• s√∏ke etter relevante ggplot-kommandoer p√• nettet, √• f√• prikkene i plottet til √• bli st√∏rre, og samtidig gj√∏re dem bl√•? L√∏sning ggplot(testdata, aes(x = X1, y = X2)) + geom_point(colour = &quot;blue&quot;, size = 5) "],["script.html", "1.9 Script", " 1.9 Script I stedet for √• skrive kommandoene rett inn i konsollen, hopper vi n√• over til teksteditoren i RStudio og lager et script i stedet. Her kan vi samle alle kommandoene v√•re i en fil, som vi kan lagre og kj√∏re igjen senere. Vi ser ogs√• hvordan vi enkelt kan kj√∏re enkeltlinjer i scriptet v√•rt i R-konsollen ved hjelp av Ctrl-Enter (Command-Enter p√• Mac). Vi ser at vi kan skrive kommentarer i scriptene v√•re ved √• bruke `#-tegnet, som kan v√¶re nyttig for √• holde oversikten. Til slutt lagrer vi scripet i arbeidsmappen. Oppgave: Pass p√• at du n√• har lagret scriptet som en .R-fil i mappen som vi laget for denne R-leksjonen. Lukk RStudio. Naviger s√• til denne mappen i filutforskeren og dobbelklikk p√• skriptet. Forh√•pentligvis √•pnes RStudio n√• (Hvis ikke, eller hvis filen √•pnes i det som heter R GUI, h√∏yreklikker du p√• filen og velger ‚Äú√Öpne i‚Äù, og deretter RStudio. Du kan ogs√• gjerne sette RStudio som standarsprogram for .R-filer). Finn ut hva gjeldende arbeidsmappe n√• er i RStudio. Hva skjedde n√•? Hvorfor er dette nyttig? L√∏sning N√•r vi √•pner RStudio ved √• dobbeltklikke p√• skriptfilen, s√• blir arbeidsstien satt automastisk til mappen der skriptfilen ligger. Dette er veldig nyttig n√•r vil kommer tilbake og skal jobbe videre med prosjektet v√•rt. "],["r-ekstra.html", "1.10 Oppsummering og ekstra oppgaver", " 1.10 Oppsummering og ekstra oppgaver I denne modulen har vi g√•tt gjennom noen helt grunnleggende funksjoner i R. Du har l√¶rt at R er navner p√• et programmeringsspr√•k, RStudio er navnet p√• et program der vi kan skrive og kj√∏re R-kode, og identifisert fire forskjellige vindu i RStudio: konsollen (der R-koden kj√∏res), teksteditoren (der vi skriver script), samt to vinduer der vi kan se en oversikt over hva som er i dataminnet og f√• opp plott og figurer som vi lager. Videre har du kj√∏rt noen enkle kommandoer, lagret tall og vektorer ved hjelp av variabelnavn, pr√∏vd ut noen innebygde R-funksjoner for √• regne ut f.eks. gjennomsnitt og standardavvik av tallvektorer, laget et spredningsplott, l√¶rt hva et working directory (arbeidsmappe) er, og installert R-pakker, f.eks readxl som vi brukte den til √• lese inn et lite datasett i R. Til slutt har du kj√∏rt en \\(t\\)-test, og skrevet et script (et lite program om du vil) der vi har lagret flere av kommandoene over i en tekstfil. Dersom du har fulgt modulen selv har du n√• kanskje skrevet et lite script i tekstvinduet som ser ut omtrent som koden under. N√•r du har gjort alt riktig, skal du n√• kunne kj√∏re gjennom disse kodelinjene uten feilmeldinger ved hjelp av Ctrl-Enter. Dette er helt grunnleggende (Sp√∏r om hjelp! Gi hjelp!). Har du problemer her, s√∏rg for √• f√• dem ordnet. Sp√∏r f√∏rst en medstudent om hjelp, og deretter eventuelt studentassistent eller foreleser. Studenter som har god erfaring med data og/eller programmering, kan l√¶re mye av √• hjelpe medstudenter l√∏se feilmeldinger. # Introduksjon til R # ------------------- # Laster inn n√∏dvendige pakker library(readxl) library(ggplot2) # Laster inn datasettet testdata &lt;- read_xls(&quot;testdata.xls&quot;) # Gj√∏r t-testen til sp√∏rsm√•l F i den f√∏rste data√∏vingen testresultat &lt;- t.test(testdata$X1, testdata$X2, var.equal = TRUE, alternative = &quot;two.sided&quot;) # Skriver ut resultatet av denne t-testen testresultat # Lager et plott av variabelen X1 mot X2 p &lt;- ggplot(testdata, aes(x = X1, y = X2)) + geom_point() # Lagrer plottet ggsave(&quot;testplot.pdf&quot;, plot = p) Lagre scriptet ditt. I RStudio velger du File -&gt; Save og trykker Ok dersom det kommer opp et vindu om character encoding e.l. Finn en fornuftig plassering (gjerne i samme mappe som √∏velsesdatasettet) og gi filen et fornuftig navn. Standard filending for R-script er .R, men det er skjult for de fleste Windowsbrukere. Lukk RStudio. Du kan n√• √•pne skriptfilen i RStudio igjen. Enten ved √• dobbeltklikke p√• den, eller ved √• √•pne RStudio, velge File -&gt; Open file, og s√• videre (dersom skriptet ikke allerede ligger √•pnet). Du kan ogs√• √•pne skriptfilen i en hvilken som helst notatbok (Notebook e.l.) og se at det er en helt standard, ren tekstfil. Hva er fordelen med √• lagre en analyse som et skript versus √• gj√∏re ting i et menydrevet grafisk grensesnitt? L√∏sning N√•r vi lagrer koden v√•r i et skript s√∏rger vi for at hele analysen v√•r er lagret, ikke bare resultatene. Med andre ord, dersom du p√• et senere tidspunkt √∏nsker √• komme tilbake til et analyseprosjekt og gj√∏re noen enkle forandringer, s√• er det fort gjort √• gj√∏re det i skriptet, og s√• kj√∏re hele analysen p√• nytt. Dersom du i stedet hadde brukt et menydrevet system for √• gjennomf√∏re analysen (pek og klikk) kunne du risikere √• m√•tte gj√∏re alt sammen p√• nytt (hvis du da husker hvordan du gjorde det), fordi du ikke like enkelt kan lagre hvert eneste museklikk. Vi skal n√• pynte p√• plottet og gj√∏re det riktig pent. Det gj√∏r vi ved √• legge til nye linjer i ggplot-kommandoen. Erstatt den nest siste linjen i skriptet med kommandoen under, og se at du f√•r en figur omtrent som den som f√∏lger under det igjen (vi bruker aksetitler i henhold til oppgavene i den f√∏rste datalabben, der vi f√•r vite at datasettet representerer kvalitet p√• kaffeavlingen f√∏r og etter en omlegging i produksjonsmetode): ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2) + xlab(&quot;Produksjonsmetode 1&quot;) + ylab(&quot;Produksjonsmetode 2&quot;) + theme_classic() Merk at vi pruker ‚Äú+‚Äù-tegnet til √• legge til flere ‚Äúlag‚Äù med grafiske egenskaper til plottet. Hvert ‚Äúlag‚Äù best√•r av en funksjon, som ofte kan ta argumenter; f.eks. brukes funksjonen geom_point() til √• lage prikker, og s√• kan vi f.eks. bruke argumentet size til √• styre st√∏rrelsen p√• prikkene. Kan du finne ut hva hvert enkelt av disse ‚Äúlagene‚Äù gj√∏r? Hint: ta bort en linje av gangen, og se hva som skjer. Pass p√• at det er et pluss mellom hvert lag. Pr√∏v √• endre p√• noen av lagene eller legg til nye. For eksempel kan du lage en tittel ved √• legge til funksjonen ggtitle() som et lag, og du kan endre aksetitlene. Pr√∏v ogs√• √• bruke argumentet shape i geom_point() til √• bytte ut prikkene med en annen form. Det finnes flere andre ‚Äútema‚Äù i tillegg til theme_classic(), f.eks. theme_bw(), theme_dark(), etc. Forslag Pr√∏v for eksempel dette: ggplot(testdata, aes(x = X1, y = X2)) + geom_point(size = 2, shape = 4) + ggtitle(&quot;Produksjonskvalitet&quot;) + xlab(&quot;Ny aksetittel&quot;) + ylab(&quot;Enda en aksetittel&quot;) + theme_light() Det f√∏lger med omfattende dokumentasjon med R. Du kan lese om alle R-funksjoner ved √• skrive ? f√∏r funksjonsnavnet i konsollen. Pr√∏v for eksempel √• skrive ?mean i konsollen og trykk enter. "],["grunnleggende-statistikk.html", " 2 Grunnleggende statistikk", " 2 Grunnleggende statistikk I denne modulen introduserer vi en del grunnleggende statistiske begreper. Mye vil oppleves som repetisjon, mens noe vil v√¶re nytt. Noe er veldig praktisk ved at vi kan bruke det direkte i eksempler, mens andre ting er mer teoretisk av natur. Felles for det vi skal se p√• her er at vi kommer til √• bruke mange av begrepene vi l√¶rer senere i kurset. "],["deskriptiv-statistikk.html", "2.1 Deskriptiv statistikk", " 2.1 Deskriptiv statistikk 2.1.1 Videoforelesninger 2.1.2 Kommentarer Deskriptiv statistikk handler ikke om analyse eller regning, men om √• presentere kompleks informasjon p√• en effektiv m√•te. Det er alts√• noe ganske annet enn det vi ellers snakker om i kurset, men det er likevel et av de nyttigste l√¶ringspunktet vi har. Hvem kan ikke regne med √• m√•tte presentere tall og resultater i l√∏pet av sin karriere? Eller selge inn forslag og planer for overordnede i h√•p om √• bli lyttet til? Det kan v√¶re direkte avgj√∏rende for din egen gjennomslagskraft at du er i stand til √• produsere overbevisende tabeller og figurer i slike situasjoner, og det er det dette temaet handler om. I l√¶reboken er det kapitlene 2‚Äì4 som behandler deskriptiv statistikk, men det er veldig Excel-fokusert, som ikke er s√• relevant for oss. Det er likevel ikke dumt √• lese gjennom stoffet for √• se hva det g√•r i, og legg spesielt merke til f√∏lgende punkter: Ulike datatyper i avsnitt 2-1. 3-4: The art and science of graphical presentations. Hva er det som gj√∏r en grafisk illustrasjon god? Pr√∏v √• ta inn over dere all informasjonen som vi lett kan lese ut av bildet p√• side 75 om Napoleons felttog mot Moskva. Her presenteres informasjon om tid, antall, geografi og temperatur p√• en helt eksepsjonelt effektiv m√•te! Videre er det noen grelle eksempler p√• hvordan vi kan bruke grafiske virkemidler til √• gi skjeve fremstillinger. I videoforelesningen gir vi flere eksempler p√• dette. Kapittel 4 g√•r litt mer i dypden om numeriske deskriptive teknikker, som gjennomsnitt, median, standardavvik, korrelasjon, osv. Dette skal v√¶re dekket greit i forelesningen, men boken g√•r litt mer i dybden. Det kan v√¶re en fin √∏velse √• kikke p√• eksemplene i l√¶reboken og fors√∏ke √• gjenskape noen av Excel-figurene i R. Se p√• eksempel 3.2, der man skal lage to histogrammer over historiske avkastninger for to ulike investeringsstrategier. Vi leser inn datasettet (last ned fra Canvas) som under og kikker p√• det: library(readxl) returns &lt;- read_xlsx(&quot;Xm03-02.xlsx&quot;) returns ## # A tibble: 50 x 2 ## `Return A` `Return B` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 30 30.3 ## 2 -2.13 -30.4 ## 3 4.3 -5.61 ## 4 25 29 ## 5 12.9 -26.0 ## 6 -20.2 0.46 ## 7 1.2 2.07 ## 8 -2.59 29.4 ## 9 33 11 ## 10 14.3 -25.9 ## # ‚Ä¶ with 40 more rows Hver stategi har sin kolonne. Merk at variabelnavnene har mellomrom i seg, noe som er upraktisk n√•r vi jobber med et seri√∏st programmeringsspr√•k. En god vane er √• rett og slett gi dem nye navn, ved f.eks. √• kj√∏re colnames(returns) &lt;- c(&quot;returnA&quot;, &quot;returnB&quot;), eller s√• m√• vi alltid referere til variabelnavnene ved √• bruke slike ‚Äúbackticks‚Äù som vi ser under. Vi kan lage to enkle histogrammer slik vi gjorde det i forelesningen: ggplot(returns, aes(x = `Return A`)) + geom_histogram(bins = 10) ggplot(returns, aes(x = `Return B`)) + geom_histogram(bins = 10) Figur 2.1: To histogrammer "],["utvalg-og-estimering.html", "2.2 Utvalg og estimering", " 2.2 Utvalg og estimering You can, for example, never foretell what any one man will do, but you can say with presicion what an average number will be up to. Individuals vary, but percentages remain constant. So says the statistician. ‚Äî Sherlock Holmes 2.2.1 Videoforelesninger 2.2.2 Kommentarer I videoforelesningene over gikk vi gjennom noen sentrale begreper i statistikk. Noen av dem skal vi bruke mye i fortsettelsen, mens andre er ment for √• gi dere et solid teoretisk fundament n√•r vi etter hvert skal begi oss ut p√• anvendt statistikk. Vi startet med √• sette opp en liten agenda. Som et f√∏rste steg kan du kikke p√•, og notere ned noen setninger til, disse punktene og se om du har f√•tt med deg hva de betyr: Samplingfordelinger Forventning/varians Sentralgrenseteoremet Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Forventningsrett Konsistens I Boken er det kapittel 9 (Sampling distributions) og 10 (Introduction to estimation) som gjelder. Kapittel 6-8 omhandler stoff skal skal v√¶re greit dekket i MET2 (Sannsynlighet, fordelinger, stokastiske variable, osv.), men det kan v√¶re nyttig √• skumme gjennom likevel hvis disse begrepene ligger langt bak i bevissheten din. Kapittel 9 starter med √• diskutere samplingfordelingen til et gjennomsnitt. Dette er nyttig lesestoff, men de viktigste punktene er som f√∏lger: Dersom observasjonene \\(X_1, X_2, \\ldots, X_n\\) er normalfordelt, er ogs√• gjennomsnittet \\(\\overline X = \\frac{1}{n}\\sum_{i=1}^n X_i\\) normalfordelt. Dersom E\\((X_i) = \\mu\\) og Var\\((X_i) = \\sigma^2\\) for alle \\(i = 1,\\ldots,n\\), er E\\((\\overline X)=\\mu\\) og Var\\((\\overline X) = \\sigma^2/n\\). Dette regnet vi ut formelt. Dersom \\(n\\) er stor, er \\(\\overline X\\) tiln√¶rmet normalfordelt, uavhengig av fordelingen til den enkelte \\(X_i\\). Dette f√∏lger av sentralgrensesetningen. Dette st√•r i en boks p√• slutten av seksjon 9-1a. Hvor stor m√• \\(n\\) v√¶re for at denne tiln√¶rmingen er god nok? Det finnes ikke et entydig svar p√•, men n√•r vi passerer 50-100 observasjoner kan vi i v√•re MET4-problemer gjerne si at \\(n\\) er ¬´stor nok¬ª. I 9-1b og 9-1c brukes sentralgrenseteoremet til √• regne p√• normalsannsynligheter i MET2-stil. I 9-1d er det noen Excel-instruksjoner som du kan hoppe over hvis du vil. Tekstboksen i 9-2c oppsummerer det vi fant ut om samplingfordelingen til en observert andel. I seksjon 9-3 snakkes det om samplingfordelingen til differansen av to gjennomsnitt. Vi gikk ikke gjennom det eksplisitt i forelesningen, men det er ikke noe substansielt nytt her. Vi skal bruke dette reultatet i neste modul n√•r vi skal sammenligne to gjennomsnitt. I seksjon 9-4 f√•r vi forklart hva vi skal bruke samplingfordelinger til fremover. B√∏r leses. Kapittel 10 omhandler estimering, dvs hvordan vi bruker data til √• ¬´gjette¬ª p√• verdien til en ukjent parameter. Vi fors√∏kte i forelesningen √• gi litt intuisjon til begrepene forventningsrett estimator, variansen til en estimator, og konsistens. Vi kan lage et punktestimat av en forventningsverdi ved √• ta gjennomsnittet av observasjoner, og vi kan lage et konfidensintervall ved √• f√∏lge oppskriften i boksen p√• s. 316 (i 11. utgave). I eksempel 10.1 har vi 25 observasjoner fra en normalfordeling. Oppgaven er √• estimere forventningsverdien med et tilh√∏rende 95% konfidensuntervall. Pass p√• at du forst√•r den manuelle utregningen. I stedet for √• bruke Excel (eller taste alle disse tallene inn p√• en kalkulator) kan du skrive et lite R-script som gj√∏r det samme: # Vi skriver inn datasettet i en vektor demand &lt;- c(235, 374, 309, 499, 253, 421, 361, 514, 462, 369, 394, 439, 348, 344, 330, 261, 374, 302, 466, 535, 386, 316, 296, 332, 334) # Vi trenger 4 verdier for √• regne ut konfidensintervallet: gj.snitt &lt;- mean(demand) # Regner ut gjennomsnittet z &lt;- 1.96 # Denne finner vi i tabellen sigma &lt;- 75 # Oppgitt i oppgaven n &lt;- length(demand) # Antall observasjoner # V√•rt estimat av forventningsverdien er bare gjennomsnittet. # Regner ut nedre og √∏vre grense i konfidensintervallet (LCL, UCL): LCL &lt;- gj.snitt - z*sigma/sqrt(n) UCL &lt;- gj.snitt + z*sigma/sqrt(n) # Samler de tre tallene i en vektor og skriver ut: c(LCL, gj.snitt, UCL) ## [1] 340.76 370.16 399.56 I seksjon 10-2a fors√∏ker boken √• forklare fortolkningen av et konfidensintervall. Hovedpoengene her er at: Et 95%-konfidensintervall skal ikke tolkes som ¬´sannsynligheten for at intervallet inneholder den sanne parameterverdien er 95%¬ª. Den korrekte tolkningen er: ¬´Dersom vi hadde hatt tilgang til √• trekke nye utvalg fra populasjonen med like mange observasjoner og bruker dem til √• regne ut nye konfidensintervaller, vil 95 av 100 intervaller inneholde den sanne parameterverdien¬ª. Forskjellen p√• disse formuleringene er meget subtil, s√• subtil faktisk at det ikke er √•penbart at det er s√¶rlig god pedagogikk √• peke p√• den. Problemet med den f√∏rste formuleringen er at vi der kan f√• inntrykk av at det er den sanne parameterverdien som er stokastisk og avhengig av datasettet vi observerer, mens det strengt tatt er grensene til konfidensintervallet som er tilfeldige, og alts√• avhengige av datasettet. Det kommer klarere frem i den andre formuleringen. Bredden til et konfidensintervall er alts√• et uttrykk for usikkerhet, eller motsatt: presisjon. Seksjon 10-2b og 10-2c kan skummes raskt gjennom. Seksjon 10-3 handler om at vi f√∏rst bestemmer oss for et presisjonsniv√• (dvs bredde p√• konfiensintervallet) \\(B\\), og s√• regner ut hvor mange observasjoner vi trenger for √• oppn√• det. Vi kommer frem til en formelen \\[n = \\left(\\frac{z_{\\alpha/2}\\sigma}{B}\\right)^2,\\] men problemet i praksis er at vi gjerne ikke kjenner \\(\\sigma\\), og vi kan heller ikke estimere den fordi vi ikke har samlet inn data enda. L√∏sningen er at vi enten p√• bruke fornuften, eller eventuelt et tidligere estimat av \\(\\sigma\\) dersom det er tilgjengelig. 2.2.3 Ekstra √∏ving i R Som demonstrert i forelesningen kan vi i R simulere standard normalfordelte observasjoner (dvs normalfordelte observasjoner med \\(\\mu = 0\\) og \\(\\sigma^2 = 1\\)) med kommandoen rnorm(n), der n er antallet observasjoner vi √∏nsker. For eksempel kan vi kj√∏re f√∏lgende kode for √• generere 10 observasjoner (du vil helt sikkert f√• andre verdier): n &lt;- 10 rnorm(n) ## [1] 0.1501713 2.1569501 0.7805240 1.0759178 2.1542171 1.2029920 ## [7] -1.4010995 -0.5742692 1.1580449 -1.0945080 Ved √• skrive mean(dnorm(n)) i stedet regner vi ut gjennomsnittet av observasjonene direkte. La oss gj√∏re dette 100 ganger og notere ned gjennomsnittet hver gang. I stedet for √• gj√∏re det manuelt, kan vi skrive et lite program som gj√∏r dette for oss ved √• bruke en for-l√∏kke. Det er ikke n√∏dvendig (eller pendum) √• forst√• akkurat hvordan dette fungerer, men dersom du kj√∏rer f√∏lgende linjer vil du f√• en ny vektor gj.snitt som inneholder 100 slike gjennomsnitt: gj.snitt &lt;- rep(NA, 100) for(i in 1:100) { gj.snitt[i] &lt;- mean(rnorm(n)) } Skriv ut denne vektoren og kontroller at det ser korrekt ut. Vi husker at funksjonen sd() regner ut standardavviket til en vektor. Hvilket tall forventer du √• f√• ut dersom du n√• kj√∏rer sd(gj.snitt) i konsollen? Stemmer det? Hint Standardavviket til de enkelte observasjonene er \\(\\sigma = 1\\), og standardavviket til et gjennomsnitt best√•ende av 10 observasjoner er \\(\\sigma/\\sqrt{n} = 1/\\sqrt{10} \\approx 0.32\\). Med andre ord skal det empiriske standardavviket sd(gj.snitt) v√¶re omtrent lik 0.32, pluss/minus en estimeringsfeil. Du kan gjerne regne ut 1000 gjennomsnitt i stedet for 100 ved √• erstatte erstatte 100 med 1000 p√• to steder i koden over. Stemmer det bedre da? Hint gj.snitt &lt;- rep(NA, 1000) # Lager en tom vektor med 1000 plasser for(i in 1:1000) { # Fyller hver plass med et gjennomsnitt av gj.snitt[i] &lt;- mean(rnorm(n)) # 10 standard normalfordelte observasjoner. } Pr√∏v √• forklare. Svar Dette er ganske enkelt, men ogs√• litt vanskelig p√• en inception-aktig m√•te. P√• samme m√•te som at gjennomsnittet blir en mer og mer presis estimator for forventningsverdien n√•r vi √∏ker antall observasjoner (m√•lt ved at standardavviket \\(\\sigma/\\sqrt{n}\\) blir mindre n√•r antall obserasjoner \\(n\\) blir st√∏rre), blir det empiriske standardavviket en mer og mer presis estimator av det sanne standardavviket n√•r vi √∏ker antall observasjoner. Alts√•; det empiriske standardavviket har ogs√• et standardavvik som g√•r mot null som \\(1/\\sqrt{n}\\) üòµ "],["sp√∏rsm√•l-og-oppgaver.html", "2.3 Sp√∏rsm√•l og oppgaver", " 2.3 Sp√∏rsm√•l og oppgaver Kontrollsp√∏rsm√•l Hva er forskjellen p√• deskriptiv statistikk og statistisk inferens? Deskriptiv statistikk kan gj√∏res grafisk eller numerisk, eventuelt som tabeller av ulike numeriske m√•l. Nevn noen fordeler og ulemper man m√• veie mot hverandre n√•r vi skal velge mellom grafisk og numerisk deskriptiv statistikk. Hva er en samplingfordeling? Hva sier sentralgrenseteoremet? Hva mener en statistiker n√•r hen sier at ‚Äúgjennomsnittet konvergerer som \\(1/\\sqrt{n}\\)‚Äù? Hva er samplingfordelingen til et gjennomsnitt? Hva er samplingfordelingen til en andel? Hva vil det si at et estimator er forventningsrett? Hva vil det si at et estimator er konsistent? Drilleoppgaver Ting fra boken, eventuelt litt bearbeidet. Skal vi ogs√• lage til l√∏sning her? Oppgaver p√• (ca) eksamensniv√• (EKS) = F√∏rst og fremst relevant for skoleeksamen. (HEKS) = F√∏rst og fremst relevant for hjemmeeksamen. Finne frem oppgaver fra gamle skoleeksamenssett. Noen av datasettene fra hjemmeeksamen; mange av f√∏rsteoppgavene har v√¶rt av typen ‚ÄúBeskriv relevante deler av datasettet‚Äù. Stargazer for summarytabeller. Summarise fra dplyr? Datasaurus; lage deskriptiv statistikk, s√• plotte? "],["hypotesetesting.html", " 3 Hypotesetesting", " 3 Hypotesetesting Hypotesetesting er et klassisk tema i statistikk. Vi skal f√∏rst l√¶re generelt om hva det egentlig vil si √• teste en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting ikke er. Vi g√•r s√• videre til √• l√¶re noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R. "],["generelt-om-hypotesetesting.html", "3.1 Generelt om hypotesetesting", " 3.1 Generelt om hypotesetesting 3.1.1 Videoforelesninger 3.1.2 Kommentarer Her snakker vi om kapittel 11 i l√¶reboken. Hvis du kan svare p√• f√∏lgende sp√∏rsm√•l har du i all hovedsak f√•tt med deg de viktigste begrepene: Hva vil det si √• gjennomf√∏re en hypotesetest? Hva er Type I-feil og hva er Type II-feil? (Seksjon 11-1 forklarer dette greit) Hva er signifikansniv√•et (\\(\\alpha\\)) til en test? Styrken (the power) til en test er definert som \\(1-P(\\textrm{Type II-feil})=1-\\beta\\). Hvordan tolker du denne st√∏rrelsen? Se ogs√• 11-3d. Hva er \\(p\\)-verdien til en test (Seksjon 11-2c)? Les ogs√• 11-2d, e og f om hvordan vi fortolker og snakker om \\(p\\)-verdien p√• en korrekt m√•te. Vi kommer tilbake til dette i kapittel 3.2. "],["chap-enpop.html", "3.2 Inferens om en populasjon", " 3.2 Inferens om en populasjon 3.2.1 Videoforelesninger 3.2.2 Kommentarer Dette er i hovedsak dekket av kapittel 12 i l√¶reboken. Sjekk om du kan svare p√• f√∏lgende kontrollsp√∏rsm√•l: Hva er det vi tester n√•r vi gjennomf√∏rer en \\(t\\)-test for √©n populasjon? Hva forutsetter vi? Hva er forskjellen p√• en ensidig og en tosidig test? (11-2j) Det kan ogs√• v√¶re greit √• repetere konfidensintervaller i seksjon 11-2k for de som har glemt det fra MET2. I Seksjon 11-2g g√•r boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gj√∏re det samme i R. P√• kursets nettside finner du alle datasettene som f√∏lger med l√¶reboken. I dette eksempelet er det snakk om Xm11-01.xlsx. Finn tak i denne filen (du kan ogs√• godt √•pne den og se p√• den i Excel!), legg den i en mappe som du kan finne igjen, og √•pne et nytt script i R-studio der du f√∏rst s√∏rger for √• sette working directory til denne mappen slik vi gjorde i R-forelesningen. Etterp√• leser du inn datasettet ved √• bruke read_xslx()-funksjonen som under: library(readxl) data &lt;- read_xlsx(&quot;Xm11-01.xlsx&quot;) # Vi bruker read_xslx() fordi det er en .xlsx-fil Konteksten til datasettet er gitt i eksempel 11.1. Det er alts√• balansen p√• 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer p√• om forventet balanse er st√∏rre enn 170. Vi setter opp f√∏lgende test: \\[\\begin{align*} &amp;H_0: \\mu = 170 \\\\ &amp;H_A: \\mu &gt; 170, \\end{align*}\\] der vi legger merke til at det blir brukt en ensidig test (hvorfor?). For √• regne ut testobservatoren for √• enutvalgs \\(z\\)-test trenger vi fire tall: \\(\\overline X\\), \\(\\mu_0\\), \\(n\\) og \\(\\sigma\\). Legger merke til at data har en kolonne som heter Accounts, og vi bruker dollartegnet til √• hente den ut som en vektor. Regner ut observatoren: gj.snitt &lt;- mean(data$Accounts) # Gjennomsnittet av observasjonene mu0 &lt;- 170 # Henter fra teksten n &lt;- length(data$Accounts) # Antall observasjoner sigma &lt;- 65 # Henter fra teksten Z &lt;- (gj.snitt - mu0)/(sigma/sqrt(n)) # Verdien av testobservatoren Z # Skriver ut testobservatoren ## [1] 2.460462 Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R: qnorm(0.95) ## [1] 1.644854 Uansett; vi forkaster \\(H_0\\) siden testobservatoren er st√∏rre enn kritisk verdi. Kapittel 11-3a-d gir enda mer forst√•else for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre. Kapittel 12 presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du f√∏rst og fremst m√• kunne fra dette kapitlet er √• gjennomf√∏re disse testene, b√•de for h√•nd med penn og papir, og i R. Under f√∏lger kode for √• gj√∏re noen av bokens eksempler i R (les i boken for kontekst): Eksempel 12.1: \\[\\begin{align*} &amp;H_0: \\mu = 2.0 \\\\ &amp;H_A: \\mu &gt; 2.0, \\end{align*}\\] data &lt;- read_xlsx(&quot;Xm12-01.xlsx&quot;) # Manuell utregning gj.snitt &lt;- mean(data$Newspaper) mu0 &lt;- 2.0 n &lt;- length(data$Newspaper) s &lt;- sd(data$Newspaper) # Testobservator: (gj.snitt - mu0)/(s/sqrt(n)) ## [1] 2.236869 Signifikansniv√•et er satt til \\(\\alpha = 1\\%\\) i eksempelet. Kritisk verdi finner vi i \\(t\\)-tabell eller rett fra R: qt(0.99, df = n-1) ## [1] 2.351983 Alts√• forkaster vi ikke nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som st√•r i boken. Alternativt bruker vi t.test()-funksjonen direkte: t.test(data$Newspaper, alternative = &quot;greater&quot;, mu = 2.0, conf.level = 0.99) ## ## One Sample t-test ## ## data: data$Newspaper ## t = 2.2369, df = 147, p-value = 0.0134 ## alternative hypothesis: true mean is greater than 2 ## 99 percent confidence interval: ## 1.990716 Inf ## sample estimates: ## mean of x ## 2.180405 Resultatet blir selvsagt det samme. N√•r \\(p\\)-verdien er st√∏rre enn signifikansniv√•et p√• 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om √• lage kondidensintervall, noe du ogs√• kan pr√∏ve √• gj√∏re ved √• regne ut de n√∏dvendige tallene i R. De som synes dette er greit kan kikke p√• seksjonene 12-1b-e for √• utvikle forst√•elsen enda litt mer. Eksempel 12.3: \\[\\begin{align*} &amp;H_0: \\sigma^2 = 1.0 \\\\ &amp;H_A: \\sigma^2 &lt; 1.0. \\end{align*}\\] Testobservator: \\[\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2}.\\] data &lt;- read_xlsx(&quot;Xm12-03.xlsx&quot;) # Regner ut testobservatoren direkte denne gangen, uten √• lagre tallene underveis: (length(data$Fills) - 1)*var(data$Fills)/1 # Kritisk verdi, 5% niv√•, ensidig test, nedre hale: qchisq(0.05, df = length(data$Fills) - 1) ## [1] 15.2 ## [1] 13.84843 Vi kan alts√• ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for √• forst√• bedre hva som skjer. Figur 12.4 viser p√• en fin m√•te hva tallene betyr. Eksempel 12.5 kan v√¶re grei √• kikke p√• ogs√•. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste: \\[\\begin{align*} &amp;H_0: p = 0.5 \\\\ &amp;H_A: p &gt; 0.5. \\end{align*}\\] Vi har en observert andel p√• \\(\\widehat p = 407/765 = 0.532\\) etter √• ha spurt \\(n = 765\\) personer. Testobservatoren er \\[Z = \\frac{\\widehat p - p}{\\sqrt{p(1-p)/n}}.\\] p.hatt &lt;- 407/765 p0 &lt;- 0.5 n &lt;- 765 (p.hatt - p0)/sqrt(p0*(1-p0)/n) ## [1] 1.771599 Kritisk verdi for en ensidig z-test p√• 5% niv√• er 1.645 (qnorm(0.95)), og vi kan forkaste nullhypotesen. Seksjonene 12-3d-f b√∏r leses p√• egen h√•nd, mens vi hopper over 12-3g. "],["inferens-om-to-populasjoner.html", "3.3 Inferens om to populasjoner", " 3.3 Inferens om to populasjoner 3.3.1 Videoforelesninger 3.3.2 Kommentarer Vi har g√•tt gjennom kapittel 13, som i all hovedsak handler om √• sammenligne to gjennomsnitt (som vi kan gj√∏re p√• tre forskjellige m√•ter), to varianser og to andeler. Her f√∏lger noen kontrollsp√∏rsm√•l som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper: Hva er nullhypotesen n√•r vi skal gjennomf√∏re en t-test for to populasjoner? ‚Ä¶ og hvilke antagelser m√• vi gj√∏re? Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj√∏r? N√•r kan vi bruke matchede par, og hva er hensikten? Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen? Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gj√∏r? Hvilken test brukes for √• teste om to andeler er like, og hva m√• du anta? Videre b√∏r du sjekke at du kan utf√∏re 3 typer \\(t\\)-tester, test for like varianser og test for like andeler b√•de for h√•nd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber). Den enkleste m√•ten √• gj√∏re \\(t\\)-tester i R p√• er √• bruke funksjonen t.test(). Kikk p√• eksempel 13.1 i l√¶rebokens 11. utgave, der vi har observert √•rlige avkastninger til to aksjefond som er kj√∏pt henholdsvis med og uten megler. # Leser inn datasettet funds &lt;- read_xlsx(&quot;Xm13-01.xlsx&quot;) # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = FALSE, conf.level = 0.95) ## ## Welch Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 97.489, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.79661 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Du kan s√• sjekke at du f√•r ut de samme tallene p√• s. 434‚Äì435. Videre kan du skrive inn ?t.test i R-konsollen i RStudio for √• lese mer om hvilke argumenter vi kan bruke i t.test()-funksjonen. Der ser vi at argumentene paired, var.equal og conf.level som utgangspunkt allerede er satt til FALSE, FALSE og 0.95 henholdsvis, s√• det hadde vi strengt tatt ikke trengt √• spesifisere i funksjonskallet over. Vi kan enkelt kj√∏re den samme testen under antakelsen om like varianser ved √• sette var.equal = TRUE: # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = TRUE, conf.level = 0.95) ## ## Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 98, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.7967156 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Resultatet bli akkurat det samme. Siden testens \\(p\\)-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og sl√• fast at forskjellen i gjennomsnitt er statistisk signifikant. I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner i de to populasjonene, s√• vi kan tenke oss at m√•lingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om gjennomsittet av differansene er signifikant forskjellig fra null. Enkelt: # Ser at det er to kolonner, ¬´Direct¬ª og ¬´Broker¬ª. Alternativhypotesen p√• s.433 spesifiserer at # differansen i forventninger er *st√∏rre* enn null, signifikansniv√•et skal v√¶re 5%. Antar f√∏rst # ulik varians og at vi ikke skal gj√∏re en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = TRUE, conf.level = 0.95) ## ## Paired t-test ## ## data: funds$Direct and funds$Broker ## t = 2.5178, df = 49, p-value = 0.007563 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.9716497 Inf ## sample estimates: ## mean of the differences ## 2.908 Da ser vi at \\(p\\)-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du pr√∏ve selv. Pass p√• at du kan gj√∏re beregningene manuelt ogs√•, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forst√•r hva som foreg√•r. Kapittel 13-2 omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig √• sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen v√•r av statistiske resultater. Det er et eksplisitt krav for √• lykkes i MET4 at du er i stand til √• sette resultatene inn i en fornuftig kontekst. I kapittel 13-4 kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R: bottle &lt;- read_xlsx(&quot;Xm13-07.xlsx&quot;) var.test(bottle$`Machine 1`, bottle$`Machine 2`, alternative = &quot;greater&quot;) ## ## F test to compare two variances ## ## data: bottle$`Machine 1` and bottle$`Machine 2` ## F = 1.3988, num df = 24, denom df = 24, p-value = 0.2085 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 0.7051295 Inf ## sample estimates: ## ratio of variances ## 1.398807 Ogs√• her kan du sammenligne med tallene som fremg√•r av bokens gjennomgang, og s√∏rg for at du f√•r til dette p√• egen h√•nd, spesielt det √• finne frem i tabellen, for det m√• du kunne p√• eksamen. Til slutt har vi test for to andeler i kapittel 13-5. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er like (\\(p_1 - p_2 = 0\\)), som er det vi har dett p√• i forelesning, men det g√•r selvsagt like fint √• sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall \\(D\\). Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved √• regne ut testobservatoren fra datasettet. Vi ser p√• eksempel 13.9, der vi f√•r oppgitt salget av en del forskjellige varenummer, og vi √∏nsker √• finne ut om andelen ¬´9077¬ª er st√∏rre i Supermarked 1 enn i Supermarked 2: # Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, s√• jeg # velger √• lese inn de to kolonnene hver for seg: soap1 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;A&quot;)) soap2 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;B&quot;)) # Hvor stor andel utgj√∏r ¬´9077¬ª i de to kolonnene? p1 &lt;- mean(soap1 == 9077) p2 &lt;- mean(soap2 == 9077) # De to utvalgsst√∏rrelsene: n1 &lt;- nrow(soap1) n2 &lt;- nrow(soap2) # Felles estimat for p under nullhypotesen: p &lt;- (n1*p1 + n2*p2)/(n1 + n2) # Testobservatoren: z &lt;- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2)) # Kritisk verdi p√• 5% niv√• for en ensidig test: qnorm(0.95) ## [1] 1.644854 Siden \\(z = 2.9\\) forkaster vi nullhypotesen om at det er lik andel ¬´9077¬ª i de to populasjonene. "],["kjikvadrattester.html", "3.4 Kjikvadrattester", " 3.4 Kjikvadrattester 3.4.1 Videoforelesninger 3.4.2 Kommentarer Vi m√• kunne to anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken: Teste for om en gitt fordeling passer med obervasjoner (‚ÄúGoodness-of-fit‚Äù). Teste for uavhengighet. I den f√∏rste anvendelsen f√•r vi oppgitt en diskret sannsynlighetsfordeling der vi har noen mulige utfall \\(u_1, \\ldots, u_k\\), med tilh√∏rende sannsynligheter \\(p_1, \\ldots,p_k\\). Dersom vi skal observere \\(n\\) utfall fra denne fordelingen, vil vi forvente \\(e_i = p_i\\cdot n\\) observasjoner av utfall \\(u_i\\). N√• har det seg slik at vi har observert \\(n\\) utfall fra fordelingen, og utfall \\(u_i\\) har skjedd \\(f_i\\) ganger. Vi lurer da p√• om de observerte frekvensene (\\(f_i\\)) er s√• forskjellige fra de forventede frekvensene (\\(e_i\\)) at vi ikke lenger tror at \\(p_1, \\ldots,p_k\\) er den sanne sannsynlighetsfordelingen. Vi kom frem til en fornuftig testobservator: \\[\\chi^2 = \\sum_{i=1}^k \\frac{(f_i - e_i)^2}{e_i},\\] som er \\(\\chi^2\\)-fordelt med \\(k-1\\) frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan g√• inn i \\(\\chi^2\\)-tabellen for √• sjekke om verdien av testobservatoren er for stor (dvs, \\(f\\)¬¥ene er for forskjellige fra \\(e\\)`ene) at vi ikke lenger tror at \\((p_1, \\ldots, p_k)\\) er den sanne sannsynlighetsfordelingen. Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte f√∏lgende kommandoer: p0 &lt;- c(0.45, 0.40, 0.15) # Fordeling under H0 f &lt;- c(102, 82, 16) # Observerte frekvenser chisq.test(x = f, p = p0) ## ## Chi-squared test for given probabilities ## ## data: f ## X-squared = 8.1833, df = 2, p-value = 0.01671 Den andre anvendelsen er √• teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for ¬´\\(A\\) og \\(B\\)¬ª som et produkt dersom de ar uavhengige: \\[P(A \\cap B) = P(A)\\cdot P(B).\\] Vi kan regne ut hvor mange observasjoner vi forventer √• se for hver kombinasjon av de to kjennetegnene (\\(e_{ij}\\)), og bruke kjikvadrattesten over til √• sjekke om disse er langt fra det vi faktisk har observert (\\(f_{ij}\\)). Boken har et eksempel p√• dette som de regner ut b√•de for h√•nd og i Excel. Slik kan vi gj√∏re det i R: # Leser inn data mba &lt;- read_xlsx(&quot;Xm15-02.xlsx&quot;) # Kikker p√• datasettet mba ## # A tibble: 152 x 2 ## Degree `MBA Major` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 2 2 ## 6 1 3 ## 7 3 1 ## 8 1 1 ## 9 2 1 ## 10 2 2 ## # ‚Ä¶ with 142 more rows Vi legger merke til at strukturen p√• datasettet er litt annerledes enn krysstabellen som er vist s. 601 i l√¶reboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av ¬´bachelorgrad¬ª og ¬´masterprofil¬ª, har vi f√•tt oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R: table(mba) ## MBA Major ## Degree 1 2 3 ## 1 31 13 16 ## 2 8 16 7 ## 3 12 10 17 ## 4 10 5 7 Det er denne som brukes som argument i chisq.test(): chisq.test(table(mba)) ## ## Pearson&#39;s Chi-squared test ## ## data: table(mba) ## X-squared = 14.702, df = 6, p-value = 0.02271 Her er det bare √• sammenligne tallene med det som l√¶reboken finner i Excel. Noen kontrollsp√∏rsm√•l: Vi har l√¶rt to veldig spesifikke anvendelser av kjikvadrattester. Hvilke? Kan du gi en intuitiv forklaring p√• hvorfor testobservatoren v√•r er fornuftig? Litt mer vanskelig: Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tiln√¶rmet kjikvadratfordelt? "],["regresjon.html", " 4 Regresjon", " 4 Regresjon I forrige modul fokuserte vi p√• bin√¶re sp√∏rsm√•l av typen ‚ÄúEr det er forskjell mellom disse to populasjonene, eller ikke?‚Äù, ‚ÄúEr disse kjennetegnene uavhengige, eller ikke?‚Äù, og s√• videre. I denne modulen skal vi pr√∏ve √• g√• et steg lenger og tillate mer interessante sp√∏rsm√•l. I stedet for bare √• sp√∏rre om en eller annen effekt er til stede (eller ikke), s√• vil vi heller finne ut hvor stor denne effekten er, hvilken retning den g√•r, og kanskje om vi kan bruke kunnskapen vi f√•r om statistiske sammenhenger til √• si noe fornuftig om hva som vil skje for noe som vi enda ikke har observert. Da er det regresjon som gjelder, og mer spesifikt for v√•r del: line√¶r regresjon. Regresjon er et hovedtema i MET4. Vi innf√∏rer en statistisk modell som i sin enkleste form sier at en forklaringsvariabel \\(X\\) henger sammen med en responsvariabel \\(Y\\) p√• en helt bestemt m√•te, nemlig gjennom ligningen \\[Y = \\beta_0 + \\beta_1 X + \\epsilon.\\] Ligningen over sier at det er en line√¶r sammenheng mellom \\(X\\) og \\(Y\\), men at det i tillegg kommer en uforutsigbar st√∏yvariabel \\(\\epsilon\\) som gj√∏r at vi ikke vil kunne observere den line√¶re sammenhengen direkte. Det vi derimot kan gj√∏re, er √• bruke de observerte \\(X\\)er og \\(Y\\)er til √• finne ut hvilke verdier av \\(\\beta_0\\) og \\(\\beta_1\\) som passer best. Til det bruker vi minste kvadraters metode, som beskrevet i videoforelesningene i denne modulen. Vi deler arbeidet med regresjon inn i tre deler. I den f√∏rste (og st√∏rste) delen g√•r vi grundig gjennom ulike sider vi den enkle line√¶re regresjonsmodellen over. I den andre delen ser vi p√• multippel regresjon som er en utvidelse av enkel regresjon der vi tillater flere forklaringsvariabler p√• h√∏yre side av likhetstegnet, og i den tredje delen ser vi p√• ulike praktiske aspekter ved regresjonsmodellering og modellbygging. "],["enkel-regresjon.html", "4.1 Enkel regresjon", " 4.1 Enkel regresjon 4.1.1 Videoforelesninger 4.1.2 Kommentarer Vi har sett p√• en del figurer som illustrerer noen pedagogiske poenger, og l√¶rebokens kapittel 16 g√•r detaljert til verks n√•r de beskriver de ulike l√¶ringsmomentene: I kapittel 16.1 kan vi lese mer om den statistiske modellen som vi kaller enkel regresjon. I kapittel 16.2 introduseres minste kvadraters metode for √• estimere regresjonskoeffisientene ved hjelp av data. De viser til og med hvordan det kan gj√∏res manuelt ved hjelp av bildatasettet, men det er selvsagt kun for √• illustrere hvodan formlene ser ut. Vi estimerer ved hjelp av R, og vi har sett i videoforelesningen hvordan vi gj√∏r det ved hjelp av lm()-funksjonen. Det som gj√∏r regresjon til et statistisk problem er feilleddet \\(\\epsilon\\). Vi tenker oss at for en gitt verdi av \\(X\\), s√• vil ¬´naturen¬ª regne ut verdien av \\(Y\\) ved √• regne ut den line√¶re sammenhengen \\(Y = \\beta_0 + \\beta_1 X\\), for legge til st√∏yvariabelen \\(\\epsilon\\) som trekkes fra en sannsynlighetsfordeling. Vi kan ikke observere direkte hvilke \\(\\epsilon\\) som ¬´naturen¬ª har ¬´trukket¬ª (for da ville vi med en gang kunne regnet oss frem til verdiene av \\(\\beta_0\\) og \\(\\beta_1\\)). For gitte estimater av regresjonskoeffisientene \\(\\widehat \\beta_0\\) og \\(\\widehat \\beta_1\\) (som vi kan finne f.eks. ved hjelp av minste kvadraters metode), s√• kan vi regne ut de observerte residualene \\[\\widehat\\epsilon_i = Y_i - \\widehat Y_i = Y_i - (\\widehat \\beta_0 + \\widehat \\beta_1 X_i).\\] Ved √• analysere residualene kan vi si mer om f.eks Er det egentlig en line√¶r sammenheng mellom \\(X\\) og \\(Y\\)? Hvis det er m√∏nstre og sammenhenger i de observerte residualene, tyder det p√• at den enkle line√¶re modellen ikke fanger opp hele sammenhengen mellom \\(X\\) og \\(Y\\). Vi kan g√• mer spesifikt til verks: n√∏yaktig hvilke antakelser om residualene er ser ut til √• v√¶re brutt? I senere √∏konometrikurs vil dere kunne l√¶re mer om hvordan vi h√•ndterer de ulike problemene. Hvor stor er variansen til \\(\\epsilon\\)? Det brukes videre til √• sette opp den viktige signifikanstesten for om stigningstallet i regresjonen er forskjellig fra null. Alt dette behandles grudig i bokens kapittel 16.3‚Äì16.6. Her b√∏r teksten leses godt. Kode til bileksempelet finnes i forelesningsnotatene. N√•r det gjelder enkel regresjon kan du sjekke om du har f√•tt med deg det vesentligste ved √• diskutere f√∏lgende sp√∏rsm√•l: Hva er responsvariabelen og hva er forklaringsvariabelen i enkel regresjon? Hva er fortolkningen av de to regresjonskoeffisientene? Hvilket prinsipp er det vi legger til grunn n√•r vi skal bestemme (estimere) verdien av koeffisientene ved hjelp av data? Skriv opp formlene for koeffisientestimatene. Kan du gi en intuitiv fortolkning av disse? Er de rimelige? Kan du ved hjelp av formelen for \\(\\widehat\\beta_1\\) utlede sammenhengen mellom stigningstallet \\(\\beta_1\\) og korrelasjonskoeffisienten mellom \\(X\\) og \\(Y\\)? Hvilken rolle spiller feilleddet (\\(\\epsilon\\))? Skriv opp de 4 + 1 forutsetningene. N√•r m√• den siste v√¶re oppfylt? N√•r kan vi klare oss uten? Hva er testobservatoren n√•r vi tester H\\(_0: \\beta_1 = 0\\)? Kan du holde styr p√• de fire standardavvikene vi har jobbet med i denne forelesningen? Hva mener vi med √• diagnostisere en regresjonsmodell? Hva er \\(R^2\\), og hva m√•ler den? Hva sier \\(R^2\\) ikke noe om? Her er noen grunnleggende ferdigheter fra kapittel 16. Klarer du dette? Bruke til √• tilpasse en enkel regresjonsmodell for et datasett? Bruke til √• skrive ut oversiktlige regresjonstabeller? Tolke en regresjonsutskrift? Hente ut relevant informasjon etter en slik tilpasning? Bruke informasjon fra regresjonsutskriften til √• regne ut antall stjerner for h√•nd? Lage diagnoseplott i ? Diagnistisere en modell? Identifisere innflytelsesrike observasjoner? "],["multippel-regresjon.html", "4.2 Multippel regresjon", " 4.2 Multippel regresjon 4.2.1 Videoforelesninger 4.2.2 Kommentarer I kapittel 17 utvides regresjonsbegrepet til multippel regresjon, som i prasis betyr at vi kan ha flere enn en forklaringsvariable: \\[Y = \\beta_0 + \\beta_1X_1 + \\cdots \\beta_kX_k + \\epsilon,\\] men utover dette er alle detaljene vi har snakket om de samme. For eksempel: Tolkningen av regresjonskoeffisienten: En endring p√• en enhet i forklaringsvariabelen \\(X_j\\) henger sammen med \\(\\beta_j\\) enhets endring i responsvariabelen \\(Y\\) (merk at jeg ikke brukker begrepet ‚Äúf√∏rer til‚Äù, vi kan ikke uten videre fortolke sammenhengen som kausal!). Analysen av residualene \\(\\widehat \\epsilon_i = Y_i - \\widehat Y_i\\) er den samme og har samme form√•l 1‚Äì3 som over. \\(R^2\\) har samme fortolkning. R-kommandoen er den samme, vi bare sette pluss mellom forklaringsvariablene, f.eks reg &lt;- lm(Y ~ X1 + ... + Xk, data = x) I tillegg innf√∏rer vi noen nye begreper: Justert \\(R^2\\): Vi viste i forelesningen at vi vil alltid klare √• √∏ke \\(R^2\\) ved √• legge til forklaringsvariable, selv om de ikke har noe med problemet √• gj√∏re. Derfor innf√∏rte vi en justert \\(R^2\\) som tar h√∏yde for nettopp dette, ved √• bli st√∏rre bare dersom den aktuelle forklaringsvariebelen faktisk forklarer en reell mengde av variasjonen i responsvariabelen. Se avsnitt 17-2f i l√¶reboken. Multikolinearitet: Dersom en forklaringsvariabel er sterkt korrelert med en eller flere andre forklaringsvariabler har vi multikolinearitet. Det blir naturlig nok et problem √• skille effekter fra hverandre n√•r de i realiteten er helt eller nesten like. Ekstremtilfellet er perfekt multikolinearitet der en variabel er en eksakt line√¶r funksjon av en eller flere andre variable. Det typiske tilfellet er at vi har to kolonner der vi m√•ler det samme fenomenet, men med to ulike enheter, f.eks. cm og m. Selvsagt kan vi ikke klare √• identifisere en separat og uavhengig effekt av \\(X\\) p√• \\(Y\\) om vi skifter m√•leenhet, og vi vil f√• en feilmelding dersom vi pr√∏ver p√• det. Det er ekvivalent med √• dele p√• null (every time you divide by zero, God kills a kitten!). L√∏sning: fjern en av kolonnene fra regresjonsanalysen. Verre er det om to variable m√•ler nesten det samme, men ikke helt, som i skoledataeksempelet der vi kunne bruke b√•de innbyggertall og antall femteklassinger i kommunen som forklaringsvariabler. De henger tett sammen, men selvsagt ikke eksakt, og det virker rart √• kunne knytte separate efekter til disse to variablene. I dette tilfellet f√•r vi likevel ikke feilmeldinger, men konsekvensen kan fort bli at standardavvikene (usikkerheten!) til koeffisientestimatene eksploderer, og at ingen av variablene blir signifikant forskjellige fra null, selv det det faktisk er en sterk sammenheng mellom kommunest√∏rrelse og pr√∏veresultat (husk at testobservatoren: \\(t = \\widehat \\beta_k/\\sigma_{\\beta_k}\\) blir liten n√•r nevneren blir stor). F-test for multiple sammenligninger: Dette henger n√∏ye sammen med variansanalyse (analysis of variance, ANOVA), som n√• er tatt ut av pensum i kurset. For √• forst√• dette kan vi sette opp et eksempel, med to forklaringsvariabler: \\[Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2.\\] Etter √• ha brukt miste kvadraters metode for √• estimere de tre koeffisientene er vi kanskje interessert i √• vurdere den statsistiske signifikansene til de to stigningstallene separat. Da tester vi de to nullhypotesene \\(\\beta_1 = 0\\) og \\(\\beta_2 = 0\\), som vi i praksis gj√∏r ved √• se p√• hvor mange stjerner de f√•r i regresjonsutskriften. Men sett at ingen av koeffisientene er signifikant forskjellige fra null, kan vi da slutte at vi ikke kan forkaste hypotesen \\(\\beta_1 = \\beta_2 = 0\\), dvs at begge koeffisientene er lik null, og at ingen av forklaringsvariablene forklarer variasjon i \\(Y\\)? NEI, det kan vi ikke. Vi kan for eksempel lett tenke oss at vi p√• grunn av multikolinearitet ikke f√•r separate forkastninger av de to nullhypotesene, men at ved √• fjerne en variabel, s√• blir den andre signifikant. For √• virkelig forst√• dette problemet kan du godt lese starten p√• kapittel 14.1 samt kapittel 14.2 om multiple sammenligninger (som strengt tatt ikke er pensum), men essensen er alts√•: \\[\\textrm{√Ö forkaste H}_0: \\beta_1 = 0 \\textrm{ og H}_0: \\beta_2 = 0 \\textrm{ er ikke det samme som √• forkaste H}_0: \\beta_1 = \\beta_2 = 0!\\] For √• gjennomf√∏re den siste testen m√• vi sette opp en egen testobservator, som viser seg √• v√¶re \\(F\\)-fordelt. L√¶reboken lister opp noen detaljer i avsnitt 17-2f, og essensen er at vi setter opp en br√∏k p√• formen \\[F = \\frac{\\textrm{Variasjon i } Y \\textrm{ som fanges opp av regresjonsmodellenmed } X_1 \\textrm{ og }X_2}{\\textrm{Variasjon i } Y \\textrm{ som fanges opp av regresjonsmodellen uten } X_1 \\textrm{ og }X_2}.\\] Dersom denne br√∏ken viser seg √• v√¶re stor (som definert av signifikansniv√• og frihetsgrader, se l√¶rebok), forkaster vi nullhypotesen om at begge koeffisientene begge kan v√¶re lik null. I en generell multippel regresjon med \\(k\\) forklaringsvariable rapporterer R F-statistic: etc, med verdien av \\(F\\)-observatoren i testen for \\[H_0: \\beta_1 = \\cdots = \\beta_k = 0,\\] og dersom den oppgitte \\(p\\)-verdien er mindre enn f. eks. 5%, kan vi slutte at ikke alle koeffisientene kan v√¶re null samtidig (selv om ingen av koeffisientene i seg selv er signifikant forskjellig fra null). Som en s√•kalt fun fact kan vi nevne at det er enkelt √• teste for signifikansen til grupper av variable p√• denne m√•ten, f.eks hvis det er noen variable som m√•ler lignende ting (si \\(X_2, X_4\\) og \\(X_5\\)). I R kan du estimere to modeller, en modell som inkluderer variablene (f.eks. reg_stor) og en modell der du tar bort de aktuelle variablene (f.eks. reg_liten). Du kan da kj√∏re kommandoen anova(reg_stor, reg_liten) for √• teste \\[H_0: \\beta_2 = \\beta_4 = \\beta_5 = 0.\\] Kritikk av l√¶reboken: L√¶reboken har en tabell p√• s. 701 som viser sammenhengen mellom ulike statistiske st√∏rrelser som vi kan regne ut for en regresjonsmodell. \\(R^2\\) kjenner vi som forklaringsgraden, \\(s_{\\epsilon}\\) er standardavviket til residualene, \\(F\\) er testobservatoren for modellgyldighet som vi definerte uformelt over, og som er definert formelt nederst p√• s. 700, mens SSE (Sum of Squares Error) henger n√∏ye sammen med standardavviket, som vi ogs√• kan se p√• s. 700. P√• disse sidene ser vi mange ligninger som viser hvordan disse st√∏rrelsene formelt henger sammen, og i tabellen p√• s. 701 ser vi blant annet at dersom SSE er liten, er ogs√• \\(s_{\\epsilon}\\) liten, \\(R^2\\) er n√¶r null, og \\(F\\)-observatoren er stor. Det er greit nok, men de har en ekstra kolonne som sl√•r fast at regresjonsmodellen er good. Her menes det ikke at regresjonsmodellen er god i den forstand at vi skal reagere med glede eller lettelse (slik noen gjerne gj√∏r), men at variasjonen i datamaterialet i stor grad lar seg forklare av modellen v√•r. I et tenkt eksempel der den sanne sammenhengen mellom \\(Y\\) og \\(X\\) er gitt ved \\(Y = \\beta_0 + \\beta_1X + \\epsilon\\), men der \\(\\beta_1\\) er forholdsvis liten og \\(s_{\\epsilon}\\) er relativt stor, vil f.eks. \\(R^2\\) bli liten, selv om den enkle line√¶re regresjonsmodellen repsesenterer sannheten og av alle tenkende mennesker m√• sies √• v√¶re god. Det er desverre mange l√¶reb√∏ker som blander disse to fortolkningene, ikke gj√∏r det! Her er enda noen grunnleggende begreper. Har du f√•tt med deg dette? Hva mener vi med at en observasjon er innflytelsesrik? Hva er grunnen til at vi trenger justert \\(R^2\\) med flere forklaringsvariable? Hva er forskjellen p√• perfekt og tiln√¶rmet multikolinearitet i line√¶r regresjon? Hva blir konsekvensen i hvert av tilfellene? Kan du gi en praktisk og intuitiv forklaring p√• hvorfor multikolinearitet n√∏dvendigvis m√• v√¶re et problem? Hva er forskjellen p√• statistisk og √∏konomisk signifikans? Kan du sette opp konkrete eksempler der vi kan estimere statistisk signifikante, men ikke √∏konomisk signifikante effekter i multippel regresjon? Hva med den motsatte situasjonen, √∏konomisk signifikant, men ikke statistisk signifikant? Grunnleggende ferdigheter: Klarer du dette? Bruke R til √• tilpasse en multippel regresjonsmodell for et datasett? Bruke R til √• finne s√¶rlig innflytelsesrike observasjoner? Tolke en multippel regresjonsutskrift? "],["modellbygging.html", "4.3 Modellbygging", " 4.3 Modellbygging 4.3.1 Videoforelesninger 4.3.2 Kommentarer Kapittel 18 dekker de grunnleggende begrepene innen modellbygging. I kap. 18.1 snakkes det om polynomiske modeller, i kap. 18.2 behandles dummyvariabler. Kapittel 18.3 og 18.4 handler om hvordan vi i praksis kan jobbe for √• velge ut variable i en gitt situasjon. Forelesningene dekker i grunn greit det vi skal f√• med oss her. Som en sjekk om du har f√•tt med deg det vesentlige, kan du svare p√• f√∏lgende sp√∏rsm√•l: Vi har l√¶rt tre typer log-transformasjoner. Hva blir fortolkningen av koeffisientene for hver av disse? Kan du nevne tre gode grunner til at log-transformasjoner er nyttige? Hvorfor sier vi at f√∏lgende modell er line√¶r? \\(Y = \\beta_0 + \\beta_1X + \\beta_1X^2 + \\varepsilon\\) Vil vi ikke f√• problemer med multikolinearitet i modellen over? Nevn en veldig god grunn til at vi m√• v√¶re ytterst forsiktig med polynomtransformasjoner. Hva er en dummyvariabel? Hva er fortolkningen av regresjonskoeffisienten til en dummyvariabel? Hva er fortolkningen av regresjonskoeffisienten til et interaksjonsledd mellom m√•levariabelen \\(X\\) og dummyvariabelen \\(D\\)? Et utrolig viktig poeng, men bruk tid til √• tenke over og formulere et svar: Hvorfor er det viktig √• tenke p√• multippel testing i sammenheng med variabelutvelgelse? Grunnleggende ferdigheter: Klarer du dette? Bruke logtransformasjoner i ? Bruke poynomtransformasjner i ? Sette opp en fornuftig regresjonsmodell ved √• ta utgangspunkt i et datasett og et analyseform√•l, og argumentere godt for dine valg? Denne ferdigheten har blitt testet p√• hver eneste hjemmeeksamen i manns minne! "],["avansert-regresjon-og-maskinl√¶ring.html", " 5 Avansert regresjon og maskinl√¶ring", " 5 Avansert regresjon og maskinl√¶ring Blabla, innledning "],["logistisk-regresjon.html", "5.1 Logistisk regresjon", " 5.1 Logistisk regresjon 5.1.1 Videoforelesninger 5.1.2 Kommentarerer I denne forelesningen ser vi p√• situasjonen der vi √∏nsker √• forklare utfallet av en bin√¶r variabel (en dummyvariabel) ved hjelp av et sett med forklaringsvariabler. Vi s√• at vanlig line√¶r regresjon ikke er s√¶rlig passende her fordi utfallet bare kan ta to verdier (0 eller 1, FALSE eller TRUE etc.), og fordi vi heller ikke kan tolke et kontinuerlig utfall direkte som en sannsynlighet fordi vi kan f√• ut verdier utenfor intervallet \\([0, 1]\\). L√∏sningen er √• heller forklare log-oddsen til suksessansynligheten. Sagt p√• en annen m√•te: p√• venstresiden i regresjonsligningen plasserer vi en transformasjon av suksessansynligheten, som gir oss en kontinuerlig variabel som kun kan variere mellom 0 og 1. Pensumboken v√•r behandler desverre ikke logistisk regresjon. Heldigvis finnes det et meget godt alternativ, An Introduction to Statistical Learning (ISLR) av James m.fl. finnes kan lastes ned gratis her: An introduction to statistical learning Denne boken er for √∏vrig pensum i BAN404. Logistisk regresjon er omhandlet i kapittel 4.3 (avsnitt 4.3.5 er ikke pensum). Eksempelet v√•rt er tatt herfra, og datasettet er, som vist i forelesningsscriptet, inkludert i bokens egen R-pakke ISLR. Bruk litt tid p√• √• lese gjennom disse sidene, konseptet er ganske godt forklart. Bli ogs√• kjent med R-syntaksen, som ligner p√• den vi allerede kan for vanlig line√¶r regresjon. Vi bruker f.eks. reg1 &lt;- glm(default ~ balance, data = Default, family = &quot;binomial&quot;) N√•r du er klar til √• pr√∏ve selv, kan du se p√• oppg 10a, b og f√∏rste del av d p√• s. 171 i ISLR. Dette datasettet er ogs√• inneholdt i ISLR-pakken. "],["introduksjon-til-maskinl√¶ring-med-knn.html", "5.2 Introduksjon til maskinl√¶ring med kNN", " 5.2 Introduksjon til maskinl√¶ring med kNN 5.2.1 Videoforelesninger 5.2.2 Kommentarer Kanskje har du allerede h√∏rt om maskinl√¶ring, ‚Äúdata science‚Äù, prediktiv modellering, ‚Äúbusiness analytics‚Äù, etc., og kanskje har du f√•tt med deg at disse tingene virkelig er i vinden for tiden. Som akademisk institusjon skal vi selvsagt v√¶re p√• vakt mot √• la popularitet v√¶re en avgj√∏rende faktor for hva vi driver med, men, som en kollega s√• treffende uttrykte seg: ‚ÄúInternett er kommet for √• bli.‚Äù Det skjer utrolig mye verdiskapning n√•r vi f√•r tak i den verdifulle informasjonen som ligger gjemt i de store datamengdene, og n√¶ringslivet skriker etter kompetanse. NHH har som svar p√• dette opprettet masterprofilen ‚ÄúBusiness Analytics (BAN)‚Äù (som ironisk nok er blitt superpopul√¶r!), og det er naturlig √• gi en liten smakebit p√• hva det g√•r ut p√• i MET4. Det herlige er at vi ikke trenger √• dykke s√• dypt i detaljene for √• f√• brukbar innsikt i hva det g√•r ut p√•. Overgangen fra logistisk regresjon er naturlig. Vi bruker det vi kan fra regresjonsanalyse til √• sette opp en modell der vi forklarer utfallet i en dummyvariabel ved hjelp av et sett forklaringsvariable i allerede observerte data. I f√∏rste omgang kan vi si at den moderne anvndelsen av logistisk regresjon (kall det gjerne en form for maskinl√¶ring) er √• bruke data til √• estimere sammenhengen mellom \\(X\\)-ene og responsvariabelen \\(Y\\), men bruke den til √• predikere \\(Y\\) for nye enheter. Artikkelen To explain or to predict av Galit Shmueli forklarer denne distinksjonen godt, og skal v√¶re noenlunde lesbar for en interessert student. Eksempelet fra logistisk regresjon er et godt eksempel p√• en anvendelse: Vi predikerer sannsynligheten for at kunder vil misligholde gjelden i fremtiden, basert p√• karakteristika vi kan observere n√•. Slike sannsynligheter kan vi mate inn i en strategisk analyse for √• bestemme oss hvem som skal f√• innvilget nye l√•n, men p√• en systematisk m√•te der vi s√∏rger for at vi oppn√•r n√∏dvendige profittmarginer og h√•ndterer risiko p√• en fornuftig m√•te, og kan ta hensyn til f.eks. etiske avveininger. Selv om vi ut fra eget behov for profitt og innenfor en akseptabel risikoprofil kan tilby nye l√•n til kunder med 15% sannsynlighet for √• havne i betalingsproblemer, b√∏r vi likevel gj√∏re det? Poenget her er at du ikke kan gj√∏re slike vurderinger f√∏r du faktisk kan estimere sannsynligheten for mislighold! Statistikken er bunnplanken, og blir mer og mer relevant etter hvert som vi innser at svarene ligger i √• analysere data. Vi g√•r videre til et annet eksempel. En teleoperat√∏r med abonnementskunder ser at det er en systematikk i hvilke kunder som sier opp avtalene sine. Ved √• se p√• spredningsplottet fra forelesningsslidsene, ser det ut til at nye kunder med dyre abonnementer ser ut til √• ha en tendens til √• forlate oss. Kan vi sette opp en klassifiseringsregel der som vi kan anvende p√• alle kundene v√•re, som automatisk plukker ut kunder som har f.eks. mer enn 50% sannsynlighet for √• si opp? Denne listen kan vi s√• sende videre til markedsavdelingen, som kan sette i verk forebyggende tiltak (f.eks. lokke de inn i bindende avtaler‚Ä¶?), og vi kan oppn√• en umiddelbar gevinst. Figur 5.1: R√∏de prikker er kunder som har sagt opp abbonnementet sitt, svarte prikker er kunder som ikke har gjort det. Finn den optimale avveiningen mellom systematikk og tilfeldig variasjon. Vi kan angripe dette datasettet p√• to m√•ter: Vi estimerer sannsynligheter ved hjelp av logistisk regresjon. Den stramme strukturen gj√∏r at klassifiseringsgrensen alltid utgj√∏r en rett linje i koordinatsystemet. Vi ser ogs√• p√• en annen klassifiseringsregel: kNN (k nearest neighbours), som ikke bruker sannsynlighetsmodeller eller regresjonsparametre til √• klassifisere, men heller er en enkel regel basert p√• f√∏lgende prinsipp: Hvis et flertall av kundene som er mest lik meg har sagt opp,er det mer enn 50% sannsynlig at ogs√• jeg vil si opp. Her bruker vi litt tid p√• detaljer, men det handler i grunn bare om √• lage en presis definisjom om hvem vi definerer som de kundene som ligner mest p√• meg, og svaret er de \\(k\\) kundene som ligger n√¶rmest meg i koordinatsystemet. P√• samme m√•te som for logistisk regresjon kan vi lese mer om kNN i ISLR. P√• s. 39‚Äì42 st√•r det hvordan teknikken fungerer, og i forelesningsnotatene og det medf√∏lgende scriptet ser vi hvordan det kan gj√∏res i praksis. N√•r vi forst√•r hvordan kNN fungerer, er neste steg √• reflektere litt over hvordan vi har tenkt √• velge parameteren \\(k\\) i praksis. Vi s√• i forelesningen at: Vi kan ikke velge \\(k\\) for liten. Da ser vi for mye p√• st√∏y og tilfeldigheter. Vi kan enkelt tenke oss at jeg er en lavrisikokunde, selv om de to kundene som er n√¶rmest meg i koordinatsystemet sa opp av en eller annen grunn. Hvis vi velger \\(k = 3\\), vil jeg likevel bli klassifisert som h√∏yrisiko og bli bombardert med un√∏dvendig reklame (som i seg selv kan gj√∏re stor skade!) Hadde vi heller valgt \\(k = 50\\) eller \\(k=500\\) ville disse to raringene ikke bli tatt hensyn til, men blitt dominert av alle andre i omr√•det som faktisk ikke har sagt opp. Alst√•: vi kan ikke henge oss for mye opp i detaljene og den tilfeldige variasjonen! Vi kan heller ikke velge \\(k\\) for stor, for det vil til slutt n√¶rme seg en situasjon det det bare blir en avstemning mellom alle kundene i datasettet. Det er flest kunder som ikke sier opp avtalen, alst√• blir alle kunder klassifisert som lavrisiko. Alts√•: vi vil heller ikke ignorere variasjonen i datamaterialet! Hele poenget er jo √• l√¶re noe nyttig fra hvordan prikkene fordeler seg i koordinatsystemet. I Figur 5.1 kan du pr√∏ve f√∏lgende: En liten \\(k\\) svarer til √• se n√∏ye p√• figuren (putt hodet ditt helt inntil skjermen!), og virkelig legge merke til hvor hver eneste en av de r√∏de prikkene befinner seg. √Ö velge en st√∏rre \\(k\\) svarer til √• trekke lenger bort, og kanskje begynne √• myse litt, slik at du f√•r √∏ye p√• systematikken, nemlig at det r√∏de dominerer nede til h√∏yre i figuren. Til slutt st√•r du i rommet ved siden av med lukkede √∏yne, og da ser du plutselig ingenting! Et eller annet sted i mellom der √∏nsker vi √• v√¶re. Kryssvalidering er en systematisk og generell m√•te √• velge k for KNN (og tilsvarende parametre i andre maskinl√¶ringsmetoder), som litt lenger enn √• bare dele datasettet inn i trenings- og testdata ISLR behandler temaet p√• s. 181‚Äì186, men det er forholdsvis teknisk og skrevet i lys av noen metoder som vi ikke har sett p√• i MET4. "],["paneldata.html", "5.3 Paneldata", " 5.3 Paneldata 5.3.1 Videoforelesninger 5.3.2 Kommentarer I denne forelesningen introduserer vi en ny datastruktur. Vi observerer flere individer (tversnittsdimensjonen) gjentatte ganger (tidsdimensjonen), og et slikt datasett kaller vi et panel, eller paneldata. Fordelen ved √• jobbe med slike data er √•penbar: vi har mer informasjon og kan gjennomf√∏re mer presise statistiske analyser. P√• den annen side m√• vi akseptere at en mer kompleks datastruktur gj√∏r det n√∏dvendig √• innf√∏re mer kompleks metodikk. Til n√• har vi typisk observert \\(n\\) individer en gang. Hvis vi holder oss til eksempelet fra forelesningen, kan vi tenke oss at vi har spurt \\(n\\) arbeidstakere om hvor mange timer de jobbet forrige √•r (\\(X\\)), og hvor mye de hadde i timel√∏nn (\\(Y\\)). Da vile datasettet sett omtrent slik ut: Her er \\(y_i\\) timel√∏nn til arbeidstaker nummer \\(i\\), og \\(x_i\\) er antall timer jobbet for arbeidstaker nummer \\(i\\). Hvis vi s√• √∏nsker √• se om det er en sammenheng mellom disse to variablene, kan vi sette opp en enkel regresjonsmodell som vi har gjort f√∏r: \\[\\begin{equation} y_i = \\alpha + \\beta x_i + \\epsilon_i, \\label{p-ols} \\end{equation}\\] der vi gj√∏r de vanlige antakelsene om homoskedastisitet, uavhengige feilledd, og selvsagt at forklaringsvariabelen er eksogen, dvs at de stokastiske variablene \\(X\\) og \\(\\epsilon\\) er uavhengige fra hverandre. Hvis vi aksepterer det, s√• kan vi estimere \\(\\beta\\) ved hjelp av minste kvadreters metode (OLS - orinary least squares), som vi kan tolke som forventet √∏kning i timel√∏nn ved √• jobbe en time ekstra. V√•rt ‚Äúproblem‚Äù n√• er at vi ikke har observert \\(n\\) arbeidstakere 1 gang, men at vi har spurt \\(N\\) arbeidstakere \\(T\\) ganger, slik at vi trenger to indekser til √• identifisere hver enkelt observasjon: \\(y_{i,t}\\) er timel√∏nn til arbeidstaker nummer \\(i\\) ved tidspunkt \\(t\\). V√•re observerte \\(X\\)er og \\(Y\\)er kan vi samle i en tabell som f√∏r, se Tabell . Legg merke til at det bare er de to f√∏rste kolonnene for \\(X\\) og \\(Y\\) som utgj√∏r de faktiske observasjonene, mens de to neste kolonnene sier hvilket individ som er observert, og ved hvilket tidspunkt observasjonen er utf√∏rt, og viser bare indeksene til \\(X\\)- og \\(Y\\)-observasjonene. Kall det gjerne metadata, og vi trenger den informasjonen n√•r vi skal utf√∏re paneldatateknikker. ‚Ä¶ her sp√∏rs det om vi m√• oppdatere litt slik at ting henger bedre sammen med videoene. Vi har ikke noe pensumlitteratur her. "],["tidsrekker.html", " 6 Tidsrekker", " 6 Tidsrekker Vi er n√• klare for den siste modulen i MET4 som handler om tidsrekker. Opplegget er ganske likt det vi har hatt s√• langt i semesteret, men siden l√¶reboken behandler dette stoffet s√¶rs stemoderlig, har vi valgt √• lage en litt annen variant. I motsetning til modulene vi har jobbet med frem til n√•, der vi separerte teorivideoene og data√∏vingene, er disse to elementene n√• blandet sammen. Vi har delt stoffet opp i en serie overskrifter, der du finner videosnuttene fulgt av en guide til relevante R-funksjoner og noen oppgaver. Det er alts√• ikke en egen data√∏vingsoppgave til tidsrekker. Hvis du jobber grundig med stoffet p√• disse sidene, enten alene eller i grupper, vil du f√• et godt grunnlag i et viktig tema innen statistikk for √∏konomifag, som g√•r igjen i mange empiriske kurs senere i studiet. Fagl√¶rer og studentassistenter vil v√¶re tilgjengelig p√• vanlig m√•te for konsultasjon, diskusjon og probleml√∏sning. Lykke til! "],["intro.html", "6.1 Introduksjon til tidsrekker", " 6.1 Introduksjon til tidsrekker 6.1.1 Kontrollsp√∏rsm√•l Hvilke forskjeller er det mellom en tidsrekke og et sett med samtidige observasjoner? Nevn noen typiske m√∏nstre som vi kan se etter i en tidsrekke. Hvorfor er det nyttig √• identifisere slike m√∏nstre? Hvorfor kan det v√¶re nyttig √• glatte en tidsrekke? Beskriv kort hvordan man regner ut et glidende gjennomsnitt. Hvorfor kan vi ikke bruke det glidende gjennomsnittet til √• predikere neste observasjon i en tidsrekke? Beskriv kort hvordan eksponensiell glatting fungerer, og hvorfor denne teknikken kan brukes til prediksjon. 6.1.2 Oppgaver fra l√¶rebok Keller: Statistics for Management and Economics, 11. utg a) Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 3 for f√∏lgende tidsrekke: b) Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 5 for tidsrekken over. c) Tegn inn tidsrekken over med de to glattingene inn i samme figur. d) Regn ut eksponensiell glatting for tidsrekken under med glattefaktor \\(w = 0.1\\): e) Gjenta oppgaven over med glattefaktor \\(w = 0.8\\). f) Tegn tidsrekken over inn i samme figur som de to glattede versjonene. Ser det ut til √• v√¶re en trend i denne tidsrekken? bonussp√∏rsm√•l) Hva blir prediksjonen av \\(Y_{11}\\) n√•r du bruker modellen i henholdsvis oppgave d) og e)? 6.1.3 R-√∏ving Vi har lastet ned den daglige prisen p√• Eqinoraksjen over en 5-√•rs periode fra Oslo B√∏rs‚Äô hjemmeside. Vi laster inn datasettet som f√∏r ved hjelp av readxl-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker rev()-funksjonen til √• reversere rekkef√∏lgen til observasjonene slik at den f√∏rste verdien komme f√∏rst: library(readxl) equinor &lt;- read_excel(&quot;equinor.xlsx&quot;) pris &lt;- rev(equinor$Siste) Du kan s√• lage et raskt plott av tidsrekken: plot(pris, type = &quot;l&quot;) B√•de glidende gjennomsnitt og eksponensiell glatting har flere ulike implementeringer i R. For glidende gjennomsnitt skal vi bruke funksjonen rollmean() i pakken zoo. Du m√• f√∏rst installere pakken og laste den inn; install.packages(&quot;zoo&quot;) library(zoo) Hvis du leser litt p√• dokumentasjonen til rollmean() ved √• kj√∏re ?rollmean vil du se at du kan regne ut f.eks et glidende gjennomsnitt for Equinoraksjen med vindusst√∏rrelse 5 ved √• kj√∏re pris_glatt5 &lt;- rollmean(pris, k = 5, fill = NA) Da f√•r vi ut en ny vektor med lik lengde som den vi hadde, og som inneholder den glattede versjonen. Den fyller opp verdiene i starten og slutten som vi ikke kan regne ut med et glidende gjennomsnitt med NA, slik at vi kan tegne inn den glattede versjonen i samme plott som vi viste selve tidsrekken: lines(pris_glatt5, col = &quot;red&quot;) Dersom du er interessert kan du lese mer her om hvordan det glidende gjennomsnittet blir brukt som en investeringsstrategi. Tanken er at det glidende gjennomsnittet representerer den langsiktige trenden. Dersom tidrekken ligger under det glidende gjennomsnittet tolkes det som at aksjen er p√• vei nedover, og motsatt: dersom prisen ligger over det glidende gjennomsnittet, s√• er det et tegn p√• at aksjen er p√• vei oppover. N√•r de to seriene krysser hverandre g√•r ‚Äúalarmen‚Äù, og man tar stilling til om man skal kj√∏pe eller selge. Vindusst√∏rrelsen velger man ut fra hvor hyppig man handler. For profesjonelle investorer som driver med handel i h√∏y hastighet kan kanskje 5-dagersviduet som vi regnet ut over v√¶re nok. Andre med mellomlang og lang sikt vil gjerne bruke et vindu p√• 50 eller 200 dager. Oppgave: Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 200 for Equinoraksjen, og tegn det inn i figuren du har laget. Hjelper denne figuren deg til √• lage en investeringsstrategi? Et problem med analysen over er at vi trenger fremtidige observasjoner til √• regne ut den glattede tidsrekken. Det betyr at vi kjenner den glattede versjonen av tidsrekken ved tid \\(t\\) f√∏rst ved tid \\(t+200\\). Vi kan enkelt lage en annen variant der vi glatter tidsrekken ved tid \\(t\\) ved √• ta gjennomsnittet av \\(Y_{t-200}, Y_{t-199}, \\ldots, Y_{t-1}\\) i stedet for \\(Y_{t-100}, \\ldots, Y_{t}, \\ldots, Y_{t+100}\\), alts√• at vi bare bruker fortiden. Det gj√∏r du i R ved √• legge til det ekstra argumentet align = &quot;right&quot; i funksjonen rollmean. Fordelen n√• er at vi ved hvert tidspunkt kjenner b√•de prisen p√• aksjen og den glattede varianten. Oppgave: Regn ut et glidende gjennomsnitt med vindusst√∏rrelse 200 for Equinoraksjen som hele tiden bruker tidligere observasjoner i glattingen. Tegn glattingen inn i figuren. Hvordan ser investeringsstrategien din ut n√•? Eksponensiell glatting har ogs√• et annet navn: Holt Winters Metode. En funksjon for √• gjennomf√∏re den finnes innebygget i R, og heter HoltWinters(). I denne funksjonen er vektparameteren \\(w\\) representert ved argumentet alpha. Funksjonen har noen flere argumenter som ikke vi skal bruke, s√• dersom vi √∏nsker √• regne ut den eksponensielle glattingen for Equinoraksjen med \\(w = 0.5\\), kj√∏rer vi: pris_exp1 &lt;- HoltWinters(pris, alpha = .5, beta = FALSE, gamma = FALSE) For √• hente ut den glattede versjonen skriver vi pris_exp1$fitted[,&quot;xhat&quot;] Oppgave: Lag en ny figur der du tegner inn aksjeprisen, samt den eksponensielle glattingen med hhv. \\(w = 0.5\\), \\(w = 0.01\\) og \\(w = 0.99\\). "],["trend-og-sesong.html", "6.2 Trend og sesong", " 6.2 Trend og sesong 6.2.1 Kontrollsp√∏rsm√•l Hvilke tre komponenter kan en tidsrekke typisk best√• av? 6.2.2 R-√∏ving 1. Data. I pakken fpp finnes en tidsrekke som heter ausbeer, som er den kvartalsvise produksjonen av √∏l i Australia fra 1956 til 2008. Du kan f√• tak i det og se p√• tidsrekken ved √• kj√∏re f√∏lgende kommandoer: install.packages(&quot;fpp&quot;) library(fpp) plot(ausbeer) Vi ser at det er en klar trendkomponent, selv om den ikke er line√¶r, samt en √•rlig sesongvariasjon. 2. Dekomponering. Funksjonen stl dekomponerer tidsrekken i de tre komponentene: trend, sesong, og tilfeldig variasjon. For √• f√• tilgang p√• denne funskjonen trenger vi pakken forecast: install.packages(&quot;forecast&quot;) library(forecast) Vi s√• kan kj√∏re funksjonen slik: dekomponert &lt;- stl(ausbeer, s.window = &quot;periodic&quot;) Vi kan hente ut de ulike komponentene ved √• bruke dollartegnet: dekomponert$time.series. Pakken forecast har en egen plottefunksjon, autoplot som er spesialdesignet for tidsrekkeobjekter. Pr√∏v √• plotte de tre komponentene hver for seg ved √• kj√∏re: autoplot(dekomponert) 3. Predikere. For predikering bruker vi funksjonen forecast(), som tar en estimert modell som input, og som bruker modellen til √• skrive frem tidsrekken ved √• estimere fremtidige verdier. Dekomponeringen over utgj√∏r ogs√• en modell som vi kan bruke til √• predikere fremtidige observasjoner med. Kodesnutten under viser hvordan man predikerer \\(10\\) tidssteg frem i tid ved √• sette h = 10 i funksjonen. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi level = 0.95 for \\(95\\%\\) prediksjonsintervall. Resultatet lagrer vi i objektet prediksjon. Dette objektet kan vi plotte ved bruk av autoplot-funksjonen: prediksjon &lt;- forecast(dekomponert, h = 10, level = 0.95) autoplot(prediksjon) "],["ar.html", "6.3 AR(p)", " 6.3 AR(p) 6.3.1 Kontrollsp√∏rsm√•l Hva er definisjonen p√• en Hvit-st√∏y-prosess? Hva er definisjonen p√• en AR(1)-prosess? Hvilken effekt har parameteren \\(\\phi\\) p√• egenskapene til en AR(1)-prosess? Hva er forskjellen p√• en AR(1)-prosess og en generell AR(\\(p\\))-prosess? Hvorfor kan vi si at AR(\\(p\\)) er en utvidelse/generalisering av hvit st√∏y? 6.3.2 R-√∏ving 1. Simulere. La oss f√∏rst se hvordan vi kan simulere noen realiseringer fra disse tidsrekkene. Hvit st√∏y best√•r av ukorrelerte trekninger som alle har samme forventningsverdi og varians, noe vi kan simulere i R ved √• bare trekke \\(n\\) uavhengige observasjoner fra hvilken som helst fordeling og kalle det en tidsrekke. For eksempel har vi tidligere trukket standard normalfordelte observasjoner ved hjelp av rnorm()-funsksjonen. La oss gj√∏re det igjen, og plotte det som en tidsrekke. Merk at din trekning ikke vil v√¶re identisk som den under: n &lt;- 50 hvit_st√∏y &lt;- rnorm(n) plot(hvit_st√∏y, type = &quot;b&quot;) Vi kan bruke funksjonen arima.sim() til √• simulere tidsrekker fra AR-modellen (og den mer generelle ARIMA-modellen, mer om det senere). Du kan for eksempel simulere \\(n\\) observasjoner fra en AR(1)-prosess med \\(\\phi = 0.95\\) ved hjelp av f√∏lgende kommandoer: ar1 &lt;- arima.sim(model = list(ar = 0.95), n) plot(ar1, type = &quot;b&quot;) I det siste eksempelet trekker arima.sim()-funskjonen hvit-st√∏y-prosessen \\(u_t\\) fra rnorm()-funksjonen, men det kan vi endre p√• hvis vi vil, se hjelpesiden ?arima.sim. Videre kan vi bruke denne funksjonen til √• simulere fra hvit st√∏y ved √• sette model-argumentet til en tom liste (model = list()), eller vi kan simulere fra en AR(2)-prosess med \\(\\phi_1 = 0.2\\) og \\(\\phi_2 = 0.1\\) ved √• sette model = list(ar = c(0.2, 0.1)). 2. Estimere. La oss i f√∏rste omgang si at vi har observert tidsrekken ar1 som vi simulerte over, at vi mistenker at den f√∏lger en AR(1)-prosess \\(Y_t = \\phi Y_{t-1} + u_t\\), og at vi √∏nsker √• estimere den ukjente parameteren \\(\\phi\\) ved hjelp av observasjonene. Som vi antydet i AR-videoen kan vi i dette tilfellet betrakte det som et regresjonsproblem med \\(Y_t\\) som responsvariabel og \\(Y_{t-1}\\) som forklaringsvariabel. La oss lage en data.frame med disse to kolonnene, og se hva vi f√•r n√•r vi bruker lm()-funksjonen. . df &lt;- data.frame(Y = ar1[2:n], lagged_Y = ar1[1:(n-1)]) summary(lm(Y ~ lagged_Y, data = df)) ## ## Call: ## lm(formula = Y ~ lagged_Y, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.67477 -0.52372 -0.00941 0.66069 1.48343 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.18783 0.15268 -1.230 0.225 ## lagged_Y 0.81625 0.08343 9.784 6.46e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.898 on 47 degrees of freedom ## Multiple R-squared: 0.6707, Adjusted R-squared: 0.6637 ## F-statistic: 95.72 on 1 and 47 DF, p-value: 6.456e-13 Vi ser at v√•rt estimat av \\(\\phi\\), som i regresjonutskriften er koeffisienten til lagged_Y, er i n√¶rheten av den sanne verdien 0.95, men med s√• f√• observasjoner kan det godt hende at ditt estimat er noe forskjellig. Poenget er: vi kan bruke line√¶r regresjon til √• estimere koeffisientene i en AR-modell basert p√• observasjoner. Som i forrige oppgave er pakken forecast sv√¶rt nyttig for estimering og predikering: library(forecast) Denne pakken inneholder en funskjon Arima for √• estimere koeffisientene i en AR-modell (egentlig den mer generelle klasssen av ARIMA-modeller som vi kommer tilbake til senere). Denne funksjonen kan vi andvende direkte p√• tidsrekken ved √• skrive Arima(ar1, order = c(1, 0, 0)) ## Series: ar1 ## ARIMA(1,0,0) with non-zero mean ## ## Coefficients: ## ar1 mean ## 0.8170 -0.7555 ## s.e. 0.0784 0.6324 ## ## sigma^2 estimated as 0.804: log likelihood=-65.02 ## AIC=136.05 AICc=136.57 BIC=141.78 I f√∏rste omgang kan vi legge merke til at vi har spesifisert hvilken modell vi √∏nsker √• estimere gjennom argumentet order = c(1, 0, 0), der ett-tallet angir AR-modellens orden \\(p\\), som i dette tilfellet er 1. Dersom du mistenker at AR(2)-modellen gir en bedre beskrivelse av tidsrekken din, kan du endre til order = c(2, 0, 0). Vi kommer tilbake til sp√∏rsm√•let om hvordan du kan velge den beste modellen for et gitt praktisk problem. Legg merke til at de to estimatene ikke er identiske selv om vi bruker det samme tidsrekken. Det er fordi arima()-funksjonen ikke bruker minste kvadraters metode til √• regne ut estimatene (slik lm() gj√∏r), men heller bruker en annen estimeringsteknikk som heter maximum likelihood. 3. Predikere. For predikering bruker vi funksjonen forecast(), som tar en estimert modell som input, og som bruker modellen til √• skrive frem tidsrekken ved √• estimere fremtidige verdier. I kodesnutten under bruker vi den simulerte tidsrekken, og estimerer en AR(1)-modell som over som vi lagrer i objektet ar1_estimat. S√• bruker vi det som argument i forecast(), der vi ogs√• spesifiserer hvor mange tidssteg fremover vi √∏nsker √• predikere, her velger vi h = 10. I tillegg kan funksjonen regne ut prediksjonsintervall med en gitt dekningsgrad, her velger vi level = 0.95 for \\(95\\%\\) prediksjonsintervall. Resultatet lagrer vi i objektet prediksjon. ar1_estimat &lt;- Arima(ar1, order = c(1, 0, 0)) prediksjon &lt;- forecast(ar1_estimat, h = 10, level = 0.95) Vi kan plotte resultatet i en pen liten figur ved √• bruke funksjonen autoplot som under: # Plotter den opprinnerlige tidsrekken, sammen med prediksjon og # prediksjonsintervall autoplot(prediksjon) "],["stasjonaritet.html", "6.4 Stasjonaritet", " 6.4 Stasjonaritet 6.4.1 Kontrollsp√∏rsm√•l Hva er definisjonen p√• en stasjon√¶r tidsrekke? Hva er poenget med √• innf√∏re stasjonaritet som et konsept i tidsrekkeanalyse? Er AR(1) prosessen \\(X_t = 1.5 X_{t - 1} + u_t\\) stasjon√¶r? 6.4.2 Merk En AR-prosess kan vi definere ogs√• med et konstantledd \\(c\\), f.eks: \\(Y_t = c + \\phi Y_{t-1} + u_t\\). Vi kan ikke forvente at alle tidsrekkene vi observerer i praksis vil ligge √• variere rundt null (dvs at E\\((Y_t) = 0\\)). Vi kan flytte den opp og ned ved √• legge til den samme konstanten \\(c\\) i hver tidssteg. I forrige oppgavesett, der vi estimerte parameteren \\(\\phi\\) i en AR(1)-modell, kom det (p√• samme m√•te som n√•r vi gj√∏r regresjon) ut et estimat av et intercept, som alts√• er denne \\(c\\)‚Äôen. I den simulerte tidsrekken vi jobbet med der, var det ikke noe konstantledd (alts√•, \\(c = 0\\)), som vi ser igjen i estimatene ved at de ikke er signifikant forskjellige fra null. Vi kunne tvunget estimeringsfunksjonene til √• sette \\(c = 0\\), f.eks ved √• inkludere argumentet include.mean = FALSE i arima()-funksjonen. "],["autokorrelasjon.html", "6.5 Autokorrelasjon", " 6.5 Autokorrelasjon 6.5.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Formuler med egne ord: Hva er autokorrelasjon? Hva kan vi l√¶re ved √• se p√• autokorrelasjonsplottet til en tidsrekke? Kan du komme p√• noe vi ikke kan finne ut av ved √• se p√• korrelasjoneplottet til en tidsrekke? 6.5.2 R-√∏ving 1. Utregning av ACF I R bruker vi funsksjonen acf() til √• lage autokorrelasjonsplott. La oss i f√∏rste omgang gjenskape noen av figurene fra videoen ved hjelp av simuleringer. For eksempel kan vi laget til to tidsrekker som p√• forrige oppgavesett, en hvit st√∏y og en AR(1): n &lt;- 50 hvit_st√∏y &lt;- rnorm(n) ar1 &lt;- arima.sim(model = list(ar = 0.95), n) Autokorrelasjonsplottene til disse to tidsrekkene kan vi f√• frem ved √• anvende acf()-funksjonen p√• dem: acf(hvit_st√∏y) acf(ar1) Vi ser igjen m√∏nsteret fra videoen: Hvit st√∏y best√•r av ukorrelerte observasjoner, mens AR(1)-modellen best√•r av observasjoner som bygger p√• forrige observasjon, slik at det er en viss korrelasjon, og dermed avhengighet fra dag til dag. Det ser vi igjen i autokorrelasjonsplottet som gir tydelig utslag, og der korrelasjonen g√•r gradvis mot null med √∏kende avstand mellom observasjonene. 2. ACF som sjekk av modell En sjekk vi gjerne gj√∏r for √• se om en estimert tidsrekkemodell passer dataene v√•re, er √• se autokorrelasjonen til residualene i modellen er liten. Det betyr nemlig at modellen plukker opp den (line√¶re) avhengigheten i tidsrekken. For en AR(1) modell er residualene f.eks gitt ved \\(\\hat{u}_t = Y_t - \\hat{\\phi}Y_{t-1}\\), men disse er tilgjengelig direkte fra modell estimeringen i R: library(forecast) ar1_estimat &lt;- Arima(ar1, order = c(1, 0, 0)) acf(ar1_estimat$residuals) 3. Oppgave: Pr√∏v n√• lage et plott av f√∏lgende tre tidsrekker, plott autokorrelasjonsfunksjonen, og knytt en kort kommentar til hver av dem om hva du l√¶rer om tidsrekken ved √• se p√• autokorrelasjonsplottet til: Prisen p√• Equinor-aksjen, som vi jobbet med i det f√∏rste oppgavesettet. Equinoraksjens prosentvise avkastning (som er tiln√¶rmet lik diff(log(pris))) fra dag til dag. Tidsrekken som er igjen etter at du fjernet trend og sesong fra √∏lproduksjonstidsrekken i det andre oppgavesettet. Til slutt: husk at ogs√• autokorrelasjonsplottene m√• pyntes og ordnes p√• hvis vi skal vise dem til andre i rapporter, innleveringer etc. Du kan stort sett bruke de samme argumetene som i vanlige plott: xlab =, ylab =, main = osv. "],["ma.html", "6.6 MA(q)", " 6.6 MA(q) 6.6.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Hva er definisjonen p√• en MA(1)- og en MA(\\(q\\))-modell? Hvordan skiller definisjonen av en MA-prosess seg fra definisjonen av en AR-prosess? P√• hvilken m√•te er autokorrelasjonsfunksjonene til AR- og MA-prosesser forskjellige? Kan du, med egne ord, beskrive en type reelle fenomener som kan modelleres som en MA-prosess? 6.6.2 R-√∏ving 1. Estimering og predikering. P√• samme m√•te som for AR-prosessen kan vi n√• simulere og estimere en MA(1)-prosess med \\(\\theta = 0.95\\): library(forecast) # Trengs for estimering n &lt;- 100 # Antall observasjoner ma1 &lt;- arima.sim(model = list(ma = 0.95), n) # Simuler tidsrekken plot(ma1, type = &quot;b&quot;) # Lag et plott Arima(ma1, order = c(0,0,1)) # Estimer theta Stemmer estimatet overens med den sanne \\(\\theta\\)? Sjekk ut dokumentasjonen ?Arima og se hva du m√• gj√∏re for √• spesifisere at modellen ikke har noe konstantledd \\(c\\). Pr√∏v ogs√• √• modifisere koden fra AR-oppgavene slik at du predikerer den simulerte MA(1)-tidsrekken 10 steg frem. 2. Analyse av global temperatur. La oss n√•r ta for oss eksempelet fra videoen der vi ser p√• den globale m√•nendlige gjennomsnittstemperaturen fra 1880 til 2016. Last ned temp.csv, som er en CSV-fil med datasettet. Se p√• de f√∏rste par radene: temp &lt;- read.csv(&quot;temp.csv&quot;) head(temp) ## Date Mean ## 1 1880-01-06 0.0009 ## 2 1880-02-06 -0.1229 ## 3 1880-03-06 -0.1357 ## 4 1880-04-06 -0.0499 ## 5 1880-05-06 -0.0738 ## 6 1880-06-06 -0.1692 F√∏rste kolonne inneholder informasjon om tidspunkt, og temperaturen er inneholdt i andre kolonne. La oss plotte b√•de temperaturrekken og den differensierte temperaturrekken (dvs. forskjellen fra dag til dag). Hvis vi avsl√∏rer at den differensierte tidsrekken kan regnes ut ved √• kj√∏re difftemp &lt;- diff(temp$Mean), skulle det n√• v√¶re grei skuring √• produsere f√∏lgende to enkle plott: difftemp &lt;- diff(temp$Mean) plot(temp$Mean, type = &quot;l&quot;) plot(difftemp, type = &quot;l&quot;) Lag videre autokorrelasjonsplottet som vist i videoen for den differensierte tidsrekken: I autokorrelasjonsplottet ser vi nettopp et slikt MA-m√∏nster som vi s√• i videoen; nemlig at autokorrelasjonen plutselig blir null (eller omtrent null) for et gitt lag. I dette tilfellet har vi at f√∏rste ordens autokorrelasjon er klart forskjellig fra null, men at den fra og med \\(k = 2\\) nesten ikke har utslag. Hvis de differensierte temperaturm√•lingene faktisk er MA(1), kan den skrives slik: \\[Y_t = c + \\theta u_{t-1} + u_t,\\] der \\(\\theta\\) er en ukjent parameter. Vi kan bruke datasettet v√•rt til √• estimere \\(\\theta\\) ved √• bruke Arima()-funksjenen p√• samme m√•te som da vi estimerte en AR(1)-modell. Den eneste forandringen vi m√• gj√∏re er √• endre order-argumentet fra c(1, 0, 0) til c(0, 0, 1): Arima(difftemp, order = c(0, 0, 1)) ## Series: difftemp ## ARIMA(0,0,1) with non-zero mean ## ## Coefficients: ## ma1 mean ## -0.4988 0.0005 ## s.e. 0.0251 0.0012 ## ## sigma^2 estimated as 0.009078: log likelihood=1532.11 ## AIC=-3058.23 AICc=-3058.21 BIC=-3042.01 Hvis du har tid til slutt og vil ha litt ekstra trening kan du pr√∏ve deg p√• f√∏lgende oppgave: Prediker den differensierte temperaturrekken tre m√•neder frem i tid. Lag en figur der du plotter de 12 siste m√•nedene i den observerte tidsrekken sammen med prediksjonene dine med prediksjonsintervaller. Bonuspoeng: Husk at vi n√• har predikert forandringen i den globale gjennomsnittstemperaturen fra m√•ned til m√•ned. Kan du heller lage en figur med selve temperaturserien og bruke prediksjonene dine til √• heller plotte inn de tilh√∏rende predikerte temperaturene? Pynt s√• figuren slik at du kan sende den fra deg. "],["arma-arima.html", "6.7 ARMA og ARIMA", " 6.7 ARMA og ARIMA 6.7.1 Kontrollsp√∏rsm√•l/Diskusjonssp√∏rsm√•l Hva er sammenhengen mellom AR-, MA-, og ARMA-modellene? Hva er en ARIMA-modell? Hvilken modell er dette: \\[y_t = \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\theta u_{t-1} + u_t\\] 6.7.2 R-√∏ving 1. Data Vi tar en ny titt p√• den daglige prisen p√• Eqinoraksjen over en 5-√•rs periode som vi s√• p√• i introduksjonen til tidsrekker. Vi laster inn datasettet som f√∏r ved hjelp av readxl-pakken, og henter ut den aktuelle kolonnen. Legg merke til at vi bruker rev()-funksjonen til √• reversere rekkef√∏lgen til observasjonene slik at den f√∏rste verdien komme f√∏rst: library(readxl) equinor &lt;- read_excel(&quot;equinor.xlsx&quot;) pris &lt;- rev(equinor$Siste) plot(pris, type = &quot;l&quot;) Vi kan lage en figur av den differensierte tidsrekken p√• f√∏lgende m√•te: # Sjekk av differanse diff_pris &lt;- diff(pris) plot(diff_pris, type = &quot;l&quot;) Oppgave: Vurder om en ARIMA modell er bedre egnet enn en ARMA modell ut fra de to figurene over. 2. Estimering av ARIMA modeller Vi bruker den samme funksjonen Arima fra forecast pakken til √• estimere b√•de ARMA og ARIMA modeller og spesifisering av modellen gj√∏r vi via argumentet order. Skal du estimerer en ARMA(1,1) modell setter du f.eks dette argumentet til c(1, 0, 1). Elementet i midten av denne vektoren spesifiserer hvor mange ganger tidsrekken skal differensieres i ARIMA modellen. Estimering av en ARIMA modell med en enkelt differensiering og ett MA og AR ledd kan gj√∏res slik: library(forecast) arima111 &lt;- Arima(pris, order = c(1, 1 , 1)) 3. Hvordan skal vi velge p, d og q i en ARIMA(p,d,q) modell? Etter √• ha tilpasset en ARIMA modell kan vi bruke modellen til √• predikere de samme observasjonene vi har brukt til √• tilpasse modellen. Vi kan s√• sammenligne hvor n√¶r prediksjoner fra forskjellige modeller er de sanne dataene. Dette heter p√• godt norsk √• gj√∏re en ‚Äúin-sample‚Äù vurdering av modellen. N√•r du har tilpasset en modell, kan du ved √• bruke summary funksjonen f√• opp flere m√•l p√• hvor god modellen er in-sample under fanen ‚ÄúTraining set error measure‚Äù: summary(arima111) ## Series: pris ## ARIMA(1,1,1) ## ## Coefficients: ## ar1 ma1 ## 0.5121 -0.5780 ## s.e. 0.1680 0.1584 ## ## sigma^2 estimated as 6.614: log likelihood=-2958.16 ## AIC=5922.32 AICc=5922.34 BIC=5937.72 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.03973471 2.568719 1.949446 0.009091475 1.251353 0.9955157 ## ACF1 ## Training set 0.02035596 Her er f.eks \\(RMSE = \\sqrt{1/T\\sum_{t = 1}^T (\\hat{y}_t - y_t)^2}\\) et slags gjennomsnittlig avvik mellom prediksjonene og observasjonene. Litt lenger oppe i summary utskriften er det ogs√• en st√∏rrelse som heter AIC som m√•ler hvor sannsynlig hver observasjon er gitt modelvalget ditt. Sammenligner du flere modeller er du p√• jakt etter den modellen som har minst RMSE og/eller AIC. Det krever en del arbeid skal du sammenligne mange ARIMA(p,d,q) modeller ettersom det er s√• mange m√•ter √• kombinere p,d og q p√• selv om du bestemmer en maksverdi for hver av dem. Det finnes heldigvis en veldig smart R funksjon kalt auto.arima som f√∏lger med pakken forecast som estimerer mange modeller og gir deg ut den modellen med minst AIC: arima_best_AIC &lt;- auto.arima(pris) summary(arima_best_AIC) ## Series: pris ## ARIMA(0,1,2) ## ## Coefficients: ## ma1 ma2 ## -0.0421 -0.0947 ## s.e. 0.0282 0.0281 ## ## sigma^2 estimated as 6.581: log likelihood=-2955.04 ## AIC=5916.09 AICc=5916.1 BIC=5931.48 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0398931 2.56232 1.948444 0.009249629 1.249956 0.9950042 ## ACF1 ## Training set -0.001297121 Hva slags modell har auto.arima valgt her? 4. Prediksjon Prediksjon gj√∏res som tidligere med forecast funksjonen, s√• hvis en vil predikere 10 tidssteg frem i tid gj√∏r man f√∏lgende: pred_arima111 &lt;- forecast(arima111, h = 10) autoplot(pred_arima111, include = 100) merk at i autoplot har vi valgt √• bare vise 100 observasjoner av tidsrekken sammen med prediksjonene "],["modellbygging-1.html", "6.8 Modellbygging", " 6.8 Modellbygging Vi har allerede sett p√• hvordan vi kan sammenligne modeller ‚Äúin-sample‚Äù. For √• sammenligne tidsrekkemodeller bruker en ofte ogs√• √• sammenligne hvor godt modellene predikerer observasjoner som ikke har v√¶rt inkludert n√•r man tilpasser modellen. Dette heter p√• godt norsk √• vurdere ‚Äúout-of-sample‚Äù egenskapene ved modellen. Det finnes mange varianter for √• unders√∏ke dette, og under skal vi ta en titt p√• en enkel variant. Oppgave Vi viser hvordan dette gj√∏res for en modell med eksponensiell glatting. Du skal gjenta prosedyren, men for en ARIMA-modell (velg den med best AIC, hint: auto.arima). Sammenlign s√• out-of-sample egenskapene til til disse to modellene. 6.8.1 R-√∏ving 1. Data Vi skal i denne √∏vingen pr√∏ve √• finne en god modell for dax-indeksen: library(forecast) dax &lt;- EuStockMarkets[ ,1] plot(dax) 2. Trening og test data Vi √∏nsker f.eks √• teste hvor god modellen er til √• predikere de 10 siste observasjonene i datasettet. Vi deler derfor dataene inn i et treningssett best√•ende av alle observasjoner utenom disse 10 siste observasjonene, og et testsett best√•ende av de 10 siste observasjonene: trening &lt;- head(dax, length(dax) - 10) test &lt;- tail(dax, 10) 3. Estimering og prediksjon Vi tilpasser s√• en modell til treningssettet ved bruk av eksponensiell glatting og predikerer 10 tidssteg frem for √• f√• prediksjoner av testsettet: fit_exp &lt;- HoltWinters(trening) pred_exp &lt;- forecast(fit_exp, h = 10) Merk at n√•r vi ikke spesifiserer noen argumenter i HoltWinters vil en mer avansert modell bli tilpasset, samtidig som glattingsparameteren faktisk vil bli estimert ved √• minimerer MSE. 3. Out-of-sample vurdering Vi kan s√• sammenligne disse prediksjonene pred_exp med de faktiske observasjonene test ved √• ‚Äúm√•le‚Äù hvor langt disse er fra hverandre. Funksjonen accuracy som kommer med forecast pakken regner ut flere forskjellig m√•l p√• avstand: accuracy(pred_exp, test) ## ME RMSE MAE MPE MAPE MASE ## Training set 1.251117 35.82454 23.42652 0.03438446 0.8276219 0.04295353 ## Test set -317.477645 350.63504 317.47765 -5.82900543 5.8290054 0.58210884 ## ACF1 Theil&#39;s U ## Training set 0.07394258 NA ## Test set 0.62441059 3.510695 Hver kolonne i utskriften over representerer et slikt m√•l, og det er rad nummer to med navn ‚ÄúTest set‚Äù som vi er interessert i siden det er utregningen av disse m√•lene mellom prediksjonene og testsettet (Den f√∏rste raden representerer in-sample egenskapene). Jo mindre disse verdiene er jo mindre er avstanden mellom prediksjonene og de sanne verdiene i v√•rt testsett. "],["data√∏vinger.html", " 7 Data√∏vinger", " 7 Data√∏vinger Blabla intro til √∏vinger "],["data√∏ving-1.html", "7.1 Data√∏ving 1", " 7.1 Data√∏ving 1 7.1.1 Innledning Velkommen til den f√∏rste data√∏velsen i MET4. I denne √∏velsen skal vi bli litt kjent med verkt√∏yene R og Rstudio som brukes i datalabbene. Disse verkt√∏yene er ogs√• essensielle for gjennomf√∏ringen av den obligatoriske innleveringen og p√• hjemmeksamen. Den f√∏rste delen av √∏vingen inneholder praktisk informasjon om bruk av R og Rstudio etterf√∏lgt av oppgaver. 7.1.2 Om R og Rstudio R er et program/programmeringsspr√•k som er spesialdesignet til √• utf√∏re statistiske analyser. R er basert p√• at du m√• skrive forskjellige kommandoer for √• utf√∏re utregninger og analyser. Gjennomsnittet av 3, 2 og 5 finner man for eksempel ved √• skrive: mean(c(3,2,5)) Dette kan for mange v√¶re litt uvant i starten, men datalabbene vil gi deg god trening p√• denne type tankegang. Rstudio er et program som gj√∏r det enklere √• bruke R. P√• samme m√•te som Word kan hjelpe deg til √• lage fine og oversiktlige tekster, kan Rstudio hjelpe deg til √• utf√∏re fine og oversiktlige statistiske analyser. Rstudio er et redigeringsprogram som vi i dette kurset skal bruke til √• redigere og utf√∏re R-kommandoer. 7.1.2.1 Installere R og Rstudio Bruker du din egen datamaskin kan du enkelt laste ned og installere R og Rstudio. Begge programvarene er gratis og kan installeres med √• f√∏lge instruksene under. F√•r du problemer kan du f√• en av studentassistentene til √• hjelpe deg. Start med √• installere R: G√• til r-project.org Last ned versjonen som passer ditt operativsystem (Windows/Mac/Linux) Kj√∏r installasjonsfilen og f√∏lg instruksene. Standard innstillingene skal v√¶re greie √• bruke, s√• du kan trykke neste/ok til installasjonen er ferdig. Installer s√• RStudio: rstudio.com, og naviger deg frem til siden for RStudio. Du skal der laste ned desktop-versjonen av programmet (‚ÄúOpen source edition‚Äù) for ditt operativsystem og installere p√• vanlig m√•te. Kj√∏r installasjonsfilen som lastes ned og f√∏lg instruksene 7.1.2.2 Vinduene i Rstudio og det √• jobbe med R F√∏rste gang du √•pner Rstudio vil du se tre vinduer. Et fjerde vindu √•pner du med √• klikke p√• File i menyen, s√• New File, og s√• R Script. Figur 7.1 viser en oversikt over de fire vinduene. Det er viktig at du forst√•r forskjellen p√• de to vinduene til venstre. Figur 7.1: Oversikt over vinduene i RStudio. Nederste vindu til venstre (b) viser R-konsollen og det er her alle utregninger blir gjennomf√∏rt. I dette vinduet kan du for eksempel skrive (3*5 - 3/4)*(2 + 2) ## [1] 57 Her er \\((3*5 - 3/4)*(2 + 2)\\) en s√•kalt kommando og det er programmet R som finner ut hva du mener med kommandoen og gir deg svaret \\(57\\) i retur. Du kan se at R tillater standard matteoperasjoner som gange, deling, pluss og minus (*, /, +, -). R er det vi kaller ‚Äòobjektbasert‚Äô, som betyr at du kan definere ‚Äòobjekter‚Äô. Utregningen over kan for eksempel ogs√• regnes ut ved √• skrive: a &lt;- 3*5 - 3/4 b &lt;- 2 + 2 a*b ## [1] 57 Her er a og b objekter som vi definerer ved bruk av ‚Äòtildelingspilen‚Äô &lt;- (du kan ogs√• bruke =). Det g√•r an √• lagre objekter i egne filer, men vi skal se at det stort sett er smartere √• lagre ‚Äòoppskriften‚Äô (selve koden) p√• hvordan de lages i en egen .R fil. Det √∏verste vinduet til venstre (a) viser en .R fil (et skript). En .R fil fungerer som et manuskript med R-kommandoer (kode) og kan lagres slik at du kan senere kan se hvilke kommandoer du har brukt i analysen og eventuelt fortsette der du slapp. I Del 2 av denne data√∏vingen skal du selv lage en .R fil som inneholder alle kommandoer som brukes i en enkel analyse. N√•r du vil at R skal utf√∏re noen av kommandoene du har skrevet i .R filen markerer du bare disse (eller lar pekeren st√• i linjen du vil kj√∏re) og trykker ctrl + Enter (Cmd + Enter p√• Mac): Figur 7.2: Utf√∏relse av kommandoer du har skrevet i R filen. Marker eller la pekeren st√• i linjen du vil kj√∏re og trykk ctrl + Enter (Cmd + Enter p√• Mac) Vinduet nederst til h√∏yre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet √∏verst til h√∏yre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en n√¶rmere titt p√• et datasett du har lest inn. Vinduet nederst til h√∏yre (d) vil vise blant annet figurer du lager og hjelpetekst. Vinduet √∏verst til h√∏yre (c) gir deg en oversikt over hvilke objekter du har laget og er spesielt nyttig hvis du vil ta en n√¶rmere titt p√• et datasett du har lest inn. Det er viktig at du forst√•r forskjellen p√• de to vinduene til venstre, alts√• .R filen og konsollen. R kode du √∏nsker √• ta vare p√• og som er en essensiell del av analysen skriver og lagrer du i .R filen, mens sm√• eksperimenter og unders√∏kelser kan du gjerne gj√∏re direkte i konsollen. For de av dere som er glad i hurtigtaster finnes det en oversikt i Rstudio som kommer opp dersom du trykker Alt + Shift + K (Option + Shift + K p√• Mac). Ofte vil man f.eks m√•tte skifte musepeker fra R-filen til konsoll og motsatt, og hurtigtaster for √• veksle mellom disse er Ctrl + 1 (R-fil) og Ctrl + 2 (konsoll). Hurtigtasten du kommer til √• bruke desidert mest er ctrl + Enter for √• kj√∏re kode fra R-skriptet ditt i konsollen (P√• Mac erstatter du ctrl med command over alt). 7.1.2.3 Funksjoner, dokumentasjon og R-pakker I R kan man lage egne funksjoner som utf√∏rer det en m√•tte √∏nske, f.eks en funksjon som regner ut t-observatoren gitt en vektor med observasjoner x og en gitt \\(\\mu_0\\): t.observator &lt;- function(x, mu0){ t &lt;- (mean(x) - mu0)/(sd(x)/sqrt(length(x))) return(t) } R kommer med en rekke ‚Äúinnebygde‚Äù funksjoner som kan utf√∏re ulike statistiske analyser. For eksempel kan en t-test utf√∏res med √• bruke en funksjon som heter nettopp t.test. Alle slike funksjoner kommer med en dokumentasjon som viser hva funksjonen gj√∏r og hvordan den skal brukes. For √• tilgang til denne dokumentasjonen skriver man ? foran funksjonen i konsollen. Skriver du f.eks ?t.test ser du at det dukker opp en side i vinduet nede til h√∏yre: Figur 7.3: Dokumentasjon av funksjoner dukker opp i et vindu nede til h√∏yre. Dette vinduet kan √•pnes til et st√∏rre vindu som vist over Dokumentasjonen vil som hovedregel inneholder en kort beskrivelse av hva funksjonen gj√∏r, hvilke argumenter funksjonen tar og hva den gir ut. Helt i slutten av dokumentasjonen er det ofte et eksempel p√• hvordan funksjonen kan brukes og er ofte sv√¶rt nyttig √• se p√•. Selv om det finnes mange funksjoner som allerede er innebygget i R, m√• man noen ganger installere ekstra ‚Äòpakker‚Äô for √• f√• tilgang til spesielle funksjoner. I oppgave 2.2 i denne √∏velsen vil vi g√• gjennom hvordan dette gj√∏res for en bestemt pakke. 7.1.2.4 Skriv pen R-kode! Det er viktig at R-koden du skriver er veldokumentert og skrevet p√• en oversiktlig og pen m√•te. Hvis vi √∏nsker √• skrive kommentarer til koder som st√•r i .R filen bruker vi tegnet # foran kommentaren. Dette gj√∏r at R ikke pr√∏ver √• evaluere kommentaren som en R-kode. Det finnes en rekke konvensjoner n√•r det kommer til mellomrom, linjeskift, navngivning av objekter og lignende. Vi anbefaler tipsene som er oppsummert p√• (http://adv-r.had.co.nz/Style.html)[http://adv-r.had.co.nz/Style.html], men det er selvsagt lov √• ha sine egne preferanser. Under ser du et eksempel p√• d√•rlig praksis ved R-koding. Her er det manglende dokumentasjon, d√•rlig navngivning og ingen ‚Äòluft‚Äô i form av mellomrom og linjeskift. Dette gj√∏r at du eller andre vil m√•tte bruke un√∏dvendig tid p√• √• finne ut hva koden faktisk gj√∏r p√• et senere tidspunkt. # D√•rlig praksis: library(readxl) library(tidyverse) d&lt;-readxl(file=&quot;financedata.xlsx&quot;,sheetIndex = 1) %&gt;% na.omit() √ò95&lt;-mean(d$value)-qt(0.975,df=length(d$value)-1)*sd(d$value) N95&lt;-mean(d$value)+qt(0.975,df=length(d$value)-1)*sd(d$value) F√∏lgende R kode gir det samme resultatet men er mye mer oversiktlig siden den er mer luftig, er brutt ned i biter, er godt dokumentert og har fornuftige objektnavn: # God praksis: # ---------- Analyse av data # N√∏dvendige pakker i analysen library(readxl) library(tidyverse) # Les data, fjern NA-verdier og hent ut gjeld my_data &lt;- readxl(file = &quot;financedata.xlsx&quot;, sheetIndex = 1) %&gt;% na.omit() debt &lt;- my_data$debt # Konfidensintervall n_obs &lt;- length(debt) # antall observasjoner alpha &lt;- 0.05 # signifikansniv√• average &lt;- mean(debt) # gjennomsnitt st_dev &lt;- sd(debt) # standardavvik lower &lt;- average - qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # nedre grense upper &lt;- average + qt(1 - alpha/2, df = n_obs - 1)*st_dev/sqrt(n) # √∏vre grense Vi oppfordrer deg til √• pr√∏ve √• skrive R-kode som er pen og oversiktlig i datalabbene fremover. D√•rlige vaner kan v√¶re vonde √• vende! 7.1.3 Oppgave 1: Interaktiv √∏velse Her skal du bruke et l√¶ringsverkt√∏y kalt swirl som vil ta deg gjennom en interaktive √∏velse hvor du m√• utf√∏re forskjellige oppgaver i konsollen. I flere av data√∏vingene vil det v√¶re en slik interaktiv del. Her er tanken at du skal leke deg litt med R. F√∏r du kan begynne m√• du installere swirl. Kopier derfor f√∏lgende tre linjer og lim dem inn i R-konsollen: install.packages(&quot;swirl&quot;) library(swirl) install_course(&quot;R Programming&quot;) For √• starte swirl skriver du s√• f√∏lgende i konsollen: swirl() Du vil i starten bli bedt om √• skrive inn ditt navn og s√• f√∏lger litt info om hvordan swirl fungerer. Du blir s√• bedt om √• velge kurs. Her skal du velge alternativet ‚ÄòR Programming‚Äô (1 og s√• enter). Du f√•r s√• se alle modulene dette kurset inneholder: I denne √∏vingen skal du pr√∏ve deg p√• modul 1 ‚ÄòBasic Building Blocks‚Äô, modul 4 ‚ÄòVectors‚Äô (kun f√∏rste halvdel), og modul 12 ‚ÄòLooking at Data‚Äô. I modul 1 vil du l√¶re litt om de mest grunnleggende operasjonene som kan gj√∏res i R. Modul 4 ser n√¶rmere p√• vektorer og her er f√∏rste halvdel av modulen mest relevant. Modul 12 tar for seg det √• utforske strukturen p√• et datasett. Start med modul 1 (1 og s√• enter). Du vil bli bedt om √• gj√∏re enkle operasjoner i R og av og til m√• du svare p√• multiple choice sp√∏rsm√•l: Merk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.1.4 Oppgave 2: Innlesning av data og deskriptiv statistikk i R I denne oppgaven skal vi lese inn noen data og produsere enkel deskriptiv statistikk av disse dataene. Dataene kommer fra et amerikansk fors√∏k hvor man ville unders√∏ke p√•standen om at voldelige dataspill f√∏rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det ‚Äúvoldelige‚Äù dataspillet var oppdraget √• skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille√∏kt ble deltakernes aggresjonsniv√• m√•lt p√• en skala fra 1 til 9 ved hjelp av en standard psykologisk test. Dette datasettet ble brukt i eksamensoppgaven v√•rsemesteret 2019. Oppgave 2.1. Last ned filen violence.xslx. Denne filen lagrer du fortrinnsvis i en egen mappe der du √∏nsker at filer fra denne √∏vingen skal ligge. √Öpne s√• RStudio, velg File -&gt; New File -&gt; R Script for √• √•pne et nytt Rscript. Lagre s√• scriptet ditt i samme mappen som du har lagt datasettet, slik at du n√• har en mappe som ser ut som figuren under: N√•r vi skal lese inn data, lagre figurer og andre ting har R en standard ‚Äòmappesti‚Äô (working directory) den leter/lagrer i. Du kan se hva denne stien peker p√• ved √• skrive i konsollen. Du skal n√• spesifisere denne mappestien til mappen du har opprettet. Dette gj√∏r du raskest ved √• velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du √•pne RStudio ved √• dobbeltklikke p√• data√∏ving1.R, og mappestien skal da settes automatisk til riktig mappe. Lag gjerne en liten overskrift ved hjelp av kommentartegnet # slik at .R filen din ser omtrent slik ut: Oppgave 2.2. Du skal n√• lese inn excel filen du lagret i over i R. Selv om det finnes mange funksjoner som allerede er innebygget i R, m√• man noen ganger installere ekstra ‚Äòpakker‚Äô for √• f√• tilgang til spesielle funksjoner. For √• lese inn en excel fil trenger du nettopp en slik ikke standard funksjon. Denne finnes i pakken readxl. Selve installeringen kan du gj√∏re direkte i konsollen med √• skrive (hvis du ikke har gjort det allerede): install.packages(&quot;readxl&quot;) Pakken legger seg da i en bibliotekmappe der R er installert. For √• gi R beskjed om √• laste inn funksjonene til pakken du nettopp installerte bruker du funksjonen library. Du har n√• tilgang til en funksjon kalt read_excel() som du kan bruke til √• lese inn excel filen: # MET4 - Data√∏ving 1 # ------------------ # les inn data library(readxl) violence &lt;- read_excel(&quot;violence.xlsx&quot;) Marker linjene du nettopp skrev i R-skriptet ditt og trykk ctrl + enter (cmd + enter), for √• opprette objektet violence som inneholder datasettet. Funksjonen ls lister opp alle objekter som har blitt definert. Du kan pr√∏ve selv √• skrive f√∏lgende i konsollen: ls() ## [1] &quot;violence&quot; Du ser at det har kommet et nytt objekt som heter violence. En tilsvarende oversikt finner du i vinduet √∏verst til h√∏yre i Rstudio (se Figur 7.1) hvor du ogs√• kan klikke p√• objektet for √• se n√¶rmere p√• det. Oppgave 2.3. Ta en titt p√• strukturen til datasettet du nettopp leste inn. Husker du kanskje noe fra den interaktive √∏velsen ‚ÄòLooking at Data‚Äô? N√•r du gj√∏r slike sm√• utforskninger kan du gjerne jobbe direkte i konsollen, og det du gj√∏r i dette punktet trenger n√∏dvendigvis ikke v√¶re med i .R-filen din. G√• til konsollen og bruk funksjoner som class, dim, names, head og str for √• utforske strukturen p√• dataene. Vi ser at det er 5 variabler: id er bare et tall som identifiserer fors√∏kspersonen. aggression_level er aggresjonsniv√•et som ble m√•lt rett etter at fors√∏kspersonen hadde spilt en viss tid. violent_treatment er varianten av dataspillet som fors√∏kspersonen ble utsatt for; enten Violent eller Less Violent. difficulty_treatment er vanskelighetsgraden av spillet, som enten var Easy eller Hard. En mulig forklaring p√• aggressiv adferd er at vanskelige spill f√∏rer til h√∏yere stressniv√•, som igjen kan f√∏re til aggressivitet. experienced_violence er svaret til fors√∏kspersonen p√• sp√∏rsm√•let om vedkommende oppfattet spillet som Violent eller Less Violent. Fors√∏kspersonene visste ikke selv hva forss√∏ket gikk ut p√•, eller at det var flere varianter av det samme spillet. Oppgave 2.4 Vi skal se n√¶rmere p√• om aggresjonsniv√•et er forskjellig i de to gruppene. Da m√• vi trekke ut de aktuelle tallene fra datasettet. Vi √∏nsker √• velge ut to vektorer for √• gj√∏re denne sammenligningen: en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene f√• navn voldelig og ikke_voldelig, og lag dem ved √• skrive f√∏lgende kodelinjer: # Vektorer med aggresjonsniv√• til gruppen som har spilt voldelig/ikke-voldelig spill voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] ikke_voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Less Violent&quot;] Sjekk n√• at dette har fungert ved √• skrive voldelig og ikke_voldelig inn i konsollen for √• se at det faktisk er vektorer som inneholder tallene 1 ‚Äì 9. Bruk ogs√• noen minutter til √• pr√∏ve √• forst√• hva kodelinjene over faktisk gj√∏r. Her er noen punkter som kan hjelpe til med √• obdusere den f√∏rste linjen: violence$aggression_level henter ut kolonnen aggression_level fra datasettet violence. Vi kan bruke firkantparantes [ ] til √• hente ut spesifikke elementer fra en vektor. Her skal vi hente ut bestemte elementer fra vektoren violence$aggression_level, og vi kan for eksempel skrive violence$aggression_level[1], violence$aggression_level[1:10] eller violence$aggression_level[c(1, 5)] for √• hente ut henholdsvis det f√∏rste, de ti f√∏rste, eller det f√∏rste og det femte tallet i vektoren. (Pr√∏v!) Vi skal hente ut noen helt bestemte tall fra violence$aggression, nemlig de m√•lingene som tilh√∏rer testpersonene som har violent_treatment lik &quot;Violent&quot;. Alle disse kan vi finne ved √• skrive inn violence$violent_treatment == &quot;Violent&quot;. Pr√∏v det. Du vil da f√• ut en vektor fylt med enten TRUE eller FALSE, alt etter om den tilh√∏rende fors√∏kspersonen har violent_treatment lik Violent eller ikke. Denne vektoren kan vi bruke til √• hente ut tall som svarer til TRUE fra violence$aggression_level ved √• putte den i firkantparanteser. Det er det som st√•r til h√∏yre for tilordningen &lt;-. Til slutt lagrer vi resultatet i vektoren voldelig. (NB! Pass p√• at du skriver Violent og Less Violent helt riktig med store og sm√• bokstaver, ellers vil det ikke fungere!) Oppgave 2.5. I eksamensoppgaven fra 2019 f√•r vi oppgitt deskriptiv statistikk over aggresjonsniv√•et for de to gruppene i f√∏lgende tabell: Bruk funksjoner som min(), max(), median(), mean(), length() og summary() til √• finne ut om tallene stemmer. Hvordan kan det ha seg at tallene ikke er identiske? Oppgave 2.6. Vi skal n√• lage et histogram av hver av gruppene du lagret som vektorer i tidligere, og vi skal gj√∏re det p√• to m√•ter: F√∏rst skal vi bruke plottefunksjonene som f√∏lger med R (‚ÄúBase R‚Äù). S√• skal vi gj√∏re det samme ved hjelp av ggplot-pakken. Vi skal f√∏rst bruke funksjonen hist() som alts√• f√∏lger med R-installasjonen din. De fleste R-funksjoner har flere argumenter slik de kan utf√∏re forskjellige operasjoner. Om vi for eksempel √∏nsker at histogrammet skal vise andel og ikke frekvens, m√• vi angi dette i ett av argumentene. For √• ta en titt p√• hvilke argument hist() har √• tilby skriver ?hist i konsollen. Det vil da poppe opp en dokumentasjonside i vinduet nede til h√∏yre. Skroll ned √• les om argumentet ‚Äòfreq‚Äô. Hva skal du erstatte sp√∏rsm√•lstegnene under med for at histogrammene skal vise andel? # Skalert Histogram, vi velger breaks = 9 fordi det er 9 mulige utfall: 1 -- 9. hist(voldelig, freq = ?, breaks = 9, main = &quot;Voldelig&quot;) hist(ikke_voldelig, freq = ?, breaks = 9, main = &quot;Ikke-voldelig&quot;) De fullf√∏rte linjene over skal v√¶re med i .R-filen din. For √• se histogrammene kan du kj√∏re kommandoene en etter en i konsoll med √• trykke ctrl + enter. Figurene dukker da opp i vinduet nede til h√∏yre. Du kan ogs√• pr√∏ve √• eksperimentere med argumentet breaks. La oss s√• fors√∏ke √• gjenta denne operasjonen ved √• bruke ggplot-pakken. Vi kan f√∏rst kikke p√• Figur 2.1 og koden som lagde disse figurene for √• f√• en id√© om hva vi m√• gj√∏re. Et sv√¶rt viktig punkt er f√∏gende: ggplot-funksjonen skal alltid ha hele datasettet (en data frame) som argument!! Det betyr at vi ikke skal bruke de to vektorene voldelig og ikke_voldelig, slik som i hist()-funksjonen, men bruke hele datasettet violence. Vi ser av oversikten over at variabelen som inneholder aggresjonsniv√•et er aggression_level, s√• det er den vi skal bruke som \\(x\\)-argument. Ved √• ta utganspunkt i koden som lagde Figur 2.1, kan vi gj√∏re et f√∏rste fors√∏k (der vi husker √• laste inn ggplot2-pakken f√∏rst): library(ggplot2) ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) Nesten! Det eneste problemet er at vi har ett histogram for alle observasjonene, mens det vi egebntlig √∏nsket var √• lage et histogram for hver av gruppene. Dette er s√•re enkelt i ggplot2. Det eneste vi trenger √• gj√∏re er √• identifisere den variabelen i datasettet som angir gruppetilh√∏righet (sjekk variabeloversikten over, svaret er experienced_violence), og s√• plusse p√• en funksjon som heter facet_wrap() som vist under. ggplot(violence, aes(x = aggression_level)) + geom_histogram(bins = 9) + facet_wrap(~ experienced_violence) Dersom vi i stedet √∏nsker et skalert histogram kan vi spesifisere y-argumentet p√• f√∏lgende vis: ggplot(violence, aes(x = aggression_level, y = ..density.. )) + geom_histogram(bins = 9) + facet_wrap(~ experienced_violence) Oppgave 2.7. N√•r man skal sammenligne sentrum og spredning i to grupper er et boxplott et ypperlig alternativ og vi kan da bruke funksjonen boxplot() i ‚Äúbase R‚Äù, eller funksjonen geom_boxplot() hvis vi heller √∏nsker √• benytte ggplot2. Vi holder oss til det siste alternativet her, og ser at kodelinjene ligner p√• det vi laget over. Dersom vi √∏nsker √• lage et enkelt boxplot av en variabel for √• sammenligne spredingen i to eller flere grupper kan vi skrive ggplot(a, aes(x = b, y = c)) + geom_boxplot() Her m√• du selv erstatte bokstavene a, b og c i henhold til f√∏lgende regel: a er navnet p√• datasettet. b er variabelen som inneholder gruppeinndelingen. c er variabelen som inneholder m√•lingene. De ferdige kodelinjene skal v√¶re med i .R-skriptet ditt. For √• se boxplottet kan du som vanlig kj√∏re kommandoene med √• trykke ctrl + enter. Ser det ut til √• v√¶re noe forskjell p√• sentrum og spredning i de to gruppene? Bonusoppgave. Bytt ut geom_boxplot() over med geom_jitter() og geom_violin(). Hva viser disse plottene? "],["data√∏ving-2.html", "7.2 Data√∏ving 2", " 7.2 Data√∏ving 2 7.2.1 Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysen begynner vi med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(&quot;swirl&quot;) i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) swirl() Du vil i starten bli bedt om √• skrive inn ditt navn. Hvis du bruker samme navn som tidligere f√•r du kanskje tilbud om √• starte opp igjen der du slapp, men da kan du bare velge det nederste valget ‚ÄòNo. Let me start something new‚Äô. Du velger s√• alternativet ‚ÄòR Programming‚Äô hvor du f√•r se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul 6 ‚ÄòSubsetting Vectors‚Äô og modul 8 ‚ÄòLogic‚Äô. Husk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl () f√∏r du begynner p√• neste del av datalabben. Lykke til! 7.2.2 Data til data√∏velsen I denne data√∏velsen skal vi ved hjelp av R gjennomf√∏re en del av testene som vi har l√¶rt i praksis. Vi skal gj√∏re b√•de ett- og to-utvalgs tester, og vi skal bruke \\(\\chi^2\\)-testen Vi skal jobbe med tre ulike datasett i denne √∏vingen, og alle sammen kan lastes ned ved √• klikke p√• lenkene under: testdata.xls violence.xlsx roubik_2002_coffee_yield.xlsx Last ned disse filene og legg dem i en mappe p√• datamaskinen din. √Öpne s√• RStudio, velg File -&gt; New File -&gt; R Script for √• √•pne et nytt Rscript, og lag gjerne en liten overskrift ved hjelp av kommentartegnet #. Lagre s√• scriptet ditt i samme mappen som du har lagt datasettene, slik at du n√• har en mappe som ser ut som figuren under: Det neste du m√• gj√∏re er √• s√∏rge for at du har satt opp riktig mappesti (working directory) i RStudio, og det gj√∏r du raskest ved √• velge Session -&gt; Set Working Directory -&gt; To Source File Location. Neste gang du skal jobbe med dette prosjektet kan du √•pne RStudio ved √• dobbeltklikke p√• data√∏ving2.R, og mappestien skal da settes automatisk til riktig mappe. I alle tilfeller skal vinduet ditt se omtrent slik ut: 7.2.3 Oppgaver til √∏vingen: 7.2.3.1 Oppgave 1 Costa Rica er en stor kaffeprodusent med moderne produksjon. Kaffeprodusentene har over lengre tid benyttet en standardisert miks av spr√∏ytemidler som skal ta knekken p√• ugress og skadelige insekter, men uten √• skade avlingen eller milj√∏et ellers. En liten kaffeplantasje i Costa Rica har begynt √• eksperimentere med en ny kombinasjon av spr√∏ytemidler som skal v√¶re like effektiv mot ugress, men samtidig enda mer sk√•nsom mot kaffeplantene, slik at avlingen blir st√∏rre. Innehaveren av plantasjen √∏nsker √• sette opp et eksperiment for √• unders√∏ke denne p√•standen. Han velger ut 25 tilfeldige jordlapper fordelt p√• hele eiendommen der han bruker de nye spr√∏ytemidlene gjennom en hel sesong. Lang erfaring har vist at avlingen ved bruk av gammel metode er normalfordelt med forventning \\(\\mu = 100\\) og varians \\(\\sigma^2 = 10\\), der vi har brukt en standardisert enhet for mengde avling per arealenhet. Hjelp bonden, ved √• l√∏se f√∏lgende oppgaver: Oppgave 1.1: Les inn datasettet testdatasdata.xsl i RStudio og se p√• de f√∏rste par radene. Det kan du gj√∏re ved √• kj√∏re f√∏lgende kodelinjer: library(readxl) # Pakke for √• lese excel-filer data &lt;- read_excel(&quot;testdata.xls&quot;) # Leser inn datasettet data # Ser p√• datasettet ## # A tibble: 25 x 4 ## X1 X2 A1 A2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 122. 121. 1 1 ## 2 101. 105 1 1 ## 3 114. 108 1 1 ## 4 103 99.1 1 0 ## 5 97.6 96.2 0 0 ## 6 85.9 95.4 0 0 ## 7 93.5 101. 0 1 ## 8 92 97 0 0 ## 9 98.8 106. 0 1 ## 10 99.9 100. 0 1 ## # ‚Ä¶ with 15 more rows Det er kolonnen X2 som inneholder de observerte avlingene p√• de 25 fors√∏ksseksjonene. Oppgave 1.2: Er forventet avling ved bruk av den nye metoden st√∏rre enn forventet avling ved bruk av den gamle metoden? Hint: Forelesningsnotatene/scriptet inneholder koden du trenger for √• l√∏se denne og neste oppgave. Oppgave 1.3: Det er viktig for kaffebonden at avlingen ikke varierer for mye mellom de ulike delene av farmen. En viktig m√•leparameter for denne type produksjon er derfor variansen. Kan vi sl√• fast at variansen til avlingen har forandret seg etter omlegging til ny metode? Oppgave 1.4: Kaffebonden er skeptisk til p√•standen om at forventet avling med den gamle metoden er \\(\\mu = 100\\), og mener at det vil variere med for eksempel jordsmonn. For √• ta h√∏yde for dette gjennomf√∏rte han √•ret i forveien tilsvarende m√•linger p√• de samme jordlappene, med med gammel spr√∏ytemetode. Disse m√•lingene finner du i kolonne X1 i datasettet. Test om avlingene er forskjellige, b√•de med og uten paring av observasjonene. Kommenter resultatet. 7.2.3.2 Oppgave 2 Vi skal i denne oppgaven se p√• oppgave 1a og 1b som ble gitt p√• skoleeksamen i MET4 v√•rsemesteret 2019. Dette er det samme datasettet som vi s√• p√• i forrige data√∏ving. I et amerikansk fors√∏k ville man unders√∏ke p√•standen om at voldelige dataspill f√∏rer til voldelig adferd ved la to grupper spille hvert sitt dataspill. I det ‚Äúvoldelige‚Äù dataspillet var oppdraget √• skyte og drepe et romvesen, mens i den ikke-voldelige varianten skulle man finne og redde romvesenet fra fare. Utover det var spillene helt likt utformet, og i etterkant av en spille√∏kt ble deltakernes aggresjonsniv√• m√•lt p√• en skala fra 1 til 9 ved hjelp av en standard psykologisk test. I denne oppgaven skal vi i hovedsak finne ut om gruppen som spilte de voldelige dataspillet hadde signifikant h√∏yere aggresjonsniv√• enn kontrollgruppen. Oppgave 2.1: Les inn datasettet violence.xslx p√• samme m√•te som over. Hvis du allerede har kj√∏rt library(readxl) trenger du ikke gj√∏re det igjen med mindre du har startet RStudio p√• nytt. Gi datasettet et passende navn, f.eks violence &lt;- read_excel(&quot;violence.xlsx&quot;) Vi skal alts√• teste om aggresjonsniv√•et er forskjellig i de to gruppene. Da m√• vi trekke ut de aktuelle tallene fra datasettet. Som vi husker fra forelesningsnotatene trenger vi to vektorer for √• gj√∏re en to-utvags \\(t\\)-test: en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det voldelige dataspillet, og en vektor som inneholder aggresjonsniv√•et til gruppen som har spilt det ikke-voldelige dataspillet. La disse to vektorene f√• navn voldelig og ikke_voldelig, og lag dem ved √• skrive f√∏lgende kodelinjer: voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] ikke_voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Less Violent&quot;] For en forklaring p√• disse kodelinjene, se Data√∏ving 1. Oppgave 2.2: Vi er n√• klare til √• gj√∏re en to-utvalgs \\(t\\)-test for om aggresjonsniv√•et er det samme i de to gruppene. Pr√∏v √• gj√∏re det n√•, men v√¶r bevisst p√• hvilke valg du gj√∏r underveis, og som du mater inn i t.test()-funksjonen, f.eks: Antar du lik varians i de to gruppene? Hvorfor/Hvorfor ikke? Bruker du ensidig eller tosidig test? Hvorfor? Oppgave 2.3: En avgj√∏rende detalj i studien som vi ser p√• i denne oppgaven er at forskerne ogs√• spurte fors√∏kspersonene hvorvidt de selv syntes spillet de spilte var voldelig. For √• kunne trekke noen som helst l√¶rdom fra et slikt fors√∏k er det viktig at den voldelige spillvarianten faktisk blir oppfattet som voldelig og vice versa. Vi √∏nsker dermed √• unders√∏ke nullhypotesen om at variablene violence_tratment og experienced_violence er uavhengige av hverandre. Den hypotesen er vi n√∏dt til √• forkaste for at fors√∏ket skal v√¶re gyldig: hvis det ikke er noen sammenheng mellom opplevd og faktisk voldelighet er fors√∏ket helt klart ugyldig. F√∏rste steg er √• lage et nytt datasett der vi bare ta med oss de to kolonnene vi er interessert i. Kall det hva du vil, f.eks. violence_redusert: violence_redusert &lt;- violence[c(&quot;violent_treatment&quot;, &quot;experienced_violence&quot;)] Vi fortsetter som i videoforelesningen og lager en krysstabell for disse variablene krysstabell &lt;- table(violence_redusert) krysstabell ## experienced_violence ## violent_treatment Less Violent Violent ## Less Violent 114 9 ## Violent 33 93 Oppgave 2.4: Heldigvis ser det ut til at det er en klar sammenheng mellom faktisk og opplevd voldelighet ved at de fleste fors√∏kspersonene havner p√• diagonalen i krysstabellen. Bruk funksjonen chisq.test() p√• samme m√•te som i forelesningen til √• teste nullhypotesen om uavhengighet formelt. 7.2.3.3 Oppgave 3 Vi skal i denne oppgaven returnere til kaffeproduksjon. Vi skal gj√∏re statistiske tester i R som i de tidligere oppgavene i denne √∏vingen, men vanskelighetsgraden g√•r opp fordi vi ogs√• m√• tenke n√∏ye over hvordan vi anvender metodene korrekt i en gitt kontekst. I 2002 publiserte det prestisjetunge tidsskriftet Nature en kort artikkel skrevet av David W. Roubik1, som handler om den kjente kaffeb√∏nnen Arabica. Arabicab√∏nnen kommer opprinnelig fra Afrika, og er en selvpollinerende plante. Det vil si at den ikke er avhengig av insekter for √• formere seg, og man trodde lenge at den heller ikke hadde noen fordeler av insektspollinering. For √• unders√∏ke denne p√•standen samlet Roubik inn historiske data over arabicaavlinger fra hele verden. Han delte verdens kaffeproduserende land inn i to kategorier: Old world som omfatter afrikanske og asiatiske land, og New world som omfatter land i Latin-Amerika. Han registrerte videre gjennomsnittlig √•rlig avling (m√•lt i kg/hektar) i to perioder: 1961‚Äì80 og 1981‚Äì2001. N√∏kkelen til analysen er at den afrikanske honningbien var en viktig pollinator i Afrika og Asia b√•de i den f√∏rste og andre perioden, men knapt eksisterte i Amerika f√∏r 1980. Etter 1980, derimot, √∏kte utbredelsen av denne bien i Amerika, og ble fort naturalisert. Kan vi sette denne utviklingen i sammenheng med √∏kt kaffeavling i Latin-Amerika etter 1980, og dermed skrote teorien om at kaffeplanter ikke drar nytte av insektspollinering? Oppgave 3.1: For √• unders√∏ke dette kan vi bruke datasettet som Roubik brukte, som finnes i filen roubik_2002_coffe_yield.xlsx. Last datasettet inn i R p√• vanlig m√•te, og se p√• det: yield &lt;- read_excel(&quot;roubik_2002_coffe_yield.xlsx&quot;) yield ## # A tibble: 28 x 4 ## world country yield_61_to_80 yield_81_to_01 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 new Costa_Rica 9139 14620 ## 2 new Bolivia 7686 8767 ## 3 new El_Salvador 9996 8729 ## 4 new Guatemala 5488 8231 ## 5 new Colombia 5920 7740 ## 6 new Honduras 4096 7264 ## 7 new Nicaragua 4566 6408 ## 8 new Brazil 4965 6283 ## 9 new Peru 5487 5740 ## 10 new Mexico 5227 5116 ## # ‚Ä¶ with 18 more rows Vi ser at det er fire kolonner i datasettet: world angir om det er snakk om New world (new) eller Old world (old). country angir navnet p√• landet. yield_61_to_80 angir avlingen i perioden 1961‚Äì80. yield_81_to_01 angir avlingen i perioden 1981‚Äì2001. Oppgave 3.2: Kall den f√∏rste tidsperioden p1 og den andre tidsperioden p2. Lag s√• fire vektorer, en for hver kombinasjon av world og tidsperiode ved √• bruke samme teknikk som i oppgave 2.2 over. N√•r du er ferdig, skal du ha laget f√∏lgende vektorer: new_p1: inneholder avling for alle land med world == new i f√∏rste periode. new_p2: inneholder avling for alle land med world == new i andre periode. old_p1: inneholder avling for alle land med world == old i f√∏rste periode. old_p2: inneholder avling for alle land med world == old i andre periode. Dersom du har gjort det riktig, ser vektorene slik ut n√•r du er ferdig: new_p1 ## [1] 9139 7686 9996 5488 5920 4096 4566 4965 5487 5227 2347 3089 1938 new_p2 ## [1] 14620 8767 8729 8231 7740 7264 6408 6283 5740 5116 4124 3240 ## [13] 2789 old_p1 ## [1] 4251 10522 3509 10028 5667 17064 5904 4001 6604 4738 5716 3824 ## [13] 3525 3393 3213 old_p2 ## [1] 13380 11561 9652 9593 8797 7869 7354 7288 6055 5432 5394 3576 ## [13] 3141 2391 2136 Oppgave 3.3: Bruk en paret \\(t\\)-test til √• finne ut om kaffeavlingen i den gamle verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.4: Bruk en paret \\(t\\)-test til √• finne ut om kaffeavlingen i den nye verden er signifikant forskjellig i de to tidsperiodene. Oppgave 3.5 (Diskusjonsopgave): Dersom du har gjort de to foreg√•ende oppgavene riktig vil du se at den gjennomsnittlige kaffeavlingen ikke har endret seg signifikant i den gamle verden, mens √∏kningen i den nye verden er klart statistisk signifikant. Vi har brukt parrede \\(t\\)-tester, slik at vi ‚Äúkontrollerer for‚Äù eventuelle landeffekter (denne terminologien blir skal vi bruke mer n√•r vi skal jobbe med regresjon). Roubik omtaler funnet som f√∏lger: A substantial increase in Latin American coffee yield partly coincided with the establishment of African honeybees in those countries, although there was no such change in the Old World, where honeybees originated [‚Ä¶]. This comparison underlines a possible cause-and-effect relationship between the presence of social bees and cofee yield. Dette er intet mindre enn en kortslutning, p√• minst to forskjellige m√•ter. Hvorfor? Diskuter med dine medstudenter. Kan det gjennomf√∏res en enkel test som gir et bedre bilde av situasjonen? 7.2.4 BONUS: En alternativ teknikk for datamanipulering (Gj√∏r bare om du har overskudd til det!) Se p√• denne kodelinjen: voldelig &lt;- violence$aggression_level[violence$violent_treatment == &quot;Violent&quot;] Vi skrev denne linjen for √• hente ut noen bestemte verdier fra et bestemt datasett. Det er kanskje ikke s√• lett √• se hva kodelinjen gj√∏r ved √• bare kaste et raskt blikk p√• den, og det er spesielt to grunner til det: den er lang, og du m√• lese den delvis ‚Äúinnenfra og ut‚Äù (alst√•, begynne innerst i parantesene) og delvis fra h√∏yre mot venstre. Spesielt det siste punktet er kontraintuitivt, siden det er motsatt av slik vi vanligvis leser. Mye arbeid i R g√•r ut p√• √• manipulere datasett p√• ulike vis (hente ut kolonner og rader, lage nye kolonner), og derfor er det utviklet noen alternative verkt√∏y for √• gj√∏re slike jobber mye mer effektivt. Vi vil i dette avsnittet gi en kort og meget grunleggende innf√∏ring i slike teknikker. Merk at dette ikke er pensum i klassisk forstand. Det viktigste er at jobben blir gjort korrekt. Hvordan du gj√∏r det er i s√• m√•te underordnet. For √• gjennomf√∏re √∏velsen under m√• du installere og laste inn en ny pakke: dplyr: install.packages(&quot;dplyr&quot;) library(dplyr) KONSEPT 1: Pipe-operatoren %&gt;% Tenk deg at vi skal regne ut logaritmen til kvadratroten av 2. Vi m√• da anvende to funksjoner i riktig rekkef√∏lge. Vi kan alltids bruke en mellomregning: kvadratroten_til_2 &lt;- sqrt(2) log(kvadratroten_til_2) ## [1] 0.3465736 Eventuelt kj√∏rer vi alt sammen i en linje: log(sqrt(2)) ## [1] 0.3465736 N√• er ikke den siste linjen spesielt lang, men den er som sagt ikke helt intuitiv. Grunnen er at hvis vi skal lese h√∏yt hva den gj√∏r, s√• m√• vi begynne innerst i parantesene: ‚ÄúVi starter med tallet 2, s√• tar vi kvadratroten, s√• tar vi logaritmen‚Ä¶‚Äù I dplyr-pakken finnes en s√•kalt pipe-operator som gj√∏r at vi kan skrive dette som kode i den rekkef√∏lgen ting skal skje. Eksempelet over skrives slik: 2 %&gt;% sqrt %&gt;% log ## [1] 0.3465736 Det som skjer er at R leser linjen fra venstre, og ved hver ‚Äúpipe/%&gt;%‚Äù sendes det som st√•r p√• venstre side inn som argument i funksjonen p√• h√∏yre side. N√•r du leser kode, kan denne operatoren uttales som s√• (then p√• engelsk): F√∏rst har vi tallet 2, s√• tar vi kvadratroten, s√• tar vi logaritmen. Tenk n√•r vi har en sekvens av 10 eller 20 eller 50 steg (ikke uvanlig i den virkelige verden), hvor mye enklere det blir √• kode p√• denne m√•ten fremfor √• ha 10, 20 eller 50 niv√• med paranteser! Tips: Hurtigtasten for %&gt;% i RStudio er Ctrl - Shift - M (Bytt ut Ctrl med Cmd p√• Mac). KONSEPT 2: Datamanipuleringsfunksjoner i dplyr I dplyr finnes det noen meget praktiske funksjoner som vi kan bruke til √• manipulere datasatt i R. La oss ta utgangspunkt i datasettet violence og pr√∏ve √• skrive om den aktuell kodelinjen over ved hjelp av pipe-operatoren. I klartekst skal vi gj√∏re f√∏lgende operasjoner: Starte med datasettet violence Plukke ut alle radene som har verdi &quot;Violent&quot; i kolonnen violent_treatment. Plukke ut kolonnen aggression_level For √• velge ut bestemte rader kan vi bruke funksjonen filter(). Ved hjelp av pipe-operatoren kan vi skrive steg 1 og 2 som violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) ## # A tibble: 126 x 5 ## id aggression_level violent_treatment difficulty_treatm‚Ä¶ experienced_viol‚Ä¶ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 4 Violent Easy Less Violent ## 2 2 5 Violent Hard Violent ## 3 5 2 Violent Easy Violent ## 4 6 9 Violent Hard Less Violent ## 5 10 4 Violent Hard Violent ## 6 18 4 Violent Hard Violent ## 7 21 4 Violent Easy Violent ## 8 22 9 Violent Hard Less Violent ## 9 25 7 Violent Easy Violent ## 10 26 1 Violent Hard Less Violent ## # ‚Ä¶ with 116 more rows N√• ser vi at vi bare har 126 rader igjen, og det er nettopp de radene som i kolonnen violent_treatment har verdi &quot;Violent&quot;. Det neste steget er √• velge ut kolonnen aggression_level. Det gj√∏r vi ved √• bruke funksjonen select(), og hele sekvensen ser da slik ut (linjeskift gj√∏r det enda mer lesbart): violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) ## # A tibble: 126 x 1 ## aggression_level ## &lt;dbl&gt; ## 1 4 ## 2 5 ## 3 2 ## 4 9 ## 5 4 ## 6 4 ## 7 4 ## 8 9 ## 9 7 ## 10 1 ## # ‚Ä¶ with 116 more rows Man kan velge flere kolonner ved √• sette komma mellom kolonnenavn, og man kan i stedet velge bort kolonner ved √• sette minustegn foran kolonnenavnet, f.eks: violence %&gt;% select(id, aggression_level) violence %&gt;% select(-id) N√• har det seg slik at vi gjerne √∏nsker √• hente ut den aktuelle kolonnen som en vektor. Det gj√∏r vi enkelt ved √• slenge p√• en pull p√• slutten av en pipe-sekvens. Til slutt m√• vi passe p√• √• lagre vektoren med riktig navn, slik at vi f√•r: voldelig &lt;- violence %&gt;% filter(violent_treatment == &quot;Violent&quot;) %&gt;% select(aggression_level) %&gt;% pull Denne koden er ekvivalent med den som startet dette avsnittet i √∏vingen. Den er derimot mye enklere √• lese, og veldig mye enklere √• utvide til √• inkludere flere operasjoner. La oss se p√• enda en funksjon som vil v√¶re sv√¶rt nyttig for oss senere. Vi kan bruke mutate() til √• lage nye kolonner. La oss for eksempel si at vi vil lagre kvadratet av aggression_level eller summen av aggression_level og id som egne kolonner (som selvsagt er helt meningsl√∏st i dette tilfellet, kun et eksempel). Det kan vi gj√∏re slik: violence %&gt;% mutate(ny1 = aggression_level^2) eller violence %&gt;% mutate(ny2 = id + aggression_level) Her er ny1 og ny2 navn p√• de nye kolonnene, som vi kan velge selv. Oppgave: Gjenta Oppgave 3.2, men ved √• bruke teknikkene i dette avsnittet. Interaktiv √∏ving i dplyr Hvis du √∏nsker √• trene mer p√• dette s√• finnes det en interaktiv modul i swirl som omhandler datamanipulasjon ved hjelp av dplyr. Hvis du ikke har gjort det alledede, skriv install.packages(&quot;swirl&quot;) i konsoll. Start du opp swirl med √• skrive f√∏lgende: library(swirl) install_course(&quot;Getting_and_Cleaning_Data &quot;) # legger til nytt kursmateriale swirl() Du vil i starten bli bedt om √• skrive inn ditt navn og s√• f√∏lger litt info om hvordan swirl fungerer. Du blir s√• bedt om √• velge kurs. Her skal du f√∏rst velge alternativet ‚ÄòGetting and Cleaning Data‚Äô. Du f√•r s√• se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul 1 ‚ÄòManipulating Data with dplyr‚Äô. David W. Roubik: The value of bees to the coffee harvest. Nature (2002)‚Ü© "],["data√∏ving-3.html", "7.3 Data√∏ving 3", " 7.3 Data√∏ving 3 7.3.1 Oppgave 1: Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysen begynner vi som vanlig med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(&quot;swirl&quot;) i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) install_course(&quot;Regression_Models&quot;) # legger til nytt kursmateriale om regresjon swirl() Du vil i starten bli bedt om √• skrive inn ditt navn. Hvis du bruker samme navn som tidligere f√•r du kanskje tilbud om √• starte opp igjen der du slapp, men da kan du bare velge det nederste valget ‚ÄòNo. Let me start something new‚Äô. Du velger s√• alternativet ‚ÄòRegression Models‚Äô hvor du f√•r se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul modul 1 ‚ÄòIntroduction‚Äô. Her vil du l√¶re litt om hvordan du kan bruke R til √• gj√∏re en regresjonsanalyse ved hjelp av et treningsdatasett. Noen av kommandoene som gjennomg√•s i denne modulen vil komme til nytte senere i datalabben. Husk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.3.2 Oppgave 2: Regresjonsanalyse Et rock-and-roll museum √•pnet i Atlanta i 1990. Museet l√• i en sentral del av byen i n√¶rheten av mange ulike butikker. Mot slutten av juli m√•ned i 1992 startet en stor brann i en av disse butikkene som √∏dela hele kvartalet, inkludert museet. Heldigvis var museet forsikret, b√•de mot selve brannskadene, og mot tapte billettinntekter i gjennoppbyggingsperioden. Vanligvis vil et forsikringsselskap beregne erstatningsbel√∏pet under antakelsen om at bes√∏kstallene i gjenoppbyggingsperioden ville v√¶rt p√• samme niv√• som bes√∏kstallene i tiden f√∏r brannen. I dette tilfellet mente derimot eierne av museet at bes√∏kstallene var √∏kende, slik at de reelt sett hadde krav p√• et st√∏rre erstatningsbel√∏p. Argumentet var basert p√• bes√∏kstallene til en forn√∏yelsespark like ved. Forn√∏yelsesparken √•pnet i desember 1991, slik at museet og parken opererte sammen i de siste fire ukene av 1991, og de f√∏rste 28 ukene i 1992 f√∏r brannen √∏dela museet. Museet √•pnet igjen i april 1995, men var da betydelig st√∏rre enn det var opprinnelig. Data for bes√∏kstall for museet og forn√∏yelsesparken finner vi i regnearket C16-01.xlsx. Som i de to foreg√•ende data√∏vingene legger du denne filen i en mappe p√• maskinen din, og oppretter et tomt R-script der du lagrer koden for denne oppgaven. Oppgave 2.1: Kikk raskt p√• datasettet i Excel eller tilsvarende. Du ser at det er tre kolonner, en som angir ukenummer (Week, teller fra 1 til 205), en som angir ukentlig bes√∏kstall p√• museet (Museum) og en som angir ukentlig bes√∏kstall i forn√∏yelsesparken (A-Park). Legg merke til at bes√∏kstallet i museet er null fra og med uke 33, til og med uke 179, som er perioden fra brannen til ny√•pning. Oppgave 2.2: Last s√• datasettet inn i R som f√∏r ved hjelp av read_excel()-funksjonen. Gi det et passelig navn (f.eks visits), og sjekk raskt at det har g√•tt bra ved √• taste inn datanavnet i konsollen. Da skal det se omtrent slik ut: visits ## # A tibble: 205 x 3 ## Week Museum `A-Park` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 787 1379 ## 2 2 1179 1396 ## 3 3 4225 5332 ## 4 4 1336 1477 ## 5 5 2122 3717 ## 6 6 1136 1663 ## 7 7 2413 3573 ## 8 8 1399 2086 ## 9 9 1528 2503 ## 10 10 1788 2553 ## # ‚Ä¶ with 195 more rows Legg merke til f√∏lgende: Observasjonene ser ut til √• v√¶re de samme som vi s√• da vi kikket p√• selve regnearket. Det er alltid en god vane √• forsikre seg om at R har lest inn datasettet p√• riktig m√•te. Et av variabelnavnene har f√•tt noen rare t√∏dler rundt seg. Grunnen til det er at A-park inneholder en bindestrek, s√• for at R ikke skal tolke det tegnet som et minustegn (og dermed gi oss et mareritt med feilmeldinger), m√• vi alltid bruke disse t√∏dlene n√•r vi refererer til denne variabelen. (P√• tastaturet som forfatteren av disse ord skriver p√•, er det Shift + tasten til venstre for Backspace. Oppgave 2.3: F√∏r vi g√•r videre, m√• vi f√• et bedre begrep om problemet ved √• kikke grafisk p√• observasjonene. La oss plotte observasjonene i et linjeplott for √• se hvordan de utvikler seg over tid, ved √• ha ukenummer p√• \\(x\\)-aksen og bes√∏kstall p√• \\(y\\)-aksen. Vi kan lage et enkelt plott for bes√∏kstall for museet ved √• skrive # Laster f√∏rst ggplot-pakken (det trenger vi bare gj√∏re en gang i skriptet) library(ggplot2) # Lager et enkelt linjeplott: ggplot(visits, aes(x = Week, y = Museum)) + geom_line() Du kan legge til bes√∏kstall for forn√∏yelsesparken ved √• plusse p√• en ny linje med geom_line(), men da m√• du spesifisere y-variabelen p√• nytt. Hele plottekommandoen blir da: ggplot(visits, aes(x = Week, y = Museum)) + geom_line() + geom_line(aes(y = `A-Park`)) Vi ser at det er en sterk sammenheng mellom bes√∏kstallene til museet og parken, spesielt etter gjen√•pningen i 1995, og det skal vi utnytte n√•r vi senere skal beregne erstatningssummen. Oppgave 2.4: Juster p√• argumentene i geom_line()-funskjonene, og legg til flere ‚Äúlag‚Äù p√• samme m√•te som vi gjorde for √• pynte p√• figuren i oppgave 3 i kapittel 1.10 (det er 100% lov √• Google). Dette ser bedre ut: Oppgave 2.5: La oss n√• ta utgangspunkt i forsikringsselskapets p√•stand: bes√∏kstallet i perioden der museet er stengt skal beregnes ved hjelp av observasjonene f√∏r brannen. Vi estimerer parametrene i en enkel regresjonsmodell \\[y_i = \\beta_0 + \\beta_1x_i + \\epsilon,\\] der responsvariabelen \\(y_i\\) er bes√∏kstallet p√• museet p√• dag nr. i, og \\(x_i\\) er bes√∏kstallet i forn√∏yelsesparken samme dag. Datasettet vi skal bruke er alts√• de 28 f√∏rste radene i datasettet visits. Da kan vi enten lage en ny tabell som best√•r av de 28 f√∏rste radene, eller s√• kan vi bruket argumentet subset i lm()-funkesjonen til √• spesifisere hvilke observasjoner som skal brukes. Estimer regresjonsmodellen ved √• kj√∏re f√∏lgende kall til lm(): reg1 &lt;- lm(Museum ~ `A-Park`, data = visits, subset = 1:28) Oppgave 2.6: Pakken stargazer inneholder funksjoner for √• lage pene regesjonstabeller automatisk fra regresjonsobjekter i R. Pakken m√• installeres og lastes p√• vanlig m√•te: install.packages(&quot;stargazer&quot;) library(stargazer) Inne i stargazer-pakken er det en funksjon som ogs√• heter stargazer(). Hvis du ikke har sett den brukt f√∏r (f.eks i forelesning), kan du lese mer om den ved hjelp av hjelpefunksjonen: ?stargazer. Bruk s√• stargazer() til √• lage f√∏lgende regresjonsutskrift (hint: bruk argumentet type = text): =============================================== Dependent variable: --------------------------- Museum ----------------------------------------------- `A-Park` 0.712*** (0.035) Constant -63.489 (160.948) ----------------------------------------------- Observations 28 R2 0.941 Adjusted R2 0.938 Residual Std. Error 355.223 (df = 26) F Statistic 411.512*** (df = 1; 26) =============================================== Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 Oppgave 2.7: Lag tre diagnoseplott etter mal som er gitt i forelesningsnotatene: Et som viser residualene i regresjonsmodellen i et spredningsdiagram, et QQ-plott, og et histogram. Kan du gj√∏re en grov vurdering om hvorvidt forutsetningene for line√¶r regresjon er oppfylt? Oppgave 2.8: Bruk denne regresjonsmodellen til √• beregne hva bes√∏kstallet hadde v√¶rt dersom museet hadde v√¶rt √•pent som vanlig. Dette kan vi gj√∏re ved √• bruke predict()-funksjonen. F√∏lg oppskriften under n√•, s√• skal du pr√∏ve √• gj√∏re det selv etterp√•. # La oss bruke R til √• finne ut hvilke uker museet var stengt. Kommandoen under # lager en vektor som viser hvilke uker museet var stengt: uker_stengt &lt;- visits$Museum == 0 # S√• lager vi en ny data frame som inneholder verdiene av ukenummer og `A-Park` # de ukene museet var stengt. Vi velger rader f√∏r kommaet i firkantparantesene, # og vi velger kolonner etter kommaet: visits_pred &lt;- visits[uker_stengt, c(&quot;Week&quot;, &quot;A-Park&quot;)] # Bruker predict()-funksjonen til √• predikere tilh√∏rende y&#39;er: predicted_visits1 &lt;- predict(reg1, newdata = visits_pred) # Til slutt legger vi til de predikerte verdiene som en ny kolonne i visits_pred: visits_pred$predikert1 &lt;- predicted_visits1 De predikerte bes√∏kstallene er n√• lagret som kolonne predicted1 i datasettet visits_pred. Oppgave 2.9 For √• f√• bedre greie p√• hvordan prediksjonene egentlig ser ut kan vi legge dem til figuren v√•r fra over. La oss lage en bl√• stiplet linje, og det kan vi gj√∏re med √• legge til enda et kall til geom_lines(). Denne gangen m√• vi bruke flere argumenter: Vi m√• bruke argumentet data til √• si at tallene vi skal plotte for den nye linjen n√• ligger i datasettet visits_pred, og ikke visits. Vi m√• bruke argumentet colour til √• fortelle hvilken farge vi skal ha p√• linjen. Vi m√• bruke argumentet linetype til √• fortelle at vi vil ha en stiplet linje. Ta for deg figuren du lagde i oppgave 2.4, og legg til f√∏lgende linjer (husk √• f√• med en + mellom hvert lag): geom_line(aes(x = Week, y = predikert1), data = visits_pred, colour = &quot;blue&quot;, linetype = &quot;dashed&quot;) Da blir figuren min seende slik ut: Oppgave 2.10: Kommenter kort regresjonsutskriften fra oppgave 2.6 og figuren fra oppgave 2.9. Ser det fornuftig ut? Oppgave 2.11: Se p√• saken heller fra museets side. De mener at det er bes√∏kstallene fra etter √•pningen i 2005 som skal brukes til √• estimere regresjonsmodellen. Det er lett √• forst√• hvorfor de √∏nsker det, for da ser det ut som at det er omtrent like mange bes√∏kende p√• museet som i forn√∏yelsesparken. Repeter oppgave 2.5, men n√• bruker du alts√• bes√∏kstallene fra etter √•pningen til √• estimere regresjonskoeffisientene. Hint 1: Det eneste du m√• endre er hva som skal inn i subset-argumentet. Hint 2: Stigningstallet i den nye modellen skal v√¶re 0.97. Oppgave 2.12: Beregn hvilke bes√∏kstall museet hadde hatt i perioden det var stengt ved √• legge til grunn den nye regresjonsmodellen etter m√∏nster fra oppgave 2.8, og legg dem inn i figuren etter m√∏nster fra oppgave 2.9. Figuren blir skal da se omtrent slik ut hvis vi bruker en finn gr√∏nnfarge (forestgreen) til den siste linjen: Oppgave 2.13: N√•r vi ser hvor tett de to bes√∏kstallene beveger seg etter ny√•pningen er det ikke rart at de beregnede bes√∏kstallene basert p√• den nye modellen (markert i gr√∏nt over) f√∏lger observasjoenen fra forn√∏yelsesparken. Anta at hver billett til museet koster $6.99. Hvor stor er differansen mellom erstatningskravet til museet og tilbudet til forsikringsselskapet? Oppgave 2.14 (Diskusjon): Det er ganske stor forskjell mellom tilbud og krav, men hvis vi tenker oss om skj√∏nner vi fort at begger parter befinner seg i en klassisk catch-22. Hvis den ene partens argument f√∏rer til en utbetaling som er for stor eller for liten fordi de tar utgangspunkt i slutten eller starten p√• en stigende utvikling, m√• n√∏dvendigvis det motsatte standpunkt ogs√• v√¶re galt av n√∏yaktig samme grunn. Kan du foresl√• et kompromiss? 7.3.3 Oppgave 3: Rapporter basert p√• R-analyser Ofte er det √∏nskelig √• bruke resultater fra R inn i rapporter, artikler og foredrag. I MET4 skal du blant annet levere b√•de en obligatorisk innlevering og en hjemmeksamen. Det er fullt mulig √• √•pne et hvilken som helst tekstdokument (f.eks Word) for s√• √• belage seg p√• en ‚Äòklipp og lim‚Äô-tiln√¶rming. I R-studio kan man lagre figurer ved √• trykke p√• ‚ÄòExport‚Äô fanen i vinduet nede til h√∏yre og s√• ‚ÄòSave as‚Äô, eventuelt bruke ggsave()-funksjonen til √• lagre plott laget med ggplot2. Disse kan s√• √•pnes i det samme dokumentet. En klipp og lim-tiln√¶rming kan v√¶re tidkrevende og det finnes verkt√∏y som gj√∏r det lett √• lage ganske s√• elegante rapporter av R-analyser. I de f√∏lgende oppgavene gir vi to alternativer til √• lage rapporter. Den f√∏rste metoden er noe enklere enn den andre. Oppgave 3.1: Rstudio kan lage en enkel rapport ut av .R filen din ved at du trykker ctrl + shift + k (cmd + shift + K p√• mac). Pr√∏v det med .R filen du laget i Oppgave 2. F√∏rste gang du gj√∏r dette blir du bedt om √• installere noen pakker og det aksepterer du. Du f√•r s√• opp et vindu som ber deg velge format p√• rapporten: Har du tilgang til ‚ÄòWord‚Äô kan du velge ‚ÄòMS word‚Äô, hvis ikke velger du formatet HTML. For PDF format er du avhengig av √• installere ‚Äòlatex‚Äô. Rapporten vil da legge seg i mappen hvor du har lagret datasettet og .R filen. Fordelen med √• velge ‚ÄòMS word‚Äô formatet er at du kan bruke den samme word filen til √• redigere og kommentere resultatene. Oppgave 3.2 (litt mer krevende): Man kan ogs√• lage rapporter ved √• bruke et tekstformat kalt R Markdown. Dette er nok litt mer utfordrende enn tiln√¶rmingen i oppgaven over, men vil gi sv√¶rt pene raporter/dokumenter. √ònsker du √• utforske denne muligheten s√• ta en titt p√• denne videoguiden. "],["data√∏ving-4.html", "7.4 Data√∏ving 4", " 7.4 Data√∏ving 4 7.4.1 Oppgave 1: Interaktiv √∏velse F√∏r vi tar fatt p√• dataanalysens begynner vi som vanlig med litt R-trening i swirl. Har du allerede installert pakken swirl (skriv install.packages(&quot;swirl&quot;) i konsoll hvis ikke) starter du opp swirl med √• skrive f√∏lgende i konsollen: library(swirl) swirl() Du vil i starten bli bedt om √• skrive inn ditt navn og s√• f√∏lger litt info om hvordan swirl fungerer. Du blir s√• bedt om √• velge kurs. Her skal du f√∏rst velge alternativet ‚ÄòR Programming‚Äô. Merk at du kanskje m√• trykke alternativet ‚ÄòNo. Let me start something new‚Äô for √• komme tilbake til hovedmenyen etter √• ha brukt swirl tidligere. Du f√•r s√• se alle modulene dette kurset inneholder. I denne √∏vingen skal du pr√∏ve deg p√• modul 9 ‚ÄòFunctions‚Äô. I denne modulen vil du l√¶re litt om funksjoner i R. Merk at det helt til h√∏yre vil st√•r hvor langt du har kommet i prosent. St√•r du helt fast med et punkt kan du skrive skip() for √• hoppe over dette punktet. N√•r du har fullf√∏rt en modul blir du spurt om du vil motta ‚Äòcredit‚Äô for √• ha fullf√∏rt modulen. Her kan du svare nei. √ònsker du √• avbryte underveis skriver du bye(). Skriver du inn det samme navnet n√•r du eventuelt starter swirl igjen kan du fortsette der du slapp. Husk √• avslutt swirl (esc) f√∏r du begynner p√• del to av √∏vingen. Lykke til! 7.4.2 Oppgave 2 - Maskinl√¶ring: Logistisk regresjon og k n√¶rmeste naboer I denne oppgaven skal vi se p√• de samme dataene som ble brukt i forelesningen om logistisk regresjon. Vi har data p√• 10000 kredittkortkunder og vi √∏nsker √• kunne bygge og trene en best mulig modell til √• predikere hvilke kunder som vil misligholde sin gjeld. Oppgave 2.1: Vi starter med √• f√• tak i dataene. Disse er integrert i pakken ISLR. Last inn pakken og ta en titt p√• dataene ved bruk av f√∏lgende linjer (hvordan du kommenterer er opp til deg): library(ISLR) # Pakke som inneholder dataene head(Default) # Viser starten p√• dataframen str(Default) # Viser hvilke typer variabler dataframen inneholder Responsvariabelen er : Dette er en kategorisk variabel. Misligholdt kunden gjelden? Forklaringsvariabler: : Kategorisk : Kontinuerlig, st√∏rrelsen p√• gjelden ($) : Kontinuerlig, kundens √•rlige inntekt ($) Oppgave 2.2: Det neste vi gj√∏r er √• visuelt unders√∏ke avhengigheten mellom det √• misligholde (default) og hvor stor gjeld (balance) kunden har . Vanligvis n√•r vi visuelt skal inspisere sammenhengen mellom to variabler lager vi et spredningsplott. Men n√•r den ene variabelen er kategorisk er det mer informativt √• sammenligne to boksplott av den kontinuerlige variabelen for hver av gruppene den kategoriske variabelen representer. Dette kan gj√∏res p√• f√∏lgende m√•te: boxplot(balance ~ default, data = Default, ylab = &quot;balance&quot;, xlab = &quot;default&quot;) Her er det formelen balance ~ default som gj√∏r at boxplot() funksjonen lager to boksplott av balance; et for gruppen som misligholdt (‚ÄúYes‚Äù) og et for gruppen som ikke misligholdt (‚ÄúNo‚Äù). Reflekter over figuren og gj√∏r deg opp en mening om sammenhengen mellom default og balance. Oppgave 2.3: Det er lurt √• dele inn dataene i et treningssett og et testsett n√•r vi driver med maskinl√¶ring. Treningsettet bruker vi til √• tilpasse (trene/l√¶re) modellen, mens testsettet bruker vi til √• se hvor godt forskjellige modeller presterer. Dette kan gj√∏res p√• flere m√•ter, men vi velger her √• bruke pakken dplyr som ble beskrevet i siste del av datalabb 2. F√∏rst legger vi til en unik id til hver kunde. Vi lar id-nummeret v√¶re lik radnummeret til kunden og til dette bruker vi funksjonen mutate: library(dplyr) my_data &lt;- Default %&gt;% mutate(id = row_number()) Siden vi n√• skal trekke et utvalg av dataene v√•re kan det v√¶re lurt √• sikre at resultatet er reprodusibelt ved √• sette set.seed(123) foran koden som f√∏lger. Du kan gjerne velge et annet tall enn 123, men n√•r en gj√∏r dette i forkant av en tilfeldig trekning i R er trekningen bestemt. S√• trekker vi et treningssett best√•ende av 70 % av dataene ved bruk av funksjonen sample_frac: train &lt;- my_data %&gt;% sample_frac(.70) De resterende kundene bruker vi som testsett ved bruk av funksjonen anti_join: test &lt;- my_data %&gt;% # Treningssettet er da de resterende 30 % av dataene anti_join(train, by = &#39;id&#39;) Koden over trekker ut alle kunder som ikke har lik id som i treningssettet som derfor svarer til de resterende 30 % av dataene. Oppgave 2.4: Vi forklarer i denne oppgaven hvordan en logistisk regresjonsmodell kan estimeres, tolkes og brukes. Du vil m√•tte lage nye modeller med tilsvarende koder i oppgavene som f√∏lger. Vi lager en modell hvor vi bruker variabelen balance (gjeld) som forklaringsvariabel. Vi bruker da funksjonen glm: model1 &lt;- glm(default ~ balance, data = train, family = &quot;binomial&quot;) Syntaksen til glm-funksjonen er veldig lik den vi bruker i regresjon (lm-funksjonen) bortsett fra at vi p√• spesifisere argumentet family = &quot;binomial&quot; for at √• fortelle R at vi √∏nsker √• gj√∏re en logistisk regresjon. Merk at vi bruker treningssettet til √• estimere (trene) modellen ved √• spesifisere argumentet data = train. Det kan v√¶re lurt √• se om forklaringsvariabelen balance har en signifikant effekt p√• default ved √• bruke summary funksjonen: summary(model1) For √• tolke hvilken effekt balance (gjeld) har p√• default (mislighold) er det lurt √• regne ut hva effekt en √∏kning p√• 1 $ i balance har p√• oddsen for default (Se forelesning): exp(coef(model1)) ## (Intercept) balance ## 2.205746e-05 1.005567e+00 Vi ser at oddsen for default √∏ker med en faktor 1.0056 (en 0.56 % √∏kning) dersom balance √∏ker med 1 $. Si at du √∏nsker √• predikere sannsynligheten for hvorvidt to kunder med henholdsvis 1000 $ og 2000 $ i balance vil misligholde sitt l√•n. Da kan vi bruke predict2 p√• f√∏lgende m√•te: to_personer &lt;- data.frame(balance = c(1000, 2000)) pred &lt;- predict(model1, newdata = to_personer, type = &quot;response&quot;) pred ## 1 2 ## 0.005648303 0.593966756 Det f√∏rste argumentet i funksjonen predict er hvilken modell vi skal bruke i prediksjonen (model1). Det andre argumentet newdata er hvilke kunder vi √∏nsker √• predikere misligholdsannsynligheter for. Vi setter dette argumentet til data.frame‚Äôn vi har kalt to_personer hvor hver rad svarer til en kunde med et sett forklaringsvariabler (i dette tilfellet to kunder og derfor to rader). Det er viktig at den inneholder en (eller flere) kolonne(r) med kolonnenavn som svarer til navnet til forklaringsvariabelen(e) vi har brukt i modellen. Argumentet type = &quot;response&quot; gj√∏r at vi f√•r returnert sannsynligheten for mislighold og ikke bare verdien av det line√¶re leddet i modellen. Hvis vi ut fra disse sannsynlighetene √∏nsker en klassifiseringsregel som klassifiserer om kunden vil misliholde eller ikke (‚ÄúYes/No‚Äù) er det naturlig √• tildele kunden ‚ÄúYes‚Äù hvis misligholdsannsynligheten overstiger en hvis grense og ‚ÄúNo‚Äù hvis ikke. Det kan det tenkes at kredittgiver vil v√¶re enten konservativ (sette grensen lavt, si 0.3) eller liberal (sette grensen h√∏yt, si 0.7), men i eksempelet under bruker vi en ‚Äún√∏ytral‚Äù grense p√• 0.5: ifelse(pred &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;) ## 1 2 ## &quot;No&quot; &quot;Yes&quot; Som navnet tilsier, vurderer ifelse funksjonen en logisk test i f√∏rste argumentet (pred &gt; 0.5 hvor pred er misligholdsannsynlighetene vi predikerte) og hvis testen har verdi TRUE gir den ut det du skriver i det andre argumentet (&quot;Yes&quot;), og det tredje argumentet (&quot;No&quot;) ellers. Vi ser at individet med 1000 $ i gjeld blir klassifisert som ‚ÄúNo‚Äù, mens individet med 2000 $ i gjeld blir klassifisert som ‚ÄúYes‚Äù. Oppgave 2.4: Lag en ny modell ved navn model2 hvor du bruker den kategoriske variabelen student som forklaringsvariabel. Hvilken effekt har det √• v√¶re student p√• for oddsen for mislighold? Prediker sannsynligheten for at en student og en ikke-student misligholder gjelden sin. Oppgave 2.5: Lag en tredje model ved navn model3 hvor du bruker alle forklaringsvariablene. Hvilken effekt har det √• v√¶re student p√• for oddsen for mislighold n√•? Sammenlign med forrige oppgave. Unders√∏k visuelt om det er en sammenheng mellom student og balance med √• lage et boxplot over balance for studenter og et for ikke-studenter (hint: se Oppgave 2.2). Prediker sannsynligheten for mislighold for en ikke-student og en student med lik balance og income p√• henholdsvis 1500 $ og 10000 $. Sammenlign med prediksjonen du gjorde i Oppgav 2.4. Basert p√• model2 og model3, hvordan skal kredittgiver forholde seg til en student versus en ikke-student dersom a) Ingen informasjon om balance eller income er oppgitt og b) dersom en vet balance og income? Oppgave 2.6: I denne oppgaven skal vi trene opp en knn (k-n√¶rmeste-naboer) modell til √• gj√∏re en tilsvarende klassifisering som den logistiske regresjonsmodellen gjorde over. Funksjonen train som vi trenger er inneholdt i pakken caret (som m√• installeres ved hjelp av install.packages(&quot;caret&quot;)). Vi velger √• tilpasse en modell hvor antall naboer ‚Äúk‚Äù velges automatisk med kryssvalidering vi argumentet ‚Äú`trControl‚Äù: library(caret) # R-kode dersom vi vil velge k automatisk set.seed(200) trControl &lt;- trainControl(method = &quot;cv&quot;, # 5-fold kryssvalidering number = 5) # Tilpasser modellen model4 &lt;- train(default ~ balance + income + student, data = train, method = &quot;knn&quot;, trControl = trControl, metric = &quot;Accuracy&quot;) Vi kan sjekke hvilken k som ble valgt p√• f√∏lgende m√•te (siden kryssvalidering bruker tilfeldige trekninger kan resultatet bli noe foreskjellig fra gang til gang, selv om datasettet er det samme): # Hvilken k valgte kryssvalideringen? k &lt;- model4$finalModel$k k ## [1] 5 Som for de andre modellene bruker vi funksjonen predict n√•r vi skal predikere og syntaksen er helt lik: to_kunder &lt;- data.frame(balance = c(1000, 2000), income = 10000, student = c(&quot;Yes&quot;, &quot;Yes&quot;)) predict(model4, newdata = to_kunder) ## [1] No Yes ## Levels: No Yes Merk at i motsetning til de logistiske regresjonsmodellene som predikerte sannsynligheter klassifiserer knn modellen kundene direkte som ‚ÄúYes‚Äù/‚ÄúNo‚Äù. Oppgave 2.7: Vi √∏nsker √• vurdere hvilken av model3 (logistisk regresjon) og model4 (knn) som er best. Vi kan da sjekke hvor godt de klarer √• klassifisere testsettet v√•rt hvor vi vet hvem som har misligholdt l√•nene sine. Vi starter med √• hente ut de sanne verdiene av default i treningssettet: sann &lt;- test$default # Den sanne verdien av default i testdataene Disse skal vi s√• sammenligne med hvordan modellene klassifiserer de samme kundene basert p√• de andre variablene. Vi gj√∏r f√∏rst klassifiseringen med den logistiske regresjonsmodellen: pred_logreg &lt;- predict(model3, newdata = test, type = &quot;response&quot;) # Predikert sannsynlighet klass_logreg &lt;- ifelse(pred_logreg &gt; 0.5, &quot;Yes&quot;, &quot;No&quot;) # Klassifisering av kundene En oversikt over hvor mange riktige/feil klassifiseringer modellen gj√∏r kan lett oppsummeres med en kontigenstabell. For √• lage en kontigenstabell i R bruker vi funksjonen table: logreg_tab &lt;- table(sann, klass_logreg) # Kontigenstabell logreg_tab ## klass_logreg ## sann No Yes ## No 2889 11 ## Yes 70 30 Her kan vi f.eks se at 2889 kunder blir riktig klassifisert som ‚ÄúNo‚Äù, dvs at de ikke misligholdt l√•net og modellen sp√•r at de ikke vil misligholde l√•net. Merk at diagonalen (2889 og 30) representerer korrekte klassifiseringer, mens av-diagonal (11 og 70) representer feil klassifiseringer. Det kan v√¶re en fordel √• dele kontigenstabellen over med totalt antall kunder for √• f√• andelel i stedet. Funksjonen prop.table gj√∏r nettopp dette: logreg_tab_norm &lt;- logreg_tab %&gt;% prop.table %&gt;% # normaliser round(3) # rund av til 3 desimaler logreg_tab_norm ## klass_logreg ## sann No Yes ## No 0.963 0.004 ## Yes 0.023 0.010 Summen av diagonalen p√• denne tabellen (0.963 og 0.01) gir da totalt andel korrekt klassifiseringer: logreg_tot &lt;- sum(diag(logreg_tab_norm)) # Total andel korrekt klassfisering logreg_tot ## [1] 0.973 Oppgave 2.8: Gj√∏r en tilsvarende klassifisering av kundene i testsettet med knn modellen model4 og sammenlign med resultatet over. Hvilken modell foretrekker du? Hvilke egenskaper ved klassifisering tror du kredittgiver vektlegger? Funksjonen predict er satt opp med litt forskjellige argumenter alt ettersom hvilken type modell vi bruker. Du kan lese dokumentasjonen ?predict.glm for √• se hvordan den er satt opp for glm objekter‚Ü© "]]
