[["hypotesetesting.html", " 3 Hypotesetesting", " 3 Hypotesetesting Hypotesetesting er et klassisk tema i statistikk. Vi skal først lære generelt om hva det egentlig vil si å teste en hypotese ved hjelp av statistikk, og kanskje like viktig: hva statistisk hypotesetesting ikke er. Vi går så videre til å lære noen vanlige anvendelser og ser hvordan alt dette kan implementeres i R. I videoforelesningene går vi gjennom noen slides, og vi skriver et R-skript. Du kan laste disse ned ved å klikke på lenkene under: Slides til Hypotesetesting R-script til Hypotesetesting TIPS: Hvis du ønsker å laste ned lysbildene som PDF trykker du på linken over, velger Skriv ut, og så skriver du ut som PDF. Før du gjør det bør du scrolle gjennom alle sidene slik at ligningene vises korrekt. "],["generelt-om-hypotesetesting.html", "3.1 Generelt om hypotesetesting", " 3.1 Generelt om hypotesetesting 3.1.1 Videoforelesninger 3.1.2 Kommentarer Her snakker vi om kapittel 11 i læreboken. Hvis du kan svare på følgende spørsmål har du i all hovedsak fått med deg de viktigste begrepene: Hva vil det si å gjennomføre en hypotesetest? Hva er Type I-feil og hva er Type II-feil? (Seksjon 11-1 forklarer dette greit) Hva er signifikansnivået (\\(\\alpha\\)) til en test? Styrken (the power) til en test er definert som \\(1-P(\\textrm{Type II-feil})=1-\\beta\\). Hvordan tolker du denne størrelsen? Se også 11-3d. Hva er \\(p\\)-verdien til en test (Seksjon 11-2c)? Les også 11-2d, e og f om hvordan vi fortolker og snakker om \\(p\\)-verdien på en korrekt måte. Vi kommer tilbake til dette i kapittel 3.2. "],["chap:enpop.html", "3.2 Inferens om en populasjon", " 3.2 Inferens om en populasjon 3.2.1 Videoforelesninger 3.2.2 Kommentarer Dette er i hovedsak dekket av kapittel 12 i læreboken. Sjekk om du kan svare på følgende kontrollspørsmål: Hva er det vi tester når vi gjennomfører en \\(t\\)-test for én populasjon? Hva forutsetter vi? Hva er forskjellen på en ensidig og en tosidig test? (11-2j) Det kan også være greit å repetere konfidensintervaller i seksjon 11-2k for de som har glemt det fra MET2. I Seksjon 11-2g går boken gjennom en ett-utvalgs t-test i bokens Excel-plugin. La oss gjøre det samme i R. På kursets nettside finner du alle datasettene som følger med læreboken. I dette eksempelet er det snakk om Xm11-01.xlsx. Finn tak i denne filen (du kan også godt åpne den og se på den i Excel!), legg den i en mappe som du kan finne igjen, og åpne et nytt script i R-studio der du først sørger for å sette working directory til denne mappen slik vi gjorde i R-forelesningen. Etterpå leser du inn datasettet ved å bruke read_xlsx()-funksjonen som under: library(readxl) data &lt;- read_xlsx(&quot;Xm11-01.xlsx&quot;) # Vi bruker read_xslx() fordi det er en .xlsx-fil Konteksten til datasettet er gitt i eksempel 11.1. Det er altså balansen på 400 tilfeldig utvalgte kredittkontoer i en butikk, og en lurer på om forventet balanse er større enn 170. Vi setter opp følgende test: \\[\\begin{align*} &amp;H_0: \\mu = 170 \\\\ &amp;H_A: \\mu &gt; 170, \\end{align*}\\] der vi legger merke til at det blir brukt en ensidig test (hvorfor?). For å regne ut testobservatoren for å enutvalgs \\(z\\)-test trenger vi fire tall: \\(\\overline X\\), \\(\\mu_0\\), \\(n\\) og \\(\\sigma\\). Legger merke til at data har en kolonne som heter Accounts, og vi bruker dollartegnet til å hente den ut som en vektor. Regner ut observatoren: gj.snitt &lt;- mean(data$Accounts) # Gjennomsnittet av observasjonene mu0 &lt;- 170 # Henter fra teksten n &lt;- length(data$Accounts) # Antall observasjoner sigma &lt;- 65 # Henter fra teksten Z &lt;- (gj.snitt - mu0)/(sigma/sqrt(n)) # Verdien av testobservatoren Z # Skriver ut testobservatoren ## [1] 2.460462 Vi ser at testobservatoren har samme verdi som i Excel-gjennomgangen. Kritisk verdi finner vi fra tabell (ensidig, 5%), eller rett fra R: qnorm(0.95) ## [1] 1.644854 Uansett; vi forkaster \\(H_0\\) siden testobservatoren er større enn kritisk verdi. Kapittel 11-3a-d gir enda mer forståelse for hypotesetesting. Hopp over e og f om du vil. Kapittel 11-4 snakker litt om hvordan vi skal bruke hypotesetesting videre. Kapittel 12 presenterer de tre testene (ett gjennomsnitt, en varians, en andel) i tur og orden. Det du først og fremst må kunne fra dette kapitlet er å gjennomføre disse testene, både for hånd med penn og papir, og i R. Under følger kode for å gjøre noen av bokens eksempler i R (les i boken for kontekst): Eksempel 12.1: \\[\\begin{align*} &amp;H_0: \\mu = 2.0 \\\\ &amp;H_A: \\mu &gt; 2.0, \\end{align*}\\] data &lt;- read_xlsx(&quot;Xm12-01.xlsx&quot;) # Manuell utregning gj.snitt &lt;- mean(data$Newspaper) mu0 &lt;- 2.0 n &lt;- length(data$Newspaper) s &lt;- sd(data$Newspaper) # Testobservator: (gj.snitt - mu0)/(s/sqrt(n)) ## [1] 2.236869 Signifikansnivået er satt til \\(\\alpha = 1\\%\\) i eksempelet. Kritisk verdi finner vi i \\(t\\)-tabell eller rett fra R: qt(0.99, df = n-1) ## [1] 2.351983 Altså forkaster vi ikke nullhypotesen. Sjekk gjerne verdiene vi regnet ut over og se at de stemmer overens med det som står i boken. Alternativt bruker vi t.test()-funksjonen direkte: t.test(data$Newspaper, alternative = &quot;greater&quot;, mu = 2.0, conf.level = 0.99) ## ## One Sample t-test ## ## data: data$Newspaper ## t = 2.2369, df = 147, p-value = 0.0134 ## alternative hypothesis: true mean is greater than 2 ## 99 percent confidence interval: ## 1.990716 Inf ## sample estimates: ## mean of x ## 2.180405 Resultatet blir selvsagt det samme. Når \\(p\\)-verdien er større enn signifikansnivået på 1%, kan vi ikke forkaste nullhypotesen. Eksempel 12.2 handler om å lage kondidensintervall, noe du også kan prøve å gjøre ved å regne ut de nødvendige tallene i R. De som synes dette er greit kan kikke på seksjonene 12-1b-e for å utvikle forståelsen enda litt mer. Eksempel 12.3: \\[\\begin{align*} &amp;H_0: \\sigma^2 = 1.0 \\\\ &amp;H_A: \\sigma^2 &lt; 1.0. \\end{align*}\\] Testobservator: \\[\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2}.\\] data &lt;- read_xlsx(&quot;Xm12-03.xlsx&quot;) # Regner ut testobservatoren direkte denne gangen, uten å lagre tallene underveis: (length(data$Fills) - 1)*var(data$Fills)/1 # Kritisk verdi, 5% nivå, ensidig test, nedre hale: qchisq(0.05, df = length(data$Fills) - 1) ## [1] 15.2 ## [1] 13.84843 Vi kan altså ikke forkaste nullhypotesen. Igjen, les eksempelet i sin fulle lengde i boken for å forstå bedre hva som skjer. Figur 12.4 viser på en fin måte hva tallene betyr. Eksempel 12.5 kan være grei å kikke på også. Vi kan selvsagt bruke R som kalkulator og regne ut det vi trenger. Vi skal teste: \\[\\begin{align*} &amp;H_0: p = 0.5 \\\\ &amp;H_A: p &gt; 0.5. \\end{align*}\\] Vi har en observert andel på \\(\\widehat p = 407/765 = 0.532\\) etter å ha spurt \\(n = 765\\) personer. Testobservatoren er \\[Z = \\frac{\\widehat p - p}{\\sqrt{p(1-p)/n}}.\\] p.hatt &lt;- 407/765 p0 &lt;- 0.5 n &lt;- 765 (p.hatt - p0)/sqrt(p0*(1-p0)/n) ## [1] 1.771599 Kritisk verdi for en ensidig z-test på 5% nivå er 1.645 (qnorm(0.95)), og vi kan forkaste nullhypotesen. Seksjonene 12-3d-f bør leses på egen hånd, mens vi hopper over 12-3g. "],["inferens-om-to-populasjoner.html", "3.3 Inferens om to populasjoner", " 3.3 Inferens om to populasjoner 3.3.1 Videoforelesninger 3.3.2 Kommentarer Vi har gått gjennom kapittel 13, som i all hovedsak handler om å sammenligne to gjennomsnitt (som vi kan gjøre på tre forskjellige måter), to varianser og to andeler. Her følger noen kontrollspørsmål som du kan tenke over, og bruke som utgangspunkt for diskusjon i f.eks. kollokviegrupper: Hva er nullhypotesen når vi skal gjennomføre en t-test for to populasjoner?  og hvilke antagelser må vi gjøre? Hvordan ser testobservatoren ut for en to-utvalgs t-test, og kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør? Når kan vi bruke matchede par, og hva er hensikten? Hvilken testobservator brukes for sammenligning av to varianser, og hvilken fordeling har den under nullhypotesen? Kan du gi en intuitiv forklaring for hvorfor den ser ut som den gjør? Hvilken test brukes for å teste om to andeler er like, og hva må du anta? Videre bør du sjekke at du kan utføre 3 typer \\(t\\)-tester, test for like varianser og test for like andeler både for hånd (relevant for skoleeksamen) og i R (relevant til hjemmeeksamen og datalabber). Den enkleste måten å gjøre \\(t\\)-tester i R på er å bruke funksjonen t.test(). Kikk på eksempel 13.1 i lærebokens 11. utgave, der vi har observert årlige avkastninger til to aksjefond som er kjøpt henholdsvis med og uten megler. # Leser inn datasettet funds &lt;- read_xlsx(&quot;Xm13-01.xlsx&quot;) # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = FALSE, conf.level = 0.95) ## ## Welch Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 97.489, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.79661 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Du kan så sjekke at du får ut de samme tallene på s. 434435. Videre kan du skrive inn ?t.test i R-konsollen i RStudio for å lese mer om hvilke argumenter vi kan bruke i t.test()-funksjonen. Der ser vi at argumentene paired, var.equal og conf.level som utgangspunkt allerede er satt til FALSE, FALSE og 0.95 henholdsvis, så det hadde vi strengt tatt ikke trengt å spesifisere i funksjonskallet over. Vi kan enkelt kjøre den samme testen under antakelsen om like varianser ved å sette var.equal = TRUE: # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = FALSE, var.equal = TRUE, conf.level = 0.95) ## ## Two Sample t-test ## ## data: funds$Direct and funds$Broker ## t = 2.2872, df = 98, p-value = 0.01217 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.7967156 Inf ## sample estimates: ## mean of x mean of y ## 6.6312 3.7232 Resultatet bli akkurat det samme. Siden testens \\(p\\)-verdi er mindre enn 5%, kan vi forkaste nullhypotesen og slå fast at forskjellen i gjennomsnitt er statistisk signifikant. I kapittel 13-3 leser vi om matchede par. Datasettet i eksempel 13.1 har like mange observasjoner i de to populasjonene, så vi kan tenke oss at målingene er gjort sekvensielt i tid, slik at vi kan matche dem, og heller se om gjennomsittet av differansene er signifikant forskjellig fra null. Enkelt: # Ser at det er to kolonner, «Direct» og «Broker». Alternativhypotesen på s.433 spesifiserer at # differansen i forventninger er *større* enn null, signifikansnivået skal være 5%. Antar først # ulik varians og at vi ikke skal gjøre en paret test: t.test(funds$Direct, funds$Broker, alternative = &quot;greater&quot;, paired = TRUE, conf.level = 0.95) ## ## Paired t-test ## ## data: funds$Direct and funds$Broker ## t = 2.5178, df = 49, p-value = 0.007563 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 0.9716497 Inf ## sample estimates: ## mean of the differences ## 2.908 Da ser vi at \\(p\\)-verdien ble enda mindre. I eksemplene 13.4 og 13.5 kan du prøve selv. Pass på at du kan gjøre beregningene manuelt også, der du regner ut gjennomsnitt, testobservator, kritisk verdi osv, slik at du forstår hva som foregår. Kapittel 13-2 omhandler forskjellen mellom observasjonsdata og eksperimentelle data. Det er i grunn ganske viktig å sette seg inn i den forskjellen fordi det ofte har betydning for tolkningen vår av statistiske resultater. Det er et eksplisitt krav for å lykkes i MET4 at du er i stand til å sette resultatene inn i en fornuftig kontekst. I kapittel 13-4 kan vi lese om varianstesten. Eksempel 13.7 ser slik ut i R: bottle &lt;- read_xlsx(&quot;Xm13-07.xlsx&quot;) var.test(bottle$`Machine 1`, bottle$`Machine 2`, alternative = &quot;greater&quot;) ## ## F test to compare two variances ## ## data: bottle$`Machine 1` and bottle$`Machine 2` ## F = 1.3988, num df = 24, denom df = 24, p-value = 0.2085 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 0.7051295 Inf ## sample estimates: ## ratio of variances ## 1.398807 Også her kan du sammenligne med tallene som fremgår av bokens gjennomgang, og sørg for at du får til dette på egen hånd, spesielt det å finne frem i tabellen, for det må du kunne på eksamen. Til slutt har vi test for to andeler i kapittel 13-5. De setter opp to varianter, en der vi sjekker om differansen mellom to andeler er like (\\(p_1 - p_2 = 0\\)), som er det vi har dett på i forelesning, men det går selvsagt like fint å sette opp en nullhypotese der differansen mellom andelene er lik et bestemt tall \\(D\\). Det finnes ingen ferdig prosedyre for denne testen i R, men vi kan sette den opp likevel ved å regne ut testobservatoren fra datasettet. Vi ser på eksempel 13.9, der vi får oppgitt salget av en del forskjellige varenummer, og vi ønsker å finne ut om andelen «9077» er større i Supermarked 1 enn i Supermarked 2: # Laster inn data. Her er det to utvalg med forskjellig antall observasjoner, så jeg # velger å lese inn de to kolonnene hver for seg: soap1 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;A&quot;)) soap2 &lt;- read_xlsx(&quot;Xm13-09.xlsx&quot;, range = cell_cols(&quot;B&quot;)) # Hvor stor andel utgjør «9077» i de to kolonnene? p1 &lt;- mean(soap1 == 9077) p2 &lt;- mean(soap2 == 9077) # De to utvalgsstørrelsene: n1 &lt;- nrow(soap1) n2 &lt;- nrow(soap2) # Felles estimat for p under nullhypotesen: p &lt;- (n1*p1 + n2*p2)/(n1 + n2) # Testobservatoren: z &lt;- (p1 - p2)/sqrt(p * (1-p)*(1/n1 + 1/n2)) # Kritisk verdi på 5% nivå for en ensidig test: qnorm(0.95) ## [1] 1.644854 Siden \\(z = 2.9\\) forkaster vi nullhypotesen om at det er lik andel «9077» i de to populasjonene. "],["kjikvadrattester.html", "3.4 Kjikvadrattester", " 3.4 Kjikvadrattester 3.4.1 Videoforelesninger 3.4.2 Kommentarer Vi må kunne to anvendelser av kjikvadrattester, der hver av de har sitt eget delkapittel i boken: Teste for om en gitt fordeling passer med obervasjoner (Goodness-of-fit). Teste for uavhengighet. I den første anvendelsen får vi oppgitt en diskret sannsynlighetsfordeling der vi har noen mulige utfall \\(u_1, \\ldots, u_k\\), med tilhørende sannsynligheter \\(p_1, \\ldots,p_k\\). Dersom vi skal observere \\(n\\) utfall fra denne fordelingen, vil vi forvente \\(e_i = p_i\\cdot n\\) observasjoner av utfall \\(u_i\\). Nå har det seg slik at vi har observert \\(n\\) utfall fra fordelingen, og utfall \\(u_i\\) har skjedd \\(f_i\\) ganger. Vi lurer da på om de observerte frekvensene (\\(f_i\\)) er så forskjellige fra de forventede frekvensene (\\(e_i\\)) at vi ikke lenger tror at \\(p_1, \\ldots,p_k\\) er den sanne sannsynlighetsfordelingen. Vi kom frem til en fornuftig testobservator: \\[\\chi^2 = \\sum_{i=1}^k \\frac{(f_i - e_i)^2}{e_i},\\] som er \\(\\chi^2\\)-fordelt med \\(k-1\\) frihetsgrader dersom nullhypotesen er sann. Det betyr at vi kan gå inn i \\(\\chi^2\\)-tabellen for å sjekke om verdien av testobservatoren er for stor (dvs, \\(f\\)´ene er for forskjellige fra \\(e\\)`ene) at vi ikke lenger tror at \\((p_1, \\ldots, p_k)\\) er den sanne sannsynlighetsfordelingen. Vi gjorde eksempelet i dette delkapitlet i forelesningen, og brukte følgende kommandoer: p0 &lt;- c(0.45, 0.40, 0.15) # Fordeling under H0 f &lt;- c(102, 82, 16) # Observerte frekvenser chisq.test(x = f, p = p0) ## ## Chi-squared test for given probabilities ## ## data: f ## X-squared = 8.1833, df = 2, p-value = 0.01671 Den andre anvendelsen er å teste for om to kjennetegn opptrer uavhengig av hverandre. Ideen er den samme som over, fordi vi kan skrive sannsunligheten for «\\(A\\) og \\(B\\)» som et produkt dersom de ar uavhengige: \\[P(A \\cap B) = P(A)\\cdot P(B).\\] Vi kan regne ut hvor mange observasjoner vi forventer å se for hver kombinasjon av de to kjennetegnene (\\(e_{ij}\\)), og bruke kjikvadrattesten over til å sjekke om disse er langt fra det vi faktisk har observert (\\(f_{ij}\\)). Boken har et eksempel på dette som de regner ut både for hånd og i Excel. Slik kan vi gjøre det i R: # Leser inn data mba &lt;- read_xlsx(&quot;Xm15-02.xlsx&quot;) # Kikker på datasettet mba ## # A tibble: 152 x 2 ## Degree `MBA Major` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 2 2 ## 6 1 3 ## 7 3 1 ## 8 1 1 ## 9 2 1 ## 10 2 2 ## # ... with 142 more rows Vi legger merke til at strukturen på datasettet er litt annerledes enn krysstabellen som er vist s. 601 i læreboken. I stedet for at vi har telt opp antall studenter i hver enkelt kominasjon av «bachelorgrad» og «masterprofil», har vi fått oppgitt en tabell der hver rad representerer en enkeltstudents fagkombinasjon. Vi kan dog enkelt lage en krysstabell i R: table(mba) ## MBA Major ## Degree 1 2 3 ## 1 31 13 16 ## 2 8 16 7 ## 3 12 10 17 ## 4 10 5 7 Det er denne som brukes som argument i chisq.test(): chisq.test(table(mba)) ## ## Pearson&#39;s Chi-squared test ## ## data: table(mba) ## X-squared = 14.702, df = 6, p-value = 0.02271 Her er det bare å sammenligne tallene med det som læreboken finner i Excel. Noen kontrollspørsmål: Vi har lært to veldig spesifikke anvendelser av kjikvadrattester. Hvilke? Kan du gi en intuitiv forklaring på hvorfor testobservatoren vår er fornuftig? Litt mer vanskelig: Kan du gi en intuitiv forklaring for hvorfor testobservatoren er tilnærmet kjikvadratfordelt? "],["oppgaver-1.html", "3.5 Oppgaver", " 3.5 Oppgaver 3.5.1 Standard oppgaver Introduksjon til hypotesetesting For hvert av scenarioene i a og b, gjør følgende: Sett opp relevant nullhypotese og alternativhypotese (hint: nullhypotese avhenger av hvor bevisbyrden bør ligge) Definer type I-og type II-feil. Diskuter konsekvensene av type I-feil og type II-feil i det aktuelle scenarioet. En ny type medisin skal vurderes for kommersialisering. Du sitter i et vurderingspanel som skal vurdere om medisinen kan bli godkjent eller ikke. Du blir presentert to ulike investeringer å velge mellom. En av dem er veldig risikabel, men med stor potensiell profitt. Den andre er mindre risikabel, men med lavere potensiell profitt. Løsning \\(H_0\\): Den nye medisinen er ikke trygg og effektiv. \\(H_1\\): Den nye medisinen er trygg og effektiv. Type I-feil: Forkaste \\(H_0\\) når \\(H_0\\) er sann. Konsekvens: Risikerer at vi begynner å produsere en medisin som ikke er trygg og effektiv. Type II-feil: Forkaster ikke \\(H_0\\) når \\(H_1\\) er sann. Konsekvens: Vi lar være å produsere en medisin som faktisk er trygg og effektiv. Kommentar: Signifikansnivået ved produksjon av medisiner settes ofte lavt fordi konsekvensene av en type I-feil kan være svært alvorlige. \\(H_0\\): Den mest risikable investeringen er mest lønnsom. \\(H_1\\): Den mest risikable investeringen er ikke mest lønnsom. Type I-feil: Forkaste \\(H_0\\) når \\(H_0\\) er sann. Konsekvens:Vi investerer i den minst risikable investeringen, som ikke er mest lønnsom. Type II-feil: Forkaster ikke \\(H_0\\) når \\(H_1\\) er sann. Konsekvens: Vi investerer i den mest risikable investeringen, som ikke er mest lønnsom. Vi har følgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 150\\) mot \\(H_1: \\mu \\neq 150\\). \\(\\sigma = 10\\), \\(n =100\\), \\(\\overline{x} = 150\\). Bestem verdi av testobservator, forkastelsesområde dersom signifikansnivået er \\(\\alpha = 0.05\\), og p-verdi. Konkluder. Løsning Her er \\(\\sigma\\) kjent så vi kan bruke en z-observator. Forkastelsesområde \\(Z &lt; -z_{0.025}=-1.96\\) eller \\(Z&gt; z_{0.025}=1.96\\). \\[Z = \\frac{\\overline{x} - \\mu}{\\sigma/\\sqrt{n}} = \\frac{150 - 150}{10/\\sqrt{100}}=0\\] p-verdi\\(=2P(Z &gt; 0) = 2\\times0.5=1\\). Vi kan ikke forkaste nullhypotesen \\(H_0: \\mu = 0\\). Faktisk er det ekstremt sannsynlig (p-verdi = 1) å observere det vi har observert dersom nullhypotesen er sann. Vi har følgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 55\\) mot \\(H_1: \\mu &gt; 55\\). \\(\\sigma = 20\\), \\(n = 25\\), \\(\\overline{x} = 67\\). Regn ut testobservatoren \\(Z\\). Regn ut p-verdi. Regn ut p-verdi, denne gangen med \\(\\overline{x}\\) = 63. Regn ut p-verdi, denne gangen med \\(\\overline{x}\\) = 59. Fastslå hva som skjer med verdien av testobservatoren (Z) og p-verdien når \\(\\overline{x}\\) nærmer seg \\(55\\) (verdien av \\(\\mu\\) under \\(H_0\\)). Løsning \\[Z = \\frac{\\overline{x} - \\mu}{\\sigma/\\sqrt{n}} = \\frac{67 - 55}{20/\\sqrt{25}}=3\\] \\(\\text{p-verdi} = P(Z &gt; 3.00) = 1  P(Z&lt;3) = 1  0.9987 = 0.0013\\). Kommentar: Her kan du bruke pnorm(3) i R til å regne ut \\(P(Z&lt;3)\\). Ny verdi av testobservator blir da \\(Z = 2\\). \\(\\text{p-verdi} = P(Z &gt; 2.00) = 1  0.9772 = 0.0228\\). Ny verdi av testobservator blir da \\(Z = 1\\). \\(\\text{p-verdi} = P(Z &gt; 1.00) = 1  0.8413 = 0.1587\\). Vi ser at testobservatoren minker og p-verdien øker når \\(\\overline{x}\\) nærmer seg \\(55\\). Forklaring: La \\(\\mu_0 = 55\\) være verdien av \\(\\mu\\) under \\(H_0\\). Z-observatoren måler avviket mellom antagelsen under \\(H_0\\) og dataene vi observerer og avtar derfor når vår observasjon av \\(\\overline{x}\\) nærmer seg \\(\\mu_0\\). P-verdien sier hvor sannsynlig det er å observere de dataene vi har dersom \\(H_0\\) er sann og øker følgelig når \\(\\overline{x}\\) nærmer seg \\(\\mu_0\\). Annta at vi har følgende hypoteser og informasjon om dataene: \\(H_0: \\mu = 50\\) mot \\(H_1: \\mu &gt; 50\\). \\(\\sigma = 10\\), \\(n = 40\\), \\(\\alpha = 0.05\\). Bestem \\(\\beta\\), altså sannsynligheten for en type-II feil, under antagelsen at \\(\\mu = 55\\). Løsning Forkastningsområdet blir da \\[Z = \\frac{\\overline{X} - 50}{10/\\sqrt{40}} &gt; Z_{0.05} = 1.645 \\] dvs at vi forkaster \\(H_0\\) når \\[\\overline{X} &gt; 50 + 1.645\\times\\frac{10}{\\sqrt{40}}=52.6\\] En type-II feil svarer til å ikke forkaste \\(H_0\\) når \\(H_1\\) er sann. For å regne på sannsynligheten for type-II feil må vi ikke bare anta at \\(H_1\\) er sann, men være spesifike på hva verdien til \\(\\mu\\) er (i dette tilfellet 55). Vi lurer altså på hva sannsynligheten for at vi ikke er i forkastnings området (\\(\\overline{X} &lt; 52.6\\)) gitt at \\(\\mu = 55\\): \\[\\begin{equation*} \\begin{split} \\beta &amp;= P(\\overline{X} &lt; 52.6\\quad\\text{gitt at $\\mu = 55$})\\\\ &amp;= P(\\frac{\\overline{X} - 55}{10/\\sqrt{40}} &lt; \\frac{52.6 - 55}{10/\\sqrt{40}})\\\\ &amp;=P(Z &lt; -1.52) = 0.064 \\end{split} \\end{equation*}\\] Merk: Et begrep som ofte blir brukt om tester er styrken til testen \\(1-\\beta\\) som da er sannsynligheten for å forkaste \\(H_0\\) når \\(H_1\\) er sann. En god test har god (stor) styrke. Hadde vi gjentatt denne testen mange ganger ville vi ha forkastet \\(H_0\\) i \\((100 - 6.4)\\% = 93.6\\%\\) av gangene dersom det faktisk er slik at sann \\(\\mu\\) er 55. En leder frykter at den gjennomsnittlige tiden ansatte daglig bruker på sosiale medier overstiger 45 minutter. For å teste denne mistanken, plukker han ut et tilfeldig utvalg på 15 personer, og spør om tid brukt på sosiale medier etter en tilfeldig arbeidsdag. Resultatene er oppsummert nedenfor. 70, 96, 58, 88, 34, 42, 34, 56, 68, 46, 26, 18, 22, 60, 84 Hvis samlingen av tider er normalfordelt med standardavvik på 20 minutter, kan lederen hevde at mistanken hans stemmer på et 1 % signifikans-nivå? Tror du observasjonene over er et representativt utvalg? Hva kunne lederen gjort annerledes? Løsning Lederen ønsker altså å teste \\(H_0: \\mu = 45\\) mot alternativ hypotesen \\(H_1: \\mu &gt; 45\\). Testobservatoren er da gitt ved \\[Z = \\frac{\\overline{X} - \\mu_0}{\\sigma/\\sqrt{n}} = \\frac{53.46 - 45}{20/\\sqrt{15}} = 1.64\\] Sannsynligheten for å observerer noe minst like ekstremt og til fordel for \\(H_1\\) (p-verdien) er da \\[P-verdi = P(Z &gt; 1.645) \\approx 0.05 &gt; 0.01\\]. Lederen kan altså ikke trekke denne konklusjonen på 1 % signifikansnivå. For å forkaste null hypotesen på et 1 % signifikansnivå, måtte vi hatt p-verdi lavere enn 1 %. Dersom lederen spør ansatte fjes til fjes er det nærliggende å tro at de ansatte vil underdrive sin bruk av sosiale medier. En anonym spørreundersøkelse ville nok gitt et mer representativt utvalg. Gjennomsnitt og standardavvik i et utvalg på \\(n=100\\) er \\(\\overline{x} = 20\\) og \\(s = 2\\). Finn 95 % konfidensintervall av gjennomsnitt (\\(\\mu\\)) i populasjonen. Gjenta a. med \\(s = 5\\). Gjenta a. med \\(s = 10\\). Fastslå hvordan det estimerte konfidensintervallet endrer seg når vi øker \\(s\\). Anta at \\(s=5\\) og regn et 95 % konfidensintervall dersom størrelsen på utvalget er henholdsvis \\(n = 50\\) og \\(n=10\\). Fastlå hvordan det estimerte konfidensintervallet endrer seg når vi øker \\(n\\). Løsning \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 1.984\\times 2/\\sqrt{100} = [19.60 ,20.40]\\] \\[ 20 \\pm 1.984\\times 5/\\sqrt{100} = [19.01 ,20.99]\\] \\[ 20 \\pm 1.984\\times 10/\\sqrt{100} = [18.02 ,21.98]\\] Konfidensintervallet blir større når \\(s\\) øker. \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 2.09\\times 5/\\sqrt{50} = [18.58 ,21.42]\\] \\[\\overline{x} \\pm t_{\\alpha/2, n - 1}s/\\sqrt{n} = 20 \\pm 2.26\\times 5/\\sqrt{10} = [16.42 ,23.58]\\] Vi ser at jo større \\(n\\) er jo mindre blir konfidensintervallet. Flere observasjoner gjør at vi med større sikkerhet (smalere intervall) kan si hvor \\(\\mu\\) ligger. Med sterkt fall i flyreiser og passasjerer på grunn av koronakrisen virker det sannsynlig at det blir færre forsinkelser i flytrafikken. Før krisen hevdet et flyselskap at de landet presist 92 % av flyreisene. I et tilfeldig utvalg flyreiser hos det samme selskapet under krisen ble 143 av 165 vurdert til å være presise. Kan vi konkludere på 5 % signifikansnivå at det er færre forsinkelser under koronakrisen? Løsning La \\(p\\) være den sanne andelen av flyreiser som blir forsinket under krisen. Vi skal da teste \\(H_0: p = 0.92\\) mot \\(H_1: p &lt; 0.92\\). Vårt estimat på \\(p\\) er \\(\\hat{p}=148/165 \\approx 0.90\\) og testobservatoren er gitt ved \\[z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1 - p_0)/n}} = \\frac{0.90 - 0.92}{\\sqrt{0.92(1 - 0.92)/165}} \\approx -0.80\\] Dersom vi bruker kritisk verdi ville forkastningsområdet vært \\(z &lt; -1.645\\) og siden \\(z&gt; -1.645\\) kan vi altså ikke forkaste \\(H_0\\). Alternativt kan vi regne ut p-verdien som er \"sannsynligheten for det vi har observert eller noe enda mer til fordel for \\(H_1\\). En enda mer negativ verdi enn -0.80 ville vært til fordel for \\(H_1\\), derfor er \\[p-verdi = P(Z &lt; - 0.8) = 0.21\\] og vi derfor ikke forkaste \\(H_0\\) siden p-verdien ikke er mindre enn 0.05. Vi har følgende informasjon fra to tilfeldige utvalg fra to ulike normalfordelte populasjoner: \\(\\overline{x}_1 = 400\\), \\(s_1 = 100\\), \\(n_1 = 130\\), \\(\\overline{x}_2 = 390\\), \\(s_2 = 50\\), \\(n_2 = 130\\). Kan vi hevde på et 5 % signifikansnivå at \\(\\mu_1\\) er større enn \\(\\mu_2\\)? Det oppgis at \\[\\nu = \\frac{\\left(\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}\\right)^2}{\\left(\\frac{s^2_{1}}{n_1}\\right)^2/(n_1 - 1) + \\left(\\frac{s^2_{2}}{n_2}\\right)^2/(n_2 - 1)}\\approx 166\\] Gjenta a., denne gangen med \\(s_1 = 30\\) og \\(s_2 = 15\\). Som over, oppgis det at \\(\\nu \\approx 190\\). Fastslå hva som skjer hvis utvalgenes standardavvik blir mindre. Gjenta a., denne gangen med utvalg på \\(n_1 = n_2 = 20\\) observasjoner. Som over, oppgis det at \\(\\nu \\approx 28\\). Fastslå effekten av å redusere utvalgsstørrelser. Løsning Vi skal altså teste \\(H_0: \\mu_1 - \\mu_2 = 0\\) mot \\(H_1: \\mu_1 - \\mu_2 &gt; 0\\). Siden variansene i utvalget er såpass ulike antar vi at vi må bruke varianten av testen med ulik varians. Testobservatoren er da gitt ved \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{130^2}{130} + \\frac{50^2}{130}}} = 0.82\\] Antall frihetsgrader oppgis til å være \\(v \\approx 166\\). Vi forkaster \\(H_0\\) dersom \\(T &gt; t_{0.05, 166} = 1.654\\), og siden dette ikke er tilfelle her kan vi ikke forkaste \\(H_0\\) ved 5 % signifikansnivå. Testobservatoren blir i dette tilfellet \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{30^2}{130} + \\frac{15^2}{130}}} = 3.40\\] Antall frihetsgrader oppgis til å være \\(v \\approx 190\\). Siden \\(T = 3.40 &gt; t_{0.05, 190} = 1.653\\) forkaster vi \\(H_0\\) på 5 % signifikansnivå. Når standardavvikene i utvalgene blir mindre øker verdien av testobservatoren. Mindre standardavvik betyr at vi er mer sikre på at \\(\\overline{x}_1 - \\overline{x}_2\\) ligger nær \\(\\mu_1 - \\mu_2\\), og at en evt. differanse kan tyde på avvik fra \\(H_0\\). Dette blir reflektert av en større testobservator. Testobservatoren blir da \\[T = \\frac{\\overline{x}_1 - \\overline{x}_2 - 0}{\\sqrt{\\frac{s^2_{1}}{n_1} + \\frac{s^2_{2}}{n_2}}}=\\frac{400 - 390}{\\sqrt{\\frac{130^2}{20} + \\frac{50^2}{20}}} = 0.40\\] Antall frihetsgrader oppgis til å være \\(v \\approx 28\\). Vi forkaster \\(H_0\\) dersom \\(T &gt; t_{0.05, 28} = 1.701\\), og siden dette ikke er tilfelle her kan vi ikke forkaste \\(H_0\\) ved 5 % signifikansnivå. Få observasjoner representerer større usikkerhet om differansen \\(\\overline{x}_1 - \\overline{x}_2\\) bare skyldes tilfeldighet, og dette reflekteres av testobservatoren som vil synke når utvalgsstørrelsen reduseres. Et nystartet firma har utviklet to løsninger for automatisk registrering av av antall lus på oppdrettslaks. Metode A er litt dyrere enn metode B, men firmaet mener Metode A en den raskeste metoden. For å teste ut denne hypotesen blir begge metodene brukt til å registrere lus på 11 basseng av ulik størrelse og med forskjellig antall fisk. Antall minutter hver metode tar blir registrert for hvert basseng. Under er det gitt en R-utskrift fra en to-utvalgs t-test. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå. ## ## Welch Two Sample t-test ## ## data: metodeB and metodeA ## t = 1.6129, df = 18.969, p-value = 0.06164 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## -0.7959228 Inf ## sample estimates: ## mean of x mean of y ## 83.44886 72.41662 Under er det gitt en R-utskrift fra en paret t-test for de samme dataene. Still opp nullhypotesen og den alternative hypotesen i samsvar med R-utskriften. Formuler testobservatoren og bruk også utskriften til å formulere en konklusjon for en test med 5% signifikansnivå. ## ## Paired t-test ## ## data: metodeB and metodeA ## t = 5.4477, df = 10, p-value = 0.0001409 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## 7.361811 Inf ## sample estimates: ## mean of the differences ## 11.03225 Hvilke av de to foregående testene bør en bruke i dette tilfellet? Løsning La \\(\\mu_1\\) og \\(\\mu_2\\) være forventet tid til registrering av lus i et basseng for hhv metode B og metode A. Da er R-utskriften en test av \\(H_0: \\mu_1 - \\mu_2 = 0\\) mot det enside alternativet \\(H_1: \\mu_1-\\mu_2 &gt; 0\\). Fra utskriften ser vi at \\(p-value= 0.06164 &gt; 0.05\\), altså kan vi ikke forkaste \\(H_0\\) ved \\(5\\%\\) signifikansnivå. Praktisk tolkning: Vi kan ikke konkludere med at det er noe forskjell i tiden de to metodene bruker. b.I en paret t-test baserer vil testen på de parvise differansene \\(d_i = x_i - y_i\\), der \\(x_i\\) og \\(y_i\\) er tiden hhv metode B og A bruker på å registrere lus i basseng nr. i. Utskriften viser en test av \\(H_0: \\mu_d = 0\\) mot det ensidige alternativet \\(H_1: \\mu_d &gt; 0\\). Testobservatoren er da gitt ved \\[T=\\frac{\\overline{d}-0}{s_d/\\sqrt{n}}\\] Fra utskriften ser vi at \\(p-value= 0.0001409 &lt; 0.05\\), altså kan vi forkaste \\(H_0\\) ved \\(5\\%\\) signifikansnivå. Praktisk tolkning: Det ser ut til at metode A er raskere enn metode B. En paret t-test er generelt det riktige valget dersom observasjonene som blir paret er avhengige. I dette tilfellet er det naturlig å tro at tiden metode A og B bruker på et basseng er avhengige størrelser (f.eks vil et basseng med mye fisk ta lang tid å registrere for begge metodene). I en to-utvalgs t-test antar vi derimot at tiden det tar for metode A og B å registrere lus for et basseng er uavhengige. 3.5.2 Nøtter Flere oppgaver kommer! "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
